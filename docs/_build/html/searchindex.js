Search.setIndex({"alltitles": {"00:00.000 total execution time for 0 files from _sourceauto_galleriesval:": [[95, "total-execution-time-for-0-files-from-sourceauto-galleriesval"]], "00:01.825 total execution time for 3 files from _sourceauto_galleriesdev2_calibration:": [[42, "total-execution-time-for-3-files-from-sourceauto-galleriesdev2-calibration"]], "00:03.829 total execution time for 7 files from _sourceauto_galleriesdev1_extmodels:": [[37, "total-execution-time-for-7-files-from-sourceauto-galleriesdev1-extmodels"]], "00:04.045 total execution time for 2 files from _sourceauto_galleriesval4_resilience:": [[82, "total-execution-time-for-2-files-from-sourceauto-galleriesval4-resilience"]], "00:04.524 total execution time for 1 file from _sourceauto_galleriesval6_fairness:": [[89, "total-execution-time-for-1-file-from-sourceauto-galleriesval6-fairness"]], "00:07.731 total execution time for 3 files from _sourceauto_galleriesutil:": [[60, "total-execution-time-for-3-files-from-sourceauto-galleriesutil"]], "00:09.445 total execution time for 2 files from _sourceauto_galleriesval7_explainability:": [[93, "total-execution-time-for-2-files-from-sourceauto-galleriesval7-explainability"]], "00:10.557 total execution time for 4 files from _sourceauto_galleriesval1_performance:": [[70, "total-execution-time-for-4-files-from-sourceauto-galleriesval1-performance"]], "00:11.851 total execution time for 2 files from _sourceauto_galleriesget_started:": [[55, "total-execution-time-for-2-files-from-sourceauto-galleriesget-started"]], "00:12.561 total execution time for 2 files from _sourceauto_galleriesval5_robustness:": [[86, "total-execution-time-for-2-files-from-sourceauto-galleriesval5-robustness"]], "00:14.139 total execution time for 2 files from _sourceauto_galleriesval2_overfitting:": [[74, "total-execution-time-for-2-files-from-sourceauto-galleriesval2-overfitting"]], "00:14.951 total execution time for 2 files from _sourceauto_galleriesval3_reliability:": [[78, "total-execution-time-for-2-files-from-sourceauto-galleriesval3-reliability"]], "00:41.758 total execution time for 10 files from _sourceauto_galleriesdata:": [[12, "total-execution-time-for-10-files-from-sourceauto-galleriesdata"]], "00:44.405 total execution time for 4 files from _sourceauto_galleriesdev3_hpo:": [[48, "total-execution-time-for-4-files-from-sourceauto-galleriesdev3-hpo"]], "00:56.414 total execution time for 1 file from _sourceauto_galleriesdev:": [[51, "total-execution-time-for-1-file-from-sourceauto-galleriesdev"]], "01:32.276 total execution time for 2 files from _sourceauto_galleriesval0_residual:": [[64, "total-execution-time-for-2-files-from-sourceauto-galleriesval0-residual"]], "04:52.046 total execution time for 14 files from _sourceauto_galleriesdev0_models:": [[28, "total-execution-time-for-14-files-from-sourceauto-galleriesdev0-models"]], "1. Aggregation Stage": [[368, "aggregation-stage"]], "1. Data Sparsity:": [[378, "data-sparsity"]], "1. Gradient Sensitivity:": [[378, "gradient-sensitivity"]], "1. Prepare data and model": [[326, "prepare-data-and-model"], [327, "prepare-data-and-model"], [328, "prepare-data-and-model"]], "1. Prepare external data and model": [[388, "prepare-external-data-and-model"]], "1. Uniform Binning": [[383, "uniform-binning"]], "1. Univariate Partitioning:": [[378, "univariate-partitioning"]], "1D ALE": [[91, "d-ale"]], "1D Partial dependency plots": [[91, "d-partial-dependency-plots"]], "2. Calibration": [[326, "calibration"], [327, "calibration"], [328, "calibration"]], "2. Complexity Measure:": [[378, "complexity-measure"]], "2. Local Curvature:": [[378, "local-curvature"]], "2. Multivariate Region Detection:": [[378, "multivariate-region-detection"]], "2. Purification Stage": [[368, "purification-stage"]], "2. Quantile Binning": [[383, "quantile-binning"]], "2. Wrapping data into Modeva": [[388, "wrapping-data-into-modeva"]], "2D ALE": [[91, "id2"]], "2D Partial dependency plots": [[91, "id1"]], "2D feature interaction analysis": [[72, "d-feature-interaction-analysis"], [73, "d-feature-interaction-analysis"]], "3. Automatic Binning Using a Depth-1 or 2 XGBoost Tree": [[383, "automatic-binning-using-a-depth-1-or-2-xgboost-tree"]], "3. Generalization Gap Connection:": [[378, "generalization-gap-connection"]], "3. Get calibrate predict proba": [[328, "get-calibrate-predict-proba"]], "3. Get calibrated prediction intervals": [[326, "get-calibrated-prediction-intervals"], [327, "get-calibrated-prediction-intervals"]], "3. Uncertainty Assessment:": [[378, "uncertainty-assessment"]], "3. Wrapping Sklearn model into Modeva": [[388, "wrapping-sklearn-model-into-modeva"]], "3D Scatter Plot": [[338, "d-scatter-plot"]], "4. Create TestSuite for model validation": [[388, "create-testsuite-for-model-validation"]], "ALE (Accumulated Local Effects)": [[343, "ale-accumulated-local-effects"], [345, null]], "API Reference": [[0, null]], "AUC Score": [[330, "auc-score"]], "Accuracy Comparison": [[330, "accuracy-comparison"], [332, "accuracy-comparison"]], "Accuracy Score": [[330, "accuracy-score"]], "Add advanced ML models": [[50, "add-advanced-ml-models"]], "Add traditional ML models": [[50, "add-traditional-ml-models"]], "Add wrapped scikit-learn model": [[50, "add-wrapped-scikit-learn-model"]], "Additional Utilities for Slicing": [[383, "additional-utilities-for-slicing"]], "Advanced Slicing": [[383, "advanced-slicing"]], "Advanced slicing analysis": [[68, "advanced-slicing-analysis"], [69, "advanced-slicing-analysis"]], "Advantages": [[369, "advantages"]], "Adverse Impact Ratio (AIR) for Disparate Impact": [[377, "adverse-impact-ratio-air-for-disparate-impact"]], "Algorithm Details": [[345, "algorithm-details"], [346, "algorithm-details"], [347, "algorithm-details"], [348, "algorithm-details"], [349, "algorithm-details"], [350, "algorithm-details"], [351, "algorithm-details"]], "Algorithms for specific models": [[351, "algorithms-for-specific-models"]], "Analysis and Comparison": [[336, "analysis-and-comparison"]], "Analyzes residuals feature importance": [[62, "analyzes-residuals-feature-importance"], [63, "analyzes-residuals-feature-importance"]], "Applications of Residual Analysis": [[379, "applications-of-residual-analysis"]], "Apply subsampling by setting active samples": [[6, "apply-subsampling-by-setting-active-samples"]], "Arbitrary Model Wrapper": [[388, "arbitrary-model-wrapper"]], "Attributes": [[57, "attributes"]], "Bandwidth Comparison": [[330, "bandwidth-comparison"], [332, "bandwidth-comparison"]], "Baseline-(Kernel) SHAP (a group of baseline samples)": [[92, "baseline-kernel-shap-a-group-of-baseline-samples"]], "Baseline-(Kernel) SHAP (a single baseline sample)": [[92, "baseline-kernel-shap-a-single-baseline-sample"]], "Basic Data Operations": [[334, null]], "Basic Dataset Operations": [[2, null]], "Basic Decomposition": [[367, "basic-decomposition"]], "Basic accuracy analysis": [[15, "basic-accuracy-analysis"], [16, "basic-accuracy-analysis"], [17, "basic-accuracy-analysis"], [18, "basic-accuracy-analysis"], [19, "basic-accuracy-analysis"], [20, "basic-accuracy-analysis"], [21, "basic-accuracy-analysis"], [22, "basic-accuracy-analysis"], [23, "basic-accuracy-analysis"], [26, "basic-accuracy-analysis"], [27, "basic-accuracy-analysis"], [66, "basic-accuracy-analysis"], [67, "basic-accuracy-analysis"]], "Basic data operations": [[2, "basic-data-operations"]], "Basic fairness analysis": [[88, "basic-fairness-analysis"]], "Basic reliability analysis": [[76, "basic-reliability-analysis"], [77, "basic-reliability-analysis"]], "Basic resilience analysis": [[80, "basic-resilience-analysis"], [81, "basic-resilience-analysis"]], "Basic robustness analysis": [[84, "basic-robustness-analysis"], [85, "basic-robustness-analysis"]], "Basic slice accuracy analysis": [[68, "basic-slice-accuracy-analysis"], [69, "basic-slice-accuracy-analysis"]], "Batch mode 1D slicing analysis": [[72, "batch-mode-1d-slicing-analysis"], [73, "batch-mode-1d-slicing-analysis"]], "Benefits": [[368, "benefits"]], "Bivariate (2D) Plots": [[338, "bivariate-2d-plots"]], "Boosted GLMTree model": [[24, "boosted-glmtree-model"], [25, "boosted-glmtree-model"]], "Build a model": [[39, "build-a-model"], [40, "build-a-model"], [41, "build-a-model"]], "Build a model and save the prediction": [[35, "build-a-model-and-save-the-prediction"], [36, "build-a-model-and-save-the-prediction"]], "Build a sklearn style model": [[32, "build-a-sklearn-style-model"]], "Built-in Dataset": [[334, "built-in-dataset"]], "Built-in Interpretable Models": [[13, null], [49, "built-in-interpretable-models"]], "CBLOF": [[340, "cblof"]], "Calibrate the model": [[39, "calibrate-the-model"], [40, "calibrate-the-model"], [41, "calibrate-the-model"]], "Calibrating Binary Classifier": [[39, null]], "Calibrating Binary Classifier Prediction Interval": [[40, null]], "Calibrating Regressor Prediction Interval": [[41, null]], "Categorical Features": [[337, "categorical-features"]], "Categorical Variable Encoding": [[334, "categorical-variable-encoding"]], "Categorical Variables": [[334, "categorical-variables"], [367, "categorical-variables"]], "Challenges in Measuring Model Performance": [[379, "challenges-in-measuring-model-performance"]], "Change Feature Types": [[337, "change-feature-types"]], "Change Log": [[96, null]], "Characterization of Weak Regions": [[378, "characterization-of-weak-regions"]], "Check proba before and after calibration": [[39, "check-proba-before-and-after-calibration"]], "Classification": [[317, "classification"]], "Classification Metrics": [[379, "classification-metrics"]], "Cluster performance analysis": [[22, "cluster-performance-analysis"], [23, "cluster-performance-analysis"]], "Cluster-Based Local Outlier Factor (CBLOF)": [[336, "cluster-based-local-outlier-factor-cblof"]], "Coefficient interpretation": [[14, "coefficient-interpretation"], [15, "coefficient-interpretation"]], "Combined Application of Threshold Adjustment and Feature Binning": [[377, "combined-application-of-threshold-adjustment-and-feature-binning"]], "Compare residuals cluster of multiple models": [[62, "compare-residuals-cluster-of-multiple-models"], [63, "compare-residuals-cluster-of-multiple-models"]], "Compare the XGBoost model with LGBM model": [[39, "compare-the-xgboost-model-with-lgbm-model"], [66, "compare-the-xgboost-model-with-lgbm-model"], [67, "compare-the-xgboost-model-with-lgbm-model"]], "Compare two scored models": [[35, "compare-two-scored-models"], [36, "compare-two-scored-models"]], "Comparison for Classification": [[330, null]], "Comparison for Regression": [[332, null]], "Comparison of Different Methods": [[336, "comparison-of-different-methods"]], "Computation times": [[12, null], [28, null], [37, null], [42, null], [48, null], [51, null], [55, null], [60, null], [64, null], [70, null], [74, null], [78, null], [82, null], [86, null], [89, null], [93, null], [95, null], [391, null]], "Conceptual Soundness": [[352, "conceptual-soundness"]], "Conditional Independence": [[339, "conditional-independence"]], "Conduct slicing analysis for overfit regions": [[72, "conduct-slicing-analysis-for-overfit-regions"], [73, "conduct-slicing-analysis-for-overfit-regions"]], "Configure MLflow settings": [[50, "configure-mlflow-settings"]], "Conformal Prediction": [[380, "conformal-prediction"]], "Continuous Formulation:": [[381, "continuous-formulation"], [381, "id1"], [381, "id2"]], "Convert the model into Modeva": [[35, "convert-the-model-into-modeva"], [36, "convert-the-model-into-modeva"]], "Correlation": [[3, "correlation"]], "Correlation Coefficient": [[339, "correlation-coefficient"]], "Correlation Heatmap": [[338, "correlation-heatmap"]], "Correlation based feature selection": [[4, "correlation-based-feature-selection"]], "Coverage Comparison": [[332, "coverage-comparison"]], "Create test suite for diagnostics": [[30, "create-test-suite-for-diagnostics"], [31, "create-test-suite-for-diagnostics"], [32, "create-test-suite-for-diagnostics"], [33, "create-test-suite-for-diagnostics"], [34, "create-test-suite-for-diagnostics"], [35, "create-test-suite-for-diagnostics"], [36, "create-test-suite-for-diagnostics"]], "Creating & Managing Experiments": [[365, "creating-managing-experiments"]], "Data Access and Properties": [[114, "data-access-and-properties"]], "Data Drift Test": [[7, null]], "Data Drift and Sampling": [[114, "data-drift-and-sampling"]], "Data Exploration": [[114, "data-exploration"]], "Data Loading": [[334, "data-loading"]], "Data Loading and Management": [[114, "data-loading-and-management"]], "Data Preparation": [[334, "data-preparation"]], "Data Preprocessing": [[334, "data-preprocessing"]], "Data Processing": [[333, null], [354, null]], "Data Processing and Feature Engineering": [[5, null]], "Data Quality (Drift Test)": [[335, null]], "Data Quality (Outlier Detection)": [[336, null]], "Data Registration": [[334, "data-registration"]], "Data Summary": [[334, "data-summary"], [337, null], [355, null]], "Data drift test between cluster \u201c1\u201d with the rest samples": [[22, "data-drift-test-between-cluster-1-with-the-rest-samples"], [23, "data-drift-test-between-cluster-1-with-the-rest-samples"]], "Data load and summary": [[5, "data-load-and-summary"]], "Data summary": [[3, "data-summary"], [11, "data-summary"]], "Data with Model Predictions": [[9, null]], "Data-Centric Approaches": [[380, "data-centric-approaches"], [381, "data-centric-approaches"], [382, "data-centric-approaches"]], "Data-Centric Solutions": [[378, "data-centric-solutions"]], "DataSet": [[114, null]], "Dataset": [[1, null]], "Dataset Workflow": [[365, "dataset-workflow"]], "Dealing with Date Variables": [[11, null]], "Dealing with Extra Data Sets": [[10, null]], "Decision Tree": [[374, null]], "Decision Tree Classification": [[16, null]], "Decision Tree Regression": [[17, null]], "Decision Tree in MoDeVa": [[374, "decision-tree-in-modeva"]], "Definitions of Group Fairness": [[377, "definitions-of-group-fairness"]], "Delete data split (if needed)": [[10, "delete-data-split-if-needed"]], "Diagnose the tuned model": [[44, "diagnose-the-tuned-model"], [45, "diagnose-the-tuned-model"], [46, "diagnose-the-tuned-model"], [47, "diagnose-the-tuned-model"]], "Diagnostic Suite": [[376, null]], "Diagnostics": [[321, "diagnostics"]], "Diagnostics Analysis with Date": [[54, null]], "Discrete Formulation (PSI):": [[381, "discrete-formulation-psi"]], "Discrete Formulation:": [[381, "discrete-formulation"], [381, "id3"]], "Display one subplot by its name": [[58, "display-one-subplot-by-its-name"]], "Distribution Drift": [[341, "distribution-drift"]], "EDA 1D": [[3, "eda-1d"]], "EDA 2D": [[3, "eda-2d"], [11, "eda-2d"]], "EDA 2D Charts": [[356, null]], "EDA 3D": [[3, "eda-3d"], [11, "eda-3d"]], "EDA 3D Scatter": [[357, null]], "EDA Multivariate": [[358, null]], "Effect Attribution": [[367, "effect-attribution"], [371, "effect-attribution"], [372, "effect-attribution"]], "Effect Computation": [[367, "effect-computation"]], "Effect Importance": [[367, "effect-importance"], [371, "effect-importance"], [372, "effect-importance"]], "Effect importance analysis": [[26, "effect-importance-analysis"], [27, "effect-importance-analysis"]], "Effects interpretation": [[21, "effects-interpretation"]], "Empirical Cumulative Distribution-based Outlier Detection": [[336, "empirical-cumulative-distribution-based-outlier-detection"]], "Empirical Results": [[368, "empirical-results"]], "Empirical Risk Decomposition": [[378, "empirical-risk-decomposition"]], "Empirical Risk and Generalization Gap": [[378, "empirical-risk-and-generalization-gap"]], "Energy Distance": [[335, "energy-distance"]], "Error Slicing for Weakness Detection": [[383, "error-slicing-for-weakness-detection"]], "Estimation from Training and Test Errors": [[378, "estimation-from-training-and-test-errors"]], "Exact Solution": [[344, "exact-solution"], [351, "exact-solution"]], "Example": [[331, null], [335, null], [336, null], [337, null], [343, null], [344, null], [350, "example"], [377, null]], "Example 1:": [[385, null], [387, null], [388, null]], "Example 1: Bike Sharing": [[345, null], [346, null], [347, null], [348, null], [349, null], [350, null], [351, null], [367, null], [368, null], [369, null], [370, null], [371, null], [372, null], [373, null], [374, null], [378, null], [379, null], [380, null], [381, null], [382, null], [383, null]], "Example 1: BikeSharing": [[332, null]], "Example 1: Grid Search": [[386, null]], "Example 2:": [[388, null]], "Example 2: Randomized Search": [[386, null]], "Example 2: SimuCredit": [[345, null], [346, null], [347, null], [348, null], [349, null], [350, null], [351, null]], "Example 3:": [[388, null]], "Example 3: Particle Swarm Optimization Search": [[386, null]], "Example 4:": [[388, null]], "Example 5:": [[388, null]], "Example of TaiwanCredit Data Exploration": [[338, null]], "Example: Conformal Prediction Calibration for Binary Classification": [[326, null]], "Example: Conformal Prediction Calibration for Regression": [[327, null]], "Example: Feature Selection": [[339, null]], "Example: Outlier Detection": [[340, null]], "Example: Probability Calibration": [[328, null]], "Example: Subsampling": [[341, null]], "Examples": [[326, "examples"], [327, "examples"], [328, "examples"], [330, "examples"], [331, "examples"], [332, "examples"], [334, "examples"], [335, "examples"], [336, "examples"], [337, "examples"], [338, "examples"], [339, "examples"], [340, "examples"], [341, "examples"], [343, "examples"], [344, "examples"], [345, "examples"], [346, "examples"], [347, "examples"], [348, "examples"], [349, "examples"], [351, "examples"], [367, "examples"], [368, "examples"], [369, "examples"], [370, "examples"], [371, "examples"], [372, "examples"], [373, "examples"], [374, "examples"], [377, "examples"], [378, "examples"], [379, "examples"], [380, "examples"], [381, "examples"], [382, "examples"], [383, "examples"], [385, "examples"], [386, "examples"], [387, "examples"], [388, "examples"]], "Examples 1: Taiwan Credit": [[330, null]], "Examples 2: Taiwan Credit": [[367, null], [368, null], [369, null], [370, null], [371, null], [372, null], [373, null], [374, null], [378, null], [379, null], [380, null], [381, null], [382, null], [383, null]], "Example\uff1a Basic Data Operations": [[334, null]], "Execute the preprocessing steps defined above": [[5, "execute-the-preprocessing-steps-defined-above"], [15, "execute-the-preprocessing-steps-defined-above"]], "Experiment Workflow": [[365, "experiment-workflow"]], "Expert Decomposition": [[371, "expert-decomposition"]], "Explainability": [[90, null], [94, "explainability"]], "Explanation": [[367, "explanation"]], "Exploratory Data Analysis": [[3, null], [338, null]], "External Dataset": [[334, "external-dataset"]], "External Models": [[29, null], [49, "external-models"]], "Extra and Protected Data Management": [[114, "extra-and-protected-data-management"]], "Extract the last hidden layer outputs": [[18, "extract-the-last-hidden-layer-outputs"], [19, "extract-the-last-hidden-layer-outputs"]], "F1 Score": [[330, "f1-score"]], "FBEDk Algorithm": [[339, "fbedk-algorithm"]], "Fairness": [[377, null]], "Fairness Analysis": [[87, null], [94, "fairness-analysis"]], "Fairness Comparison": [[331, null], [377, "fairness-comparison"]], "Fairness Evaluation in MoDeVa": [[377, "fairness-evaluation-in-modeva"]], "Fairness Metrics": [[331, "fairness-metrics"]], "Fairness Metrics in MoDeVa": [[377, "fairness-metrics-in-modeva"]], "Fairness Mitigation": [[377, "fairness-mitigation"]], "Fairness comparison": [[88, "fairness-comparison"]], "Feature Binning": [[377, "feature-binning"]], "Feature Engineering Solutions": [[378, "feature-engineering-solutions"]], "Feature Importance": [[339, "feature-importance"], [367, "feature-importance"], [371, "feature-importance"], [372, "feature-importance"]], "Feature Importance Plot": [[373, "feature-importance-plot"]], "Feature Manipulation": [[337, "feature-manipulation"]], "Feature Selection": [[4, null], [339, null]], "Feature Selection and Management": [[114, "feature-selection-and-management"]], "Feature importance": [[14, "feature-importance"], [15, "feature-importance"]], "Feature importance analysis": [[20, "feature-importance-analysis"], [21, "feature-importance-analysis"], [26, "feature-importance-analysis"], [27, "feature-importance-analysis"]], "Feature selection operations": [[4, "feature-selection-operations"]], "First Example with Modeva": [[53, null]], "Frequently Asked Questions": [[97, null]], "Full Conformal Prediction": [[380, "full-conformal-prediction"]], "Functional ANOVA Decomposition": [[369, "functional-anova-decomposition"]], "Functional ANOVA Decomposition Process for Tree Ensembles": [[368, "functional-anova-decomposition-process-for-tree-ensembles"]], "Functional ANOVA Representation": [[367, "functional-anova-representation"], [372, "functional-anova-representation"]], "GAMI-Net": [[367, null]], "GAMI-Net in MoDeVa": [[367, "gami-net-in-modeva"]], "GAMINet Classification": [[20, null]], "GAMINet Regression": [[21, null]], "GBDT in MoDeVa": [[368, "gbdt-in-modeva"]], "GBLT in MoDeVa": [[369, "gblt-in-modeva"]], "GLM in MoDeVa": [[370, "glm-in-modeva"]], "Gallery of Modeva Examples": [[98, null]], "Gating Decomposition": [[371, "gating-decomposition"]], "Generalization Gap": [[378, "generalization-gap"]], "Generalized Linear Models": [[370, null]], "Generate and save plots": [[58, "generate-and-save-plots"]], "Get Started": [[52, null]], "Get data split by name": [[10, "get-data-split-by-name"]], "Get prediction interval": [[40, "get-prediction-interval"], [41, "get-prediction-interval"]], "Global Effect Plot": [[367, "global-effect-plot"], [368, "global-effect-plot"], [371, "global-effect-plot"], [372, "global-effect-plot"]], "Global Explainability": [[91, null], [343, null]], "Global Interpretation": [[367, "global-interpretation"], [368, "global-interpretation"], [369, "global-interpretation"], [370, "global-interpretation"], [371, "global-interpretation"], [372, "global-interpretation"], [374, "global-interpretation"]], "Global effects interpretation": [[20, "global-effects-interpretation"]], "Global tree interpretation": [[16, "global-tree-interpretation"], [17, "global-tree-interpretation"]], "Gradient Boosted Decision Trees": [[368, null]], "Gradient Boosted Linear Tree (GBLT)": [[369, "gradient-boosted-linear-tree-gblt"]], "Grid Search": [[44, null]], "H-statistic": [[91, "h-statistic"]], "Handling Missing Values": [[334, "handling-missing-values"]], "Histogram-based outlier detection": [[336, "histogram-based-outlier-detection"]], "Hstats (Friedman\u2019s H-statistic)": [[343, "hstats-friedman-s-h-statistic"], [346, null]], "Hyperparameter Tuning": [[43, null], [49, "hyperparameter-tuning"], [316, null]], "ICE (Individual Conditional Expectation)": [[347, null]], "Identification of Reliability Issue and Impactful Variables": [[380, "identification-of-reliability-issue-and-impactful-variables"]], "Identification of Robustness Issue and Impactful Variables": [[382, "identification-of-robustness-issue-and-impactful-variables"]], "Identifying Problematic Regions": [[378, "identifying-problematic-regions"]], "Implementation Considerations": [[367, "implementation-considerations"], [372, "implementation-considerations"]], "Implementation Framework": [[378, "implementation-framework"]], "Individual Prediction Analysis": [[367, "individual-prediction-analysis"], [368, "individual-prediction-analysis"], [369, "individual-prediction-analysis"], [371, "individual-prediction-analysis"], [372, "individual-prediction-analysis"], [373, "individual-prediction-analysis"]], "Inherent Interpretation": [[321, "inherent-interpretation"]], "Initialize ModelZoo": [[50, "initialize-modelzoo"]], "Initialize the Panel": [[354, "initialize-the-panel"], [355, "initialize-the-panel"], [356, "initialize-the-panel"], [357, "initialize-the-panel"], [358, "initialize-the-panel"], [359, "initialize-the-panel"], [360, "initialize-the-panel"], [361, "initialize-the-panel"], [363, "initialize-the-panel"], [364, "initialize-the-panel"], [365, "initialize-the-panel"]], "Initialize the pipeline with steps": [[59, "initialize-the-pipeline-with-steps"]], "Input Perturbation for Robustness Test": [[382, "input-perturbation-for-robustness-test"]], "Installation": [[112, null], [112, "id1"]], "Interaction with ANOVA Decomposition": [[368, "interaction-with-anova-decomposition"]], "Interpret effect importance": [[22, "interpret-effect-importance"], [23, "interpret-effect-importance"]], "Interpret effects": [[22, "interpret-effects"], [23, "interpret-effects"]], "Interpret feature importance": [[22, "interpret-feature-importance"], [23, "interpret-feature-importance"]], "Interpret residual by a XGB depth-2 model": [[62, "interpret-residual-by-a-xgb-depth-2-model"], [63, "interpret-residual-by-a-xgb-depth-2-model"]], "Interpretability Enhancement": [[368, "interpretability-enhancement"]], "Interpretability Through Functional ANOVA": [[368, "interpretability-through-functional-anova"]], "Interpretable Models": [[317, null], [366, null]], "Interpretation: Functional ANOVA Representation": [[371, "interpretation-functional-anova-representation"]], "Interpreting Residual Analysis Results": [[379, "interpreting-residual-analysis-results"]], "Interval Calibration for Classification": [[326, null]], "Interval Calibration for Regression": [[327, null]], "Introduction": [[352, null], [379, "introduction"], [383, "introduction"]], "Isolation Forest": [[336, "isolation-forest"], [340, "isolation-forest"]], "Jensen-Shannon Divergence": [[381, "jensen-shannon-divergence"]], "K-Nearest Neighbor": [[336, "k-nearest-neighbor"]], "KernelSHAP": [[344, "kernelshap"], [351, "kernelshap"]], "Key Approaches to Weakness Detection": [[383, "key-approaches-to-weakness-detection"]], "Key Modules": [[352, "key-modules"]], "KmeansTree": [[336, "kmeanstree"]], "Kolmogorov-Smirnov Statistic": [[381, "kolmogorov-smirnov-statistic"]], "LGBM Linear Tree model": [[24, "lgbm-linear-tree-model"], [25, "lgbm-linear-tree-model"]], "LIME": [[92, "lime"]], "LIME (Local Interpretable Model-Agnostic Explanation)": [[344, "lime-local-interpretable-model-agnostic-explanation"], [348, null]], "LLM Summary Table": [[373, "llm-summary-table"]], "LLM parallel coordinate plot": [[18, "llm-parallel-coordinate-plot"], [19, "llm-parallel-coordinate-plot"]], "LLM profile plot": [[373, "llm-profile-plot"]], "LLM profile plot against a feature": [[18, "llm-profile-plot-against-a-feature"], [19, "llm-profile-plot-against-a-feature"]], "LLM summary table": [[18, "llm-summary-table"], [19, "llm-summary-table"]], "Limit the number of bars in bar plots": [[58, "limit-the-number-of-bars-in-bar-plots"]], "Linear Regression (Regression)": [[15, null]], "Linear Tree": [[369, "linear-tree"]], "Linear Tree Classification": [[24, null]], "Linear Tree Regression": [[25, null]], "Linear Tree and Gradient Boosted Linear Trees": [[369, null]], "Linear Tree in MoDeVa": [[369, "linear-tree-in-modeva"]], "LinearSHAP and TreeSHAP": [[344, "linearshap-and-treeshap"]], "List the available sub-figure names": [[58, "list-the-available-sub-figure-names"]], "Load and Register Fitted Models": [[385, "load-and-register-fitted-models"]], "Load and prepare dataset": [[50, "load-and-prepare-dataset"]], "Load and verify registered models": [[50, "load-and-verify-registered-models"]], "Load data from MLFlow": [[2, "load-data-from-mlflow"]], "Load the built-in data": [[2, "load-the-built-in-data"]], "Load the first 5000 rows into Modeva": [[10, "load-the-first-5000-rows-into-modeva"]], "Load the samples indexed from 5000 to 8000 as \u201coot1\u201d data split": [[10, "load-the-samples-indexed-from-5000-to-8000-as-oot1-data-split"]], "Load the samples indexed from 8000 to 9000 as \u201coot2\u201d data split": [[10, "load-the-samples-indexed-from-8000-to-9000-as-oot2-data-split"]], "Load the samples indexed from 9000 to the last one as \u201coot3\u201d data split": [[10, "load-the-samples-indexed-from-9000-to-the-last-one-as-oot3-data-split"]], "Local Explainability": [[92, null], [344, null]], "Local Interpretation": [[367, "local-interpretation"], [368, "local-interpretation"], [369, "local-interpretation"], [370, "local-interpretation"], [371, "local-interpretation"], [372, "local-interpretation"], [373, "local-interpretation"], [374, "local-interpretation"]], "Local Linear Models (LLM)": [[373, "local-linear-models-llm"]], "Local MOE weights interpretation": [[22, "local-moe-weights-interpretation"], [23, "local-moe-weights-interpretation"]], "Local effect importance analysis": [[22, "local-effect-importance-analysis"], [23, "local-effect-importance-analysis"], [26, "local-effect-importance-analysis"], [27, "local-effect-importance-analysis"]], "Local feature importance analysis": [[14, "local-feature-importance-analysis"], [15, "local-feature-importance-analysis"], [18, "local-feature-importance-analysis"], [19, "local-feature-importance-analysis"], [20, "local-feature-importance-analysis"], [21, "local-feature-importance-analysis"], [22, "local-feature-importance-analysis"], [23, "local-feature-importance-analysis"], [26, "local-feature-importance-analysis"], [27, "local-feature-importance-analysis"]], "Local feature importance with linear coefficients": [[14, "local-feature-importance-with-linear-coefficients"], [15, "local-feature-importance-with-linear-coefficients"]], "Local tree interpretation": [[16, "local-tree-interpretation"], [17, "local-tree-interpretation"]], "Logistic Regression (Classification)": [[14, null]], "Loss Function with Monotonicity Constraint": [[372, "loss-function-with-monotonicity-constraint"]], "Loss Function with Monotonicity Constraint in GAMI-Net": [[367, "loss-function-with-monotonicity-constraint-in-gami-net"]], "Low Code": [[113, null]], "Low code": [[353, null]], "Main Effects": [[368, "main-effects"]], "Main effect plot": [[14, "main-effect-plot"], [15, "main-effect-plot"], [26, "main-effect-plot"], [27, "main-effect-plot"]], "Managing Datasets": [[365, "managing-datasets"]], "Manifestations": [[378, "manifestations"]], "Marginal Distribution Drift": [[335, "marginal-distribution-drift"]], "Marginal Distribution of Outliers": [[336, "marginal-distribution-of-outliers"]], "Mathematical Formulation": [[368, "mathematical-formulation"], [371, "mathematical-formulation"]], "Mean Absolute Error": [[332, "mean-absolute-error"]], "Mean Squared Error": [[332, "mean-squared-error"]], "Measuring Distribution Drift": [[381, "measuring-distribution-drift"]], "Methodology": [[336, "methodology"], [379, "methodology"]], "Metrics for Group Fairness": [[377, "metrics-for-group-fairness"]], "Mixture of Expert (MoE) Classification": [[22, null]], "Mixture of Expert (MoE) Regression": [[23, null]], "Mixture of Experts (MoE)": [[371, null]], "MoDeVa.ai": [[389, null]], "MoE in MoDeVa": [[371, "moe-in-modeva"]], "MoReLUDNN Classification": [[18, null]], "MoReLUDNN Regression": [[19, null]], "Model Architecture": [[371, "model-architecture"]], "Model Calibration": [[38, null], [49, "model-calibration"], [325, null]], "Model Comparison": [[321, "model-comparison"], [329, null], [359, null]], "Model Development": [[49, null]], "Model Explainability": [[342, null], [360, null]], "Model Fairness Analysis (Classification)": [[88, null]], "Model Interpretation": [[373, "model-interpretation"]], "Model Management": [[318, "model-management"], [387, "model-management"]], "Model Performance": [[65, null], [94, "model-performance"]], "Model Probability Calibration": [[328, null]], "Model Quality": [[368, "model-quality"]], "Model Registry": [[318, "model-registry"]], "Model Residual": [[61, null], [94, "model-residual"]], "Model Test": [[361, null]], "Model Training": [[318, "model-training"], [362, null], [384, null]], "Model Tuning": [[363, null], [386, null]], "Model Validation": [[94, null]], "Model Wrappers": [[323, null], [388, null]], "Model Wrapping": [[375, null]], "Model Zoo": [[318, null]], "Model Zoo and Leaderboard": [[387, null]], "Model architecture": [[372, "model-architecture"], [373, "model-architecture"]], "Model comparison": [[68, "model-comparison"], [69, "model-comparison"], [72, "model-comparison"], [73, "model-comparison"]], "Model interpretation examples": [[50, "model-interpretation-examples"]], "Model registration and loading": [[50, "model-registration-and-loading"]], "Model reliability comparison": [[76, "model-reliability-comparison"], [77, "model-reliability-comparison"]], "Model robustness comparison": [[85, "model-robustness-comparison"]], "Model-Centric Approaches": [[378, "model-centric-approaches"], [381, "model-centric-approaches"], [382, "model-centric-approaches"]], "ModelTune Usage": [[386, "modeltune-usage"]], "ModelZoo": [[50, null]], "Monotonicity Constraint in GBDT": [[368, "monotonicity-constraint-in-gbdt"]], "Monotonicity Constraints in GAMI-Net": [[367, "monotonicity-constraints-in-gami-net"]], "Monotonicity Constraints in Neural Tree": [[372, "monotonicity-constraints-in-neural-tree"]], "Neural Tree": [[372, null]], "Neural Tree in MoDeVa": [[372, "neural-tree-in-modeva"]], "Neural Tree model with Monotonicity Constraints": [[24, "neural-tree-model-with-monotonicity-constraints"], [25, "neural-tree-model-with-monotonicity-constraints"]], "Nonconformity Score:": [[380, "nonconformity-score"]], "Numerical Features": [[337, "numerical-features"]], "Numerical Variable Binning": [[334, "numerical-variable-binning"]], "Numerical Variable Scaling": [[334, "numerical-variable-scaling"]], "Numerical Variables": [[334, "numerical-variables"]], "One Class SVM": [[336, "one-class-svm"]], "One-way ALE": [[345, "one-way-ale"]], "One-way PDPs": [[349, "one-way-pdps"]], "Outcome Analysis": [[352, "outcome-analysis"]], "Outlier Detection": [[8, null], [114, "outlier-detection"], [340, null]], "Outlier Score distribution": [[336, "outlier-score-distribution"]], "Outlier detection by CBLOF": [[8, "outlier-detection-by-cblof"]], "Outlier detection by Isolation forest": [[8, "outlier-detection-by-isolation-forest"]], "Outlier detection by PCA": [[8, "outlier-detection-by-pca"]], "Overall Model f(\\mathbf{x})": [[369, "overall-model-f-mathbf-x"]], "Overfit Comparison": [[330, "overfit-comparison"], [332, "overfit-comparison"], [378, "overfit-comparison"]], "Overfit Detection": [[71, null], [94, "overfit-detection"]], "Overfitting Analysis (Classification)": [[72, null]], "Overfitting Analysis (Regression)": [[73, null]], "Overfitting Characterization": [[378, "overfitting-characterization"]], "Overfitting Slicing in MoDeVa": [[378, "overfitting-slicing-in-modeva"]], "Overfitting and Model Robustness": [[378, "overfitting-and-model-robustness"]], "PCA": [[3, "pca"]], "PCA Plot": [[338, "pca-plot"]], "PCA-based Method": [[340, "pca-based-method"]], "PDP (Partial Dependence Plot)": [[343, "pdp-partial-dependence-plot"], [349, null]], "PFI (Permutation Feature Importance)": [[343, "pfi-permutation-feature-importance"], [350, null]], "Pairwise Interactions": [[368, "pairwise-interactions"]], "Parallel Coordinate Plot": [[373, "parallel-coordinate-plot"]], "Particle Swarm Optimization Search": [[46, null]], "Performance Comparison": [[379, "performance-comparison"]], "Performance Evaluation in MoDeVa": [[379, "performance-evaluation-in-modeva"]], "Performance Metrics (Classification)": [[66, null]], "Performance Metrics (Regression)": [[67, null]], "Performance and Residual Analysis": [[379, null]], "Permutation feature importance": [[91, "permutation-feature-importance"]], "Perturbation for Categorical Variable": [[382, "perturbation-for-categorical-variable"]], "Pipeline": [[59, null], [319, null]], "Post-hoc Explanation": [[321, "post-hoc-explanation"]], "Practical Applications": [[378, "practical-applications"]], "Practical Considerations": [[382, "practical-considerations"]], "Preprocessing": [[114, "preprocessing"]], "Prerequisite": [[112, "prerequisite"]], "Principal Component Analysis": [[336, "principal-component-analysis"]], "Properties": [[318, "properties"]], "Purification Constraints": [[367, "purification-constraints"]], "Purpose of Residual Analysis": [[379, "purpose-of-residual-analysis"]], "Quantile Perturbation with Uniform Noise": [[382, "quantile-perturbation-with-uniform-noise"]], "R-squared Score": [[332, "r-squared-score"]], "RCIT Test": [[339, "rcit-test"]], "RCIT based feature selection": [[4, "rcit-based-feature-selection"]], "Random Search": [[45, null]], "Random forest-based residual clustering analysis (absolute residual)": [[62, "random-forest-based-residual-clustering-analysis-absolute-residual"], [63, "random-forest-based-residual-clustering-analysis-absolute-residual"]], "Random forest-based residual clustering analysis (perturbed residual)": [[62, "random-forest-based-residual-clustering-analysis-perturbed-residual"], [63, "random-forest-based-residual-clustering-analysis-perturbed-residual"]], "Random forest-based residual clustering analysis (prediction interval width)": [[62, "random-forest-based-residual-clustering-analysis-prediction-interval-width"], [63, "random-forest-based-residual-clustering-analysis-prediction-interval-width"]], "Random subsampling": [[6, "random-subsampling"]], "ReLU DNN in MoDeVa": [[373, "relu-dnn-in-modeva"]], "ReLU Neural Network": [[373, null]], "References": [[336, null], [338, "references"], [338, null], [339, "references"], [339, null], [340, "references"], [340, null], [343, "references"], [343, null], [344, "references"], [344, null], [346, null], [347, null], [350, null], [351, null], [367, "references"], [367, null], [368, "references"], [368, null], [369, "references"], [369, null], [373, "references"], [373, null]], "Register H2O Models": [[385, null]], "Register data into MLFlow": [[2, "register-data-into-mlflow"]], "Registry Hub": [[365, null]], "Regression": [[317, "regression"]], "Regression Metrics": [[379, "regression-metrics"]], "Reliability": [[380, null]], "Reliability Analysis": [[75, null], [94, "reliability-analysis"]], "Reliability Analysis (Classification)": [[76, null]], "Reliability Analysis (Regression)": [[77, null]], "Reliability Analysis in MoDeVa": [[380, "reliability-analysis-in-modeva"]], "Reliability Assessment:": [[380, "reliability-assessment"]], "Reliability Comparison": [[330, "reliability-comparison"], [332, "reliability-comparison"], [380, "reliability-comparison"]], "Reliability Diagnostics in MoDeVa": [[380, "reliability-diagnostics-in-modeva"]], "Reliability Diagram Comparison": [[330, "reliability-diagram-comparison"]], "Remediation Strategies for Model Weaknesses Identified by Gap Analysis": [[378, "remediation-strategies-for-model-weaknesses-identified-by-gap-analysis"]], "Remove Features": [[337, "remove-features"]], "Reset preprocessing": [[5, "reset-preprocessing"]], "Reset subsampling by ds.set_active_samples()": [[6, "reset-subsampling-by-ds-set-active-samples"]], "Residual Analysis": [[379, "residual-analysis"]], "Residual Analysis (Classification)": [[62, null]], "Residual Analysis (Regression)": [[63, null]], "Residual Analysis in MoDeVa": [[379, "residual-analysis-in-modeva"]], "Resilience": [[381, null]], "Resilience Analysis": [[79, null], [94, "resilience-analysis"]], "Resilience Analysis (Classification)": [[80, null]], "Resilience Analysis (Regression)": [[81, null]], "Resilience Analysis in MoDeVa": [[381, "resilience-analysis-in-modeva"]], "Resilience Comparison": [[330, "resilience-comparison"], [332, "resilience-comparison"], [381, "resilience-comparison"]], "Resilience Distance": [[330, "resilience-distance"], [332, "resilience-distance"]], "Resilience Performance": [[330, "resilience-performance"], [332, "resilience-performance"]], "Resilience comparison": [[80, "resilience-comparison"], [81, "resilience-comparison"]], "Rest calibration when needed": [[39, "rest-calibration-when-needed"], [40, "rest-calibration-when-needed"], [41, "rest-calibration-when-needed"]], "Retrain model with best hyperparameter": [[44, "retrain-model-with-best-hyperparameter"], [45, "retrain-model-with-best-hyperparameter"], [46, "retrain-model-with-best-hyperparameter"], [47, "retrain-model-with-best-hyperparameter"]], "Robustness": [[382, null]], "Robustness Analysis": [[83, null], [94, "robustness-analysis"]], "Robustness Analysis (Classification)": [[84, null]], "Robustness Analysis (Regression)": [[85, null]], "Robustness Analysis in MoDeVa": [[382, "robustness-analysis-in-modeva"]], "Robustness Comparison": [[330, "robustness-comparison"], [332, "robustness-comparison"], [382, "robustness-comparison"]], "Robustness Performance": [[330, "robustness-performance"], [332, "robustness-performance"]], "Robustness Performance on Worst Samples": [[330, "robustness-performance-on-worst-samples"], [332, "robustness-performance-on-worst-samples"]], "Robustness comparison": [[84, "robustness-comparison"]], "Run Diagnostic Tests": [[385, "run-diagnostic-tests"]], "Run HPO": [[47, "run-hpo"]], "Run PSO search": [[46, "run-pso-search"]], "Run grid search": [[44, "run-grid-search"]], "Run random search": [[45, "run-random-search"]], "Run the pipeline": [[59, "run-the-pipeline"]], "SHAP (SHapley Additive exPlanations)": [[344, "shap-shapley-additive-explanations"], [351, null]], "SHAP Dependence Plot": [[351, "shap-dependence-plot"]], "SHAP Feature importance": [[351, "shap-feature-importance"]], "SHAP Summary plot": [[351, "shap-summary-plot"]], "Save Fitted Models": [[385, "save-fitted-models"]], "Save figures": [[58, "save-figures"]], "Save the pipeline results (optional)": [[59, "save-the-pipeline-results-optional"]], "Scored Model Wrapper": [[388, "scored-model-wrapper"]], "Scripts for building a H2O model": [[30, "scripts-for-building-a-h2o-model"]], "Scripts for building a pyspark model": [[31, "scripts-for-building-a-pyspark-model"]], "Scripts to build a model": [[33, "scripts-to-build-a-model"], [34, "scripts-to-build-a-model"]], "Segmented": [[331, "segmented"]], "Set the data steps": [[5, "set-the-data-steps"]], "Show the available data splits": [[10, "show-the-available-data-splits"]], "Simple Perturbation with Normally Distributed Random Noise": [[382, "simple-perturbation-with-normally-distributed-random-noise"]], "Sklearn Model Wrapper": [[388, "sklearn-model-wrapper"]], "Sliced Performance (Classification)": [[68, null]], "Sliced Performance (Regression)": [[69, null]], "Slicing Generalization Gap": [[378, "slicing-generalization-gap"]], "Slicing accuracy diagnostics against date": [[54, "slicing-accuracy-diagnostics-against-date"]], "Slicing fairness analysis": [[88, "slicing-fairness-analysis"]], "Slicing for Fairness Diagnostics": [[377, "slicing-for-fairness-diagnostics"]], "Slicing overfit with date": [[54, "slicing-overfit-with-date"]], "Slicing reliability": [[76, "slicing-reliability"], [77, "slicing-reliability"]], "Slicing reliability with date": [[54, "slicing-reliability-with-date"]], "Slicing robustness analysis": [[84, "slicing-robustness-analysis"], [85, "slicing-robustness-analysis"]], "Slicing robustness with date": [[54, "slicing-robustness-with-date"]], "Special Cases with Limited Depth": [[368, "special-cases-with-limited-depth"]], "Special Features": [[352, "special-features"]], "Split Conformal Prediction": [[380, "split-conformal-prediction"]], "Step 1: Dataset & Model Selection": [[362, "step-1-dataset-model-selection"]], "Step 1: Load and Select Dataset": [[355, "step-1-load-and-select-dataset"], [356, "step-1-load-and-select-dataset"], [357, "step-1-load-and-select-dataset"], [358, "step-1-load-and-select-dataset"], [360, "step-1-load-and-select-dataset"]], "Step 1: Select Dataset & Model": [[361, "step-1-select-dataset-model"]], "Step 1: Select Dataset & Models": [[359, "step-1-select-dataset-models"], [364, "step-1-select-dataset-models"]], "Step 1: Select Dataset, Model, and Search Method": [[363, "step-1-select-dataset-model-and-search-method"]], "Step 1: Select variables and global settings": [[354, "step-1-select-variables-and-global-settings"]], "Step 2: Configure Tuning Parameters": [[363, "step-2-configure-tuning-parameters"]], "Step 2: Configure Visualization Settings": [[356, "step-2-configure-visualization-settings"], [357, "step-2-configure-visualization-settings"]], "Step 2: Detect Weak Features and Segments": [[364, "step-2-detect-weak-features-and-segments"]], "Step 2: Global Explanations": [[360, "step-2-global-explanations"]], "Step 2: Perform Correlation Analysis": [[358, "step-2-perform-correlation-analysis"]], "Step 2: Performance Comparison": [[359, "step-2-performance-comparison"]], "Step 2: Performance Evaluation": [[361, "step-2-performance-evaluation"]], "Step 2: Process Features": [[354, "step-2-process-features"]], "Step 2: Review Dataset Overview": [[355, "step-2-review-dataset-overview"]], "Step 2: Train a Model": [[362, "step-2-train-a-model"]], "Step 3: Adjust Feature Types (If Necessary)": [[356, "step-3-adjust-feature-types-if-necessary"], [357, "step-3-adjust-feature-types-if-necessary"]], "Step 3: Analyze Numerical Features": [[355, "step-3-analyze-numerical-features"]], "Step 3: Apply Principal Component Analysis (PCA)": [[358, "step-3-apply-principal-component-analysis-pca"]], "Step 3: Evaluate and Compare Models": [[362, "step-3-evaluate-and-compare-models"]], "Step 3: Local Explanations": [[360, "step-3-local-explanations"]], "Step 3: Reliability Comparison": [[359, "step-3-reliability-comparison"]], "Step 3: Reliability Testing": [[361, "step-3-reliability-testing"]], "Step 3: Run Tuning": [[363, "step-3-run-tuning"]], "Step 3: Saving Results": [[364, "step-3-saving-results"]], "Step 3: Splitting, Sampling & Registering": [[354, "step-3-splitting-sampling-registering"]], "Step 4: Analyze Categorical Features": [[355, "step-4-analyze-categorical-features"]], "Step 4: Apply UMAP for Advanced Visualization": [[358, "step-4-apply-umap-for-advanced-visualization"]], "Step 4: Register a Model": [[362, "step-4-register-a-model"]], "Step 4: Register and Save the Visualization:": [[356, "step-4-register-and-save-the-visualization"], [357, "step-4-register-and-save-the-visualization"]], "Step 4: Register the Best Model": [[363, "step-4-register-the-best-model"]], "Step 4: Robustness Comparison": [[359, "step-4-robustness-comparison"]], "Step 4: Robustness Testing": [[361, "step-4-robustness-testing"]], "Step 4: Saving Results": [[360, "step-4-saving-results"]], "Step 5: Adjust Data Types (If Necessary)": [[355, "step-5-adjust-data-types-if-necessary"]], "Step 5: Resilience Comparison": [[359, "step-5-resilience-comparison"]], "Step 5: Resilience Testing": [[361, "step-5-resilience-testing"]], "Step 5: Save and Export Results": [[358, "step-5-save-and-export-results"]], "Step 6: Save and Export Results": [[355, "step-6-save-and-export-results"]], "Step 6: Saving Results": [[359, "step-6-saving-results"], [361, "step-6-saving-results"]], "Step-by-Step Process": [[371, "step-by-step-process"], [372, "step-by-step-process"]], "Step-by-Step Transformation": [[369, "step-by-step-transformation"]], "Steps in Residual Analysis": [[379, "steps-in-residual-analysis"]], "Strategies for Addressing Model Weaknesses": [[380, "strategies-for-addressing-model-weaknesses"], [381, "strategies-for-addressing-model-weaknesses"], [382, "strategies-for-addressing-model-weaknesses"]], "Subsampling": [[6, null], [341, "subsampling"]], "Subsampling and Data Drift": [[341, null]], "Summary Statistics": [[337, "summary-statistics"]], "Supervised Learning for Residual Analysis": [[379, "supervised-learning-for-residual-analysis"]], "Supervised Machine Learning: Random Forest Clustering": [[380, "supervised-machine-learning-random-forest-clustering"], [382, "supervised-machine-learning-random-forest-clustering"]], "Techniques for Residual Analysis": [[379, "techniques-for-residual-analysis"]], "Test Error:": [[378, "test-error"]], "Test Suite": [[321, null]], "The Waterfall plot": [[351, "the-waterfall-plot"]], "Theoretical Framework": [[378, "theoretical-framework"]], "Threshold Adjustment": [[377, "threshold-adjustment"]], "Track Experiments": [[365, "track-experiments"]], "Tradeoffs Between Performance and Fairness": [[377, "tradeoffs-between-performance-and-fairness"]], "Train all models and show leaderboard": [[50, "train-all-models-and-show-leaderboard"]], "Train and Register Models": [[385, "train-and-register-models"]], "Train model": [[14, "train-model"], [15, "train-model"], [16, "train-model"], [17, "train-model"], [18, "train-model"], [19, "train-model"], [20, "train-model"], [21, "train-model"], [26, "train-model"], [27, "train-model"]], "Train models": [[22, "train-models"], [23, "train-models"]], "Train-Test Split Management": [[114, "train-test-split-management"]], "Training Error:": [[378, "training-error"]], "Training and Leaderboard": [[387, "training-and-leaderboard"]], "Tree Ensemble Models (Classification)": [[26, null]], "Tree Ensemble Models (Regression)": [[27, null]], "Tree Structure T_m": [[369, "tree-structure-t-m"]], "Trouble Shooting": [[112, "trouble-shooting"]], "Troubleshooting": [[358, "troubleshooting"], [363, "troubleshooting"]], "Tuning with optuna (Experimental)": [[47, null]], "Two-way ALE": [[345, "two-way-ale"]], "Two-way PDPs": [[349, "two-way-pdps"]], "Umap": [[3, "umap"]], "Underfitting and Overfitting": [[378, null]], "Unfairness mitigation": [[88, "unfairness-mitigation"]], "Univariate (1D) Plots": [[338, "univariate-1d-plots"]], "Unused API Entries": [[390, null]], "Uploading Data": [[365, "uploading-data"]], "Usage": [[345, "usage"], [346, "usage"], [347, "usage"], [348, "usage"], [349, "usage"], [350, "usage"], [351, "usage"]], "Using Modeva": [[324, null]], "Utilities": [[56, null], [321, "utilities"], [322, null]], "Validation Result": [[320, null]], "ValidationResult - Attributes": [[57, null]], "ValidationResult - Visualization": [[58, null]], "View and use outlier detection results": [[8, "view-and-use-outlier-detection-results"]], "Visualize prediction interval": [[41, "visualize-prediction-interval"]], "Visualize the residual against date": [[54, "visualize-the-residual-against-date"]], "Visualize the residual against model prediction": [[63, "visualize-the-residual-against-model-prediction"]], "Visualize the residual against model prediction (predict proba)": [[62, "visualize-the-residual-against-model-prediction-predict-proba"]], "Visualize the residual against predictor": [[62, "visualize-the-residual-against-predictor"], [63, "visualize-the-residual-against-predictor"]], "Visualize the residual against response variable": [[62, "visualize-the-residual-against-response-variable"], [63, "visualize-the-residual-against-response-variable"]], "Wasserstein Distance": [[381, "wasserstein-distance"]], "Weakness Comparison": [[383, "weakness-comparison"]], "Weakness Detection": [[383, null]], "Weakness Detection Methods": [[378, "weakness-detection-methods"]], "Weakness Detection in MoDeVa": [[383, "weakness-detection-in-modeva"]], "Weakness Test": [[364, null]], "Weakspot Comparison": [[330, "weakspot-comparison"], [332, "weakspot-comparison"]], "Why Weakness Detection is Important": [[383, "why-weakness-detection-is-important"]], "Workflow": [[354, "workflow"], [355, "workflow"], [356, "workflow"], [357, "workflow"], [358, "workflow"], [359, "workflow"], [360, "workflow"], [361, "workflow"], [362, "workflow"], [363, "workflow"], [364, "workflow"]], "Wrap the PySpark model into Modeva": [[31, "wrap-the-pyspark-model-into-modeva"]], "Wrap the data": [[31, "wrap-the-data"]], "Wrap the data into Modeva": [[30, "wrap-the-data-into-modeva"], [32, "wrap-the-data-into-modeva"], [33, "wrap-the-data-into-modeva"], [34, "wrap-the-data-into-modeva"], [35, "wrap-the-data-into-modeva"], [36, "wrap-the-data-into-modeva"]], "Wrap the model into Modeva": [[30, "wrap-the-model-into-modeva"], [32, "wrap-the-model-into-modeva"], [33, "wrap-the-model-into-modeva"], [34, "wrap-the-model-into-modeva"]], "Wrapping Arbitrary Classifier": [[33, null]], "Wrapping Arbitrary Regressor": [[34, null]], "Wrapping H2O Models": [[30, null]], "Wrapping PySpark Models": [[31, null]], "Wrapping Scored Classifier": [[35, null]], "Wrapping Scored Regressor": [[36, null]], "Wrapping sklearn-style Models": [[32, null]], "XGB-PFI based feature selection": [[4, "xgb-pfi-based-feature-selection"]], "modeva.DataSet.all_feature_names": [[115, null]], "modeva.DataSet.all_feature_types": [[116, null]], "modeva.DataSet.bin_numerical": [[117, null]], "modeva.DataSet.data": [[118, null]], "modeva.DataSet.data_drift_test": [[119, null]], "modeva.DataSet.delete_extra_data": [[120, null]], "modeva.DataSet.delete_registered_data": [[121, null]], "modeva.DataSet.detect_outlier_cblof": [[122, null]], "modeva.DataSet.detect_outlier_isolation_forest": [[123, null]], "modeva.DataSet.detect_outlier_pca": [[124, null]], "modeva.DataSet.eda_1d": [[125, null]], "modeva.DataSet.eda_2d": [[126, null]], "modeva.DataSet.eda_3d": [[127, null]], "modeva.DataSet.eda_correlation": [[128, null]], "modeva.DataSet.eda_pca": [[129, null]], "modeva.DataSet.eda_umap": [[130, null]], "modeva.DataSet.encode_categorical": [[131, null]], "modeva.DataSet.feature_names": [[132, null]], "modeva.DataSet.feature_names_categorical": [[133, null]], "modeva.DataSet.feature_names_mixed": [[134, null]], "modeva.DataSet.feature_names_numerical": [[135, null]], "modeva.DataSet.feature_select_corr": [[136, null]], "modeva.DataSet.feature_select_rcit": [[137, null]], "modeva.DataSet.feature_select_xgbpfi": [[138, null]], "modeva.DataSet.feature_types": [[139, null]], "modeva.DataSet.get_X_y_data": [[140, null]], "modeva.DataSet.get_active_sample_idx": [[141, null]], "modeva.DataSet.get_data": [[142, null]], "modeva.DataSet.get_data_list": [[143, null]], "modeva.DataSet.get_extra_data_list": [[144, null]], "modeva.DataSet.get_preprocessor": [[145, null]], "modeva.DataSet.get_protected_data": [[146, null]], "modeva.DataSet.get_raw_data": [[147, null]], "modeva.DataSet.impute_missing": [[148, null]], "modeva.DataSet.inverse_transform": [[149, null]], "modeva.DataSet.is_splitted": [[150, null]], "modeva.DataSet.list_registered_data": [[151, null]], "modeva.DataSet.load": [[152, null]], "modeva.DataSet.load_csv": [[153, null]], "modeva.DataSet.load_dataframe": [[154, null]], "modeva.DataSet.load_dataframe_train_test": [[155, null]], "modeva.DataSet.load_preprocessing": [[156, null]], "modeva.DataSet.load_registered_data": [[157, null]], "modeva.DataSet.load_spark": [[158, null]], "modeva.DataSet.n_features": [[159, null]], "modeva.DataSet.name": [[160, null]], "modeva.DataSet.prediction_name": [[161, null]], "modeva.DataSet.prediction_proba_name": [[162, null]], "modeva.DataSet.preprocess": [[163, null]], "modeva.DataSet.protected_feature_names": [[164, null]], "modeva.DataSet.raw_data": [[165, null]], "modeva.DataSet.register": [[166, null]], "modeva.DataSet.reset_preprocess": [[167, null]], "modeva.DataSet.sample_weight": [[168, null]], "modeva.DataSet.sample_weight_name": [[169, null]], "modeva.DataSet.save_preprocessing": [[170, null]], "modeva.DataSet.scale_numerical": [[171, null]], "modeva.DataSet.set_active_features": [[172, null]], "modeva.DataSet.set_feature_type": [[173, null]], "modeva.DataSet.set_inactive_features": [[174, null]], "modeva.DataSet.set_prediction": [[175, null]], "modeva.DataSet.set_prediction_proba": [[176, null]], "modeva.DataSet.set_protected_data": [[177, null]], "modeva.DataSet.set_protected_extra_data": [[178, null]], "modeva.DataSet.set_random_split": [[179, null]], "modeva.DataSet.set_raw_extra_data": [[180, null]], "modeva.DataSet.set_sample_weight": [[181, null]], "modeva.DataSet.set_target": [[182, null]], "modeva.DataSet.set_task_type": [[183, null]], "modeva.DataSet.set_test_idx": [[184, null]], "modeva.DataSet.set_train_idx": [[185, null]], "modeva.DataSet.shape": [[186, null]], "modeva.DataSet.subsample_random": [[187, null]], "modeva.DataSet.summary": [[188, null]], "modeva.DataSet.target_feature_name": [[189, null]], "modeva.DataSet.task_type": [[190, null]], "modeva.DataSet.test_sample_weight": [[191, null]], "modeva.DataSet.test_x": [[192, null]], "modeva.DataSet.test_y": [[193, null]], "modeva.DataSet.to_df": [[194, null]], "modeva.DataSet.train_sample_weight": [[195, null]], "modeva.DataSet.train_x": [[196, null]], "modeva.DataSet.train_y": [[197, null]], "modeva.DataSet.transform": [[198, null]], "modeva.DataSet.x": [[199, null]], "modeva.DataSet.y": [[200, null]], "modeva.ModelZoo.add_model": [[201, null]], "modeva.ModelZoo.dataset": [[202, null]], "modeva.ModelZoo.delete_registered_model": [[203, null]], "modeva.ModelZoo.get_model": [[204, null]], "modeva.ModelZoo.leaderboard": [[205, null]], "modeva.ModelZoo.list_model_names": [[206, null]], "modeva.ModelZoo.list_registered_models": [[207, null]], "modeva.ModelZoo.load_registered_model": [[208, null]], "modeva.ModelZoo.models": [[209, null]], "modeva.ModelZoo.register": [[210, null]], "modeva.ModelZoo.train": [[211, null]], "modeva.ModelZoo.train_all": [[212, null]], "modeva.TestSuite.compare_accuracy_table": [[213, null]], "modeva.TestSuite.compare_fairness": [[214, null]], "modeva.TestSuite.compare_reliability": [[215, null]], "modeva.TestSuite.compare_residual_cluster": [[216, null]], "modeva.TestSuite.compare_resilience": [[217, null]], "modeva.TestSuite.compare_robustness": [[218, null]], "modeva.TestSuite.compare_slicing_accuracy": [[219, null]], "modeva.TestSuite.compare_slicing_fairness": [[220, null]], "modeva.TestSuite.compare_slicing_overfit": [[221, null]], "modeva.TestSuite.compare_slicing_reliability": [[222, null]], "modeva.TestSuite.compare_slicing_robustness": [[223, null]], "modeva.TestSuite.delete_registed_test": [[224, null]], "modeva.TestSuite.diagnose_accuracy_table": [[225, null]], "modeva.TestSuite.diagnose_fairness": [[226, null]], "modeva.TestSuite.diagnose_mitigate_unfair_binning": [[227, null]], "modeva.TestSuite.diagnose_mitigate_unfair_thresholding": [[228, null]], "modeva.TestSuite.diagnose_reliability": [[229, null]], "modeva.TestSuite.diagnose_residual_analysis": [[230, null]], "modeva.TestSuite.diagnose_residual_cluster": [[231, null]], "modeva.TestSuite.diagnose_residual_interpret": [[232, null]], "modeva.TestSuite.diagnose_resilience": [[233, null]], "modeva.TestSuite.diagnose_robustness": [[234, null]], "modeva.TestSuite.diagnose_slicing_accuracy": [[235, null]], "modeva.TestSuite.diagnose_slicing_fairness": [[236, null]], "modeva.TestSuite.diagnose_slicing_overfit": [[237, null]], "modeva.TestSuite.diagnose_slicing_reliability": [[238, null]], "modeva.TestSuite.diagnose_slicing_robustness": [[239, null]], "modeva.TestSuite.display_test_results": [[240, null]], "modeva.TestSuite.explain_ale": [[241, null]], "modeva.TestSuite.explain_hstatistic": [[242, null]], "modeva.TestSuite.explain_lime": [[243, null]], "modeva.TestSuite.explain_pdp": [[244, null]], "modeva.TestSuite.explain_pfi": [[245, null]], "modeva.TestSuite.explain_shap": [[246, null]], "modeva.TestSuite.export_report": [[247, null]], "modeva.TestSuite.get_dataset": [[248, null]], "modeva.TestSuite.get_interactions": [[249, null]], "modeva.TestSuite.get_main_effects": [[250, null]], "modeva.TestSuite.get_model": [[251, null]], "modeva.TestSuite.interpret_coef": [[252, null]], "modeva.TestSuite.interpret_effects": [[253, null]], "modeva.TestSuite.interpret_effects_moe_average": [[254, null]], "modeva.TestSuite.interpret_fi": [[255, null]], "modeva.TestSuite.interpret_global_tree": [[256, null]], "modeva.TestSuite.interpret_llm_pc": [[257, null]], "modeva.TestSuite.interpret_llm_profile": [[258, null]], "modeva.TestSuite.interpret_llm_summary": [[259, null]], "modeva.TestSuite.interpret_llm_violin": [[260, null]], "modeva.TestSuite.interpret_local_fi": [[261, null]], "modeva.TestSuite.interpret_local_linear_fi": [[262, null]], "modeva.TestSuite.interpret_local_moe_weights": [[263, null]], "modeva.TestSuite.interpret_local_tree": [[264, null]], "modeva.TestSuite.interpret_moe_cluster_analysis": [[265, null]], "modeva.TestSuite.list": [[266, null]], "modeva.TestSuite.list_registered_tests": [[267, null]], "modeva.TestSuite.load_registered_test": [[268, null]], "modeva.TestSuite.register": [[269, null]], "modeva.TestSuite.set_dataset": [[270, null]], "modeva.TestSuite.set_model": [[271, null]], "modeva.automation.pipeline.Pipeline": [[272, null]], "modeva.models.MoCatBoostClassifier": [[273, null]], "modeva.models.MoCatBoostRegressor": [[274, null]], "modeva.models.MoClassifier": [[275, null]], "modeva.models.MoDecisionTreeClassifier": [[276, null]], "modeva.models.MoDecisionTreeRegressor": [[277, null]], "modeva.models.MoElasticNet": [[278, null]], "modeva.models.MoGAMINetClassifier": [[279, null]], "modeva.models.MoGAMINetRegressor": [[280, null]], "modeva.models.MoGLMTreeBoostClassifier": [[281, null]], "modeva.models.MoGLMTreeBoostRegressor": [[282, null]], "modeva.models.MoGLMTreeClassifier": [[283, null]], "modeva.models.MoGLMTreeRegressor": [[284, null]], "modeva.models.MoGradientBoostingClassifier": [[285, null]], "modeva.models.MoGradientBoostingRegressor": [[286, null]], "modeva.models.MoLGBMClassifier": [[287, null]], "modeva.models.MoLGBMRegressor": [[288, null]], "modeva.models.MoLogisticRegression": [[289, null]], "modeva.models.MoMoEClassifier": [[290, null]], "modeva.models.MoMoERegressor": [[291, null]], "modeva.models.MoNeuralTreeClassifier": [[292, null]], "modeva.models.MoNeuralTreeRegressor": [[293, null]], "modeva.models.MoRandomForestClassifier": [[294, null]], "modeva.models.MoRandomForestRegressor": [[295, null]], "modeva.models.MoReLUDNNClassifier": [[296, null]], "modeva.models.MoReLUDNNRegressor": [[297, null]], "modeva.models.MoRegressor": [[298, null]], "modeva.models.MoSKLearnClassifier": [[299, null]], "modeva.models.MoSKLearnRegressor": [[300, null]], "modeva.models.MoScoredClassifier": [[301, null]], "modeva.models.MoScoredRegressor": [[302, null]], "modeva.models.MoXGBClassifier": [[303, null]], "modeva.models.MoXGBRegressor": [[304, null]], "modeva.models.ModelBaseClassifier": [[305, null]], "modeva.models.ModelBaseRegressor": [[306, null]], "modeva.models.ModelTuneGridSearch": [[307, null]], "modeva.models.ModelTuneOptuna": [[308, null]], "modeva.models.ModelTunePSO": [[309, null]], "modeva.models.ModelTuneRandomSearch": [[310, null]], "modeva.testsuite.utils.slicing_utils.get_data_info": [[311, null]], "modeva.utils.mlflow.clear_mlflow_home": [[312, null]], "modeva.utils.mlflow.get_mlflow_home": [[313, null]], "modeva.utils.mlflow.set_mlflow_home": [[314, null]], "modeva.utils.results.ValidationResult": [[315, null]], "sphinx_gallery.backreferences": [[99, null]], "sphinx_gallery.block_parser": [[100, null]], "sphinx_gallery.directives": [[101, null]], "sphinx_gallery.docs_resolv": [[102, null]], "sphinx_gallery.downloads": [[103, null]], "sphinx_gallery.gen_gallery": [[104, null]], "sphinx_gallery.gen_rst": [[105, null]], "sphinx_gallery.interactive_example": [[106, null]], "sphinx_gallery.notebook": [[107, null]], "sphinx_gallery.py_source_parser": [[108, null]], "sphinx_gallery.scrapers": [[109, null]], "sphinx_gallery.sorting": [[110, null]], "sphinx_gallery.utils.optipng": [[111, null]]}, "docnames": ["_source/api_ref", "_source/auto_galleries/data/index", "_source/auto_galleries/data/plot_0_data_operations", "_source/auto_galleries/data/plot_1_eda", "_source/auto_galleries/data/plot_2_feature_selection", "_source/auto_galleries/data/plot_3_feature_engineering", "_source/auto_galleries/data/plot_4_subsampling", "_source/auto_galleries/data/plot_5_drift_test", "_source/auto_galleries/data/plot_6_outlier_detection", "_source/auto_galleries/data/plot_7_data_with_prediction", "_source/auto_galleries/data/plot_8_extra_data", "_source/auto_galleries/data/plot_9_date_variable", "_source/auto_galleries/data/sg_execution_times", "_source/auto_galleries/dev/0_models/index", "_source/auto_galleries/dev/0_models/plot_0_glm_cls", "_source/auto_galleries/dev/0_models/plot_0_glm_reg", "_source/auto_galleries/dev/0_models/plot_1_dt_cls", "_source/auto_galleries/dev/0_models/plot_1_dt_reg", "_source/auto_galleries/dev/0_models/plot_2_reludnn_cls", "_source/auto_galleries/dev/0_models/plot_2_reludnn_reg", "_source/auto_galleries/dev/0_models/plot_3_gaminet_cls", "_source/auto_galleries/dev/0_models/plot_3_gaminet_reg", "_source/auto_galleries/dev/0_models/plot_4_moe_cls", "_source/auto_galleries/dev/0_models/plot_4_moe_reg", "_source/auto_galleries/dev/0_models/plot_5_lineartree_cls", "_source/auto_galleries/dev/0_models/plot_5_lineartree_reg", "_source/auto_galleries/dev/0_models/plot_6_const_tree_cls", "_source/auto_galleries/dev/0_models/plot_6_const_tree_reg", "_source/auto_galleries/dev/0_models/sg_execution_times", "_source/auto_galleries/dev/1_extmodels/index", "_source/auto_galleries/dev/1_extmodels/noplot_3_h2o", "_source/auto_galleries/dev/1_extmodels/noplot_4_spark", "_source/auto_galleries/dev/1_extmodels/plot_0_sklearn", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_cls", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_reg", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_cls", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_reg", "_source/auto_galleries/dev/1_extmodels/sg_execution_times", "_source/auto_galleries/dev/2_calibration/index", "_source/auto_galleries/dev/2_calibration/plot_0_calibrate_proba", "_source/auto_galleries/dev/2_calibration/plot_1_calibrate_interval_cls", "_source/auto_galleries/dev/2_calibration/plot_1_calibrate_interval_reg", "_source/auto_galleries/dev/2_calibration/sg_execution_times", "_source/auto_galleries/dev/3_hpo/index", "_source/auto_galleries/dev/3_hpo/plot_0_grid", "_source/auto_galleries/dev/3_hpo/plot_1_random", "_source/auto_galleries/dev/3_hpo/plot_2_pso", "_source/auto_galleries/dev/3_hpo/plot_3_optuna", "_source/auto_galleries/dev/3_hpo/sg_execution_times", "_source/auto_galleries/dev/index", "_source/auto_galleries/dev/plot_0_modelzoo", "_source/auto_galleries/dev/sg_execution_times", "_source/auto_galleries/get_started/index", "_source/auto_galleries/get_started/plot_0_demo", "_source/auto_galleries/get_started/plot_0_diagnostics_date", "_source/auto_galleries/get_started/sg_execution_times", "_source/auto_galleries/util/index", "_source/auto_galleries/util/plot_0_valres_attributes", "_source/auto_galleries/util/plot_1_valres_save", "_source/auto_galleries/util/plot_2_pipeline", "_source/auto_galleries/util/sg_execution_times", "_source/auto_galleries/val/0_residual/index", "_source/auto_galleries/val/0_residual/plot_0_residual_cls", "_source/auto_galleries/val/0_residual/plot_0_residual_reg", "_source/auto_galleries/val/0_residual/sg_execution_times", "_source/auto_galleries/val/1_performance/index", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_cls", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_reg", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_cls", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_reg", "_source/auto_galleries/val/1_performance/sg_execution_times", "_source/auto_galleries/val/2_overfitting/index", "_source/auto_galleries/val/2_overfitting/plot_0_slice_overfit_cls", "_source/auto_galleries/val/2_overfitting/plot_1_slice_overfit_reg", "_source/auto_galleries/val/2_overfitting/sg_execution_times", "_source/auto_galleries/val/3_reliability/index", "_source/auto_galleries/val/3_reliability/plot_0_reliability_cls", "_source/auto_galleries/val/3_reliability/plot_1_reliability_reg", "_source/auto_galleries/val/3_reliability/sg_execution_times", "_source/auto_galleries/val/4_resilience/index", "_source/auto_galleries/val/4_resilience/plot_0_resilience_cls", "_source/auto_galleries/val/4_resilience/plot_1_resilience_reg", "_source/auto_galleries/val/4_resilience/sg_execution_times", "_source/auto_galleries/val/5_robustness/index", "_source/auto_galleries/val/5_robustness/plot_0_robustness_cls", "_source/auto_galleries/val/5_robustness/plot_1_robustness_reg", "_source/auto_galleries/val/5_robustness/sg_execution_times", "_source/auto_galleries/val/6_fairness/index", "_source/auto_galleries/val/6_fairness/plot_0_fairness_cls", "_source/auto_galleries/val/6_fairness/sg_execution_times", "_source/auto_galleries/val/7_explainability/index", "_source/auto_galleries/val/7_explainability/plot_0_global_explain", "_source/auto_galleries/val/7_explainability/plot_1_local_explain", "_source/auto_galleries/val/7_explainability/sg_execution_times", "_source/auto_galleries/val/index", "_source/auto_galleries/val/sg_execution_times", "_source/changes", "_source/faq", "_source/galleries", "_source/gen_modules/sphinx_gallery.backreferences", "_source/gen_modules/sphinx_gallery.block_parser", "_source/gen_modules/sphinx_gallery.directives", "_source/gen_modules/sphinx_gallery.docs_resolv", "_source/gen_modules/sphinx_gallery.downloads", "_source/gen_modules/sphinx_gallery.gen_gallery", "_source/gen_modules/sphinx_gallery.gen_rst", "_source/gen_modules/sphinx_gallery.interactive_example", "_source/gen_modules/sphinx_gallery.notebook", "_source/gen_modules/sphinx_gallery.py_source_parser", "_source/gen_modules/sphinx_gallery.scrapers", "_source/gen_modules/sphinx_gallery.sorting", "_source/gen_modules/sphinx_gallery.utils.optipng", "_source/install", "_source/lowcode-gallery", "_source/modules/data", "_source/modules/generated/modeva.DataSet.all_feature_names", "_source/modules/generated/modeva.DataSet.all_feature_types", "_source/modules/generated/modeva.DataSet.bin_numerical", "_source/modules/generated/modeva.DataSet.data", "_source/modules/generated/modeva.DataSet.data_drift_test", "_source/modules/generated/modeva.DataSet.delete_extra_data", "_source/modules/generated/modeva.DataSet.delete_registered_data", "_source/modules/generated/modeva.DataSet.detect_outlier_cblof", "_source/modules/generated/modeva.DataSet.detect_outlier_isolation_forest", "_source/modules/generated/modeva.DataSet.detect_outlier_pca", "_source/modules/generated/modeva.DataSet.eda_1d", "_source/modules/generated/modeva.DataSet.eda_2d", "_source/modules/generated/modeva.DataSet.eda_3d", "_source/modules/generated/modeva.DataSet.eda_correlation", "_source/modules/generated/modeva.DataSet.eda_pca", "_source/modules/generated/modeva.DataSet.eda_umap", "_source/modules/generated/modeva.DataSet.encode_categorical", "_source/modules/generated/modeva.DataSet.feature_names", "_source/modules/generated/modeva.DataSet.feature_names_categorical", "_source/modules/generated/modeva.DataSet.feature_names_mixed", "_source/modules/generated/modeva.DataSet.feature_names_numerical", "_source/modules/generated/modeva.DataSet.feature_select_corr", "_source/modules/generated/modeva.DataSet.feature_select_rcit", "_source/modules/generated/modeva.DataSet.feature_select_xgbpfi", "_source/modules/generated/modeva.DataSet.feature_types", "_source/modules/generated/modeva.DataSet.get_X_y_data", "_source/modules/generated/modeva.DataSet.get_active_sample_idx", "_source/modules/generated/modeva.DataSet.get_data", "_source/modules/generated/modeva.DataSet.get_data_list", "_source/modules/generated/modeva.DataSet.get_extra_data_list", "_source/modules/generated/modeva.DataSet.get_preprocessor", "_source/modules/generated/modeva.DataSet.get_protected_data", "_source/modules/generated/modeva.DataSet.get_raw_data", "_source/modules/generated/modeva.DataSet.impute_missing", "_source/modules/generated/modeva.DataSet.inverse_transform", "_source/modules/generated/modeva.DataSet.is_splitted", "_source/modules/generated/modeva.DataSet.list_registered_data", "_source/modules/generated/modeva.DataSet.load", "_source/modules/generated/modeva.DataSet.load_csv", "_source/modules/generated/modeva.DataSet.load_dataframe", "_source/modules/generated/modeva.DataSet.load_dataframe_train_test", "_source/modules/generated/modeva.DataSet.load_preprocessing", "_source/modules/generated/modeva.DataSet.load_registered_data", "_source/modules/generated/modeva.DataSet.load_spark", "_source/modules/generated/modeva.DataSet.n_features", "_source/modules/generated/modeva.DataSet.name", "_source/modules/generated/modeva.DataSet.prediction_name", "_source/modules/generated/modeva.DataSet.prediction_proba_name", "_source/modules/generated/modeva.DataSet.preprocess", "_source/modules/generated/modeva.DataSet.protected_feature_names", "_source/modules/generated/modeva.DataSet.raw_data", "_source/modules/generated/modeva.DataSet.register", "_source/modules/generated/modeva.DataSet.reset_preprocess", "_source/modules/generated/modeva.DataSet.sample_weight", "_source/modules/generated/modeva.DataSet.sample_weight_name", "_source/modules/generated/modeva.DataSet.save_preprocessing", "_source/modules/generated/modeva.DataSet.scale_numerical", "_source/modules/generated/modeva.DataSet.set_active_features", "_source/modules/generated/modeva.DataSet.set_feature_type", "_source/modules/generated/modeva.DataSet.set_inactive_features", "_source/modules/generated/modeva.DataSet.set_prediction", "_source/modules/generated/modeva.DataSet.set_prediction_proba", "_source/modules/generated/modeva.DataSet.set_protected_data", "_source/modules/generated/modeva.DataSet.set_protected_extra_data", "_source/modules/generated/modeva.DataSet.set_random_split", "_source/modules/generated/modeva.DataSet.set_raw_extra_data", "_source/modules/generated/modeva.DataSet.set_sample_weight", "_source/modules/generated/modeva.DataSet.set_target", "_source/modules/generated/modeva.DataSet.set_task_type", "_source/modules/generated/modeva.DataSet.set_test_idx", "_source/modules/generated/modeva.DataSet.set_train_idx", "_source/modules/generated/modeva.DataSet.shape", "_source/modules/generated/modeva.DataSet.subsample_random", "_source/modules/generated/modeva.DataSet.summary", "_source/modules/generated/modeva.DataSet.target_feature_name", "_source/modules/generated/modeva.DataSet.task_type", "_source/modules/generated/modeva.DataSet.test_sample_weight", "_source/modules/generated/modeva.DataSet.test_x", "_source/modules/generated/modeva.DataSet.test_y", "_source/modules/generated/modeva.DataSet.to_df", "_source/modules/generated/modeva.DataSet.train_sample_weight", "_source/modules/generated/modeva.DataSet.train_x", "_source/modules/generated/modeva.DataSet.train_y", "_source/modules/generated/modeva.DataSet.transform", "_source/modules/generated/modeva.DataSet.x", "_source/modules/generated/modeva.DataSet.y", "_source/modules/generated/modeva.ModelZoo.add_model", "_source/modules/generated/modeva.ModelZoo.dataset", "_source/modules/generated/modeva.ModelZoo.delete_registered_model", "_source/modules/generated/modeva.ModelZoo.get_model", "_source/modules/generated/modeva.ModelZoo.leaderboard", "_source/modules/generated/modeva.ModelZoo.list_model_names", "_source/modules/generated/modeva.ModelZoo.list_registered_models", "_source/modules/generated/modeva.ModelZoo.load_registered_model", "_source/modules/generated/modeva.ModelZoo.models", "_source/modules/generated/modeva.ModelZoo.register", "_source/modules/generated/modeva.ModelZoo.train", "_source/modules/generated/modeva.ModelZoo.train_all", "_source/modules/generated/modeva.TestSuite.compare_accuracy_table", "_source/modules/generated/modeva.TestSuite.compare_fairness", "_source/modules/generated/modeva.TestSuite.compare_reliability", "_source/modules/generated/modeva.TestSuite.compare_residual_cluster", "_source/modules/generated/modeva.TestSuite.compare_resilience", "_source/modules/generated/modeva.TestSuite.compare_robustness", "_source/modules/generated/modeva.TestSuite.compare_slicing_accuracy", "_source/modules/generated/modeva.TestSuite.compare_slicing_fairness", "_source/modules/generated/modeva.TestSuite.compare_slicing_overfit", "_source/modules/generated/modeva.TestSuite.compare_slicing_reliability", "_source/modules/generated/modeva.TestSuite.compare_slicing_robustness", "_source/modules/generated/modeva.TestSuite.delete_registed_test", "_source/modules/generated/modeva.TestSuite.diagnose_accuracy_table", "_source/modules/generated/modeva.TestSuite.diagnose_fairness", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_binning", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_thresholding", "_source/modules/generated/modeva.TestSuite.diagnose_reliability", "_source/modules/generated/modeva.TestSuite.diagnose_residual_analysis", "_source/modules/generated/modeva.TestSuite.diagnose_residual_cluster", "_source/modules/generated/modeva.TestSuite.diagnose_residual_interpret", "_source/modules/generated/modeva.TestSuite.diagnose_resilience", "_source/modules/generated/modeva.TestSuite.diagnose_robustness", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_accuracy", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_fairness", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_overfit", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_reliability", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_robustness", "_source/modules/generated/modeva.TestSuite.display_test_results", "_source/modules/generated/modeva.TestSuite.explain_ale", "_source/modules/generated/modeva.TestSuite.explain_hstatistic", "_source/modules/generated/modeva.TestSuite.explain_lime", "_source/modules/generated/modeva.TestSuite.explain_pdp", "_source/modules/generated/modeva.TestSuite.explain_pfi", "_source/modules/generated/modeva.TestSuite.explain_shap", "_source/modules/generated/modeva.TestSuite.export_report", "_source/modules/generated/modeva.TestSuite.get_dataset", "_source/modules/generated/modeva.TestSuite.get_interactions", "_source/modules/generated/modeva.TestSuite.get_main_effects", "_source/modules/generated/modeva.TestSuite.get_model", "_source/modules/generated/modeva.TestSuite.interpret_coef", "_source/modules/generated/modeva.TestSuite.interpret_effects", "_source/modules/generated/modeva.TestSuite.interpret_effects_moe_average", "_source/modules/generated/modeva.TestSuite.interpret_fi", "_source/modules/generated/modeva.TestSuite.interpret_global_tree", "_source/modules/generated/modeva.TestSuite.interpret_llm_pc", "_source/modules/generated/modeva.TestSuite.interpret_llm_profile", "_source/modules/generated/modeva.TestSuite.interpret_llm_summary", "_source/modules/generated/modeva.TestSuite.interpret_llm_violin", "_source/modules/generated/modeva.TestSuite.interpret_local_fi", "_source/modules/generated/modeva.TestSuite.interpret_local_linear_fi", "_source/modules/generated/modeva.TestSuite.interpret_local_moe_weights", "_source/modules/generated/modeva.TestSuite.interpret_local_tree", "_source/modules/generated/modeva.TestSuite.interpret_moe_cluster_analysis", "_source/modules/generated/modeva.TestSuite.list", "_source/modules/generated/modeva.TestSuite.list_registered_tests", "_source/modules/generated/modeva.TestSuite.load_registered_test", "_source/modules/generated/modeva.TestSuite.register", "_source/modules/generated/modeva.TestSuite.set_dataset", "_source/modules/generated/modeva.TestSuite.set_model", "_source/modules/generated/modeva.automation.pipeline.Pipeline", "_source/modules/generated/modeva.models.MoCatBoostClassifier", "_source/modules/generated/modeva.models.MoCatBoostRegressor", "_source/modules/generated/modeva.models.MoClassifier", "_source/modules/generated/modeva.models.MoDecisionTreeClassifier", "_source/modules/generated/modeva.models.MoDecisionTreeRegressor", "_source/modules/generated/modeva.models.MoElasticNet", "_source/modules/generated/modeva.models.MoGAMINetClassifier", "_source/modules/generated/modeva.models.MoGAMINetRegressor", "_source/modules/generated/modeva.models.MoGLMTreeBoostClassifier", "_source/modules/generated/modeva.models.MoGLMTreeBoostRegressor", "_source/modules/generated/modeva.models.MoGLMTreeClassifier", "_source/modules/generated/modeva.models.MoGLMTreeRegressor", "_source/modules/generated/modeva.models.MoGradientBoostingClassifier", "_source/modules/generated/modeva.models.MoGradientBoostingRegressor", "_source/modules/generated/modeva.models.MoLGBMClassifier", "_source/modules/generated/modeva.models.MoLGBMRegressor", "_source/modules/generated/modeva.models.MoLogisticRegression", "_source/modules/generated/modeva.models.MoMoEClassifier", "_source/modules/generated/modeva.models.MoMoERegressor", "_source/modules/generated/modeva.models.MoNeuralTreeClassifier", "_source/modules/generated/modeva.models.MoNeuralTreeRegressor", "_source/modules/generated/modeva.models.MoRandomForestClassifier", "_source/modules/generated/modeva.models.MoRandomForestRegressor", "_source/modules/generated/modeva.models.MoReLUDNNClassifier", "_source/modules/generated/modeva.models.MoReLUDNNRegressor", "_source/modules/generated/modeva.models.MoRegressor", "_source/modules/generated/modeva.models.MoSKLearnClassifier", "_source/modules/generated/modeva.models.MoSKLearnRegressor", "_source/modules/generated/modeva.models.MoScoredClassifier", "_source/modules/generated/modeva.models.MoScoredRegressor", "_source/modules/generated/modeva.models.MoXGBClassifier", "_source/modules/generated/modeva.models.MoXGBRegressor", "_source/modules/generated/modeva.models.ModelBaseClassifier", "_source/modules/generated/modeva.models.ModelBaseRegressor", "_source/modules/generated/modeva.models.ModelTuneGridSearch", "_source/modules/generated/modeva.models.ModelTuneOptuna", "_source/modules/generated/modeva.models.ModelTunePSO", "_source/modules/generated/modeva.models.ModelTuneRandomSearch", "_source/modules/generated/modeva.testsuite.utils.slicing_utils.get_data_info", "_source/modules/generated/modeva.utils.mlflow.clear_mlflow_home", "_source/modules/generated/modeva.utils.mlflow.get_mlflow_home", "_source/modules/generated/modeva.utils.mlflow.set_mlflow_home", "_source/modules/generated/modeva.utils.results.ValidationResult", "_source/modules/hpo", "_source/modules/models", "_source/modules/modelzoo", "_source/modules/pipeline", "_source/modules/results", "_source/modules/testsuite", "_source/modules/utilities", "_source/modules/wrappers", "_source/usage", "_source/user_guide/calibration", "_source/user_guide/calibration/pred_interval_cls", "_source/user_guide/calibration/pred_interval_reg", "_source/user_guide/calibration/pred_proba", "_source/user_guide/compare", "_source/user_guide/compare/compare_classification", "_source/user_guide/compare/compare_fairness", "_source/user_guide/compare/compare_regression", "_source/user_guide/data", "_source/user_guide/data/data_basic_operations", "_source/user_guide/data/data_quality_drift", "_source/user_guide/data/data_quality_outlier", "_source/user_guide/data/data_summary", "_source/user_guide/data/eda", "_source/user_guide/data/feature_select", "_source/user_guide/data/outlier_detect", "_source/user_guide/data/subsample", "_source/user_guide/explain", "_source/user_guide/explain/Global", "_source/user_guide/explain/Local", "_source/user_guide/explain/ale", "_source/user_guide/explain/hstats", "_source/user_guide/explain/ice", "_source/user_guide/explain/lime", "_source/user_guide/explain/pdp", "_source/user_guide/explain/pfi", "_source/user_guide/explain/shap", "_source/user_guide/introduction", "_source/user_guide/low_code", "_source/user_guide/low_code/data_process", "_source/user_guide/low_code/data_summary", "_source/user_guide/low_code/eda_2d", "_source/user_guide/low_code/eda_3d", "_source/user_guide/low_code/eda_multivariate", "_source/user_guide/low_code/model_compare", "_source/user_guide/low_code/model_explainability", "_source/user_guide/low_code/model_test", "_source/user_guide/low_code/model_train", "_source/user_guide/low_code/model_tune", "_source/user_guide/low_code/model_weakness", "_source/user_guide/low_code/registry_hub", "_source/user_guide/models", "_source/user_guide/models/gaminet", "_source/user_guide/models/gbdt", "_source/user_guide/models/gblt", "_source/user_guide/models/glm", "_source/user_guide/models/moe", "_source/user_guide/models/neuraltree", "_source/user_guide/models/reludnn", "_source/user_guide/models/tree", "_source/user_guide/modelwrapping", "_source/user_guide/testing", "_source/user_guide/testing/fairness", "_source/user_guide/testing/overfit", "_source/user_guide/testing/performance", "_source/user_guide/testing/reliability", "_source/user_guide/testing/resilience", "_source/user_guide/testing/robustness", "_source/user_guide/testing/weakspot", "_source/user_guide/train", "_source/user_guide/wrapping/h2o", "_source/user_guide/wrapping/hpo", "_source/user_guide/wrapping/modelzoo", "_source/user_guide/wrapping/wrappers", "index", "sg_api_usage", "sg_execution_times"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2}, "filenames": ["_source/api_ref.rst", "_source/auto_galleries/data/index.rst", "_source/auto_galleries/data/plot_0_data_operations.rst", "_source/auto_galleries/data/plot_1_eda.rst", "_source/auto_galleries/data/plot_2_feature_selection.rst", "_source/auto_galleries/data/plot_3_feature_engineering.rst", "_source/auto_galleries/data/plot_4_subsampling.rst", "_source/auto_galleries/data/plot_5_drift_test.rst", "_source/auto_galleries/data/plot_6_outlier_detection.rst", "_source/auto_galleries/data/plot_7_data_with_prediction.rst", "_source/auto_galleries/data/plot_8_extra_data.rst", "_source/auto_galleries/data/plot_9_date_variable.rst", "_source/auto_galleries/data/sg_execution_times.rst", "_source/auto_galleries/dev/0_models/index.rst", "_source/auto_galleries/dev/0_models/plot_0_glm_cls.rst", "_source/auto_galleries/dev/0_models/plot_0_glm_reg.rst", "_source/auto_galleries/dev/0_models/plot_1_dt_cls.rst", "_source/auto_galleries/dev/0_models/plot_1_dt_reg.rst", "_source/auto_galleries/dev/0_models/plot_2_reludnn_cls.rst", "_source/auto_galleries/dev/0_models/plot_2_reludnn_reg.rst", "_source/auto_galleries/dev/0_models/plot_3_gaminet_cls.rst", "_source/auto_galleries/dev/0_models/plot_3_gaminet_reg.rst", "_source/auto_galleries/dev/0_models/plot_4_moe_cls.rst", "_source/auto_galleries/dev/0_models/plot_4_moe_reg.rst", "_source/auto_galleries/dev/0_models/plot_5_lineartree_cls.rst", "_source/auto_galleries/dev/0_models/plot_5_lineartree_reg.rst", "_source/auto_galleries/dev/0_models/plot_6_const_tree_cls.rst", "_source/auto_galleries/dev/0_models/plot_6_const_tree_reg.rst", "_source/auto_galleries/dev/0_models/sg_execution_times.rst", "_source/auto_galleries/dev/1_extmodels/index.rst", "_source/auto_galleries/dev/1_extmodels/noplot_3_h2o.rst", "_source/auto_galleries/dev/1_extmodels/noplot_4_spark.rst", "_source/auto_galleries/dev/1_extmodels/plot_0_sklearn.rst", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_cls.rst", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_reg.rst", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_cls.rst", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_reg.rst", "_source/auto_galleries/dev/1_extmodels/sg_execution_times.rst", "_source/auto_galleries/dev/2_calibration/index.rst", "_source/auto_galleries/dev/2_calibration/plot_0_calibrate_proba.rst", "_source/auto_galleries/dev/2_calibration/plot_1_calibrate_interval_cls.rst", "_source/auto_galleries/dev/2_calibration/plot_1_calibrate_interval_reg.rst", "_source/auto_galleries/dev/2_calibration/sg_execution_times.rst", "_source/auto_galleries/dev/3_hpo/index.rst", "_source/auto_galleries/dev/3_hpo/plot_0_grid.rst", "_source/auto_galleries/dev/3_hpo/plot_1_random.rst", "_source/auto_galleries/dev/3_hpo/plot_2_pso.rst", "_source/auto_galleries/dev/3_hpo/plot_3_optuna.rst", "_source/auto_galleries/dev/3_hpo/sg_execution_times.rst", "_source/auto_galleries/dev/index.rst", "_source/auto_galleries/dev/plot_0_modelzoo.rst", "_source/auto_galleries/dev/sg_execution_times.rst", "_source/auto_galleries/get_started/index.rst", "_source/auto_galleries/get_started/plot_0_demo.rst", "_source/auto_galleries/get_started/plot_0_diagnostics_date.rst", "_source/auto_galleries/get_started/sg_execution_times.rst", "_source/auto_galleries/util/index.rst", "_source/auto_galleries/util/plot_0_valres_attributes.rst", "_source/auto_galleries/util/plot_1_valres_save.rst", "_source/auto_galleries/util/plot_2_pipeline.rst", "_source/auto_galleries/util/sg_execution_times.rst", "_source/auto_galleries/val/0_residual/index.rst", "_source/auto_galleries/val/0_residual/plot_0_residual_cls.rst", "_source/auto_galleries/val/0_residual/plot_0_residual_reg.rst", "_source/auto_galleries/val/0_residual/sg_execution_times.rst", "_source/auto_galleries/val/1_performance/index.rst", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_cls.rst", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_reg.rst", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_cls.rst", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_reg.rst", "_source/auto_galleries/val/1_performance/sg_execution_times.rst", "_source/auto_galleries/val/2_overfitting/index.rst", "_source/auto_galleries/val/2_overfitting/plot_0_slice_overfit_cls.rst", "_source/auto_galleries/val/2_overfitting/plot_1_slice_overfit_reg.rst", "_source/auto_galleries/val/2_overfitting/sg_execution_times.rst", "_source/auto_galleries/val/3_reliability/index.rst", "_source/auto_galleries/val/3_reliability/plot_0_reliability_cls.rst", "_source/auto_galleries/val/3_reliability/plot_1_reliability_reg.rst", "_source/auto_galleries/val/3_reliability/sg_execution_times.rst", "_source/auto_galleries/val/4_resilience/index.rst", "_source/auto_galleries/val/4_resilience/plot_0_resilience_cls.rst", "_source/auto_galleries/val/4_resilience/plot_1_resilience_reg.rst", "_source/auto_galleries/val/4_resilience/sg_execution_times.rst", "_source/auto_galleries/val/5_robustness/index.rst", "_source/auto_galleries/val/5_robustness/plot_0_robustness_cls.rst", "_source/auto_galleries/val/5_robustness/plot_1_robustness_reg.rst", "_source/auto_galleries/val/5_robustness/sg_execution_times.rst", "_source/auto_galleries/val/6_fairness/index.rst", "_source/auto_galleries/val/6_fairness/plot_0_fairness_cls.rst", "_source/auto_galleries/val/6_fairness/sg_execution_times.rst", "_source/auto_galleries/val/7_explainability/index.rst", "_source/auto_galleries/val/7_explainability/plot_0_global_explain.rst", "_source/auto_galleries/val/7_explainability/plot_1_local_explain.rst", "_source/auto_galleries/val/7_explainability/sg_execution_times.rst", "_source/auto_galleries/val/index.rst", "_source/auto_galleries/val/sg_execution_times.rst", "_source/changes.rst", "_source/faq.rst", "_source/galleries.rst", "_source/gen_modules/sphinx_gallery.backreferences.rst", "_source/gen_modules/sphinx_gallery.block_parser.rst", "_source/gen_modules/sphinx_gallery.directives.rst", "_source/gen_modules/sphinx_gallery.docs_resolv.rst", "_source/gen_modules/sphinx_gallery.downloads.rst", "_source/gen_modules/sphinx_gallery.gen_gallery.rst", "_source/gen_modules/sphinx_gallery.gen_rst.rst", "_source/gen_modules/sphinx_gallery.interactive_example.rst", "_source/gen_modules/sphinx_gallery.notebook.rst", "_source/gen_modules/sphinx_gallery.py_source_parser.rst", "_source/gen_modules/sphinx_gallery.scrapers.rst", "_source/gen_modules/sphinx_gallery.sorting.rst", "_source/gen_modules/sphinx_gallery.utils.optipng.rst", "_source/install.rst", "_source/lowcode-gallery.rst", "_source/modules/data.rst", "_source/modules/generated/modeva.DataSet.all_feature_names.rst", "_source/modules/generated/modeva.DataSet.all_feature_types.rst", "_source/modules/generated/modeva.DataSet.bin_numerical.rst", "_source/modules/generated/modeva.DataSet.data.rst", "_source/modules/generated/modeva.DataSet.data_drift_test.rst", "_source/modules/generated/modeva.DataSet.delete_extra_data.rst", "_source/modules/generated/modeva.DataSet.delete_registered_data.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_cblof.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_isolation_forest.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_pca.rst", "_source/modules/generated/modeva.DataSet.eda_1d.rst", "_source/modules/generated/modeva.DataSet.eda_2d.rst", "_source/modules/generated/modeva.DataSet.eda_3d.rst", "_source/modules/generated/modeva.DataSet.eda_correlation.rst", "_source/modules/generated/modeva.DataSet.eda_pca.rst", "_source/modules/generated/modeva.DataSet.eda_umap.rst", "_source/modules/generated/modeva.DataSet.encode_categorical.rst", "_source/modules/generated/modeva.DataSet.feature_names.rst", "_source/modules/generated/modeva.DataSet.feature_names_categorical.rst", "_source/modules/generated/modeva.DataSet.feature_names_mixed.rst", "_source/modules/generated/modeva.DataSet.feature_names_numerical.rst", "_source/modules/generated/modeva.DataSet.feature_select_corr.rst", "_source/modules/generated/modeva.DataSet.feature_select_rcit.rst", "_source/modules/generated/modeva.DataSet.feature_select_xgbpfi.rst", "_source/modules/generated/modeva.DataSet.feature_types.rst", "_source/modules/generated/modeva.DataSet.get_X_y_data.rst", "_source/modules/generated/modeva.DataSet.get_active_sample_idx.rst", "_source/modules/generated/modeva.DataSet.get_data.rst", "_source/modules/generated/modeva.DataSet.get_data_list.rst", "_source/modules/generated/modeva.DataSet.get_extra_data_list.rst", "_source/modules/generated/modeva.DataSet.get_preprocessor.rst", "_source/modules/generated/modeva.DataSet.get_protected_data.rst", "_source/modules/generated/modeva.DataSet.get_raw_data.rst", "_source/modules/generated/modeva.DataSet.impute_missing.rst", "_source/modules/generated/modeva.DataSet.inverse_transform.rst", "_source/modules/generated/modeva.DataSet.is_splitted.rst", "_source/modules/generated/modeva.DataSet.list_registered_data.rst", "_source/modules/generated/modeva.DataSet.load.rst", "_source/modules/generated/modeva.DataSet.load_csv.rst", "_source/modules/generated/modeva.DataSet.load_dataframe.rst", "_source/modules/generated/modeva.DataSet.load_dataframe_train_test.rst", "_source/modules/generated/modeva.DataSet.load_preprocessing.rst", "_source/modules/generated/modeva.DataSet.load_registered_data.rst", "_source/modules/generated/modeva.DataSet.load_spark.rst", "_source/modules/generated/modeva.DataSet.n_features.rst", "_source/modules/generated/modeva.DataSet.name.rst", "_source/modules/generated/modeva.DataSet.prediction_name.rst", "_source/modules/generated/modeva.DataSet.prediction_proba_name.rst", "_source/modules/generated/modeva.DataSet.preprocess.rst", "_source/modules/generated/modeva.DataSet.protected_feature_names.rst", "_source/modules/generated/modeva.DataSet.raw_data.rst", "_source/modules/generated/modeva.DataSet.register.rst", "_source/modules/generated/modeva.DataSet.reset_preprocess.rst", "_source/modules/generated/modeva.DataSet.sample_weight.rst", "_source/modules/generated/modeva.DataSet.sample_weight_name.rst", "_source/modules/generated/modeva.DataSet.save_preprocessing.rst", "_source/modules/generated/modeva.DataSet.scale_numerical.rst", "_source/modules/generated/modeva.DataSet.set_active_features.rst", "_source/modules/generated/modeva.DataSet.set_feature_type.rst", "_source/modules/generated/modeva.DataSet.set_inactive_features.rst", "_source/modules/generated/modeva.DataSet.set_prediction.rst", "_source/modules/generated/modeva.DataSet.set_prediction_proba.rst", "_source/modules/generated/modeva.DataSet.set_protected_data.rst", "_source/modules/generated/modeva.DataSet.set_protected_extra_data.rst", "_source/modules/generated/modeva.DataSet.set_random_split.rst", "_source/modules/generated/modeva.DataSet.set_raw_extra_data.rst", "_source/modules/generated/modeva.DataSet.set_sample_weight.rst", "_source/modules/generated/modeva.DataSet.set_target.rst", "_source/modules/generated/modeva.DataSet.set_task_type.rst", "_source/modules/generated/modeva.DataSet.set_test_idx.rst", "_source/modules/generated/modeva.DataSet.set_train_idx.rst", "_source/modules/generated/modeva.DataSet.shape.rst", "_source/modules/generated/modeva.DataSet.subsample_random.rst", "_source/modules/generated/modeva.DataSet.summary.rst", "_source/modules/generated/modeva.DataSet.target_feature_name.rst", "_source/modules/generated/modeva.DataSet.task_type.rst", "_source/modules/generated/modeva.DataSet.test_sample_weight.rst", "_source/modules/generated/modeva.DataSet.test_x.rst", "_source/modules/generated/modeva.DataSet.test_y.rst", "_source/modules/generated/modeva.DataSet.to_df.rst", "_source/modules/generated/modeva.DataSet.train_sample_weight.rst", "_source/modules/generated/modeva.DataSet.train_x.rst", "_source/modules/generated/modeva.DataSet.train_y.rst", "_source/modules/generated/modeva.DataSet.transform.rst", "_source/modules/generated/modeva.DataSet.x.rst", "_source/modules/generated/modeva.DataSet.y.rst", "_source/modules/generated/modeva.ModelZoo.add_model.rst", "_source/modules/generated/modeva.ModelZoo.dataset.rst", "_source/modules/generated/modeva.ModelZoo.delete_registered_model.rst", "_source/modules/generated/modeva.ModelZoo.get_model.rst", "_source/modules/generated/modeva.ModelZoo.leaderboard.rst", "_source/modules/generated/modeva.ModelZoo.list_model_names.rst", "_source/modules/generated/modeva.ModelZoo.list_registered_models.rst", "_source/modules/generated/modeva.ModelZoo.load_registered_model.rst", "_source/modules/generated/modeva.ModelZoo.models.rst", "_source/modules/generated/modeva.ModelZoo.register.rst", "_source/modules/generated/modeva.ModelZoo.train.rst", "_source/modules/generated/modeva.ModelZoo.train_all.rst", "_source/modules/generated/modeva.TestSuite.compare_accuracy_table.rst", "_source/modules/generated/modeva.TestSuite.compare_fairness.rst", "_source/modules/generated/modeva.TestSuite.compare_reliability.rst", "_source/modules/generated/modeva.TestSuite.compare_residual_cluster.rst", "_source/modules/generated/modeva.TestSuite.compare_resilience.rst", "_source/modules/generated/modeva.TestSuite.compare_robustness.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_accuracy.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_fairness.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_overfit.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_reliability.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_robustness.rst", "_source/modules/generated/modeva.TestSuite.delete_registed_test.rst", "_source/modules/generated/modeva.TestSuite.diagnose_accuracy_table.rst", "_source/modules/generated/modeva.TestSuite.diagnose_fairness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_binning.rst", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_thresholding.rst", "_source/modules/generated/modeva.TestSuite.diagnose_reliability.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_analysis.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_cluster.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_interpret.rst", "_source/modules/generated/modeva.TestSuite.diagnose_resilience.rst", "_source/modules/generated/modeva.TestSuite.diagnose_robustness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_accuracy.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_fairness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_overfit.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_reliability.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_robustness.rst", "_source/modules/generated/modeva.TestSuite.display_test_results.rst", "_source/modules/generated/modeva.TestSuite.explain_ale.rst", "_source/modules/generated/modeva.TestSuite.explain_hstatistic.rst", "_source/modules/generated/modeva.TestSuite.explain_lime.rst", "_source/modules/generated/modeva.TestSuite.explain_pdp.rst", "_source/modules/generated/modeva.TestSuite.explain_pfi.rst", "_source/modules/generated/modeva.TestSuite.explain_shap.rst", "_source/modules/generated/modeva.TestSuite.export_report.rst", "_source/modules/generated/modeva.TestSuite.get_dataset.rst", "_source/modules/generated/modeva.TestSuite.get_interactions.rst", "_source/modules/generated/modeva.TestSuite.get_main_effects.rst", "_source/modules/generated/modeva.TestSuite.get_model.rst", "_source/modules/generated/modeva.TestSuite.interpret_coef.rst", "_source/modules/generated/modeva.TestSuite.interpret_effects.rst", "_source/modules/generated/modeva.TestSuite.interpret_effects_moe_average.rst", "_source/modules/generated/modeva.TestSuite.interpret_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_global_tree.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_pc.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_profile.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_summary.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_violin.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_linear_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_moe_weights.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_tree.rst", "_source/modules/generated/modeva.TestSuite.interpret_moe_cluster_analysis.rst", "_source/modules/generated/modeva.TestSuite.list.rst", "_source/modules/generated/modeva.TestSuite.list_registered_tests.rst", "_source/modules/generated/modeva.TestSuite.load_registered_test.rst", "_source/modules/generated/modeva.TestSuite.register.rst", "_source/modules/generated/modeva.TestSuite.set_dataset.rst", "_source/modules/generated/modeva.TestSuite.set_model.rst", "_source/modules/generated/modeva.automation.pipeline.Pipeline.rst", "_source/modules/generated/modeva.models.MoCatBoostClassifier.rst", "_source/modules/generated/modeva.models.MoCatBoostRegressor.rst", "_source/modules/generated/modeva.models.MoClassifier.rst", "_source/modules/generated/modeva.models.MoDecisionTreeClassifier.rst", "_source/modules/generated/modeva.models.MoDecisionTreeRegressor.rst", "_source/modules/generated/modeva.models.MoElasticNet.rst", "_source/modules/generated/modeva.models.MoGAMINetClassifier.rst", "_source/modules/generated/modeva.models.MoGAMINetRegressor.rst", "_source/modules/generated/modeva.models.MoGLMTreeBoostClassifier.rst", "_source/modules/generated/modeva.models.MoGLMTreeBoostRegressor.rst", "_source/modules/generated/modeva.models.MoGLMTreeClassifier.rst", "_source/modules/generated/modeva.models.MoGLMTreeRegressor.rst", "_source/modules/generated/modeva.models.MoGradientBoostingClassifier.rst", "_source/modules/generated/modeva.models.MoGradientBoostingRegressor.rst", "_source/modules/generated/modeva.models.MoLGBMClassifier.rst", "_source/modules/generated/modeva.models.MoLGBMRegressor.rst", "_source/modules/generated/modeva.models.MoLogisticRegression.rst", "_source/modules/generated/modeva.models.MoMoEClassifier.rst", "_source/modules/generated/modeva.models.MoMoERegressor.rst", "_source/modules/generated/modeva.models.MoNeuralTreeClassifier.rst", "_source/modules/generated/modeva.models.MoNeuralTreeRegressor.rst", "_source/modules/generated/modeva.models.MoRandomForestClassifier.rst", "_source/modules/generated/modeva.models.MoRandomForestRegressor.rst", "_source/modules/generated/modeva.models.MoReLUDNNClassifier.rst", "_source/modules/generated/modeva.models.MoReLUDNNRegressor.rst", "_source/modules/generated/modeva.models.MoRegressor.rst", "_source/modules/generated/modeva.models.MoSKLearnClassifier.rst", "_source/modules/generated/modeva.models.MoSKLearnRegressor.rst", "_source/modules/generated/modeva.models.MoScoredClassifier.rst", "_source/modules/generated/modeva.models.MoScoredRegressor.rst", "_source/modules/generated/modeva.models.MoXGBClassifier.rst", "_source/modules/generated/modeva.models.MoXGBRegressor.rst", "_source/modules/generated/modeva.models.ModelBaseClassifier.rst", "_source/modules/generated/modeva.models.ModelBaseRegressor.rst", "_source/modules/generated/modeva.models.ModelTuneGridSearch.rst", "_source/modules/generated/modeva.models.ModelTuneOptuna.rst", "_source/modules/generated/modeva.models.ModelTunePSO.rst", "_source/modules/generated/modeva.models.ModelTuneRandomSearch.rst", "_source/modules/generated/modeva.testsuite.utils.slicing_utils.get_data_info.rst", "_source/modules/generated/modeva.utils.mlflow.clear_mlflow_home.rst", "_source/modules/generated/modeva.utils.mlflow.get_mlflow_home.rst", "_source/modules/generated/modeva.utils.mlflow.set_mlflow_home.rst", "_source/modules/generated/modeva.utils.results.ValidationResult.rst", "_source/modules/hpo.rst", "_source/modules/models.rst", "_source/modules/modelzoo.rst", "_source/modules/pipeline.rst", "_source/modules/results.rst", "_source/modules/testsuite.rst", "_source/modules/utilities.rst", "_source/modules/wrappers.rst", "_source/usage.rst", "_source/user_guide/calibration.rst", "_source/user_guide/calibration/pred_interval_cls.rst", "_source/user_guide/calibration/pred_interval_reg.rst", "_source/user_guide/calibration/pred_proba.rst", "_source/user_guide/compare.rst", "_source/user_guide/compare/compare_classification.rst", "_source/user_guide/compare/compare_fairness.rst", "_source/user_guide/compare/compare_regression.rst", "_source/user_guide/data.rst", "_source/user_guide/data/data_basic_operations.rst", "_source/user_guide/data/data_quality_drift.rst", "_source/user_guide/data/data_quality_outlier.rst", "_source/user_guide/data/data_summary.rst", "_source/user_guide/data/eda.rst", "_source/user_guide/data/feature_select.rst", "_source/user_guide/data/outlier_detect.rst", "_source/user_guide/data/subsample.rst", "_source/user_guide/explain.rst", "_source/user_guide/explain/Global.rst", "_source/user_guide/explain/Local.rst", "_source/user_guide/explain/ale.rst", "_source/user_guide/explain/hstats.rst", "_source/user_guide/explain/ice.rst", "_source/user_guide/explain/lime.rst", "_source/user_guide/explain/pdp.rst", "_source/user_guide/explain/pfi.rst", "_source/user_guide/explain/shap.rst", "_source/user_guide/introduction.rst", "_source/user_guide/low_code.rst", "_source/user_guide/low_code/data_process.rst", "_source/user_guide/low_code/data_summary.rst", "_source/user_guide/low_code/eda_2d.rst", "_source/user_guide/low_code/eda_3d.rst", "_source/user_guide/low_code/eda_multivariate.rst", "_source/user_guide/low_code/model_compare.rst", "_source/user_guide/low_code/model_explainability.rst", "_source/user_guide/low_code/model_test.rst", "_source/user_guide/low_code/model_train.rst", "_source/user_guide/low_code/model_tune.rst", "_source/user_guide/low_code/model_weakness.rst", "_source/user_guide/low_code/registry_hub.rst", "_source/user_guide/models.rst", "_source/user_guide/models/gaminet.rst", "_source/user_guide/models/gbdt.rst", "_source/user_guide/models/gblt.rst", "_source/user_guide/models/glm.rst", "_source/user_guide/models/moe.rst", "_source/user_guide/models/neuraltree.rst", "_source/user_guide/models/reludnn.rst", "_source/user_guide/models/tree.rst", "_source/user_guide/modelwrapping.rst", "_source/user_guide/testing.rst", "_source/user_guide/testing/fairness.rst", "_source/user_guide/testing/overfit.rst", "_source/user_guide/testing/performance.rst", "_source/user_guide/testing/reliability.rst", "_source/user_guide/testing/resilience.rst", "_source/user_guide/testing/robustness.rst", "_source/user_guide/testing/weakspot.rst", "_source/user_guide/train.rst", "_source/user_guide/wrapping/h2o.rst", "_source/user_guide/wrapping/hpo.rst", "_source/user_guide/wrapping/modelzoo.rst", "_source/user_guide/wrapping/wrappers.rst", "index.rst", "sg_api_usage.rst", "sg_execution_times.rst"], "indexentries": {"active_interaction_index_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.active_interaction_index_", false]], "active_interaction_index_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.active_interaction_index_", false]], "active_main_effect_index_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.active_main_effect_index_", false]], "active_main_effect_index_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.active_main_effect_index_", false]], "add_model() (modeva.modelzoo method)": [[201, "modeva.ModelZoo.add_model", false]], "add_step() (modeva.automation.pipeline.pipeline method)": [[272, "modeva.automation.pipeline.Pipeline.add_step", false]], "all_feature_names (modeva.dataset property)": [[115, "modeva.DataSet.all_feature_names", false]], "all_feature_types (modeva.dataset property)": [[116, "modeva.DataSet.all_feature_types", false]], "bin_numerical() (modeva.dataset method)": [[117, "modeva.DataSet.bin_numerical", false]], "calibrate_interval() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.calibrate_interval", false]], "calibrate_interval() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.calibrate_interval", false]], "calibrate_proba() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.calibrate_proba", false]], "calibrate_proba() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.calibrate_proba", false]], "clear_mlflow_home() (in module modeva.utils.mlflow)": [[312, "modeva.utils.mlflow.clear_mlflow_home", false]], "compare_accuracy_table() (modeva.testsuite method)": [[213, "modeva.TestSuite.compare_accuracy_table", false]], "compare_fairness() (modeva.testsuite method)": [[214, "modeva.TestSuite.compare_fairness", false]], "compare_reliability() (modeva.testsuite method)": [[215, "modeva.TestSuite.compare_reliability", false]], "compare_residual_cluster() (modeva.testsuite method)": [[216, "modeva.TestSuite.compare_residual_cluster", false]], "compare_resilience() (modeva.testsuite method)": [[217, "modeva.TestSuite.compare_resilience", false]], "compare_robustness() (modeva.testsuite method)": [[218, "modeva.TestSuite.compare_robustness", false]], "compare_slicing_accuracy() (modeva.testsuite method)": [[219, "modeva.TestSuite.compare_slicing_accuracy", false]], "compare_slicing_fairness() (modeva.testsuite method)": [[220, "modeva.TestSuite.compare_slicing_fairness", false]], "compare_slicing_overfit() (modeva.testsuite method)": [[221, "modeva.TestSuite.compare_slicing_overfit", false]], "compare_slicing_reliability() (modeva.testsuite method)": [[222, "modeva.TestSuite.compare_slicing_reliability", false]], "compare_slicing_robustness() (modeva.testsuite method)": [[223, "modeva.TestSuite.compare_slicing_robustness", false]], "data (modeva.dataset property)": [[118, "modeva.DataSet.data", false]], "data (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.data", false]], "data_drift_test() (modeva.dataset method)": [[119, "modeva.DataSet.data_drift_test", false]], "dataset (modeva.modelzoo property)": [[202, "modeva.ModelZoo.dataset", false]], "decision_function() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.decision_function", false]], "decision_function() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.decision_function", false]], "decision_function() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.decision_function", false]], "decision_function() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.decision_function", false]], "decision_function() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.decision_function", false]], "decision_function() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.decision_function", false]], "decision_function() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.decision_function", false]], "decision_function() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.decision_function", false]], "decision_function() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.decision_function", false]], "decision_function() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.decision_function", false]], "decision_function() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.decision_function", false]], "decision_function() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.decision_function", false]], "decision_function() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.decision_function", false]], "decision_function() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.decision_function", false]], "decision_function() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.decision_function", false]], "decision_function() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.decision_function", false]], "decision_function() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.decision_function", false]], "delete_extra_data() (modeva.dataset method)": [[120, "modeva.DataSet.delete_extra_data", false]], "delete_registed_test() (modeva.testsuite method)": [[224, "modeva.TestSuite.delete_registed_test", false]], "delete_registered_data() (modeva.dataset method)": [[121, "modeva.DataSet.delete_registered_data", false]], "delete_registered_model() (modeva.modelzoo method)": [[203, "modeva.ModelZoo.delete_registered_model", false]], "detect_outlier_cblof() (modeva.dataset method)": [[122, "modeva.DataSet.detect_outlier_cblof", false]], "detect_outlier_isolation_forest() (modeva.dataset method)": [[123, "modeva.DataSet.detect_outlier_isolation_forest", false]], "detect_outlier_pca() (modeva.dataset method)": [[124, "modeva.DataSet.detect_outlier_pca", false]], "diagnose_accuracy_table() (modeva.testsuite method)": [[225, "modeva.TestSuite.diagnose_accuracy_table", false]], "diagnose_fairness() (modeva.testsuite method)": [[226, "modeva.TestSuite.diagnose_fairness", false]], "diagnose_mitigate_unfair_binning() (modeva.testsuite method)": [[227, "modeva.TestSuite.diagnose_mitigate_unfair_binning", false]], "diagnose_mitigate_unfair_thresholding() (modeva.testsuite method)": [[228, "modeva.TestSuite.diagnose_mitigate_unfair_thresholding", false]], "diagnose_reliability() (modeva.testsuite method)": [[229, "modeva.TestSuite.diagnose_reliability", false]], "diagnose_residual_analysis() (modeva.testsuite method)": [[230, "modeva.TestSuite.diagnose_residual_analysis", false]], "diagnose_residual_cluster() (modeva.testsuite method)": [[231, "modeva.TestSuite.diagnose_residual_cluster", false]], "diagnose_residual_interpret() (modeva.testsuite method)": [[232, "modeva.TestSuite.diagnose_residual_interpret", false]], "diagnose_resilience() (modeva.testsuite method)": [[233, "modeva.TestSuite.diagnose_resilience", false]], "diagnose_robustness() (modeva.testsuite method)": [[234, "modeva.TestSuite.diagnose_robustness", false]], "diagnose_slicing_accuracy() (modeva.testsuite method)": [[235, "modeva.TestSuite.diagnose_slicing_accuracy", false]], "diagnose_slicing_fairness() (modeva.testsuite method)": [[236, "modeva.TestSuite.diagnose_slicing_fairness", false]], "diagnose_slicing_overfit() (modeva.testsuite method)": [[237, "modeva.TestSuite.diagnose_slicing_overfit", false]], "diagnose_slicing_reliability() (modeva.testsuite method)": [[238, "modeva.TestSuite.diagnose_slicing_reliability", false]], "diagnose_slicing_robustness() (modeva.testsuite method)": [[239, "modeva.TestSuite.diagnose_slicing_robustness", false]], "display_test_results() (modeva.testsuite method)": [[240, "modeva.TestSuite.display_test_results", false]], "eda_1d() (modeva.dataset method)": [[125, "modeva.DataSet.eda_1d", false]], "eda_2d() (modeva.dataset method)": [[126, "modeva.DataSet.eda_2d", false]], "eda_3d() (modeva.dataset method)": [[127, "modeva.DataSet.eda_3d", false]], "eda_correlation() (modeva.dataset method)": [[128, "modeva.DataSet.eda_correlation", false]], "eda_pca() (modeva.dataset method)": [[129, "modeva.DataSet.eda_pca", false]], "eda_umap() (modeva.dataset method)": [[130, "modeva.DataSet.eda_umap", false]], "encode_categorical() (modeva.dataset method)": [[131, "modeva.DataSet.encode_categorical", false]], "estimators_ (modeva.models.moglmtreeboostclassifier attribute)": [[281, "modeva.models.MoGLMTreeBoostClassifier.estimators_", false]], "estimators_ (modeva.models.moglmtreeboostregressor attribute)": [[282, "modeva.models.MoGLMTreeBoostRegressor.estimators_", false]], "explain_ale() (modeva.testsuite method)": [[241, "modeva.TestSuite.explain_ale", false]], "explain_hstatistic() (modeva.testsuite method)": [[242, "modeva.TestSuite.explain_hstatistic", false]], "explain_lime() (modeva.testsuite method)": [[243, "modeva.TestSuite.explain_lime", false]], "explain_pdp() (modeva.testsuite method)": [[244, "modeva.TestSuite.explain_pdp", false]], "explain_pfi() (modeva.testsuite method)": [[245, "modeva.TestSuite.explain_pfi", false]], "explain_shap() (modeva.testsuite method)": [[246, "modeva.TestSuite.explain_shap", false]], "export_report() (modeva.testsuite method)": [[247, "modeva.TestSuite.export_report", false]], "feature_names (modeva.dataset property)": [[132, "modeva.DataSet.feature_names", false]], "feature_names_categorical (modeva.dataset property)": [[133, "modeva.DataSet.feature_names_categorical", false]], "feature_names_mixed (modeva.dataset property)": [[134, "modeva.DataSet.feature_names_mixed", false]], "feature_names_numerical (modeva.dataset property)": [[135, "modeva.DataSet.feature_names_numerical", false]], "feature_select_corr() (modeva.dataset method)": [[136, "modeva.DataSet.feature_select_corr", false]], "feature_select_rcit() (modeva.dataset method)": [[137, "modeva.DataSet.feature_select_rcit", false]], "feature_select_xgbpfi() (modeva.dataset method)": [[138, "modeva.DataSet.feature_select_xgbpfi", false]], "feature_types (modeva.dataset property)": [[139, "modeva.DataSet.feature_types", false]], "fit() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.fit", false]], "fit() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.fit", false]], "fit() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.fit", false]], "fit() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.fit", false]], "fit() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.fit", false]], "fit() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.fit", false]], "fit() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.fit", false]], "fit() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.fit", false]], "fit() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.fit", false]], "fit() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.fit", false]], "fit() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.fit", false]], "fit() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.fit", false]], "fit() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.fit", false]], "fit() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.fit", false]], "fit() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.fit", false]], "fit() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.fit", false]], "fit() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.fit", false]], "fit() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.fit", false]], "fit() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.fit", false]], "fit() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.fit", false]], "fit() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.fit", false]], "fit() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.fit", false]], "fit() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.fit", false]], "fit() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.fit", false]], "fit() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.fit", false]], "fit() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.fit", false]], "func (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.func", false]], "get_active_sample_idx() (modeva.dataset method)": [[141, "modeva.DataSet.get_active_sample_idx", false]], "get_data() (modeva.dataset method)": [[142, "modeva.DataSet.get_data", false]], "get_data_info() (in module modeva.testsuite.utils.slicing_utils)": [[311, "modeva.testsuite.utils.slicing_utils.get_data_info", false]], "get_data_list() (modeva.dataset method)": [[143, "modeva.DataSet.get_data_list", false]], "get_dataset() (modeva.testsuite method)": [[248, "modeva.TestSuite.get_dataset", false]], "get_extra_data_list() (modeva.dataset method)": [[144, "modeva.DataSet.get_extra_data_list", false]], "get_figure_names() (modeva.utils.results.validationresult method)": [[315, "modeva.utils.results.ValidationResult.get_figure_names", false]], "get_interactions() (modeva.testsuite method)": [[249, "modeva.TestSuite.get_interactions", false]], "get_main_effects() (modeva.testsuite method)": [[250, "modeva.TestSuite.get_main_effects", false]], "get_mlflow_home() (in module modeva.utils.mlflow)": [[313, "modeva.utils.mlflow.get_mlflow_home", false]], "get_model() (modeva.modelzoo method)": [[204, "modeva.ModelZoo.get_model", false]], "get_model() (modeva.testsuite method)": [[251, "modeva.TestSuite.get_model", false]], "get_params() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.get_params", false]], "get_params() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.get_params", false]], "get_params() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.get_params", false]], "get_params() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.get_params", false]], "get_params() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.get_params", false]], "get_params() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.get_params", false]], "get_params() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.get_params", false]], "get_params() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.get_params", false]], "get_params() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.get_params", false]], "get_params() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.get_params", false]], "get_params() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.get_params", false]], "get_params() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.get_params", false]], "get_params() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.get_params", false]], "get_params() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.get_params", false]], "get_params() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.get_params", false]], "get_params() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.get_params", false]], "get_params() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.get_params", false]], "get_params() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.get_params", false]], "get_params() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.get_params", false]], "get_params() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.get_params", false]], "get_params() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.get_params", false]], "get_params() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.get_params", false]], "get_params() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.get_params", false]], "get_params() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.get_params", false]], "get_params() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.get_params", false]], "get_params() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.get_params", false]], "get_params() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.get_params", false]], "get_params() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.get_params", false]], "get_params() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.get_params", false]], "get_params() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.get_params", false]], "get_params() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.get_params", false]], "get_params() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.get_params", false]], "get_params() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.get_params", false]], "get_params() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.get_params", false]], "get_preprocessor() (modeva.dataset method)": [[145, "modeva.DataSet.get_preprocessor", false]], "get_protected_data() (modeva.dataset method)": [[146, "modeva.DataSet.get_protected_data", false]], "get_raw_data() (modeva.dataset method)": [[147, "modeva.DataSet.get_raw_data", false]], "get_x_y_data() (modeva.dataset method)": [[140, "modeva.DataSet.get_X_y_data", false]], "impute_missing() (modeva.dataset method)": [[148, "modeva.DataSet.impute_missing", false]], "inputs (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.inputs", false]], "interaction_list_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.interaction_list_", false]], "interaction_list_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.interaction_list_", false]], "interaction_val_loss_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.interaction_val_loss_", false]], "interaction_val_loss_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.interaction_val_loss_", false]], "interpret_coef() (modeva.testsuite method)": [[252, "modeva.TestSuite.interpret_coef", false]], "interpret_effects() (modeva.testsuite method)": [[253, "modeva.TestSuite.interpret_effects", false]], "interpret_effects_moe_average() (modeva.testsuite method)": [[254, "modeva.TestSuite.interpret_effects_moe_average", false]], "interpret_fi() (modeva.testsuite method)": [[255, "modeva.TestSuite.interpret_fi", false]], "interpret_global_tree() (modeva.testsuite method)": [[256, "modeva.TestSuite.interpret_global_tree", false]], "interpret_llm_pc() (modeva.testsuite method)": [[257, "modeva.TestSuite.interpret_llm_pc", false]], "interpret_llm_profile() (modeva.testsuite method)": [[258, "modeva.TestSuite.interpret_llm_profile", false]], "interpret_llm_summary() (modeva.testsuite method)": [[259, "modeva.TestSuite.interpret_llm_summary", false]], "interpret_llm_violin() (modeva.testsuite method)": [[260, "modeva.TestSuite.interpret_llm_violin", false]], "interpret_local_fi() (modeva.testsuite method)": [[261, "modeva.TestSuite.interpret_local_fi", false]], "interpret_local_linear_fi() (modeva.testsuite method)": [[262, "modeva.TestSuite.interpret_local_linear_fi", false]], "interpret_local_moe_weights() (modeva.testsuite method)": [[263, "modeva.TestSuite.interpret_local_moe_weights", false]], "interpret_local_tree() (modeva.testsuite method)": [[264, "modeva.TestSuite.interpret_local_tree", false]], "interpret_moe_cluster_analysis() (modeva.testsuite method)": [[265, "modeva.TestSuite.interpret_moe_cluster_analysis", false]], "inverse_transform() (modeva.dataset method)": [[149, "modeva.DataSet.inverse_transform", false]], "is_splitted() (modeva.dataset method)": [[150, "modeva.DataSet.is_splitted", false]], "key (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.key", false]], "leaderboard() (modeva.modelzoo method)": [[205, "modeva.ModelZoo.leaderboard", false]], "leaf_estimators_ (modeva.models.moglmtreeclassifier attribute)": [[283, "modeva.models.MoGLMTreeClassifier.leaf_estimators_", false]], "list() (modeva.testsuite class method)": [[266, "modeva.TestSuite.list", false]], "list_model_names() (modeva.modelzoo method)": [[206, "modeva.ModelZoo.list_model_names", false]], "list_registered_data() (modeva.dataset method)": [[151, "modeva.DataSet.list_registered_data", false]], "list_registered_models() (modeva.modelzoo method)": [[207, "modeva.ModelZoo.list_registered_models", false]], "list_registered_tests() (modeva.testsuite method)": [[267, "modeva.TestSuite.list_registered_tests", false]], "load() (modeva.dataset method)": [[152, "modeva.DataSet.load", false]], "load() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.load", false]], "load() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.load", false]], "load() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.load", false]], "load() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.load", false]], "load() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.load", false]], "load() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.load", false]], "load() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.load", false]], "load() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.load", false]], "load() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.load", false]], "load() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.load", false]], "load() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.load", false]], "load() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.load", false]], "load() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.load", false]], "load() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.load", false]], "load() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.load", false]], "load() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.load", false]], "load() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.load", false]], "load() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.load", false]], "load() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.load", false]], "load() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.load", false]], "load() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.load", false]], "load() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.load", false]], "load() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.load", false]], "load() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.load", false]], "load() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.load", false]], "load() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.load", false]], "load() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.load", false]], "load() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.load", false]], "load() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.load", false]], "load() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.load", false]], "load() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.load", false]], "load() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.load", false]], "load() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.load", false]], "load() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.load", false]], "load_csv() (modeva.dataset method)": [[153, "modeva.DataSet.load_csv", false]], "load_dataframe() (modeva.dataset method)": [[154, "modeva.DataSet.load_dataframe", false]], "load_dataframe_train_test() (modeva.dataset method)": [[155, "modeva.DataSet.load_dataframe_train_test", false]], "load_preprocessing() (modeva.dataset method)": [[156, "modeva.DataSet.load_preprocessing", false]], "load_registered_data() (modeva.dataset method)": [[157, "modeva.DataSet.load_registered_data", false]], "load_registered_model() (modeva.modelzoo method)": [[208, "modeva.ModelZoo.load_registered_model", false]], "load_registered_test() (modeva.testsuite method)": [[268, "modeva.TestSuite.load_registered_test", false]], "load_spark() (modeva.dataset method)": [[158, "modeva.DataSet.load_spark", false]], "main_effect_val_loss_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.main_effect_val_loss_", false]], "main_effect_val_loss_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.main_effect_val_loss_", false]], "mocatboostclassifier (class in modeva.models)": [[273, "modeva.models.MoCatBoostClassifier", false]], "mocatboostregressor (class in modeva.models)": [[274, "modeva.models.MoCatBoostRegressor", false]], "moclassifier (class in modeva.models)": [[275, "modeva.models.MoClassifier", false]], "modecisiontreeclassifier (class in modeva.models)": [[276, "modeva.models.MoDecisionTreeClassifier", false]], "modecisiontreeregressor (class in modeva.models)": [[277, "modeva.models.MoDecisionTreeRegressor", false]], "model (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.model", false]], "modelbaseclassifier (class in modeva.models)": [[305, "modeva.models.ModelBaseClassifier", false]], "modelbaseregressor (class in modeva.models)": [[306, "modeva.models.ModelBaseRegressor", false]], "models (modeva.modelzoo property)": [[209, "modeva.ModelZoo.models", false]], "modeltunegridsearch (class in modeva.models)": [[307, "modeva.models.ModelTuneGridSearch", false]], "modeltuneoptuna (class in modeva.models)": [[308, "modeva.models.ModelTuneOptuna", false]], "modeltunepso (class in modeva.models)": [[309, "modeva.models.ModelTunePSO", false]], "modeltunerandomsearch (class in modeva.models)": [[310, "modeva.models.ModelTuneRandomSearch", false]], "module": [[107, "module-notebook", false]], "moelasticnet (class in modeva.models)": [[278, "modeva.models.MoElasticNet", false]], "mogaminetclassifier (class in modeva.models)": [[279, "modeva.models.MoGAMINetClassifier", false]], "mogaminetregressor (class in modeva.models)": [[280, "modeva.models.MoGAMINetRegressor", false]], "moglmtreeboostclassifier (class in modeva.models)": [[281, "modeva.models.MoGLMTreeBoostClassifier", false]], "moglmtreeboostregressor (class in modeva.models)": [[282, "modeva.models.MoGLMTreeBoostRegressor", false]], "moglmtreeclassifier (class in modeva.models)": [[283, "modeva.models.MoGLMTreeClassifier", false]], "moglmtreeregressor (class in modeva.models)": [[284, "modeva.models.MoGLMTreeRegressor", false]], "mogradientboostingclassifier (class in modeva.models)": [[285, "modeva.models.MoGradientBoostingClassifier", false]], "mogradientboostingregressor (class in modeva.models)": [[286, "modeva.models.MoGradientBoostingRegressor", false]], "molgbmclassifier (class in modeva.models)": [[287, "modeva.models.MoLGBMClassifier", false]], "molgbmregressor (class in modeva.models)": [[288, "modeva.models.MoLGBMRegressor", false]], "mologisticregression (class in modeva.models)": [[289, "modeva.models.MoLogisticRegression", false]], "momoeclassifier (class in modeva.models)": [[290, "modeva.models.MoMoEClassifier", false]], "momoeregressor (class in modeva.models)": [[291, "modeva.models.MoMoERegressor", false]], "moneuraltreeclassifier (class in modeva.models)": [[292, "modeva.models.MoNeuralTreeClassifier", false]], "moneuraltreeregressor (class in modeva.models)": [[293, "modeva.models.MoNeuralTreeRegressor", false]], "morandomforestclassifier (class in modeva.models)": [[294, "modeva.models.MoRandomForestClassifier", false]], "morandomforestregressor (class in modeva.models)": [[295, "modeva.models.MoRandomForestRegressor", false]], "moregressor (class in modeva.models)": [[298, "modeva.models.MoRegressor", false]], "moreludnnclassifier (class in modeva.models)": [[296, "modeva.models.MoReLUDNNClassifier", false]], "moreludnnregressor (class in modeva.models)": [[297, "modeva.models.MoReLUDNNRegressor", false]], "moscoredclassifier (class in modeva.models)": [[301, "modeva.models.MoScoredClassifier", false]], "moscoredregressor (class in modeva.models)": [[302, "modeva.models.MoScoredRegressor", false]], "mosklearnclassifier (class in modeva.models)": [[299, "modeva.models.MoSKLearnClassifier", false]], "mosklearnregressor (class in modeva.models)": [[300, "modeva.models.MoSKLearnRegressor", false]], "moxgbclassifier (class in modeva.models)": [[303, "modeva.models.MoXGBClassifier", false]], "moxgbregressor (class in modeva.models)": [[304, "modeva.models.MoXGBRegressor", false]], "n_features (modeva.dataset property)": [[159, "modeva.DataSet.n_features", false]], "n_features_in_ (modeva.models.moglmtreeboostclassifier attribute)": [[281, "modeva.models.MoGLMTreeBoostClassifier.n_features_in_", false]], "n_features_in_ (modeva.models.moglmtreeboostregressor attribute)": [[282, "modeva.models.MoGLMTreeBoostRegressor.n_features_in_", false]], "n_interactions_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.n_interactions_", false]], "n_interactions_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.n_interactions_", false]], "name (modeva.dataset property)": [[160, "modeva.DataSet.name", false]], "net_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.net_", false]], "net_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.net_", false]], "net_ (modeva.models.moneuraltreeclassifier attribute)": [[292, "modeva.models.MoNeuralTreeClassifier.net_", false]], "net_ (modeva.models.moneuraltreeregressor attribute)": [[293, "modeva.models.MoNeuralTreeRegressor.net_", false]], "net_ (modeva.models.moreludnnclassifier attribute)": [[296, "modeva.models.MoReLUDNNClassifier.net_", false]], "net_ (modeva.models.moreludnnregressor attribute)": [[297, "modeva.models.MoReLUDNNRegressor.net_", false]], "notebook": [[107, "module-notebook", false]], "options (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.options", false]], "optipng() (in module sphinx_gallery.utils)": [[111, "sphinx_gallery.utils.optipng", false]], "pipeline (class in modeva.automation.pipeline)": [[272, "modeva.automation.pipeline.Pipeline", false]], "plot() (modeva.utils.results.validationresult method)": [[315, "modeva.utils.results.ValidationResult.plot", false]], "plot_save() (modeva.utils.results.validationresult method)": [[315, "modeva.utils.results.ValidationResult.plot_save", false]], "predict() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.predict", false]], "predict() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.predict", false]], "predict() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.predict", false]], "predict() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.predict", false]], "predict() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.predict", false]], "predict() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.predict", false]], "predict() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.predict", false]], "predict() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.predict", false]], "predict() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.predict", false]], "predict() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.predict", false]], "predict() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.predict", false]], "predict() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.predict", false]], "predict() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.predict", false]], "predict() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.predict", false]], "predict() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.predict", false]], "predict() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.predict", false]], "predict() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.predict", false]], "predict() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.predict", false]], "predict() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.predict", false]], "predict() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.predict", false]], "predict() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.predict", false]], "predict() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.predict", false]], "predict() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.predict", false]], "predict() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.predict", false]], "predict() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.predict", false]], "predict() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.predict", false]], "predict() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.predict", false]], "predict() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.predict", false]], "predict() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.predict", false]], "predict() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.predict", false]], "predict() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.predict", false]], "predict() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.predict", false]], "predict() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.predict", false]], "predict() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.predict", false]], "predict_interval() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.predict_interval", false]], "predict_interval() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.predict_interval", false]], "predict_interval() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.predict_interval", false]], "predict_interval() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.predict_interval", false]], "predict_interval() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.predict_interval", false]], "predict_interval() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.predict_interval", false]], "predict_interval() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.predict_interval", false]], "predict_interval() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.predict_interval", false]], "predict_interval() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.predict_interval", false]], "predict_interval() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.predict_interval", false]], "predict_interval() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.predict_interval", false]], "predict_interval() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.predict_interval", false]], "predict_interval() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.predict_interval", false]], "predict_interval() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.predict_interval", false]], "predict_interval() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.predict_interval", false]], "predict_interval() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.predict_interval", false]], "predict_interval() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.predict_interval", false]], "predict_interval() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.predict_interval", false]], "predict_interval() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.predict_interval", false]], "predict_interval() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.predict_interval", false]], "predict_interval() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.predict_interval", false]], "predict_interval() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.predict_interval", false]], "predict_interval() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.predict_interval", false]], "predict_interval() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.predict_interval", false]], "predict_interval() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.predict_interval", false]], "predict_proba() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.predict_proba", false]], "predict_proba() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.predict_proba", false]], "predict_proba() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.predict_proba", false]], "predict_proba() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.predict_proba", false]], "predict_proba() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.predict_proba", false]], "predict_proba() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.predict_proba", false]], "predict_proba() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.predict_proba", false]], "predict_proba() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.predict_proba", false]], "predict_proba() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.predict_proba", false]], "predict_proba() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.predict_proba", false]], "predict_proba() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.predict_proba", false]], "predict_proba() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.predict_proba", false]], "predict_proba() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.predict_proba", false]], "predict_proba() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.predict_proba", false]], "prediction_name (modeva.dataset property)": [[161, "modeva.DataSet.prediction_name", false]], "prediction_proba_name (modeva.dataset property)": [[162, "modeva.DataSet.prediction_proba_name", false]], "preprocess() (modeva.dataset method)": [[163, "modeva.DataSet.preprocess", false]], "protected_feature_names (modeva.dataset property)": [[164, "modeva.DataSet.protected_feature_names", false]], "raw_data (modeva.dataset property)": [[165, "modeva.DataSet.raw_data", false]], "register() (modeva.dataset method)": [[166, "modeva.DataSet.register", false]], "register() (modeva.modelzoo method)": [[210, "modeva.ModelZoo.register", false]], "register() (modeva.testsuite method)": [[269, "modeva.TestSuite.register", false]], "reset_preprocess() (modeva.dataset method)": [[167, "modeva.DataSet.reset_preprocess", false]], "run() (modeva.automation.pipeline.pipeline method)": [[272, "modeva.automation.pipeline.Pipeline.run", false]], "run() (modeva.models.modeltunegridsearch method)": [[307, "modeva.models.ModelTuneGridSearch.run", false]], "run() (modeva.models.modeltuneoptuna method)": [[308, "modeva.models.ModelTuneOptuna.run", false]], "run() (modeva.models.modeltunepso method)": [[309, "modeva.models.ModelTunePSO.run", false]], "run() (modeva.models.modeltunerandomsearch method)": [[310, "modeva.models.ModelTuneRandomSearch.run", false]], "sample_weight (modeva.dataset property)": [[168, "modeva.DataSet.sample_weight", false]], "sample_weight_name (modeva.dataset property)": [[169, "modeva.DataSet.sample_weight_name", false]], "save() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.save", false]], "save() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.save", false]], "save() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.save", false]], "save() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.save", false]], "save() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.save", false]], "save() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.save", false]], "save() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.save", false]], "save() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.save", false]], "save() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.save", false]], "save() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.save", false]], "save() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.save", false]], "save() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.save", false]], "save() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.save", false]], "save() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.save", false]], "save() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.save", false]], "save() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.save", false]], "save() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.save", false]], "save() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.save", false]], "save() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.save", false]], "save() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.save", false]], "save() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.save", false]], "save() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.save", false]], "save() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.save", false]], "save() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.save", false]], "save() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.save", false]], "save() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.save", false]], "save() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.save", false]], "save() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.save", false]], "save() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.save", false]], "save() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.save", false]], "save() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.save", false]], "save() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.save", false]], "save() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.save", false]], "save() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.save", false]], "save_preprocessing() (modeva.dataset method)": [[170, "modeva.DataSet.save_preprocessing", false]], "scale_numerical() (modeva.dataset method)": [[171, "modeva.DataSet.scale_numerical", false]], "set_active_features() (modeva.dataset method)": [[172, "modeva.DataSet.set_active_features", false]], "set_dataset() (modeva.testsuite method)": [[270, "modeva.TestSuite.set_dataset", false]], "set_feature_type() (modeva.dataset method)": [[173, "modeva.DataSet.set_feature_type", false]], "set_inactive_features() (modeva.dataset method)": [[174, "modeva.DataSet.set_inactive_features", false]], "set_mlflow_home() (in module modeva.utils.mlflow)": [[314, "modeva.utils.mlflow.set_mlflow_home", false]], "set_model() (modeva.testsuite method)": [[271, "modeva.TestSuite.set_model", false]], "set_params() (modeva.models.mocatboostclassifier method)": [[273, "modeva.models.MoCatBoostClassifier.set_params", false]], "set_params() (modeva.models.mocatboostregressor method)": [[274, "modeva.models.MoCatBoostRegressor.set_params", false]], "set_params() (modeva.models.moclassifier method)": [[275, "modeva.models.MoClassifier.set_params", false]], "set_params() (modeva.models.modecisiontreeclassifier method)": [[276, "modeva.models.MoDecisionTreeClassifier.set_params", false]], "set_params() (modeva.models.modecisiontreeregressor method)": [[277, "modeva.models.MoDecisionTreeRegressor.set_params", false]], "set_params() (modeva.models.modelbaseclassifier method)": [[305, "modeva.models.ModelBaseClassifier.set_params", false]], "set_params() (modeva.models.modelbaseregressor method)": [[306, "modeva.models.ModelBaseRegressor.set_params", false]], "set_params() (modeva.models.moelasticnet method)": [[278, "modeva.models.MoElasticNet.set_params", false]], "set_params() (modeva.models.mogaminetclassifier method)": [[279, "modeva.models.MoGAMINetClassifier.set_params", false]], "set_params() (modeva.models.mogaminetregressor method)": [[280, "modeva.models.MoGAMINetRegressor.set_params", false]], "set_params() (modeva.models.moglmtreeboostclassifier method)": [[281, "modeva.models.MoGLMTreeBoostClassifier.set_params", false]], "set_params() (modeva.models.moglmtreeboostregressor method)": [[282, "modeva.models.MoGLMTreeBoostRegressor.set_params", false]], "set_params() (modeva.models.moglmtreeclassifier method)": [[283, "modeva.models.MoGLMTreeClassifier.set_params", false]], "set_params() (modeva.models.moglmtreeregressor method)": [[284, "modeva.models.MoGLMTreeRegressor.set_params", false]], "set_params() (modeva.models.mogradientboostingclassifier method)": [[285, "modeva.models.MoGradientBoostingClassifier.set_params", false]], "set_params() (modeva.models.mogradientboostingregressor method)": [[286, "modeva.models.MoGradientBoostingRegressor.set_params", false]], "set_params() (modeva.models.molgbmclassifier method)": [[287, "modeva.models.MoLGBMClassifier.set_params", false]], "set_params() (modeva.models.molgbmregressor method)": [[288, "modeva.models.MoLGBMRegressor.set_params", false]], "set_params() (modeva.models.mologisticregression method)": [[289, "modeva.models.MoLogisticRegression.set_params", false]], "set_params() (modeva.models.momoeclassifier method)": [[290, "modeva.models.MoMoEClassifier.set_params", false]], "set_params() (modeva.models.momoeregressor method)": [[291, "modeva.models.MoMoERegressor.set_params", false]], "set_params() (modeva.models.moneuraltreeclassifier method)": [[292, "modeva.models.MoNeuralTreeClassifier.set_params", false]], "set_params() (modeva.models.moneuraltreeregressor method)": [[293, "modeva.models.MoNeuralTreeRegressor.set_params", false]], "set_params() (modeva.models.morandomforestclassifier method)": [[294, "modeva.models.MoRandomForestClassifier.set_params", false]], "set_params() (modeva.models.morandomforestregressor method)": [[295, "modeva.models.MoRandomForestRegressor.set_params", false]], "set_params() (modeva.models.moregressor method)": [[298, "modeva.models.MoRegressor.set_params", false]], "set_params() (modeva.models.moreludnnclassifier method)": [[296, "modeva.models.MoReLUDNNClassifier.set_params", false]], "set_params() (modeva.models.moreludnnregressor method)": [[297, "modeva.models.MoReLUDNNRegressor.set_params", false]], "set_params() (modeva.models.moscoredclassifier method)": [[301, "modeva.models.MoScoredClassifier.set_params", false]], "set_params() (modeva.models.moscoredregressor method)": [[302, "modeva.models.MoScoredRegressor.set_params", false]], "set_params() (modeva.models.mosklearnclassifier method)": [[299, "modeva.models.MoSKLearnClassifier.set_params", false]], "set_params() (modeva.models.mosklearnregressor method)": [[300, "modeva.models.MoSKLearnRegressor.set_params", false]], "set_params() (modeva.models.moxgbclassifier method)": [[303, "modeva.models.MoXGBClassifier.set_params", false]], "set_params() (modeva.models.moxgbregressor method)": [[304, "modeva.models.MoXGBRegressor.set_params", false]], "set_prediction() (modeva.dataset method)": [[175, "modeva.DataSet.set_prediction", false]], "set_prediction_proba() (modeva.dataset method)": [[176, "modeva.DataSet.set_prediction_proba", false]], "set_protected_data() (modeva.dataset method)": [[177, "modeva.DataSet.set_protected_data", false]], "set_protected_extra_data() (modeva.dataset method)": [[178, "modeva.DataSet.set_protected_extra_data", false]], "set_random_split() (modeva.dataset method)": [[179, "modeva.DataSet.set_random_split", false]], "set_raw_extra_data() (modeva.dataset method)": [[180, "modeva.DataSet.set_raw_extra_data", false]], "set_sample_weight() (modeva.dataset method)": [[181, "modeva.DataSet.set_sample_weight", false]], "set_target() (modeva.dataset method)": [[182, "modeva.DataSet.set_target", false]], "set_task_type() (modeva.dataset method)": [[183, "modeva.DataSet.set_task_type", false]], "set_test_idx() (modeva.dataset method)": [[184, "modeva.DataSet.set_test_idx", false]], "set_train_idx() (modeva.dataset method)": [[185, "modeva.DataSet.set_train_idx", false]], "shape (modeva.dataset property)": [[186, "modeva.DataSet.shape", false]], "subsample_random() (modeva.dataset method)": [[187, "modeva.DataSet.subsample_random", false]], "summary() (modeva.dataset method)": [[188, "modeva.DataSet.summary", false]], "table (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.table", false]], "target_feature_name (modeva.dataset property)": [[189, "modeva.DataSet.target_feature_name", false]], "task_type (modeva.dataset property)": [[190, "modeva.DataSet.task_type", false]], "test_sample_weight (modeva.dataset property)": [[191, "modeva.DataSet.test_sample_weight", false]], "test_x (modeva.dataset property)": [[192, "modeva.DataSet.test_x", false]], "test_y (modeva.dataset property)": [[193, "modeva.DataSet.test_y", false]], "time_cost_ (modeva.models.mogaminetclassifier attribute)": [[279, "modeva.models.MoGAMINetClassifier.time_cost_", false]], "time_cost_ (modeva.models.mogaminetregressor attribute)": [[280, "modeva.models.MoGAMINetRegressor.time_cost_", false]], "to_df() (modeva.dataset method)": [[194, "modeva.DataSet.to_df", false]], "train() (modeva.modelzoo method)": [[211, "modeva.ModelZoo.train", false]], "train_all() (modeva.modelzoo method)": [[212, "modeva.ModelZoo.train_all", false]], "train_epoch_loss_ (modeva.models.moreludnnclassifier attribute)": [[296, "modeva.models.MoReLUDNNClassifier.train_epoch_loss_", false]], "train_epoch_loss_ (modeva.models.moreludnnregressor attribute)": [[297, "modeva.models.MoReLUDNNRegressor.train_epoch_loss_", false]], "train_sample_weight (modeva.dataset property)": [[195, "modeva.DataSet.train_sample_weight", false]], "train_x (modeva.dataset property)": [[196, "modeva.DataSet.train_x", false]], "train_y (modeva.dataset property)": [[197, "modeva.DataSet.train_y", false]], "transform() (modeva.dataset method)": [[198, "modeva.DataSet.transform", false]], "tree_ (modeva.models.moglmtreeclassifier attribute)": [[283, "modeva.models.MoGLMTreeClassifier.tree_", false]], "tree_ (modeva.models.moglmtreeregressor attribute)": [[284, "modeva.models.MoGLMTreeRegressor.tree_", false]], "validation_epoch_loss_ (modeva.models.moreludnnclassifier attribute)": [[296, "modeva.models.MoReLUDNNClassifier.validation_epoch_loss_", false]], "validation_epoch_loss_ (modeva.models.moreludnnregressor attribute)": [[297, "modeva.models.MoReLUDNNRegressor.validation_epoch_loss_", false]], "validationresult (class in modeva.utils.results)": [[315, "modeva.utils.results.ValidationResult", false]], "value (modeva.utils.results.validationresult attribute)": [[315, "modeva.utils.results.ValidationResult.value", false]], "x (modeva.dataset property)": [[199, "modeva.DataSet.x", false]], "y (modeva.dataset property)": [[200, "modeva.DataSet.y", false]]}, "objects": {"": [[107, 5, 0, "-", "notebook"]], "modeva.DataSet": [[115, 0, 1, "", "all_feature_names"], [116, 0, 1, "", "all_feature_types"], [117, 1, 1, "", "bin_numerical"], [118, 0, 1, "", "data"], [119, 1, 1, "", "data_drift_test"], [120, 1, 1, "", "delete_extra_data"], [121, 1, 1, "", "delete_registered_data"], [122, 1, 1, "", "detect_outlier_cblof"], [123, 1, 1, "", "detect_outlier_isolation_forest"], [124, 1, 1, "", "detect_outlier_pca"], [125, 1, 1, "", "eda_1d"], [126, 1, 1, "", "eda_2d"], [127, 1, 1, "", "eda_3d"], [128, 1, 1, "", "eda_correlation"], [129, 1, 1, "", "eda_pca"], [130, 1, 1, "", "eda_umap"], [131, 1, 1, "", "encode_categorical"], [132, 0, 1, "", "feature_names"], [133, 0, 1, "", "feature_names_categorical"], [134, 0, 1, "", "feature_names_mixed"], [135, 0, 1, "", "feature_names_numerical"], [136, 1, 1, "", "feature_select_corr"], [137, 1, 1, "", "feature_select_rcit"], [138, 1, 1, "", "feature_select_xgbpfi"], [139, 0, 1, "", "feature_types"], [140, 1, 1, "", "get_X_y_data"], [141, 1, 1, "", "get_active_sample_idx"], [142, 1, 1, "", "get_data"], [143, 1, 1, "", "get_data_list"], [144, 1, 1, "", "get_extra_data_list"], [145, 1, 1, "", "get_preprocessor"], [146, 1, 1, "", "get_protected_data"], [147, 1, 1, "", "get_raw_data"], [148, 1, 1, "", "impute_missing"], [149, 1, 1, "", "inverse_transform"], [150, 1, 1, "", "is_splitted"], [151, 1, 1, "", "list_registered_data"], [152, 1, 1, "", "load"], [153, 1, 1, "", "load_csv"], [154, 1, 1, "", "load_dataframe"], [155, 1, 1, "", "load_dataframe_train_test"], [156, 1, 1, "", "load_preprocessing"], [157, 1, 1, "", "load_registered_data"], [158, 1, 1, "", "load_spark"], [159, 0, 1, "", "n_features"], [160, 0, 1, "", "name"], [161, 0, 1, "", "prediction_name"], [162, 0, 1, "", "prediction_proba_name"], [163, 1, 1, "", "preprocess"], [164, 0, 1, "", "protected_feature_names"], [165, 0, 1, "", "raw_data"], [166, 1, 1, "", "register"], [167, 1, 1, "", "reset_preprocess"], [168, 0, 1, "", "sample_weight"], [169, 0, 1, "", "sample_weight_name"], [170, 1, 1, "", "save_preprocessing"], [171, 1, 1, "", "scale_numerical"], [172, 1, 1, "", "set_active_features"], [173, 1, 1, "", "set_feature_type"], [174, 1, 1, "", "set_inactive_features"], [175, 1, 1, "", "set_prediction"], [176, 1, 1, "", "set_prediction_proba"], [177, 1, 1, "", "set_protected_data"], [178, 1, 1, "", "set_protected_extra_data"], [179, 1, 1, "", "set_random_split"], [180, 1, 1, "", "set_raw_extra_data"], [181, 1, 1, "", "set_sample_weight"], [182, 1, 1, "", "set_target"], [183, 1, 1, "", "set_task_type"], [184, 1, 1, "", "set_test_idx"], [185, 1, 1, "", "set_train_idx"], [186, 0, 1, "", "shape"], [187, 1, 1, "", "subsample_random"], [188, 1, 1, "", "summary"], [189, 0, 1, "", "target_feature_name"], [190, 0, 1, "", "task_type"], [191, 0, 1, "", "test_sample_weight"], [192, 0, 1, "", "test_x"], [193, 0, 1, "", "test_y"], [194, 1, 1, "", "to_df"], [195, 0, 1, "", "train_sample_weight"], [196, 0, 1, "", "train_x"], [197, 0, 1, "", "train_y"], [198, 1, 1, "", "transform"], [199, 0, 1, "", "x"], [200, 0, 1, "", "y"]], "modeva.ModelZoo": [[201, 1, 1, "", "add_model"], [202, 0, 1, "", "dataset"], [203, 1, 1, "", "delete_registered_model"], [204, 1, 1, "", "get_model"], [205, 1, 1, "", "leaderboard"], [206, 1, 1, "", "list_model_names"], [207, 1, 1, "", "list_registered_models"], [208, 1, 1, "", "load_registered_model"], [209, 0, 1, "", "models"], [210, 1, 1, "", "register"], [211, 1, 1, "", "train"], [212, 1, 1, "", "train_all"]], "modeva.TestSuite": [[213, 1, 1, "", "compare_accuracy_table"], [214, 1, 1, "", "compare_fairness"], [215, 1, 1, "", "compare_reliability"], [216, 1, 1, "", "compare_residual_cluster"], [217, 1, 1, "", "compare_resilience"], [218, 1, 1, "", "compare_robustness"], [219, 1, 1, "", "compare_slicing_accuracy"], [220, 1, 1, "", "compare_slicing_fairness"], [221, 1, 1, "", "compare_slicing_overfit"], [222, 1, 1, "", "compare_slicing_reliability"], [223, 1, 1, "", "compare_slicing_robustness"], [224, 1, 1, "", "delete_registed_test"], [225, 1, 1, "", "diagnose_accuracy_table"], [226, 1, 1, "", "diagnose_fairness"], [227, 1, 1, "", "diagnose_mitigate_unfair_binning"], [228, 1, 1, "", "diagnose_mitigate_unfair_thresholding"], [229, 1, 1, "", "diagnose_reliability"], [230, 1, 1, "", "diagnose_residual_analysis"], [231, 1, 1, "", "diagnose_residual_cluster"], [232, 1, 1, "", "diagnose_residual_interpret"], [233, 1, 1, "", "diagnose_resilience"], [234, 1, 1, "", "diagnose_robustness"], [235, 1, 1, "", "diagnose_slicing_accuracy"], [236, 1, 1, "", "diagnose_slicing_fairness"], [237, 1, 1, "", "diagnose_slicing_overfit"], [238, 1, 1, "", "diagnose_slicing_reliability"], [239, 1, 1, "", "diagnose_slicing_robustness"], [240, 1, 1, "", "display_test_results"], [241, 1, 1, "", "explain_ale"], [242, 1, 1, "", "explain_hstatistic"], [243, 1, 1, "", "explain_lime"], [244, 1, 1, "", "explain_pdp"], [245, 1, 1, "", "explain_pfi"], [246, 1, 1, "", "explain_shap"], [247, 1, 1, "", "export_report"], [248, 1, 1, "", "get_dataset"], [249, 1, 1, "", "get_interactions"], [250, 1, 1, "", "get_main_effects"], [251, 1, 1, "", "get_model"], [252, 1, 1, "", "interpret_coef"], [253, 1, 1, "", "interpret_effects"], [254, 1, 1, "", "interpret_effects_moe_average"], [255, 1, 1, "", "interpret_fi"], [256, 1, 1, "", "interpret_global_tree"], [257, 1, 1, "", "interpret_llm_pc"], [258, 1, 1, "", "interpret_llm_profile"], [259, 1, 1, "", "interpret_llm_summary"], [260, 1, 1, "", "interpret_llm_violin"], [261, 1, 1, "", "interpret_local_fi"], [262, 1, 1, "", "interpret_local_linear_fi"], [263, 1, 1, "", "interpret_local_moe_weights"], [264, 1, 1, "", "interpret_local_tree"], [265, 1, 1, "", "interpret_moe_cluster_analysis"], [266, 1, 1, "", "list"], [267, 1, 1, "", "list_registered_tests"], [268, 1, 1, "", "load_registered_test"], [269, 1, 1, "", "register"], [270, 1, 1, "", "set_dataset"], [271, 1, 1, "", "set_model"]], "modeva.automation.pipeline": [[272, 2, 1, "", "Pipeline"]], "modeva.automation.pipeline.Pipeline": [[272, 1, 1, "", "add_step"], [272, 1, 1, "", "run"]], "modeva.models": [[273, 2, 1, "", "MoCatBoostClassifier"], [274, 2, 1, "", "MoCatBoostRegressor"], [275, 2, 1, "", "MoClassifier"], [276, 2, 1, "", "MoDecisionTreeClassifier"], [277, 2, 1, "", "MoDecisionTreeRegressor"], [278, 2, 1, "", "MoElasticNet"], [279, 2, 1, "", "MoGAMINetClassifier"], [280, 2, 1, "", "MoGAMINetRegressor"], [281, 2, 1, "", "MoGLMTreeBoostClassifier"], [282, 2, 1, "", "MoGLMTreeBoostRegressor"], [283, 2, 1, "", "MoGLMTreeClassifier"], [284, 2, 1, "", "MoGLMTreeRegressor"], [285, 2, 1, "", "MoGradientBoostingClassifier"], [286, 2, 1, "", "MoGradientBoostingRegressor"], [287, 2, 1, "", "MoLGBMClassifier"], [288, 2, 1, "", "MoLGBMRegressor"], [289, 2, 1, "", "MoLogisticRegression"], [290, 2, 1, "", "MoMoEClassifier"], [291, 2, 1, "", "MoMoERegressor"], [292, 2, 1, "", "MoNeuralTreeClassifier"], [293, 2, 1, "", "MoNeuralTreeRegressor"], [294, 2, 1, "", "MoRandomForestClassifier"], [295, 2, 1, "", "MoRandomForestRegressor"], [296, 2, 1, "", "MoReLUDNNClassifier"], [297, 2, 1, "", "MoReLUDNNRegressor"], [298, 2, 1, "", "MoRegressor"], [299, 2, 1, "", "MoSKLearnClassifier"], [300, 2, 1, "", "MoSKLearnRegressor"], [301, 2, 1, "", "MoScoredClassifier"], [302, 2, 1, "", "MoScoredRegressor"], [303, 2, 1, "", "MoXGBClassifier"], [304, 2, 1, "", "MoXGBRegressor"], [305, 2, 1, "", "ModelBaseClassifier"], [306, 2, 1, "", "ModelBaseRegressor"], [307, 2, 1, "", "ModelTuneGridSearch"], [308, 2, 1, "", "ModelTuneOptuna"], [309, 2, 1, "", "ModelTunePSO"], [310, 2, 1, "", "ModelTuneRandomSearch"]], "modeva.models.MoCatBoostClassifier": [[273, 1, 1, "", "calibrate_interval"], [273, 1, 1, "", "calibrate_proba"], [273, 1, 1, "", "decision_function"], [273, 1, 1, "", "fit"], [273, 1, 1, "", "get_params"], [273, 1, 1, "", "load"], [273, 1, 1, "", "predict"], [273, 1, 1, "", "predict_interval"], [273, 1, 1, "", "predict_proba"], [273, 1, 1, "", "save"], [273, 1, 1, "", "set_params"]], "modeva.models.MoCatBoostRegressor": [[274, 1, 1, "", "calibrate_interval"], [274, 1, 1, "", "fit"], [274, 1, 1, "", "get_params"], [274, 1, 1, "", "load"], [274, 1, 1, "", "predict"], [274, 1, 1, "", "predict_interval"], [274, 1, 1, "", "save"], [274, 1, 1, "", "set_params"]], "modeva.models.MoClassifier": [[275, 1, 1, "", "calibrate_interval"], [275, 1, 1, "", "calibrate_proba"], [275, 1, 1, "", "decision_function"], [275, 1, 1, "", "fit"], [275, 1, 1, "", "get_params"], [275, 1, 1, "", "load"], [275, 1, 1, "", "predict"], [275, 1, 1, "", "predict_interval"], [275, 1, 1, "", "predict_proba"], [275, 1, 1, "", "save"], [275, 1, 1, "", "set_params"]], "modeva.models.MoDecisionTreeClassifier": [[276, 1, 1, "", "calibrate_interval"], [276, 1, 1, "", "calibrate_proba"], [276, 1, 1, "", "decision_function"], [276, 1, 1, "", "fit"], [276, 1, 1, "", "get_params"], [276, 1, 1, "", "load"], [276, 1, 1, "", "predict"], [276, 1, 1, "", "predict_interval"], [276, 1, 1, "", "predict_proba"], [276, 1, 1, "", "save"], [276, 1, 1, "", "set_params"]], "modeva.models.MoDecisionTreeRegressor": [[277, 1, 1, "", "calibrate_interval"], [277, 1, 1, "", "fit"], [277, 1, 1, "", "get_params"], [277, 1, 1, "", "load"], [277, 1, 1, "", "predict"], [277, 1, 1, "", "predict_interval"], [277, 1, 1, "", "save"], [277, 1, 1, "", "set_params"]], "modeva.models.MoElasticNet": [[278, 1, 1, "", "calibrate_interval"], [278, 1, 1, "", "fit"], [278, 1, 1, "", "get_params"], [278, 1, 1, "", "load"], [278, 1, 1, "", "predict"], [278, 1, 1, "", "predict_interval"], [278, 1, 1, "", "save"], [278, 1, 1, "", "set_params"]], "modeva.models.MoGAMINetClassifier": [[279, 3, 1, "", "active_interaction_index_"], [279, 3, 1, "", "active_main_effect_index_"], [279, 1, 1, "", "calibrate_interval"], [279, 1, 1, "", "calibrate_proba"], [279, 1, 1, "", "decision_function"], [279, 1, 1, "", "fit"], [279, 1, 1, "", "get_params"], [279, 3, 1, "", "interaction_list_"], [279, 3, 1, "", "interaction_val_loss_"], [279, 1, 1, "", "load"], [279, 3, 1, "", "main_effect_val_loss_"], [279, 3, 1, "", "n_interactions_"], [279, 3, 1, "", "net_"], [279, 1, 1, "", "predict"], [279, 1, 1, "", "predict_interval"], [279, 1, 1, "", "predict_proba"], [279, 1, 1, "", "save"], [279, 1, 1, "", "set_params"], [279, 3, 1, "", "time_cost_"]], "modeva.models.MoGAMINetRegressor": [[280, 3, 1, "", "active_interaction_index_"], [280, 3, 1, "", "active_main_effect_index_"], [280, 1, 1, "", "calibrate_interval"], [280, 1, 1, "", "fit"], [280, 1, 1, "", "get_params"], [280, 3, 1, "", "interaction_list_"], [280, 3, 1, "", "interaction_val_loss_"], [280, 1, 1, "", "load"], [280, 3, 1, "", "main_effect_val_loss_"], [280, 3, 1, "", "n_interactions_"], [280, 3, 1, "", "net_"], [280, 1, 1, "", "predict"], [280, 1, 1, "", "predict_interval"], [280, 1, 1, "", "save"], [280, 1, 1, "", "set_params"], [280, 3, 1, "", "time_cost_"]], "modeva.models.MoGLMTreeBoostClassifier": [[281, 1, 1, "", "calibrate_interval"], [281, 1, 1, "", "calibrate_proba"], [281, 1, 1, "", "decision_function"], [281, 3, 1, "", "estimators_"], [281, 1, 1, "", "fit"], [281, 1, 1, "", "get_params"], [281, 1, 1, "", "load"], [281, 3, 1, "", "n_features_in_"], [281, 1, 1, "", "predict"], [281, 1, 1, "", "predict_interval"], [281, 1, 1, "", "predict_proba"], [281, 1, 1, "", "save"], [281, 1, 1, "", "set_params"]], "modeva.models.MoGLMTreeBoostRegressor": [[282, 1, 1, "", "calibrate_interval"], [282, 3, 1, "", "estimators_"], [282, 1, 1, "", "fit"], [282, 1, 1, "", "get_params"], [282, 1, 1, "", "load"], [282, 3, 1, "", "n_features_in_"], [282, 1, 1, "", "predict"], [282, 1, 1, "", "predict_interval"], [282, 1, 1, "", "save"], [282, 1, 1, "", "set_params"]], "modeva.models.MoGLMTreeClassifier": [[283, 1, 1, "", "calibrate_interval"], [283, 1, 1, "", "calibrate_proba"], [283, 1, 1, "", "decision_function"], [283, 1, 1, "", "get_params"], [283, 3, 1, "", "leaf_estimators_"], [283, 1, 1, "", "load"], [283, 1, 1, "", "predict"], [283, 1, 1, "", "predict_interval"], [283, 1, 1, "", "predict_proba"], [283, 1, 1, "", "save"], [283, 1, 1, "", "set_params"], [283, 3, 1, "", "tree_"]], "modeva.models.MoGLMTreeRegressor": [[284, 1, 1, "", "calibrate_interval"], [284, 1, 1, "", "get_params"], [284, 1, 1, "", "load"], [284, 1, 1, "", "predict"], [284, 1, 1, "", "predict_interval"], [284, 1, 1, "", "save"], [284, 1, 1, "", "set_params"], [284, 3, 1, "", "tree_"]], "modeva.models.MoGradientBoostingClassifier": [[285, 1, 1, "", "calibrate_interval"], [285, 1, 1, "", "calibrate_proba"], [285, 1, 1, "", "decision_function"], [285, 1, 1, "", "fit"], [285, 1, 1, "", "get_params"], [285, 1, 1, "", "load"], [285, 1, 1, "", "predict"], [285, 1, 1, "", "predict_interval"], [285, 1, 1, "", "predict_proba"], [285, 1, 1, "", "save"], [285, 1, 1, "", "set_params"]], "modeva.models.MoGradientBoostingRegressor": [[286, 1, 1, "", "calibrate_interval"], [286, 1, 1, "", "fit"], [286, 1, 1, "", "get_params"], [286, 1, 1, "", "load"], [286, 1, 1, "", "predict"], [286, 1, 1, "", "predict_interval"], [286, 1, 1, "", "save"], [286, 1, 1, "", "set_params"]], "modeva.models.MoLGBMClassifier": [[287, 1, 1, "", "calibrate_interval"], [287, 1, 1, "", "calibrate_proba"], [287, 1, 1, "", "decision_function"], [287, 1, 1, "", "fit"], [287, 1, 1, "", "get_params"], [287, 1, 1, "", "load"], [287, 1, 1, "", "predict"], [287, 1, 1, "", "predict_interval"], [287, 1, 1, "", "predict_proba"], [287, 1, 1, "", "save"], [287, 1, 1, "", "set_params"]], "modeva.models.MoLGBMRegressor": [[288, 1, 1, "", "calibrate_interval"], [288, 1, 1, "", "fit"], [288, 1, 1, "", "get_params"], [288, 1, 1, "", "load"], [288, 1, 1, "", "predict"], [288, 1, 1, "", "predict_interval"], [288, 1, 1, "", "save"], [288, 1, 1, "", "set_params"]], "modeva.models.MoLogisticRegression": [[289, 1, 1, "", "calibrate_interval"], [289, 1, 1, "", "calibrate_proba"], [289, 1, 1, "", "decision_function"], [289, 1, 1, "", "fit"], [289, 1, 1, "", "get_params"], [289, 1, 1, "", "load"], [289, 1, 1, "", "predict"], [289, 1, 1, "", "predict_interval"], [289, 1, 1, "", "predict_proba"], [289, 1, 1, "", "save"], [289, 1, 1, "", "set_params"]], "modeva.models.MoMoEClassifier": [[290, 1, 1, "", "calibrate_interval"], [290, 1, 1, "", "calibrate_proba"], [290, 1, 1, "", "decision_function"], [290, 1, 1, "", "fit"], [290, 1, 1, "", "get_params"], [290, 1, 1, "", "load"], [290, 1, 1, "", "predict"], [290, 1, 1, "", "predict_interval"], [290, 1, 1, "", "predict_proba"], [290, 1, 1, "", "save"], [290, 1, 1, "", "set_params"]], "modeva.models.MoMoERegressor": [[291, 1, 1, "", "calibrate_interval"], [291, 1, 1, "", "fit"], [291, 1, 1, "", "get_params"], [291, 1, 1, "", "load"], [291, 1, 1, "", "predict"], [291, 1, 1, "", "predict_interval"], [291, 1, 1, "", "save"], [291, 1, 1, "", "set_params"]], "modeva.models.MoNeuralTreeClassifier": [[292, 1, 1, "", "calibrate_interval"], [292, 1, 1, "", "calibrate_proba"], [292, 1, 1, "", "decision_function"], [292, 1, 1, "", "get_params"], [292, 1, 1, "", "load"], [292, 3, 1, "", "net_"], [292, 1, 1, "", "predict"], [292, 1, 1, "", "predict_interval"], [292, 1, 1, "", "predict_proba"], [292, 1, 1, "", "save"], [292, 1, 1, "", "set_params"]], "modeva.models.MoNeuralTreeRegressor": [[293, 1, 1, "", "calibrate_interval"], [293, 1, 1, "", "get_params"], [293, 1, 1, "", "load"], [293, 3, 1, "", "net_"], [293, 1, 1, "", "predict"], [293, 1, 1, "", "predict_interval"], [293, 1, 1, "", "save"], [293, 1, 1, "", "set_params"]], "modeva.models.MoRandomForestClassifier": [[294, 1, 1, "", "calibrate_interval"], [294, 1, 1, "", "calibrate_proba"], [294, 1, 1, "", "decision_function"], [294, 1, 1, "", "fit"], [294, 1, 1, "", "get_params"], [294, 1, 1, "", "load"], [294, 1, 1, "", "predict"], [294, 1, 1, "", "predict_interval"], [294, 1, 1, "", "predict_proba"], [294, 1, 1, "", "save"], [294, 1, 1, "", "set_params"]], "modeva.models.MoRandomForestRegressor": [[295, 1, 1, "", "calibrate_interval"], [295, 1, 1, "", "fit"], [295, 1, 1, "", "get_params"], [295, 1, 1, "", "load"], [295, 1, 1, "", "predict"], [295, 1, 1, "", "predict_interval"], [295, 1, 1, "", "save"], [295, 1, 1, "", "set_params"]], "modeva.models.MoReLUDNNClassifier": [[296, 1, 1, "", "calibrate_interval"], [296, 1, 1, "", "calibrate_proba"], [296, 1, 1, "", "decision_function"], [296, 1, 1, "", "fit"], [296, 1, 1, "", "get_params"], [296, 1, 1, "", "load"], [296, 3, 1, "", "net_"], [296, 1, 1, "", "predict"], [296, 1, 1, "", "predict_interval"], [296, 1, 1, "", "predict_proba"], [296, 1, 1, "", "save"], [296, 1, 1, "", "set_params"], [296, 3, 1, "", "train_epoch_loss_"], [296, 3, 1, "", "validation_epoch_loss_"]], "modeva.models.MoReLUDNNRegressor": [[297, 1, 1, "", "calibrate_interval"], [297, 1, 1, "", "fit"], [297, 1, 1, "", "get_params"], [297, 1, 1, "", "load"], [297, 3, 1, "", "net_"], [297, 1, 1, "", "predict"], [297, 1, 1, "", "predict_interval"], [297, 1, 1, "", "save"], [297, 1, 1, "", "set_params"], [297, 3, 1, "", "train_epoch_loss_"], [297, 3, 1, "", "validation_epoch_loss_"]], "modeva.models.MoRegressor": [[298, 1, 1, "", "calibrate_interval"], [298, 1, 1, "", "fit"], [298, 1, 1, "", "get_params"], [298, 1, 1, "", "load"], [298, 1, 1, "", "predict"], [298, 1, 1, "", "predict_interval"], [298, 1, 1, "", "save"], [298, 1, 1, "", "set_params"]], "modeva.models.MoSKLearnClassifier": [[299, 1, 1, "", "calibrate_interval"], [299, 1, 1, "", "calibrate_proba"], [299, 1, 1, "", "decision_function"], [299, 1, 1, "", "fit"], [299, 1, 1, "", "get_params"], [299, 1, 1, "", "load"], [299, 1, 1, "", "predict"], [299, 1, 1, "", "predict_interval"], [299, 1, 1, "", "predict_proba"], [299, 1, 1, "", "save"], [299, 1, 1, "", "set_params"]], "modeva.models.MoSKLearnRegressor": [[300, 1, 1, "", "calibrate_interval"], [300, 1, 1, "", "fit"], [300, 1, 1, "", "get_params"], [300, 1, 1, "", "load"], [300, 1, 1, "", "predict"], [300, 1, 1, "", "predict_interval"], [300, 1, 1, "", "save"], [300, 1, 1, "", "set_params"]], "modeva.models.MoScoredClassifier": [[301, 1, 1, "", "calibrate_interval"], [301, 1, 1, "", "calibrate_proba"], [301, 1, 1, "", "decision_function"], [301, 1, 1, "", "get_params"], [301, 1, 1, "", "load"], [301, 1, 1, "", "predict"], [301, 1, 1, "", "predict_interval"], [301, 1, 1, "", "predict_proba"], [301, 1, 1, "", "save"], [301, 1, 1, "", "set_params"]], "modeva.models.MoScoredRegressor": [[302, 1, 1, "", "calibrate_interval"], [302, 1, 1, "", "get_params"], [302, 1, 1, "", "load"], [302, 1, 1, "", "predict"], [302, 1, 1, "", "predict_interval"], [302, 1, 1, "", "save"], [302, 1, 1, "", "set_params"]], "modeva.models.MoXGBClassifier": [[303, 1, 1, "", "calibrate_interval"], [303, 1, 1, "", "calibrate_proba"], [303, 1, 1, "", "decision_function"], [303, 1, 1, "", "fit"], [303, 1, 1, "", "get_params"], [303, 1, 1, "", "load"], [303, 1, 1, "", "predict"], [303, 1, 1, "", "predict_interval"], [303, 1, 1, "", "predict_proba"], [303, 1, 1, "", "save"], [303, 1, 1, "", "set_params"]], "modeva.models.MoXGBRegressor": [[304, 1, 1, "", "calibrate_interval"], [304, 1, 1, "", "fit"], [304, 1, 1, "", "get_params"], [304, 1, 1, "", "load"], [304, 1, 1, "", "predict"], [304, 1, 1, "", "predict_interval"], [304, 1, 1, "", "save"], [304, 1, 1, "", "set_params"]], "modeva.models.ModelBaseClassifier": [[305, 1, 1, "", "calibrate_interval"], [305, 1, 1, "", "calibrate_proba"], [305, 1, 1, "", "decision_function"], [305, 1, 1, "", "get_params"], [305, 1, 1, "", "load"], [305, 1, 1, "", "predict"], [305, 1, 1, "", "predict_interval"], [305, 1, 1, "", "predict_proba"], [305, 1, 1, "", "save"], [305, 1, 1, "", "set_params"]], "modeva.models.ModelBaseRegressor": [[306, 1, 1, "", "calibrate_interval"], [306, 1, 1, "", "get_params"], [306, 1, 1, "", "load"], [306, 1, 1, "", "predict"], [306, 1, 1, "", "predict_interval"], [306, 1, 1, "", "save"], [306, 1, 1, "", "set_params"]], "modeva.models.ModelTuneGridSearch": [[307, 1, 1, "", "run"]], "modeva.models.ModelTuneOptuna": [[308, 1, 1, "", "run"]], "modeva.models.ModelTunePSO": [[309, 1, 1, "", "run"]], "modeva.models.ModelTuneRandomSearch": [[310, 1, 1, "", "run"]], "modeva.testsuite.utils.slicing_utils": [[311, 4, 1, "", "get_data_info"]], "modeva.utils.mlflow": [[312, 4, 1, "", "clear_mlflow_home"], [313, 4, 1, "", "get_mlflow_home"], [314, 4, 1, "", "set_mlflow_home"]], "modeva.utils.results": [[315, 2, 1, "", "ValidationResult"]], "modeva.utils.results.ValidationResult": [[315, 3, 1, "", "data"], [315, 3, 1, "", "func"], [315, 1, 1, "", "get_figure_names"], [315, 3, 1, "", "inputs"], [315, 3, 1, "", "key"], [315, 3, 1, "", "model"], [315, 3, 1, "", "options"], [315, 1, 1, "", "plot"], [315, 1, 1, "", "plot_save"], [315, 3, 1, "", "table"], [315, 3, 1, "", "value"]], "sphinx_gallery.utils": [[111, 4, 1, "", "optipng"]]}, "objnames": {"0": ["py", "property", "Python property"], "1": ["py", "method", "Python method"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "module", "Python module"]}, "objtypes": {"0": "py:property", "1": "py:method", "2": "py:class", "3": "py:attribute", "4": "py:function", "5": "py:module"}, "terms": {"": [5, 50, 117, 128, 136, 140, 141, 142, 146, 147, 213, 219, 220, 221, 222, 223, 225, 228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 252, 253, 255, 256, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 328, 330, 334, 335, 336, 338, 339, 340, 341, 342, 344, 345, 347, 349, 350, 351, 355, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 89, 91, 92, 93, 112, 117, 122, 123, 124, 125, 126, 127, 128, 129, 130, 136, 137, 138, 148, 171, 179, 187, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 254, 261, 262, 263, 264, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 326, 327, 330, 331, 332, 335, 336, 338, 339, 344, 345, 346, 348, 349, 351, 354, 356, 357, 359, 361, 363, 364, 367, 368, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387, 388, 391], "00": [2, 8, 9, 10, 11, 26, 28, 36, 50, 64, 68, 69, 72, 73, 76, 77, 84, 85, 88, 391], "000": [37, 330, 365, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 391], "0000": [8, 9, 10, 11, 18, 24, 25, 57, 72, 76, 77, 84, 88], "000000": [2, 3, 5], "00000002e": 26, "000028": 5, "000043": [2, 5], "0001": [15, 24, 25, 45, 279, 280, 292, 293], "000139": 54, "000194": 54, "0002": [21, 24, 25, 57, 72, 373], "00021112504082323335": 57, "0003": [25, 73, 91], "0004": [24, 44], "000434": [2, 3, 5], "0004342": 2, "000488": 335, "0005": 91, "0006": 62, "00065090e": 26, "0007": [24, 25, 35, 57], "0007069232358482019": 57, "0008": 24, "000806": 16, "0008e": 24, "0009": [21, 45], "000e": 10, "001": [24, 25, 26, 27, 44, 46, 47, 50, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 292, 293, 296, 297, 373, 386], "0010": [24, 25, 91], "0011": 47, "0012": 24, "0013": [20, 36, 45], "001398e": 346, "0016": 47, "00162004": 41, "0017": 44, "00178131": 26, "0019": [24, 44], "0020": [57, 73], "002041522022738862": 57, "0021": 73, "00214606": 26, "0022": [24, 36], "0023": 26, "0024": 25, "0025": [25, 47], "0025790630388779416": 57, "00259": 25, "0026": [21, 24, 25, 57], "00260": 25, "00262": 25, "00263": 25, "00267": 25, "00268": 25, "0027": 21, "00272": 25, "00278": 25, "00286": 25, "00287": 25, "00289": 25, "0029": [21, 91], "00291": 25, "00292": 25, "00293": 25, "00295": 25, "00297": 25, "0030": [24, 27, 35], "00302": 25, "00307": 25, "0031": 91, "003126e": 346, "00315": 25, "0033": 35, "0033984293947358856": 57, "0034": [24, 57], "00340": 25, "003448": 16, "00347": 25, "00354": 25, "00354041": 26, "0036": [25, 91], "003683": 11, "00369": 25, "00371": 25, "003728": 16, "0038": 25, "00380": 25, "00382": 336, "00387936": 26, "00388": 25, "0039": [20, 25, 26, 39], "0040": 25, "0041": 19, "0042": [19, 24, 25, 44], "00420": 25, "0043": [19, 25], "0044": [19, 25], "00441816": 26, "00444": 25, "0045": [19, 25], "0046": 19, "0047": [19, 25], "00471474": 26, "0048": [19, 25], "0049": [19, 25], "00490": 25, "004945": 14, "00499824": 8, "0050": [19, 25], "0051": [19, 25, 63, 72], "00511972": 8, "0052": [19, 25, 91], "0053": [19, 25], "0054": [19, 36], "0055": [19, 25], "0056": [19, 35], "00568": 25, "0057": [19, 27, 39], "005714": 11, "0058": 19, "0059": [19, 47], "0060": 19, "006083": 16, "0061": [19, 35], "0062": 19, "006292": 14, "0063": 19, "0065": [19, 378], "0066": 19, "0067": 25, "00676261": 26, "0069": 19, "0070": 19, "0071": 24, "0072": 19, "0073": 44, "0075": 19, "0076": 19, "007705": 15, "0078": 35, "0079": [19, 24, 47], "008": [91, 93, 391], "0080": [19, 85], "0081": 19, "00813082": 26, "00817011": 26, "0082": [24, 73], "00823353": 8, "008289": 16, "0083": 91, "00835": 25, "0084": [27, 72], "0085": [19, 24, 26], "0086": 24, "0087": 24, "0088": 19, "00881300e": 26, "00889805": 26, "0090": [19, 20], "0091": 20, "0093": 26, "00935902": 26, "0094": 19, "0095": [19, 20, 26], "009701": 9, "009832": 15, "0099": 19, "00996485": 26, "01": [4, 10, 11, 12, 15, 24, 26, 28, 37, 44, 46, 47, 50, 54, 82, 88, 279, 280, 309, 370, 382, 391], "0100": 19, "0101": 24, "0102": 35, "01028866": 8, "0105": 19, "01055193": 26, "01075141": 26, "0110": 19, "0113": 23, "01136341": 26, "0115": [19, 45], "0116": 91, "0117": 35, "01185624": 26, "0120": 19, "01217": 25, "0124": [19, 72], "0125": 19, "0126": 24, "012624": 15, "01265278": 26, "0128": 19, "01286074": 26, "0129": 19, "0130": 73, "0131": 36, "0134": 19, "0135": 19, "01355191": 26, "01358633": 26, "0137": [19, 45], "01371426": 26, "013826": 14, "01398571": 26, "0140": 19, "0142": [19, 35], "01428879": 8, "0143": [19, 35], "0145": 19, "0146": 19, "0148": 19, "0149": [24, 35], "0150": [19, 35], "0151": 19, "0152": 19, "0154": [19, 35], "0155": 19, "0156": 19, "0157": 19, "0158": 19, "0160": 19, "0161": 19, "0162": 19, "0163": 19, "0164": [19, 24, 35, 73], "01641528": 26, "0165": 19, "01658904": 26, "0166": [19, 35], "0167e": 19, "0168": 19, "0169": [19, 73], "0170": [19, 35, 47], "01700743": 26, "017097": 15, "0171": 19, "0172": 19, "0173": [19, 25, 36], "0174": 73, "0175": 19, "017541e": 346, "0176": 72, "0177": [19, 73], "0178": [45, 73], "0180": 19, "0181": [19, 72], "01815329": 26, "0182": 19, "0183": 19, "01830676": 41, "0184": 19, "01845475": 8, "0185": 19, "01853939": 8, "0188": 72, "01883298": 26, "0189": 19, "01901355": 26, "0191": [19, 36, 73], "0192": 47, "019206": 14, "0194": 19, "0196": 45, "0197": [19, 73], "0198": 85, "0198504": 26, "02": [10, 11, 19, 44, 48, 50, 60, 68, 70, 73, 82, 88, 93, 346, 382, 391], "0201": 19, "0202": [45, 73], "0204": 73, "020537e": 346, "0206": [19, 73], "02073921": 26, "0211": 19, "021241": 17, "021339": 17, "0214": 22, "0216": 47, "0218": 19, "02180920e": 26, "0219": [23, 47], "0220": 45, "02204623": 26, "0221": 19, "02214641": 26, "0222": [46, 73], "022405e": 346, "0225": 19, "0226": 45, "0227": 47, "02270906": 26, "02299061": 26, "0233": 19, "0235": 67, "023606": 3, "0237": [23, 73], "0238": 19, "02398097": 8, "024": [11, 12, 391], "0240": 45, "02418091": 26, "0243": [36, 44], "0244": [19, 73], "0245": [19, 44], "0247": [19, 44, 45], "02474484": 26, "0248": [19, 73], "0250": 24, "0251": 72, "0252": 19, "0254": 46, "02541088": 26, "0255": [19, 73], "0257": [35, 85], "0258": 19, "0260": 35, "0261": 19, "0262": 73, "0263": 19, "0264": 85, "02643381": 26, "0265": 19, "0266": 44, "0268": [19, 73], "0269": [22, 35], "026928": 15, "0271": [19, 72], "0277": 45, "0278": 19, "0284": 19, "0287": 72, "0287415": 26, "028757": 5, "0291": 45, "02922558": 26, "029384": [2, 5], "02953576": 26, "0296": [24, 47], "03": [2, 19, 25, 44, 68, 70, 84, 86, 346, 391], "0300": 19, "03026423": 26, "0303": 8, "0305": 45, "0305032": 8, "03081845": 26, "03114211": 26, "0312": [19, 88], "0317": 72, "0318": 24, "0319": [36, 72], "0324": 73, "0325": [45, 72], "03263528": 18, "03267184": 26, "0328": 47, "03286639": 26, "0333": [35, 47], "0334": 25, "0336": [72, 73], "0337": 72, "03414900e": 26, "0343": 19, "034555e": 346, "0345931": 26, "0349187": 26, "035233": 3, "0355": 32, "03566952": 26, "03576016": 26, "0358": 25, "0359": 47, "036": [32, 37, 391], "0367": 21, "0368": 25, "036867": 3, "0369": [36, 73], "037": [76, 78, 391], "0370": 63, "0371": 36, "0372": 19, "0376": [21, 73], "0377": 24, "038": [6, 12, 391], "0380": 44, "0381": 73, "0387": [24, 73], "03888": [344, 351], "03891696": 8, "0394": 44, "03964159": 26, "0397": 73, "0398": 73, "04": [2, 8, 12, 35, 44, 48, 50, 74, 77, 78, 346, 351, 391], "0401": 44, "04027566": 26, "04028322": 26, "04034364": 26, "04041": 373, "0405": 44, "04067592": 8, "0408": 73, "0411": 73, "0414": 19, "0417": 73, "041787": [2, 5], "0419": 44, "04199568": 26, "0423": 67, "0423956": 26, "04257239": 26, "0427": 36, "04270729": 26, "0430": 73, "04318783": 26, "04341139": 26, "04367255e": 26, "044": [10, 12, 391], "04415915e": 26, "0443": 73, "0444": 25, "0448": 91, "04500528": 26, "0451": 25, "0452": [35, 73], "0454": 73, "0459": 62, "045e": 10, "046093": 50, "0466": 73, "0467": [35, 85], "04677684": 26, "04687064": 26, "0471": [19, 32, 47], "0474": 73, "047750": 17, "0478": 18, "04787676": 26, "0479": 67, "0485": 36, "0488": 63, "04900599": 26, "0491": 45, "04949369": 26, "0497": 35, "04975605": 26, "0498": 73, "05": [19, 24, 25, 35, 44, 55, 60, 68, 296, 297, 356, 357, 391], "0505": 73, "0506": 63, "05087281": 26, "0514": 19, "0516": 72, "05168332976549405": 57, "0517": 57, "0519": 73, "0520": 73, "05251747": 8, "05253822": 26, "052885": 9, "0530": 19, "0532": 24, "0533": 36, "0534514": 26, "0536": 73, "0538": 85, "0540": 57, "05400321268524999": 57, "05408157": 26, "05424298": 26, "0543": [47, 88], "0544": 35, "0546": 25, "0547": 25, "0549": 73, "05490845": 26, "055148": 9, "05536766": 26, "056328": 3, "05644409": 26, "0570": 35, "05759116": 8, "0578455": 26, "058": [84, 86, 391], "05801912": 26, "05822533": 26, "0583": 35, "0586": 32, "0588013": 26, "059": [20, 28, 391], "0590748": 26, "0591": [24, 73], "0593": 35, "0599": [67, 73], "06": [54, 55, 68, 137, 346, 391], "06005889": 8, "0601": 24, "0602": 73, "0607": 46, "06129566246677624": 57, "0613": [57, 85], "061519": 3, "0617": 44, "0619": 73, "0622": 35, "0623": 73, "0626": 72, "0627": 36, "062784e": 346, "0633": [19, 44, 46], "0634": [35, 44], "0635": 47, "0636": 19, "0639": [35, 44, 73], "0644": 85, "0647": [22, 36], "0650": 63, "06531028": 26, "06555223": 26, "0656": 73, "0659": 85, "0660": 73, "0661": 73, "0667": 85, "0669": 73, "067656": 9, "06786967": 26, "0681": 36, "0682": 73, "0684": 66, "069200": 3, "0695": [46, 73], "0697": 73, "07": [12, 28, 35, 50, 68, 93, 346, 351, 391], "0701": 44, "07045835": 26, "07084209": 26, "07132": 367, "07145943": 26, "071514": [2, 5], "0720": 35, "0722": 73, "072233": 50, "07236131": 8, "07256868277920407": 57, "0726": 57, "0727": 73, "0728": 45, "0728663": 26, "0730": 63, "073938": [2, 5], "07412234": 26, "0744": 46, "07455473": 8, "07458042": 26, "0746": 19, "074631": 3, "07463474": 26, "0748": 85, "0749": 19, "07496113": 26, "0754": 46, "07552771": 19, "07558263": 26, "0758": 73, "07592173": 8, "0761": 36, "07630248": 8, "0764496": 26, "0765": 72, "07686822": 26, "0769": 46, "0770": 73, "0772": 19, "0773e": 19, "0774": 73, "07869662": 18, "0788": 73, "0789": 45, "0790": 19, "0790521": 26, "0793": 24, "079543": [2, 5], "0797": 46, "0799": 46, "08": [48, 50, 73, 346, 391], "0801": 73, "080281": 9, "0805": 73, "0807": 46, "08112": 50, "08114306": 26, "0812": 73, "08127522": 26, "0820": 85, "0830": 46, "08304836": 8, "083151": 9, "0833": [24, 76], "0834": 46, "0836": 73, "0849": 36, "0852": [46, 73], "08544422": 8, "08572601": 26, "0860": 73, "0862": 73, "086518": 9, "086587": 50, "0872": 63, "0873": 62, "0877": 63, "0879": 18, "0880": 72, "0884": [18, 46, 73], "0886037": 18, "08875921": 26, "08920078": 26, "0895": 47, "0896": [8, 10], "0897": 72, "09": [50, 74, 76, 86, 346, 391], "0900": 73, "0902": [67, 73], "0905": 73, "0906": 46, "0908": 35, "0909": 46, "09141124": 18, "0915": 22, "0916": 46, "0919": 73, "0920": 72, "0926": 73, "093": [17, 28, 391], "0930": 73, "093091": 9, "0931": 85, "0932": 24, "0937": 46, "0942": 73, "0944": 85, "0962": 85, "0963": 46, "0972": 73, "09737877": 26, "097382": 9, "0977724": 26, "09817635": 26, "0982": 72, "09821501": 26, "0989": [19, 46], "09906073": 26, "0991": 73, "09918538": 26, "099335": 3, "0_model": 391, "0_residu": 391, "1": [2, 3, 4, 5, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112, 117, 122, 123, 124, 128, 130, 136, 138, 171, 187, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 244, 246, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 325, 331, 335, 336, 338, 339, 341, 343, 344, 377], "10": [2, 3, 5, 9, 10, 11, 18, 19, 22, 23, 24, 25, 26, 27, 28, 35, 36, 44, 45, 46, 47, 50, 53, 57, 62, 63, 68, 69, 72, 73, 76, 77, 78, 80, 81, 84, 85, 88, 91, 112, 117, 119, 122, 125, 138, 187, 216, 217, 218, 219, 220, 221, 222, 223, 227, 231, 233, 234, 235, 236, 237, 238, 239, 242, 245, 279, 280, 283, 284, 290, 291, 292, 293, 296, 297, 308, 309, 310, 330, 332, 334, 335, 336, 340, 341, 345, 346, 347, 348, 349, 354, 365, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382, 383, 386, 391], "100": [9, 10, 18, 19, 24, 25, 26, 27, 44, 46, 47, 50, 53, 57, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 123, 130, 216, 231, 232, 233, 254, 279, 280, 281, 282, 309, 339, 345, 347, 349, 351, 363, 367, 368, 369, 371, 372, 377, 378, 379, 380, 381, 382, 383, 386], "1000": [3, 6, 7, 10, 11, 15, 24, 25, 45, 57, 84, 127, 171, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 279, 280, 292, 293, 296, 297, 341, 386], "10000": [3, 5, 35, 36, 57, 279, 280, 335], "100000": 2, "1000000": [3, 5, 68, 383], "10004": 6, "10020": 6, "10027": 6, "1003": 36, "10034": 6, "10039": 6, "1004": 85, "10054": 6, "10063": 6, "10074": 6, "10080": 6, "10087": 6, "10091232": 26, "100e": 10, "101": 72, "1010": 73, "1011": 36, "1013": 6, "10134": 6, "1015": 36, "1016": 36, "10160": 6, "1018": 6, "1019": 36, "10202": 6, "10218": 6, "1024": 73, "1026": 46, "10279": 6, "10284346": 26, "10287": 6, "10294": 6, "10295": 6, "103": [6, 9], "10310": 6, "10323": 6, "10331": 6, "10344": 6, "10344295": 8, "10369": 6, "10388": 6, "104": [68, 72], "1041": 46, "1043": 22, "10444": 6, "10448": 6, "1044807": 8, "1045": [10, 11], "10452": 6, "10459": 6, "10469937": 18, "10471": 6, "10481": 6, "10487": 6, "1049": 36, "105": 73, "1051": [23, 85], "105361": 5, "10544": 6, "10549": 6, "105570": 373, "10561": 6, "10564": 6, "1057": 6, "10571": 6, "10572": 6, "10585": 3, "1059": 343, "10594": 6, "1060883": 8, "106133": 3, "10623": 6, "1063": 35, "10639": 6, "10659": 6, "1066": 73, "10666": 6, "10667": 6, "10674": 6, "10685": 6, "1071": 18, "10711": 6, "1072": 73, "10722": 6, "10723": 6, "1073": 73, "10743": [6, 9], "10759": 6, "1076": 73, "10769": 6, "1077": 73, "1078": [6, 73], "1079": 73, "1081": 73, "10818": 6, "10820": 6, "10829": 6, "10849": 6, "10855": 6, "1086": [6, 343], "10861737": 26, "10862531": 8, "10869": 6, "1087": 85, "10870": 6, "10875": 6, "10876": 6, "10880": 6, "109": 62, "10941": 6, "10947": 6, "1095": 36, "10954": 6, "10977": 6, "1098": 73, "10989": 6, "1099": 73, "11": [2, 3, 5, 9, 11, 18, 19, 24, 25, 26, 35, 44, 45, 46, 50, 68, 69, 72, 73, 76, 84, 85, 88, 112, 346, 348], "110": [10, 62, 73], "1100": 73, "110027e": 346, "11003": 6, "11008": 6, "1101": 73, "11018": 6, "1103": [6, 73], "1104": 73, "11058": 6, "1107": 69, "11086": 6, "1109": [336, 340], "110928": 50, "1110": [9, 73], "11109": 6, "11113": 6, "111206": 9, "11126": 6, "11153": 6, "11159": 6, "11185": 6, "11192": 6, "112": [9, 73], "1120": [22, 45], "11229": 6, "1123": [73, 76], "1124": 6, "11243": 6, "1125": [68, 72, 73, 84], "11257": 6, "1128": 63, "113": [19, 63], "11304": 6, "1131": 73, "1132": 73, "11339": 6, "11345341": 8, "11356": 6, "113943": [2, 5], "1139433": 2, "11398": 6, "11399": 6, "1141": 73, "11413": [6, 11], "11415": 6, "1143": 6, "1145": [6, 63], "11454": 6, "1146": 73, "11469": 6, "11473": 6, "11476": 6, "1149": 73, "11493": 6, "11499": 6, "115": [8, 9], "1150": [35, 63], "1151": 63, "11510": 6, "1154": 35, "11541": 6, "11559": 6, "1156": 24, "11563613": 26, "1157": 46, "11570": 6, "11573": 6, "11588": 6, "11589": 6, "116": [128, 136, 338], "1160": 9, "1161": 73, "1162": 73, "1163": 19, "1164": [18, 73], "11644": 6, "1165": 73, "1166": [9, 73], "11673": 6, "1168": 9, "11689": 6, "11690": 6, "117": 63, "1170": 73, "11704": 6, "1171": [9, 73], "1172": 6, "11725": 6, "1173": 73, "1175": [9, 73], "11754": 6, "1176": 35, "11765": 6, "11769": 6, "1178": 73, "1181": 69, "1182": [6, 73], "1182e": 19, "11835": 6, "118367": 3, "1186": 73, "11862": 6, "11865": 11, "1187": 6, "11877264": 8, "11879": 6, "1188": [72, 84], "11885": 6, "11888": 3, "1189": 343, "119": [9, 10, 11], "1191": [72, 84], "1193": 73, "1194": 6, "11944": 6, "1195": 6, "11952": 6, "1196": 35, "11962": 6, "1197": [46, 68], "11972": 6, "1199": 73, "11997": 6, "12": [2, 5, 6, 8, 9, 10, 11, 18, 19, 24, 25, 26, 44, 45, 46, 50, 54, 57, 68, 69, 72, 73, 76, 77, 84, 85, 88, 112, 346], "120": [10, 63, 73, 76], "1200": 84, "120000": 2, "12004": 6, "1201": 73, "1202": [8, 339], "12023": 6, "12043": 6, "12047": 6, "12051": 6, "12052": 6, "12056": 6, "12060": 6, "1207": 73, "12071": 6, "12080": 6, "12087": 6, "1209": 85, "121": 73, "12105": 6, "12119": 6, "1212": 73, "12122": 6, "1213": 85, "12135": 6, "1214": 72, "12141": 6, "122": 73, "1220": 73, "12200": 6, "1222": 24, "122337": 11, "12237": 6, "12240358": 8, "12244993": 26, "12252": 6, "1226": 36, "12260411": 26, "1229": 73, "12302": 6, "1232": 343, "12325": 6, "12330": 6, "12338": 6, "1234": [30, 31], "1235": 8, "12390": 6, "12392": 6, "124": [6, 10, 35], "12409": 6, "1241": 73, "1242532": 26, "1243": 76, "12434": 6, "12467": 6, "12470": 6, "12490": 6, "12493": 6, "1250": [72, 76], "125000": 26, "1252": 69, "125214": 9, "1255": 73, "12559": 6, "12567": 6, "1257": 25, "1258": 73, "12587": 6, "12592": 6, "126": [68, 72], "12622": 6, "12624014": 26, "1263": [69, 73], "12634": 9, "12640": 6, "12658": 6, "126673": 50, "12674": 6, "1268": 73, "12692": 6, "12693": 6, "127": 6, "12716": 6, "12718679": 26, "12735": 6, "12754": 6, "12759": 6, "1276295": 26, "12788": 6, "1280": 73, "12805": 6, "12806": 6, "12815": 6, "12817": 6, "1282": [35, 46, 69, 72, 73], "12846": 6, "1286": 46, "12863": 6, "1287": [73, 85], "12870": 6, "1288": 23, "12881": 6, "12899": 6, "129": 85, "1290": [6, 73], "12914": 6, "12920": 6, "12925": 6, "12929": 6, "12971": 6, "129740": 5, "129745": 3, "1298": 6, "12982": 6, "12983": 6, "12989": 6, "1299": 76, "12994237": 8, "13": [2, 5, 8, 9, 10, 11, 18, 19, 24, 25, 26, 44, 45, 46, 54, 68, 69, 72, 73, 76, 84, 85, 336, 346], "1301": 85, "13013": 6, "13021": 6, "1303": [6, 35, 73], "13032": 6, "130323": 50, "13036": 6, "13044491": 19, "1305": [62, 73], "13050": 6, "13055": 6, "13066686": 8, "13068": 6, "130687": 50, "1307": 24, "13071": 6, "13073": 6, "13080": 6, "1309": 73, "130937": 50, "130939": 50, "130998": 50, "131": 76, "1310": 6, "131044": 50, "1311": [20, 26], "131115": 50, "13112096": 26, "1313": 73, "13132": 6, "1314": 73, "1318": 46, "13199": 6, "132": 68, "13214": 6, "1322": 85, "13221": 6, "132260": [2, 5], "1326": [24, 73], "13269": 6, "1327": 69, "13273": 6, "1328": 6, "13281": 6, "13283": 6, "13296": 6, "133": 76, "133016": 50, "13323": 6, "13324": 6, "133381": 50, "1334": [6, 22, 26], "13407": 6, "13425": 6, "1343": [8, 9, 10, 11, 72], "13436": 6, "13451": 6, "13464": 6, "13465": 6, "1347": 46, "13471": 6, "13481": 6, "1349": 73, "13496": 6, "13497": 6, "135": [72, 73], "13504": 6, "1351": [20, 46], "135229": 16, "13531": 6, "13538": 6, "1354": [57, 73], "13541995570654827": 57, "13559": 6, "13564104": 26, "1358": 6, "13586": 6, "13587": 6, "13606": 6, "13619": 6, "1362": 6, "1363": [35, 46], "13638": 6, "13658": 6, "13659": 3, "13663": 6, "13664": 6, "13670": 6, "13673": 6, "13682": 6, "137": [9, 68], "137084": 50, "13709": 6, "13739": 6, "1374": 62, "13745": 6, "13759": 6, "13761": 382, "1377": 8, "13771": 6, "13774": 6, "13780": 6, "13782": 6, "1379": 46, "13792": 6, "13796": 6, "138": [68, 73], "13805": 6, "13810": 6, "13818": 6, "13827": 6, "1383343": 2, "13835849": 26, "1384": 62, "138412": 9, "13850": 6, "13863": 6, "13875": 6, "13877": 6, "13889": 335, "138957": 16, "1389656": 2, "139": 68, "13903": 54, "1391": 85, "1392": 6, "13931": 6, "13934": 6, "1394": 9, "13940": 6, "139443": 50, "13954": 6, "13965": 6, "139691e": 346, "13973": 6, "13975": 72, "13976": 6, "1399": [69, 73], "14": [2, 3, 5, 9, 10, 18, 19, 24, 25, 26, 44, 45, 46, 50, 68, 69, 72, 73, 76, 84, 85, 88, 346], "140": [57, 68], "140000": [3, 5], "1401": 46, "14030": 3, "14035251191539191": 57, "1404": 57, "14045": 6, "14055": 6, "14069": 6, "14071": 6, "14077": 6, "14088": 6, "141": [68, 72, 74, 391], "14107": 6, "14108088": 8, "1411": [35, 46], "14125": 6, "14139967": 26, "1414": 46, "14149": 6, "14162": 6, "14183": 6, "1419": 11, "14198544": 8, "142": [6, 11, 24, 28, 68, 391], "1422": 63, "14232": 6, "14237": 6, "14243": 6, "14257": 6, "14260": 6, "1427": 6, "14280": 6, "1429": 76, "14303": 6, "143034": 50, "14333": 6, "1435": 46, "14357": 6, "1436": 85, "1437": 73, "1438": [67, 73], "1442": 9, "14427": 6, "14429": 6, "1443": [73, 336], "14430": 6, "14454": 6, "14464": 6, "14481": 6, "14499": 6, "145": [8, 73], "145000": 26, "14514": 6, "14519": 6, "14520": 6, "1453": 47, "1454": 9, "1456": 9, "14562": 6, "14566": 6, "1457": [9, 62], "1458": 9, "14582492": 8, "14583421": 8, "14599": 6, "146": 10, "1460": 6, "14615": 6, "14617": 6, "14664": 6, "1468": [46, 63, 69], "1469": 6, "14695": 6, "146996": [2, 5], "147": [8, 63], "1471": 336, "14716": 6, "14724": 6, "14726": 6, "1474": 73, "14747": 6, "14756": 6, "14772": 6, "1478": 73, "14787": 6, "14794": 6, "148": 8, "1480": 6, "14818567": 26, "14829": 6, "14833": 6, "14855": 6, "14858": 6, "1487": 35, "14873": 6, "14875539": 8, "14877": 6, "14892": 6, "149": 8, "1490": 73, "14901": 6, "1491": 72, "14919": 6, "1493": 73, "14935775": 26, "1495": 6, "1497": 73, "14972": 6, "14973": 6, "15": [2, 5, 8, 9, 11, 14, 15, 18, 19, 24, 25, 26, 44, 45, 46, 47, 50, 57, 68, 72, 73, 76, 84, 85, 130, 344, 346, 351, 370], "150": [8, 63, 81, 82, 391], "1500": 46, "150000": [2, 5], "1501": 73, "15015": 6, "15028": 6, "15038": 6, "1504": 73, "15050": 6, "15060264": 8, "1507": 73, "15075029": 26, "1508": [69, 73], "15091": 6, "15094": 6, "15100": 6, "151090": 3, "1511": 85, "15121": 6, "1514": 73, "1515": [10, 35], "1517": 73, "15192": 6, "15198": 6, "15203": 6, "1521": 62, "15210": 6, "15220": 6, "15228": 6, "15231": 6, "15244": 6, "15257": 6, "15260": 9, "15280": 6, "15282": 6, "15297": 6, "153": 8, "1531": [63, 73], "1532": [35, 73], "15322": 6, "15324403": 8, "15333": 6, "15366": 6, "15388": 6, "154": 6, "15417": 6, "1543": 6, "15462": 6, "15470": 6, "15472": 6, "15479": 6, "155": [8, 63], "155000": 26, "15501": 6, "1551": 85, "15510": 6, "15517": 6, "1552055": 8, "15524": 6, "15532": 6, "15538": 6, "15545": 6, "1555": 73, "15556": 72, "155640": [2, 5], "15565": 6, "15579": 6, "15585": 6, "15587": 6, "156": 6, "15615": 6, "1562": [32, 76], "156307": [2, 5], "15647769": 26, "1565": 69, "15668": 6, "15670": [6, 369], "156719": 5, "15673": 6, "1569": 73, "157": 8, "1571": 88, "15718208": 8, "15725": 6, "15729": 6, "1573": 73, "15738": 6, "15745": 6, "1576": 73, "15767": 6, "15772": 6, "15781": 6, "15793": 6, "15796": 6, "1581": 73, "15812": 6, "1582": 73, "15827": 6, "1583": [6, 73, 76], "1585": 73, "15857": 72, "1586": [6, 73], "158681e": 346, "1587": [69, 73], "15873": 6, "1588": 72, "15888": 6, "1589": 77, "15894": 6, "159": [6, 8, 76], "15904": 6, "15908": 6, "15910": 6, "15930": 6, "15945": 6, "15953": 6, "15964": 3, "15966": 6, "1596886": 8, "1597": 73, "15984": 6, "15991107": 26, "15998": 6, "16": [3, 5, 6, 8, 9, 10, 11, 18, 19, 22, 24, 25, 26, 28, 35, 45, 46, 54, 68, 69, 72, 73, 76, 77, 84, 85, 346, 365, 391], "160": 8, "1602": 47, "1603": [6, 73, 76], "16042": 6, "16085": 6, "161": [8, 19], "1612": 69, "16144": 6, "1615": 76, "16158": 6, "16160": 6, "16196": 6, "16199": 6, "16220": 6, "1623": 73, "1624": 6, "1626": 8, "1627": 47, "16272": 6, "16275": 6, "16285": 6, "16294": 6, "163": [8, 18, 28, 391], "16313": 6, "1632": [69, 73], "16325": 6, "1635372": 26, "16367": 6, "1637": 62, "16373902": 8, "1638": 73, "164": 8, "1640": 85, "1641": [36, 336, 340], "1642": [8, 9, 10, 11], "16425": 6, "1645": 6, "16452": 6, "1646": 73, "1647": 6, "16474": 6, "16478": 6, "16491": 6, "165": 8, "1650": [44, 336, 340], "16508": 6, "16518": 6, "16524": 6, "16532": 6, "16556": 6, "1658": [44, 66, 73], "16584": 6, "166": [8, 10, 73], "1660": 46, "16600": 6, "16621": 6, "166214e": 346, "16642": 6, "16665": 6, "1667": [10, 76], "167": 8, "167233": 3, "1672709": 18, "167295": 5, "16733": 6, "1674": 44, "167484": 3, "167502": 5, "16767": 6, "16770": 6, "168": 88, "1680": 73, "16819": 6, "1684": [69, 73], "16842": 6, "1686": [44, 76], "1687": 46, "16879": 11, "16890": 6, "16892": 6, "169": 8, "1690": 45, "16901": 6, "16902": 6, "16904": 6, "16906": 6, "16948": 6, "16960": 6, "1698": [46, 76], "16997403": 26, "17": [2, 3, 5, 8, 9, 10, 18, 19, 20, 24, 25, 26, 28, 45, 46, 50, 68, 72, 73, 76, 84, 85, 332, 336, 340, 345, 346, 347, 348, 349, 350, 351, 391], "1700": 73, "1702": 73, "17033": 6, "17035": 6, "1704": [35, 44], "17041": 8, "17042": 8, "17043": 8, "17044": 6, "170817": [14, 50], "17085": 6, "171": 8, "17105": 6, "1710586": 19, "17125": 6, "17127": 6, "17162": 6, "17167": 6, "171845": 11, "172": 8, "17204": 6, "17205": 8, "17211": 6, "17226": 6, "17247": 6, "1725": 73, "1725592": 8, "1727": [6, 73], "17285": 6, "17287": 6, "173": 10, "17305": 6, "17319": 8, "1732": 73, "17320": [6, 8], "17339": 6, "17347": 6, "1735": 44, "17353": 6, "1736": 9, "17364": 11, "17367": 6, "1737": [9, 35, 73], "17374": [8, 9, 10, 11], "17375": [8, 9, 10, 11], "17376": [8, 9, 10, 11], "17377": [8, 9, 10, 11], "17378": [8, 9, 10, 11], "17379": [6, 9, 10, 11], "174": 8, "1742": 73, "1743": 9, "174612": [2, 5], "1747": 73, "1747162": 8, "17478107": 19, "1752667": 26, "1755": [46, 69, 73], "1756": 45, "175762": [14, 50], "1758": [44, 46], "1759": 6, "176": 63, "17617815": 26, "17623590e": 26, "176381": [2, 3, 5], "1765": 35, "1765252": 26, "1768": 85, "1769": 35, "177": 19, "1771": 73, "1772": 85, "177261": 9, "17742966": 8, "177892": 9, "178": 8, "1780": 73, "1781": 6, "1785": [6, 73], "1786": 62, "179": [8, 36, 63], "17904737": 26, "1793": 44, "1794": 44, "1795": [44, 66], "1798": 35, "17becf": 57, "18": [3, 5, 6, 8, 9, 10, 11, 12, 18, 19, 24, 25, 26, 35, 45, 46, 50, 68, 69, 72, 73, 76, 84, 85, 346, 347, 391], "180": [35, 88], "180000": 5, "1802": [344, 351], "18033722": 19, "1804": 47, "1805": [45, 76], "1808": 76, "1809": 62, "181": 11, "1811": 73, "18112": 3, "1814": 73, "181558": [2, 5], "1816": 46, "1818": 10, "182": 8, "1821": 35, "18238135": 26, "1826": 47, "1828": 63, "183": 6, "1835": 6, "184": 8, "1843": 44, "1844": 47, "1845": 6, "18458366509258792": 57, "1846": 57, "1847": 6, "185089": [2, 5], "1854": 6, "18544136": 8, "18554294": 26, "1858": 24, "186": 88, "1861": 6, "1863": 76, "1868": 24, "187": [8, 72, 85], "18726286": 19, "1876": 73, "187721e": 346, "188": [8, 63], "1880": 63, "188366": 2, "18843615e": 26, "1884769": 8, "1887635938666557": 57, "1888": 57, "1889": 6, "189": [9, 11, 36, 54], "1894": 45, "19": [5, 8, 9, 10, 11, 18, 19, 24, 25, 26, 45, 46, 68, 69, 72, 73, 76, 84, 85, 88, 336, 346], "190098": 11, "190408": 50, "19098": 368, "191": 72, "19129001": 26, "19129730e": 26, "1913": 35, "1915": 6, "1916": 6, "191731": [2, 5], "19179": 9, "1918": 73, "192": [8, 57, 60, 391], "1920": 44, "1921": 44, "192551": 11, "1926": [45, 69, 73], "19284549": 8, "192924": 11, "1933": 6, "1939": 44, "1940": [10, 11], "194163": 50, "1948": 62, "195": [8, 88], "19509665e": 26, "1953": 35, "1956": 63, "1957": 76, "1959": 44, "196": [8, 36], "1966": 73, "196632": 3, "19668267": 8, "1970": [8, 10, 35], "1972": 6, "197313": 9, "198": 36, "1980e": 25, "1981": 85, "1985": 6, "1986": 73, "199": 68, "1990": [69, 73], "19940979": 8, "1995": [9, 35, 36, 69, 73, 76], "1996": [9, 35, 36], "1997": [9, 35, 36], "1998": [9, 35, 36, 73], "1999": [9, 35, 36], "1_extmodel": 391, "1_perform": 391, "1d": [68, 69, 76, 77, 84, 85, 88, 235, 236, 237, 238, 239, 241, 244, 253, 254, 298, 309, 333, 335, 341, 345, 347, 349, 352, 356, 367], "1e": [137, 279, 280, 296, 297, 373, 381], "1em": 369, "1f77b4": 57, "1f968b": 57, "2": [2, 3, 5, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 92, 112, 130, 136, 137, 179, 187, 216, 217, 218, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 244, 249, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 325, 334, 335, 336, 339, 340, 343, 344, 377, 387], "20": [3, 5, 8, 9, 10, 11, 18, 19, 24, 25, 26, 27, 36, 44, 45, 46, 47, 50, 53, 54, 57, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 228, 241, 244, 279, 280, 281, 282, 283, 284, 296, 297, 339, 346, 351, 354, 365, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 386, 388], "200": [8, 44, 92, 253, 292, 293, 309], "2000": [7, 9, 35, 36, 57, 62, 63, 76, 91, 216, 230, 231, 336, 339, 345, 346, 347, 349, 379, 380, 382], "20000": [2, 5], "200000": [5, 24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "2001": [336, 343, 350], "2002": 336, "2003": [336, 340, 367], "2005": [35, 330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "200671": 5, "2007": [6, 73], "2008": [336, 340, 343, 346], "2009": [128, 136, 338], "200e": 10, "201": [6, 19, 36, 88], "2011": [11, 54, 373], "2012": [11, 54, 336, 339], "20135065": 26, "2015": 347, "2016": [343, 344], "2017": 344, "2018": [344, 351], "2019": 339, "202": [8, 88], "2020": [339, 343, 367, 373], "2021": [128, 136, 336, 338], "2022": [128, 136, 338], "2023": 382, "2024": [36, 92, 368, 369], "2025": [2, 50], "2029": [6, 35], "203": [8, 36], "2030": 73, "2031": 73, "2036": [73, 76], "203604": [2, 5], "2037": [67, 69], "203739e": 346, "204": [8, 76, 84, 88], "2040": 6, "2043": 73, "2045": 72, "20452690e": 26, "2046": 63, "205": [10, 35, 76, 84, 88], "2050": 73, "2053": 76, "2059": 73, "206": [40, 42, 76, 84, 88, 391], "20604": 3, "2062": 85, "2068": 85, "207": [8, 62, 76, 84, 88], "2071": [6, 76], "2072": 36, "2074": 46, "2075": 47, "2076": [69, 73], "2078": 36, "2079": 63, "208": [8, 76, 84, 88], "2080": 44, "2082": 24, "2083": 76, "2084": 6, "209": [36, 76, 84], "209284": 5, "20a386": 57, "21": [2, 3, 8, 9, 10, 11, 18, 19, 25, 26, 46, 50, 68, 69, 73, 76, 84, 85, 88, 112, 346], "210": 8, "2100": 68, "21010": 3, "2102": 69, "2108": [6, 62], "211": 8, "2111": [19, 76], "2112": 73, "2114": 73, "212": [6, 8], "21208736": 8, "2121": 10, "2135": 18, "214": 8, "2140": 35, "2148": 32, "2149762": 26, "215": 339, "21508346": 8, "2154": 72, "21548": 3, "2158": 6, "216167": 50, "216418": 50, "216430": [2, 5], "2165": 9, "2169": 24, "217": 8, "2174": 35, "217750": 3, "218": 8, "2181": [9, 73], "2183": 6, "2184": 9, "2186": 45, "2188": 9, "219": 8, "219010": 3, "219618": 50, "21968930e": 26, "2197": 73, "21974921": 8, "2198": 73, "22": [2, 8, 9, 10, 11, 18, 19, 25, 26, 35, 46, 54, 68, 73, 76, 84, 85, 346, 391], "2200": 6, "220000": [2, 5], "220098": 3, "2201": [6, 336], "22026": 3, "2209": 73, "221": 6, "221177": 3, "22122524": 8, "2215": 73, "222": 8, "2223": 6, "222458": 50, "223": [6, 35], "2232": 76, "22346": 3, "2237": 73, "2239": 10, "2240": 45, "2241": [6, 35], "22424265": 8, "224594e": 346, "224693": 9, "225": 8, "2250": 84, "2259": 23, "226342": [2, 5], "226409": 3, "2265": 63, "2268": 85, "227": [8, 36, 63], "22723": 3, "2273724": 2, "2277": 73, "2279": 72, "227978": 9, "228": 8, "2295": 73, "22nd": 344, "23": [5, 8, 9, 10, 11, 18, 19, 25, 35, 46, 50, 68, 69, 72, 73, 76, 84, 85, 336, 346], "230": [63, 339], "2304": 382, "230452": 3, "2305": 369, "2308": 73, "231": 8, "232285": 3, "2324": 62, "2325": 85, "23254459": 26, "23268937": 8, "2328": 73, "2329": 69, "233": [8, 58, 60, 391], "2330": 6, "23364": 3, "2342": 36, "234716": 5, "2351": [69, 73], "2352": 36, "2356": 35, "23565667": 8, "2361": 6, "2362": 85, "23693366": 26, "237": [9, 63], "237041": [2, 5], "2371": 6, "237566": 3, "238": 8, "2383": 35, "2385": 73, "2389": 62, "238a8d": 57, "2393": 73, "2395": 73, "2396": 36, "24": [2, 3, 5, 8, 9, 10, 11, 18, 19, 25, 35, 46, 50, 54, 68, 73, 76, 84, 336, 340, 346, 347], "240": [8, 63], "2400": 6, "24000": 50, "240000": [3, 5], "2401": 85, "2405e": 25, "24081257": 26, "2410": 368, "2414": 88, "242": 63, "2424": 8, "2429": [6, 46], "2434": [69, 73], "24355615": 26, "244024": 3, "245": 85, "2450": 6, "2453": 76, "2453e": 25, "2457": 6, "246": 8, "246499": 3, "2467": 73, "2468": [47, 73], "2469": 73, "2474": 6, "2476": [6, 73], "2478": 23, "248": [8, 73, 88], "24835294": 26, "249": 8, "2491": 6, "2492": 45, "2493": 73, "25": [2, 3, 5, 9, 10, 11, 18, 19, 25, 46, 50, 68, 72, 73, 76, 84, 137, 187, 346, 377], "2500": [68, 76], "25000": 26, "250000": 5, "250372": 3, "251": 8, "2511": 35, "2513": 25, "251380": 3, "2515": 36, "2517": 6, "252": [6, 8], "2525": 6, "2528": 72, "253": 72, "2531": 63, "2535": 6, "2537": [8, 10, 11], "254": [8, 35], "255514": [2, 3, 5], "2558": 45, "256": 73, "256477": [2, 5], "256837e": 346, "2569": [6, 73], "2570": 35, "25754": 9, "2576": [8, 9, 10, 11, 73], "2578": 73, "257811": 3, "25827247": 18, "2585": 6, "2592": 73, "25th": 334, "26": [2, 8, 9, 10, 11, 18, 19, 25, 35, 46, 50, 72, 73, 76, 84, 112, 346], "2600": 6, "260000": 5, "261": [6, 8], "2617427": 18, "2618": 6, "2619": 6, "262214": [2, 5], "2623": 35, "2631": 63, "263324": 54, "2636": 62, "2639": 6, "2641": 6, "264345": [2, 5], "26452012": 8, "2646": 73, "266": 8, "266068e": 346, "26611415e": 26, "26635944": 8, "266649": 9, "266958": 5, "267": [9, 62, 69, 73, 85], "2673": [35, 73], "2674": 24, "268": 8, "26802368": 41, "2685": 72, "26863568": 26, "2688": 24, "269": 19, "2692": [69, 73], "27": [2, 18, 19, 25, 35, 46, 50, 72, 73, 76, 84, 346], "270": 8, "2702": [6, 85], "2706": [69, 73], "270654": 50, "27079123": 26, "2709": 6, "27130596": 8, "2716": 76, "271688e": 346, "2723": 32, "2727": [8, 9, 10, 11, 54, 76], "273": 8, "2734": 85, "27368400e": 26, "2739": 66, "2742": 6, "275": 6, "27521925e": 26, "2755": 73, "2759": 6, "276": [73, 339], "2760": 57, "27604510845035524": 57, "276345": [2, 5], "277": [63, 73], "2783": 6, "2786": 27, "2788": 63, "2789": 63, "279": 73, "279756": 9, "279964": 3, "28": [3, 5, 18, 19, 25, 46, 48, 68, 73, 76, 84, 112, 346, 391], "280": [8, 18, 69, 73, 76], "2800": 24, "2805": 6, "2808": 73, "2809": 68, "281": [8, 11], "2813": 6, "281760": [2, 5], "282": [10, 73], "282101": [2, 5], "283": [54, 69, 73, 85], "2831581": 8, "2834": 18, "2839": 6, "284": [9, 69, 73, 85], "2841": 6, "2842": 18, "2848818": 2, "284882": [2, 5], "285": [8, 9, 69, 73, 85], "285000": 26, "285143": [2, 5], "286": 73, "2861982": 26, "286861": [2, 5], "2869": 6, "287": [8, 69, 73], "2870": 27, "287682": 5, "2878": 85, "2879": [8, 9, 10, 11, 54], "287d8e": 57, "2880562": 26, "2883": 63, "2883102": 8, "2884": 24, "2889": [63, 84], "289": 73, "2890": 24, "289794": 5, "289872e": 346, "29": [5, 10, 18, 19, 25, 35, 46, 50, 73, 76, 84, 336, 343, 346], "290": [9, 54, 55, 69, 85, 391], "2903": [69, 73], "291": [9, 69, 73, 85], "2913": 36, "2919": 6, "292": [6, 8], "2926": 69, "2936": 72, "29381192": 18, "294": [9, 69, 73, 85], "2941": 62, "2948": [6, 62], "295": [6, 69, 73, 85], "2955": 63, "2956": 6, "296": [69, 73, 85], "297": 73, "2971": 73, "2972": 6, "297246": 26, "2976": 6, "2977": 73, "2979": 63, "298": [35, 73], "2980": 6, "298096": 9, "2984": 6, "2985": [10, 35, 73], "2995": [10, 63], "2996": 10, "29962235": 8, "2997": 10, "2998": 10, "2999": 10, "29991030e": 26, "29995": [2, 5], "29996": [2, 5], "29997": [2, 5], "29998": [2, 5], "29999": [2, 5], "29af7f": 57, "2_calibr": 391, "2_overfit": 391, "2ca02c": 57, "2d": [54, 57, 69, 76, 77, 127, 235, 236, 237, 238, 239, 241, 244, 253, 254, 275, 298, 324, 333, 336, 345, 349, 352, 353, 357, 367], "2d718e": 57, "3": [2, 3, 5, 8, 9, 10, 11, 16, 17, 18, 19, 24, 25, 26, 35, 36, 41, 44, 45, 46, 47, 50, 54, 57, 59, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 112, 130, 216, 217, 227, 231, 233, 279, 280, 283, 284, 290, 291, 325, 332, 337, 345, 346, 347, 351, 368, 371, 372, 373, 377, 380, 381, 382], "30": [5, 9, 10, 11, 18, 19, 25, 36, 46, 50, 54, 57, 68, 69, 72, 73, 76, 84, 85, 88, 258, 330, 344, 346, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "300": 57, "3000": [10, 57, 68, 72], "30000": [2, 3, 5], "30000000000000004": 45, "3002": 63, "3003": 63, "300e": 10, "301": 73, "301052": [2, 5], "301247": [2, 5], "3012471": 2, "301258121278325": 47, "3013": 47, "30135555": 26, "301387": 5, "3019": 6, "302": [8, 73], "302398e": 346, "3025": 6, "3028": 6, "302969": 3, "303": 62, "3030": [6, 8], "303196": 3, "3035": [6, 63], "30378332": 8, "3040": 62, "305": [59, 60, 73, 391], "305000": 26, "3053": 63, "305351": [2, 5], "3054e": 19, "3055": 6, "3058": 88, "30592314": 26, "306": 73, "3062105": 2, "306258": 9, "3074": 73, "3075": 6, "307556": 50, "3078": [6, 32], "3079": 72, "3079e": 19, "308": 6, "3080": 62, "308986": 5, "309": [72, 73], "3098": 18, "31": [2, 5, 18, 19, 24, 25, 26, 27, 35, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 346], "310": 8, "310554": 9, "310739e": 346, "311": 8, "3120": 6, "312386": 50, "31249470e": 26, "3125": 6, "3126": 6, "3131": 6, "313509": [2, 5], "314": 339, "3148": 6, "315": 72, "3153": 6, "3158": 6, "3161": 6, "31663391": 8, "317": 8, "3171": 6, "31771278": 8, "317854": [2, 5], "3179": 72, "318": 76, "3181": [6, 35], "3182": 10, "318827": [2, 5], "319710": [2, 5], "32": [9, 10, 11, 18, 19, 25, 28, 46, 50, 54, 68, 72, 73, 76, 343, 346, 350, 391], "320": 8, "320000": 5, "3202": 24, "3204": 73, "320997": [2, 5], "3211": 18, "322": 8, "322426": 3, "322667": 3, "32294844": 8, "323": [8, 35], "3234": [69, 73], "32395616": 26, "324": 62, "3240": 6, "324067": 9, "3245": 84, "3257": [6, 73], "326357": 3, "3265": 6, "3270": 63, "32731152": 8, "3277": 6, "3279": [69, 73], "3284": 8, "3287": 35, "329": [45, 48, 73, 391], "3294": 63, "33": [2, 18, 19, 25, 46, 50, 59, 72, 73, 76, 346], "3304": 85, "3311": [69, 73], "3313": [24, 73], "332": 8, "3323": 35, "333": 57, "3333": [10, 11], "3335": 6, "3336": 6, "33365986": 41, "3339": 76, "334": 8, "3341": 6, "33446600e": 26, "3346861": 8, "33472527": 26, "335": 6, "3358": 73, "3359": 6, "336": 62, "33638d": 57, "3375": 6, "337599": 3, "33798283": 18, "338": 76, "3383": 36, "3387": 63, "33972852": 8, "33973635": 26, "34": [2, 3, 5, 10, 18, 19, 25, 46, 47, 63, 64, 73, 76, 84, 346, 391], "340": 8, "3400": 11, "3405": 73, "3411": 6, "341274": 9, "3419": 73, "34190655": 8, "342": [35, 73], "3423": 63, "342442": [2, 5], "3426": 73, "3430": 45, "3432": 6, "3439": 6, "345": 35, "34549761": 8, "3455": 63, "3456": 85, "34597341": 8, "34619687": 8, "346930": 9, "346985": 9, "3476": 335, "3479": 6, "3480": 6, "3485": 10, "34879130e": 26, "3488": [6, 24, 62], "3489307": 26, "349": 63, "3492": 6, "3494": 6, "34941552": 8, "349909": 3, "35": [3, 5, 18, 19, 25, 26, 46, 57, 68, 72, 73, 76, 346], "350": [63, 73], "3502": 73, "3505": 6, "351": 8, "352": 8, "3521": [68, 72, 84], "353": [8, 9, 12, 62, 391], "35396525e": 26, "354": 8, "3542": 73, "35430714": 8, "354665e": 346, "3547": 35, "355": 62, "355216e": 346, "355448": 9, "355489": 50, "356": [18, 391], "357": 8, "35708636": 8, "3572": 6, "3578e": 24, "358": 8, "3582e": 24, "358358": 5, "3584": 73, "3585": 6, "358546": 50, "3586": 6, "35866153": 19, "359": 8, "3590": 6, "35911069": 8, "36": [9, 10, 18, 19, 21, 24, 25, 28, 46, 68, 73, 76, 339, 346, 391], "3600": 6, "360000": 5, "3601": 6, "3622": 22, "3629": 6, "363": [8, 63], "3636": 10, "3638": 73, "3639": 73, "363952": 50, "364": 72, "3658": 73, "3667": [35, 73], "3668836": 8, "3669": 73, "366936": 3, "367038e": 346, "367725": 5, "368296": 9, "369609": 9, "3697": 46, "37": [2, 5, 10, 18, 19, 25, 35, 46, 73, 76, 346], "3701": 6, "371": [8, 35], "3713": 62, "3719": [6, 63], "372": 8, "3725": 6, "373": 8, "3732": 85, "37398868": 8, "374": 8, "3750": 84, "3756": 63, "3759": 36, "376": [35, 72], "3766": 19, "3769": 24, "377": [3, 8], "3770237": 8, "3775": 339, "378": 18, "3788": 62, "379": 6, "3797": 36, "38": [9, 10, 18, 19, 25, 35, 46, 50, 73, 76, 84, 346], "380": 6, "3807": 6, "38169601": 8, "3819": 62, "382": 10, "382035e": 346, "3822": 6, "382380": 11, "3825739": 8, "38260215e": 26, "3828": 76, "383": [8, 35, 73], "38305": 50, "384": 8, "385": 8, "3850": 69, "3858271": 19, "385873": 9, "386703": 50, "387": 8, "3873": 63, "38810125e": 26, "38877612": 8, "38886216": 26, "389": [67, 70, 332, 345, 346, 347, 348, 349, 350, 351, 391], "3890": 45, "3893": 24, "3893073": 41, "3896": 46, "3899": 6, "39": [2, 5, 9, 18, 19, 25, 26, 46, 47, 50, 73, 76, 85, 88, 112, 346], "3900": [69, 73], "390088": 26, "39070830e": 26, "3908": 6, "390801": 9, "391": 8, "391002": 9, "3914": 6, "3919": 6, "392": 8, "3921": 6, "39269155": 19, "393": 8, "3939": 10, "394": 8, "3940": 73, "3942": 62, "395": 62, "3951375": 18, "39558c": 57, "3956": [72, 84], "3959": 6, "396": 18, "3965": 6, "3967": 62, "397": 62, "3970": 6, "3980": 6, "39820050e": 26, "3994": 63, "3995": 84, "39957": 9, "3996": 72, "399835": 9, "3_hpo": 391, "3_reliabl": 391, "3d": [127, 324, 352, 353, 358], "3dbc74": 57, "4": [2, 3, 5, 7, 8, 9, 10, 11, 18, 19, 24, 25, 26, 35, 36, 41, 44, 45, 46, 47, 50, 54, 57, 59, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 112, 279, 280, 332, 343, 345, 346, 347, 365, 371, 372, 373, 377, 378, 380, 381, 382], "40": [2, 9, 10, 11, 18, 19, 25, 36, 46, 50, 54, 57, 68, 69, 72, 76, 77, 84, 85, 88, 296, 297, 332, 346, 373, 382], "400": [39, 41, 57, 63, 382], "4000": [35, 72, 76], "40019150e": 26, "4002": 69, "4007": 63, "40079126": 8, "400e": 10, "401": 63, "4011": 88, "4012": 6, "40173483": 8, "4019": 6, "40198600e": 26, "402": [62, 63], "4036": 6, "403976": 3, "4043": [27, 35], "404688": 57, "405": 8, "405027e": 346, "4063": 6, "4074": 18, "408": 73, "4082": 19, "4083": 19, "4084": 19, "408438": 50, "4085": 19, "4086": 19, "4087": 19, "4096": 69, "41": [2, 3, 5, 8, 9, 10, 18, 19, 25, 73, 346], "4100": 27, "4106": 6, "411566": 3, "4117694": 8, "412": [8, 69, 73], "4123": 6, "4125": 6, "41267808": 8, "413": [336, 340], "414": [50, 391], "41498684": 8, "415": 73, "415164": 5, "4156": 45, "4157": 62, "4158": 39, "4159": 62, "416": 69, "4162": 24, "416251": 50, "4165": 39, "416518": 50, "4166": 45, "4167": 68, "4175": 45, "417972": 50, "417998": 50, "418": 8, "418748e": 346, "4189": 73, "4198": 24, "42": [2, 8, 18, 19, 25, 32, 33, 34, 35, 36, 68, 84, 346, 360, 388], "420": [27, 28, 88, 391], "420104": 50, "4202": 6, "420393": 50, "4204": 39, "4208": 20, "4209": 63, "421141": 50, "421357": 9, "4216": [26, 39], "421604": 50, "422": [8, 336, 340], "4222": 36, "42231476": 8, "4226": 6, "4232": 24, "4236": 6, "423921": 3, "424": [8, 35], "4242": [8, 11], "424638": 50, "425": 76, "4251": 62, "4255": [6, 26], "425528": 50, "4259185": 8, "426064": 3, "4266": 18, "4269": [18, 22], "427": [73, 336], "4270": 18, "4271": 18, "4272": 18, "4274": 18, "4275": 18, "4277": 18, "428": [9, 69, 73, 85], "4280": 18, "4281": 18, "4283e": 19, "4285": 18, "428621": [2, 5], "4287": 18, "4288": 18, "4289": 18, "4290": 18, "4292": 88, "4293": 18, "4294": 18, "4295": 18, "4296": 18, "4298": 20, "4299": 18, "43": [2, 5, 10, 18, 19, 25, 50, 346], "4300": 18, "4301": 18, "4302": 18, "4304": 18, "4305": 18, "4309": 6, "431": [35, 73], "4311": 18, "4312": 18, "4313": [6, 18], "4316": 18, "4317": 18, "432": 8, "4322": [18, 88], "4323": 18, "432403": 50, "4326": 18, "433": [9, 69, 73], "4330": [6, 18], "43309994": 8, "4333": 18, "4334": 18, "4334417": 26, "4336": [18, 72], "4339": 18, "4340": 18, "43404303": 8, "4342": 24, "4348": 18, "4349": 18, "4352": 18, "4358": 88, "436": 62, "43600182": 8, "4362": 18, "43645358": 8, "436493": 16, "4366": 18, "4367": [18, 46], "4368": 46, "437": [73, 92, 93, 391], "4374": 18, "4377": 18, "437721": 3, "4378": 18, "438": [8, 336], "4382": 18, "4383": 18, "4384": [18, 24], "4386": 18, "438677": 11, "4387": 18, "4388": 18, "4389": [6, 18], "4390": 18, "4391": 18, "4392": [6, 18], "4393": 18, "4394": [18, 24], "4395": 18, "4396": 18, "4397": [18, 66], "4398": 18, "4399": 18, "44": [2, 6, 18, 19, 25, 35, 69, 72, 73, 76, 346, 347], "440": [8, 63, 73], "4400": 18, "4401": [18, 46], "440154": 57, "4402": [6, 18], "4403": 18, "4404": 18, "4405": [18, 45], "4406": 18, "4407": [18, 46], "440752": [2, 5], "4408": 18, "4409": [11, 18], "441": [69, 73], "4410": 18, "4411": 18, "4412": 18, "4414": 18, "4415": 18, "4416": 18, "4417": [18, 36], "441707": 3, "441833": 5, "442": 8, "4421": 18, "4423": 18, "4425": 18, "4426": 18, "4428": 18, "4429": [18, 19], "443": [8, 73], "4430": 18, "4431": 6, "4433": 18, "4434": [6, 18], "4436": 6, "4438": 18, "4439": 18, "4440": 18, "4441": 46, "4444": 18, "444782": 16, "4448": 18, "445": [9, 69, 85], "4451": 18, "4454": 18, "4457": 18, "445729": 50, "4458": 18, "4460": 18, "4462": 18, "4463": 18, "4464": 18, "4465": 18, "4466": 18, "4467": 6, "447": [9, 69, 73, 85], "4470": [18, 19], "4472": 18, "4475": 18, "4476": [24, 35], "4477": 18, "4479": 46, "4481": 18, "4484": 18, "4485": 18, "4486": [18, 69], "4487": 18, "4490": 18, "4491": 18, "4494": 46, "4496": 11, "4496842": 26, "4497": [18, 46], "45": [6, 8, 10, 18, 19, 25, 26, 72, 85, 88, 343, 350], "4500": 72, "45000": 26, "4501": 18, "4504": 46, "4506": 18, "451": [33, 37, 62, 391], "4510": 46, "451197": 50, "4512": 18, "4513": 36, "451952": 5, "4520": 45, "452016": [2, 5], "45206945": 8, "4521": 18, "4522": 18, "4523": 6, "45238": 24, "4525": 18, "4528": 45, "45290": 24, "4530": 18, "4531": [18, 45], "45338": 24, "453781": 57, "4539": 45, "45391": 24, "45396535": 8, "4540": 45, "4541": 18, "454125": 50, "45425": 24, "4544": 11, "45458": 24, "45465": 24, "454741": 3, "4552": 24, "45525": 24, "4553": 18, "45535": 24, "4554": 18, "45545": 24, "4558": 6, "456": [69, 73, 85], "4561": [22, 72], "456563": 50, "4568": [18, 45], "45725397": 26, "458": 73, "4581": 62, "45813": 24, "4582": 18, "4585": 6, "4587": 20, "4589": 24, "4594": 18, "4597": 18, "46": [2, 5, 10, 18, 19, 25, 72, 88], "460": 8, "4602": 6, "4606": [50, 63], "461": 6, "4615": 84, "461799": [2, 5], "4622": 19, "4627": 6, "46286": 24, "463088": 11, "4631": 6, "4633": 46, "4634": 46, "4635": 6, "4636": 6, "4637": [6, 18], "464": [16, 28, 391], "4647": 62, "4648": 18, "4654": 18, "46568324": 8, "4659": 6, "465977": [2, 5], "4662439": 18, "4676": 46, "468": [44, 48, 391], "4682": 20, "4683": 6, "4691": 36, "4694": 24, "4696": 6, "47": [9, 18, 19, 25, 72], "4703": 36, "4704": 6, "4705": 85, "470528": [2, 5], "4713": 36, "4721": 6, "4726": 26, "472634": 50, "472756": 3, "4728": 88, "473737": 16, "4738": 88, "4739": 18, "47391497": 8, "4741": 6, "4744": [62, 63], "474543": 16, "4747": [6, 72], "475053": 3, "475099": 3, "475775": 11, "4758": 46, "476388": 50, "4769": 6, "477": 72, "47719370e": 26, "4775": 24, "477859": 26, "478": 8, "4784": [18, 63], "479": 8, "47997744": 41, "48": [6, 9, 18, 19, 25, 47, 57, 68, 76, 88], "4800": [6, 11], "4803": 63, "480644": 50, "4808": 6, "4809": 63, "481": 35, "48118": 50, "4812": 26, "481467": 57, "482576": 57, "483111": 50, "4834": 6, "484015": [2, 5], "484224": 3, "4846": [19, 24], "4848": 11, "484c": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "4855": 47, "485500": 3, "4858": 24, "486": 8, "4862": 72, "486322": 50, "48640678": 41, "486594": 50, "4871": 63, "487169": 5, "487297": 50, "487756": 50, "4878481": 8, "488": 6, "488310": 15, "488876e": 346, "4889": 46, "489": 6, "4895": 68, "49": [5, 9, 10, 11, 18, 19, 25, 35, 68, 72, 73, 84, 85], "4907": 36, "49080441": 8, "491": 85, "4915": 46, "4915018": 2, "491502": [2, 5], "4917": 3, "491782": [2, 5], "4919": 47, "492": 68, "4934": 47, "4939": 18, "4943": 6, "494683": [2, 5], "4952176": 8, "4956": 36, "495683": 3, "4963": 19, "4965": 6, "496987": 11, "4970": 47, "497456": 50, "4975": 84, "4977": 72, "4983": 44, "499": 6, "499088": 3, "4991": 47, "4994": 45, "4996": 63, "499676e": 346, "4999": 18, "4_resili": 391, "4th": 349, "5": [2, 3, 5, 8, 9, 11, 15, 18, 19, 24, 25, 26, 35, 36, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 112, 117, 137, 215, 216, 219, 220, 221, 222, 223, 227, 229, 231, 235, 236, 237, 238, 239, 274, 277, 278, 279, 280, 281, 282, 284, 286, 288, 291, 293, 295, 296, 297, 298, 300, 302, 304, 306, 308, 309, 310, 330, 334, 337, 339, 343, 346, 350, 356, 357, 364, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387], "50": [2, 9, 11, 18, 19, 24, 25, 35, 36, 44, 50, 57, 68, 69, 72, 73, 76, 84, 85, 88, 229, 274, 277, 278, 280, 281, 282, 283, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 380], "500": [11, 39, 41, 246, 296, 297, 344, 351], "5000": [11, 35, 68, 72, 88, 241, 242, 244, 245, 254, 279, 280], "50000": [2, 3, 5, 68, 383], "500000": 2, "50000000e": 26, "5002": 6, "5003": 6, "5007": 36, "500934": 15, "500e": 10, "5010": 44, "5023": 6, "503": [6, 85, 86, 391], "5036": [6, 63], "5045": 47, "505": 62, "5056": 6, "506": 63, "5061": 44, "5063": 6, "506395": 9, "5064": 18, "507501": 3, "5081": 62, "5082": 6, "5093": 6, "50986901": 8, "5099": 44, "51": [5, 6, 9, 18, 19, 25, 76, 88], "510080e": 346, "5101": 6, "51036978": 8, "5107": 6, "510933": [2, 5], "511033": 50, "5111": 62, "51115655e": 26, "5117": 47, "5118": 6, "5129": 18, "513": [72, 84], "5134": 68, "513484": [2, 5], "5138": 18, "5141": 6, "5148": 6, "514946": [2, 5], "515154": 9, "51526166": 8, "5153": 373, "5155": 44, "5161": [47, 72], "5169": 18, "51749181": 8, "518": 62, "5199": 36, "52": [18, 19, 25, 73, 339], "520": 8, "5218": 6, "523": 8, "5232": 6, "5234": 36, "52340825": 8, "5236": 62, "5238": [36, 88], "523983": [14, 50], "524": [88, 391], "52420093": 8, "5243": [6, 47], "5244": 44, "5256": 72, "5257": 47, "525951": [2, 5], "5260": 6, "5262": 24, "5265": 6, "5271": 6, "5276": 6, "5283": 6, "5288": 18, "529": [8, 23, 28, 391], "5297": 6, "53": [18, 19, 25, 50, 68, 73, 76, 339], "5309": 44, "530973": 3, "5321": [36, 63], "532205": 3, "5327": 72, "532754": [2, 5], "5336": 46, "5344": 6, "5354e": 19, "536": [6, 128, 136, 338], "537775": 11, "537809": [14, 50], "538574": [2, 5], "54": [2, 18, 19, 50, 84], "5401": 44, "5404": 44, "5405": 62, "54057249": 8, "5406": 44, "5410": 19, "542": 73, "5426": 85, "5427": 36, "5428": 6, "5429": 88, "5430": 36, "5436": [35, 47], "5439": 6, "5440": 6, "5444": 84, "544440": [2, 5], "5449": 6, "545": 76, "5450": 73, "54575816": 8, "546": [18, 62, 63, 64, 391], "5466": 6, "546752": 11, "547011": 3, "547405": [2, 5], "5476": 6, "548": 6, "5483": 73, "5490": 6, "5494": 46, "5495846": 18, "549641": 9, "55": [8, 9, 18, 19, 72], "5500": 6, "5501": 6, "550138": 50, "5514": 11, "551419": 3, "552181": [2, 5], "5523": 6, "5525": 44, "5528": 6, "55287443": 8, "553": 76, "55334894": 8, "553405e": 346, "5538": 62, "5539": 46, "554319": [2, 5], "5554": [6, 36], "5557": 6, "5558": 36, "555878": 17, "556": [6, 88], "5564": 62, "5565": 63, "5574": 36, "5578": 62, "5583": 6, "5587": 6, "5588": 72, "558922": 9, "559": 85, "56": [3, 8, 9, 10, 11, 18, 19, 50, 62, 68, 84, 391], "5601": 6, "5604": 22, "5607": 6, "5609": 6, "561": [53, 55, 391], "5610": 46, "5619": 6, "5621": 72, "5623": 72, "562721": [2, 5], "56381725": 8, "5639": 6, "5644": 6, "564453": [2, 5], "5649": 62, "565": [2, 12, 391], "5651": 6, "5652": 62, "5684": 73, "5685": 72, "569": [66, 70, 391], "56906283": 8, "5694": 73, "56c667": 57, "57": [2, 9, 18, 19, 35, 50, 62, 64, 84, 391], "5701": 18, "5702": [6, 62], "5713": 44, "5714": 72, "5715": 44, "572": 62, "5727": 6, "5730": 18, "5733": 8, "5741": 24, "57501659": 8, "5756": 72, "5759": 6, "576": 8, "5762": 62, "576596": 3, "577": [6, 85], "5770": 6, "5771": 44, "5773": [62, 84], "5774": [24, 62], "578": [6, 68], "5785": 35, "5790": 24, "579652": 17, "5797": 68, "5798e": 19, "58": [18, 19, 73], "580": 62, "5804": 6, "58060728": 8, "5809": 19, "5813": 44, "581320": 9, "582": [8, 73], "5822": 6, "5825": 6, "5831": 6, "5833": 6, "5836": 24, "5837": 63, "584": [69, 73, 85], "5840": 62, "5843": [62, 72], "584421": 373, "5846": 88, "585": 8, "5852": 6, "5854": 8, "5864": 62, "58744649": 8, "58798145": 8, "588": 88, "588372": 9, "5889": 6, "5891": 6, "59": [8, 9, 18, 19, 63, 68, 73, 85, 88, 336], "5908": 72, "591": 73, "592177": 3, "5922": 8, "5924": [6, 63], "5925": [6, 72], "592621": [2, 5], "5929": 36, "5933": 6, "5942": 72, "5945": 36, "5948": 6, "595": [7, 12, 391], "5960": 62, "5963": 68, "5966": 6, "597": 68, "5975": 63, "598": 8, "5981": 47, "59815633": 18, "5983": 62, "599": 85, "599323": 3, "5_robust": 391, "6": [2, 3, 5, 8, 9, 10, 11, 18, 19, 24, 25, 26, 35, 36, 44, 45, 46, 47, 50, 53, 54, 59, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 112, 137, 315, 330, 332, 345, 346, 347, 372, 377, 381, 383], "60": [6, 8, 9, 10, 11, 18, 19, 35, 36, 50, 68, 69, 72, 76, 77, 84, 85, 88, 377], "600": [57, 68], "6000": 84, "6006": 63, "600893": 17, "601": 68, "6016": 63, "6017": 6, "602": [8, 68, 72], "6021686": 2, "602169": 3, "6023": 6, "6025": 18, "603": 68, "603604": 3, "603628": 17, "6037": 18, "60372308": 8, "6044": 88, "6048": 6, "605": 8, "60513461": 41, "6053": 63, "605574": 3, "606": 8, "6060": 6, "6061": 10, "6064909": 18, "6069": 44, "6074": 18, "6075": 6, "6078": 6, "6080": 18, "6088": 6, "609": 8, "6097": 62, "6097598": 26, "60986068": 8, "61": [9, 10, 11, 18, 19, 68, 391], "610": 6, "6104": 68, "611": [3, 8, 12, 391], "6114": 72, "6115": 62, "6124": 9, "613": 73, "61302157": 8, "6133": 62, "61372": 50, "613720": 14, "6138": 84, "61438626": 26, "6146": 68, "615382e": 346, "6158": 36, "6161": 72, "6163": 62, "6165": 24, "6165768": 19, "6167": 6, "619": 8, "6190": 63, "6193": 6, "619748": 3, "619822": 50, "62": [10, 18, 19, 35, 62, 72, 73, 76], "6201": 6, "6202": 62, "6212": 11, "62129865": 8, "622": 6, "6224": 6, "6227": 72, "6233528": 2, "623353": [2, 5], "6238": 72, "624": 6, "6240": 62, "624382": 9, "6249": 6, "6252": 19, "6257": 84, "6258": 6, "6261": 68, "627229": 11, "6277": 18, "6279": 6, "6282": 72, "6285": 18, "629466": 9, "6298": 6, "629950": 3, "63": [18, 19, 63, 68, 336], "6300": 11, "630000": 5, "6302": 62, "6304": 88, "6311": 62, "6315": 6, "6319": 6, "632": 6, "63209229": 8, "6321": 6, "6326": 84, "632617": 9, "632926": [14, 50], "6343": 6, "6351": 6, "6352": [36, 62], "636641": 9, "637": [5, 12, 391], "637231": 3, "6377": 6, "6381": [6, 72], "6386": 62, "639": 73, "639519": 3, "6398": 6, "64": [10, 18, 19, 72, 84, 88], "640": [8, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "640444": 9, "6409": 6, "6411": 72, "64117468": 8, "64293911": 8, "6436": 35, "6439": 6, "6444": 18, "646": 69, "6460": 68, "6466": 62, "6467": 72, "647": 76, "6472": [6, 84], "64728517": 8, "6473": 6, "648": 63, "6481": 6, "6487": 63, "6488": 6, "6492": 6, "6494": 46, "6499": 6, "65": [8, 9, 10, 11, 18, 19, 68, 72, 76, 347, 383], "6507": 62, "6509": 68, "6524": 24, "6529": 88, "6531": 68, "65313364": 8, "65340550e": 26, "653791": 3, "6538": 18, "6539": [68, 84], "654": 6, "6542": 6, "654506": 3, "6548": 72, "6556": 6, "6557": 9, "6558": 72, "6560": 72, "656616": 9, "65801040e": 26, "6584": 72, "6595109": 8, "6599": 72, "66": [10, 18, 19, 72, 73], "660": [35, 37, 391], "6600": 11, "66048595e": 26, "6615": 72, "6618": 88, "6619": 6, "663": 6, "66311172": 8, "6636": 3, "6639": 6, "6641": 88, "66410094": 18, "664760": 9, "6648": 72, "6649": 18, "6650": 18, "6651": 18, "6652": 18, "6653": 18, "6654": 18, "6655": 24, "6666": 46, "6667": [72, 76], "6672": 63, "6673": 6, "667824": 9, "6680": 63, "6682": 45, "66824562": 8, "6688": 24, "6692": 6, "66937524": 19, "67": [18, 19, 35, 69, 73], "6700": 6, "670062": 3, "6710": 35, "6713": 6, "6718": 6, "67196976": 8, "672015": [2, 5], "6744": 72, "6747": 6, "67514110e": 26, "6752": 6, "6753": 6, "6755": 6, "6771": 62, "6773": 72, "6774": 6, "6775": 72, "6780": 72, "6784": 36, "678666": 3, "6790": 36, "68": [5, 9, 18, 19, 62, 68, 69, 73, 76, 77, 85], "6800": 84, "680607": [2, 5], "6814": 84, "6818": 10, "6823": 35, "6829": 72, "683353": [2, 5], "6837": 6, "685": 8, "68506386": 8, "6856": 6, "6866": 72, "6873": 6, "687531": 9, "6877": 72, "6878": 6, "6886": 6, "689033e": 346, "6891": [6, 62], "689362": [2, 5], "6895": 6, "6897": 3, "689708": [2, 5], "69": [18, 19, 35, 68, 69, 72, 73, 84, 85], "69050610e": 26, "6908": 18, "6910": 6, "6912": 6, "6919": 6, "691958": 3, "6920": 72, "6923": 6, "6926": 6, "6927": 88, "692776": [2, 5], "6937": 3, "6939": 3, "69402145": 26, "6954": 6, "6961": 63, "696166": 9, "696219": 9, "696812": 3, "696924": [2, 5], "6975": 6, "6977": 6, "698437": 9, "6986": 72, "69896608": 8, "6990569": 2, "699057": [2, 3, 5], "6991": 36, "69910025": 26, "699317": [2, 5], "699578": 3, "6_fair": 391, "6th": 336, "7": [2, 4, 5, 9, 10, 11, 18, 19, 23, 24, 25, 26, 35, 36, 44, 45, 46, 47, 50, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 91, 112, 227, 311, 330, 336, 339, 346, 377, 382], "70": [3, 9, 18, 19, 36, 50, 68, 69, 72, 73, 76, 84, 85], "70000": 5, "7005": 6, "7006": 6, "700630": 3, "700e": 10, "7014": 62, "70141498": 8, "701555": 9, "701679": 50, "701683": 17, "7017": 6, "7024171": 19, "7034": 72, "703447": 9, "703580e": 346, "70426": 50, "7049": 36, "7052": 6, "7058": 72, "7062": 62, "70624983": 18, "7069": [68, 72], "7077": 84, "7081": 84, "70876671": 8, "709229": 50, "71": [18, 19, 68, 69, 73, 76, 88], "7109": 6, "711": [68, 70, 391], "7111": 72, "7113": 68, "7115": 6, "7118": 6, "712": 69, "7131": 72, "71343716": 8, "7136": 6, "714": [39, 42, 391], "7145": 6, "715107": 8, "715251": [2, 5], "7154": 62, "7157": 84, "717": 63, "7170": 68, "7175": 6, "7177": 44, "718": 46, "7180374727086953": 46, "7196138": 8, "7198": 6, "72": [9, 10, 18, 19, 69, 84], "7208288": 26, "721": 69, "7222": 6, "722428": [2, 5], "723": 6, "723022": 17, "7231485": 8, "723182": 3, "7238": 6, "723989": [2, 5], "724": 11, "725": 11, "7256": 46, "726041": 9, "7263": 35, "7273": 10, "7274": 6, "7277": 18, "727856": 9, "7279": 6, "7281": 6, "7284": 88, "7285": 9, "728754": 3, "7297": 72, "73": [18, 19, 62, 73, 88], "730": 68, "7302": 6, "7305": 68, "7308": 72, "731": [47, 48, 62, 64, 391], "7312": 6, "7314": 6, "7317": 6, "73172633": 8, "73282696": 41, "733311": 16, "733875": 3, "7340": 6, "7341": 72, "7344": 44, "7345": 44, "7347": 72, "7349": 84, "7350": 6, "735054": 373, "7355": 88, "73576964": 8, "736452": 3, "736758": 16, "7369": [18, 68], "737": 6, "7372": 68, "7378": 44, "7381": 72, "739": 8, "7391e": 19, "7393": 84, "73937898": 8, "739384": 3, "7398": [6, 47], "74": [6, 10, 18, 19, 72, 73, 88], "740": [72, 84], "7400": 47, "7403": 36, "7405": 84, "7406": [44, 84], "7407": 44, "7408": 44, "74094000e": 26, "7411": 84, "7412": 84, "7414": 84, "7417": 84, "7418": [44, 84], "7419": 6, "7420": 84, "7421": 84, "7424": [10, 84], "7427": 84, "7428": 84, "7433": [46, 63, 84], "7434": 84, "7435": [6, 84], "7437": 84, "7438": 84, "7439": 84, "7443": 84, "7444": 84, "7445": 84, "7446": 84, "7448": 84, "7450": 84, "7453": 6, "7454": [44, 84], "7455": 84, "7456": [6, 84], "7460": 84, "7462": 35, "7464": [46, 72, 84], "7465": 68, "746540": 9, "7466": 84, "7467": 47, "747": 36, "7471": 6, "7474": 6, "747475": 57, "7476": 6, "7484": 47, "7492": 44, "7494": 47, "749674": 50, "75": [3, 5, 8, 9, 10, 11, 18, 19, 50, 54, 68, 72, 73, 88, 383], "7500": 44, "75000": 26, "7502": 6, "7503": 6, "7505": 25, "7509": 19, "7512": [46, 72], "751288": 9, "7514": 72, "7518": 3, "752": [68, 72, 84], "7525": 47, "7525315": 26, "75308490e": 26, "7532": 6, "753660": [2, 5], "7538": 6, "753876": 9, "7539": 44, "7540": 44, "7547": 47, "75513729": 8, "7552": [36, 44], "7554": 68, "755482": 9, "7556": 88, "7557": 46, "7559": 46, "7560": 25, "7561": 47, "7563": 47, "756332": 9, "7566": 44, "7569": 6, "7574": 47, "7575": 68, "757503e": 346, "7576": 10, "7577": 6, "7578": 68, "7580": 6, "7582": 24, "7584": 6, "7589": 68, "759": 85, "759269": 50, "7593": 44, "7598": 44, "75d054": 57, "75th": 334, "76": [10, 18, 19, 68, 72, 73, 88], "760": 6, "7619": 36, "76191292": 8, "7621": 47, "7624": 6, "762511": 3, "763": 6, "7632": [46, 47], "7633": 46, "7641": [46, 62], "7645": 6, "7646": 46, "764923": 2, "7655": 46, "7658": 68, "76589893": 8, "7662": [66, 84], "7664": 6, "766402": 3, "7667": 6, "7669": 68, "7675": 6, "768": 6, "7681": 6, "7683": 6, "768472": 50, "7690": [6, 68], "7691": 36, "769194e": 346, "7695": 24, "7696": 46, "77": [18, 19, 47, 72, 73, 77, 85, 88], "7701": 6, "7705": 6, "7706": 46, "7708": 35, "77098477": 18, "771": 35, "77103605": 26, "77109665": 18, "7711": 6, "7714": 68, "7716": 62, "772": [6, 26, 28, 76, 391], "772886e": 346, "773": 84, "77373500e": 26, "773772": 50, "7742": 24, "7748": 46, "77488155e": 26, "775": 6, "7751": 46, "775229": 50, "7754": 72, "7757": 6, "776": 72, "7765": [6, 22, 35], "777542": [14, 50], "7779": 24, "7782731": 8, "7793": 24, "779349": 3, "77944850e": 26, "77957888": 8, "7798899449724863": 5, "78": [18, 19, 68, 72, 77, 85, 88], "780": 36, "7800": [6, 11], "780283": 50, "7803": 26, "78091513": 8, "7815": 35, "781533": 50, "78185": 50, "7819": 20, "782492": 3, "7826": 6, "7829": 6, "783": 76, "7832": 20, "783313": 50, "783833": [14, 50], "7840": [6, 24], "784044": 50, "7842": 46, "7847": 36, "7854": 68, "7857": 19, "786645": 50, "787": [6, 36], "7870": 6, "7872": 24, "7873": 62, "7882": 88, "78831236": 8, "7886": 36, "7887": 76, "789": 36, "7896": [26, 68], "789608": 50, "7899": 3, "79": [3, 18, 19, 50, 68, 73, 77, 84, 85], "790": 8, "7902": 6, "7906": 47, "791": 6, "7910": 73, "7911": 6, "791414": 50, "7918": 68, "7919": 6, "7922": 47, "7925": [24, 44], "7926": 6, "793092": 3, "7943": [3, 6], "7945": 6, "795420": 3, "7955": 72, "7956": 68, "796": [34, 37, 391], "7964": 24, "796663": 50, "796958": 50, "7973": 6, "7974": 6, "7980": 6, "7981": 36, "798615": 15, "798646e": 346, "7993": 44, "7994": 6, "7996": 68, "799742": 50, "7_explain": 391, "7f7f7f": 57, "8": [2, 3, 5, 6, 9, 10, 11, 18, 19, 24, 25, 26, 30, 31, 35, 36, 44, 45, 46, 47, 50, 57, 62, 63, 68, 69, 72, 73, 76, 84, 85, 88, 112, 330, 331, 346, 347, 351, 377, 382], "80": [8, 9, 10, 11, 18, 19, 36, 50, 54, 68, 69, 72, 73, 76, 77, 84, 85, 377], "800": [36, 57], "80000": [2, 5], "8001": 6, "800262": 9, "8006": [6, 45], "8010": 44, "8011": 36, "801333": 50, "802": 36, "802168": 50, "8022": 6, "8031": 35, "8032": 44, "803478": 9, "8035": [36, 44], "8038": 6, "8039": 76, "8040": 6, "8045": 50, "804507e": 346, "80464866": 8, "805": 36, "8050": 68, "8051": 6, "8061": 63, "806229": 3, "806320": 15, "8069": 68, "80710694": 41, "8085": [24, 36], "81": [3, 5, 8, 9, 10, 11, 18, 19, 54, 77, 85], "8101": 44, "81036737": 8, "8111": 35, "812": [6, 36], "812167": 50, "8122": 47, "8129": 47, "813179": 9, "8136": [25, 72], "81561248": 8, "8157": 6, "8158": [46, 72], "816": 62, "8164": 6, "8168": 44, "81689633": 8, "8169": [6, 44], "8170": [44, 72], "81719511": 8, "817664": 3, "8179": [6, 20], "8183": 9, "8185": 25, "8187": 6, "8195": 22, "8196": 6, "819798": 5, "8199": 24, "82": [10, 18, 19, 77, 85, 88, 343], "8201": 36, "8202": [6, 47, 66], "820250": 16, "8203": 68, "8205": 26, "820542": 50, "8207": 24, "820e": 10, "8210": [6, 44], "821208": 50, "8217": 24, "8224": 35, "82275": 50, "823": [69, 73, 85], "823167": 50, "823417": 50, "8237": 44, "82406478": 8, "8251": 6, "8256": 47, "8261": 47, "826333": 16, "826671": 3, "826716e": 346, "8270": 20, "8275": 6, "8276": 44, "827667": 50, "8277": [44, 47, 68], "8278": 36, "827833": 50, "828": 62, "8286": 68, "829": 6, "829167": 50, "8294": 19, "8296": 44, "8297": 6, "8298": 24, "83": [10, 18, 19, 50, 72, 73, 77, 85], "830": [14, 28, 36, 391], "8300": 26, "8307": 6, "831": 50, "8312": 68, "8315": 44, "8317": 6, "8321": [6, 47], "8325088": 2, "832509": [2, 5], "83255660e": 26, "8327": 6, "832875": 50, "8330": 6, "833031": 3, "8332428": 26, "8339": 44, "8343": 46, "8348": 47, "8349": 47, "8350": [24, 36, 44], "8360": 32, "83600735e": 26, "836042": 50, "8363": 44, "8366": 6, "8374": 10, "8375": 10, "8376": [10, 47], "8377": 10, "8378": 10, "837806": 9, "8379": 10, "8383": 6, "8384": 73, "8387": 47, "838849": [2, 5], "8394": 6, "839678": 9, "84": [18, 19, 50, 77], "841": 6, "8412": 46, "84176620e": 26, "8425": 6, "842721e": 346, "8428": 35, "8430": 6, "84309127": 8, "843542": 50, "8436": 44, "843718": 3, "8441": 6, "8446": 47, "845": 6, "84516": 2, "84522210e": 26, "8458": 68, "8462": 76, "8464": 22, "8469": 6, "8479": 6, "848": 36, "8488": 6, "8494": 19, "8496": 6, "8499": 6, "84it": 50, "85": [18, 19, 35, 73, 88], "850124": 3, "8507": 11, "85092333": 8, "8513": 36, "852405": 9, "8527": 35, "8529": 76, "853476": 9, "8540": 88, "8542": 6, "854855": 5, "8555": 46, "855556": 9, "85635531": 8, "8571": 72, "8577": 19, "858": 8, "8582": 27, "8588": 35, "8589": 6, "85911047": 8, "86": [10, 18, 19, 35, 73], "861": [25, 28, 391], "8612": 27, "86173277": 8, "86308480e": 26, "8645": 11, "864547": 3, "86580032": 8, "866": 68, "86689458": 8, "867": [69, 73, 85], "8677": 88, "867905": 3, "8680": 22, "869": 11, "87": [10, 18, 19, 35, 50, 85], "8710": 36, "8713": [6, 46], "8716": 88, "8719": 6, "872": [21, 28, 391], "8723": 35, "8724": 6, "8728": 6, "8734": [11, 24], "874": [69, 73, 85], "874094": 26, "874692": 9, "8757": 25, "8763": 6, "87638926": 8, "87680055": 8, "8769": 76, "877": [46, 48, 391], "8774": 76, "879374": 3, "88": [18, 19, 69, 72, 73, 88], "880594": 50, "881": 6, "8825": 25, "882553": [2, 5], "8831": 32, "88344987": 8, "8847": 76, "885018e": 346, "885958": 3, "886": [36, 37, 391], "8863": 45, "8869": 6, "8872": 76, "8875": 6, "8876": 45, "888": 148, "88811712": 8, "8883": 6, "8885": 66, "8888": 6, "889": [69, 70, 391], "89": [9, 10, 11, 18, 19, 50, 76, 85], "8901": 63, "8907": 77, "89070025": 26, "89082292": 8, "891201e": 346, "8922": 76, "8924": 77, "8929": 46, "893123": 9, "8936": [6, 76], "89376030e": 26, "8938": 6, "894205": [2, 5], "8946": 76, "895": [80, 82, 391], "8965": 76, "8978": 76, "8981": 6, "89852583": 8, "8987": 76, "8991": 6, "8992": 6, "8996": 6, "8999": 76, "8c564b": 57, "8e93": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "9": [2, 3, 5, 8, 9, 10, 18, 19, 24, 25, 26, 35, 36, 44, 45, 46, 47, 50, 62, 63, 68, 69, 72, 73, 76, 84, 85, 88, 112, 117, 124, 217, 219, 220, 221, 222, 223, 227, 233, 235, 236, 237, 238, 239, 336, 340, 346, 347, 359, 361, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "90": [9, 10, 11, 18, 19, 36, 50, 57, 69, 76, 77, 85, 216, 229, 231, 332, 359, 361], "90000": 2, "9001": 6, "9002": 76, "901": 8, "9010": 6, "901036": 9, "9030": 76, "9039": 35, "90398368": 8, "90417395e": 26, "9042": 77, "9049": 6, "90490433": 8, "905": [41, 42, 391], "906131": 3, "9063": 6, "9068": 36, "9070": 36, "9080": 6, "9091": 6, "91": [18, 19, 47, 68, 85, 88], "910277": 3, "910548e": 346, "911598": 3, "912": [8, 36, 69, 73, 85], "9122": 6, "9131": [6, 36], "9133": 6, "9134": 6, "9135": 6, "914": [77, 78, 391], "9142": 35, "914206": 11, "9149": 36, "916": [343, 346], "9161": 36, "9164": 6, "9168": 35, "9169": 35, "917": [4, 12, 35, 391], "9170e": 19, "9171": 6, "9174": 36, "9175": 35, "918397": 5, "92": [18, 19, 35, 72, 88], "920": 63, "921166": 3, "9219": 6, "92212328": 8, "9228": 6, "923": [22, 28, 391], "9244": 36, "9255": 35, "9257": 6, "925868": 50, "926": 36, "9263": 46, "9277": 6, "928576": 59, "9291": 35, "929470": [2, 5], "9295": 35, "92it": 50, "93": [8, 9, 18, 19, 50, 68], "9303": 9, "93043925e": 26, "9311": 6, "931103": 9, "931307": 3, "931323": 5, "9319": 6, "9324": [6, 35], "9332": 35, "9333": [6, 35], "93370274": 8, "93374030e": 26, "933998": [2, 5], "9340": 6, "9341": 6, "935406": [2, 5], "9355069": 26, "9357": 24, "9359": 77, "9363": 23, "93651168": 8, "9368": 24, "9389": 36, "939141e": 346, "94": [8, 18, 19, 62], "9406": 35, "9407": 76, "940e": 10, "941289": 3, "9426": 6, "9427": 36, "9430": 6, "94301852": 8, "9431": 6, "9432": 6, "9442": 6, "94448235e": 26, "944507": [2, 5], "9447": 6, "9449": [21, 35], "9453": 6, "945496": 9, "9457": [24, 35, 66], "946": [19, 28, 391], "94615745e": 26, "9467bd": 57, "9470": 6, "9472": [6, 62], "9475": 21, "9476": 23, "9479": 6, "9494": 36, "95": [10, 18, 19, 68, 72, 73, 84], "95000": 26, "950164": 3, "95042713": 8, "950861": 3, "951874": 9, "952": 6, "9521": 35, "9523": 36, "952328": 3, "9524": 6, "9530": 36, "953276": [2, 5], "954": [343, 346], "954194": [2, 5], "9542909": 2, "954291": [2, 5], "9544": 6, "9554": 67, "95640850e": 26, "9574": 24, "957594": 9, "9576": 36, "95855359": 8, "9589": 62, "9590": 6, "9599828": 26, "95d840": 57, "96": [18, 19, 35, 68, 69, 72, 84], "96001879": 8, "96020776": 8, "960e": 10, "9612": 35, "962809": 9, "9642": 35, "9648": 6, "965827": 3, "966": 8, "9660": 6, "9662": 6, "967160": 3, "9679": 6, "9685": 36, "9689": 6, "969": [15, 28, 391], "9698": 45, "97": [10, 18, 19, 47, 68, 72, 84], "9713": 36, "9714": 36, "9725": 6, "972620": 9, "9728": 35, "974": 6, "9741": 6, "975": [8, 12, 391], "976": 36, "9769": 36, "977": 11, "9772": 6, "9777": 6, "9788": 35, "9789": 67, "9791": 36, "98": [18, 19, 63, 68, 69, 72, 84, 85], "980": 6, "9803": 77, "9808": 6, "981730": 3, "98238435": 26, "9830": 6, "98300947": 8, "983024": 3, "9836": 6, "9839": [24, 62], "984": 76, "984308": 3, "985": 35, "9851": 6, "9852": 6, "9858": 6, "9861": 6, "987": 68, "9881": 57, "9881131988260086": 57, "9882": 6, "9887": 36, "989": [6, 36], "98914508": 8, "989873e": 346, "99": [9, 18, 19, 68, 72, 73, 84, 85, 88, 122, 123, 124], "9902": 6, "9910": 6, "9912": 36, "9920": 36, "9923": 6, "9926": 35, "992965": 3, "9930": 36, "993234": 5, "99470963": 8, "99496903": 8, "995": [3, 10], "99578865": 26, "996": [3, 10, 36], "996155": 9, "99629270e": 26, "997": [3, 10], "9971": 6, "9973": 36, "9977": 6, "998": [3, 10, 73, 74, 391], "9984": 36, "999": [3, 10, 148], "A": [57, 95, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 166, 171, 187, 188, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 229, 230, 232, 233, 238, 239, 243, 245, 246, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 264, 266, 273, 274, 275, 276, 277, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 315, 328, 335, 336, 338, 340, 343, 344, 345, 349, 362, 363, 369, 371, 372, 373, 374, 377, 379, 382, 389], "And": [54, 232, 279, 280, 336], "As": [58, 76, 77, 232, 279, 280, 330, 336, 337, 339, 345, 350, 351, 373, 385], "At": 368, "But": [235, 336, 340], "By": [88, 330, 332, 336, 337, 340, 343, 347, 348, 350, 354, 371, 373, 377, 378, 379, 381, 382, 383], "For": [20, 21, 26, 27, 117, 140, 141, 142, 146, 148, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 244, 246, 253, 265, 279, 280, 309, 326, 330, 334, 335, 336, 337, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 388], "If": [111, 112, 117, 119, 121, 126, 127, 128, 129, 130, 131, 142, 148, 151, 157, 166, 171, 172, 174, 187, 194, 205, 210, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 244, 245, 246, 252, 253, 254, 262, 269, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 313, 314, 315, 326, 327, 328, 336, 340, 343, 345, 346, 347, 348, 349, 350, 351, 365, 381, 382], "In": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 309, 330, 331, 332, 335, 336, 337, 339, 340, 343, 344, 345, 347, 348, 349, 350, 351, 363, 367, 371, 372, 373, 377, 380, 381, 382, 385, 388], "It": [122, 123, 124, 125, 127, 128, 130, 131, 136, 137, 140, 141, 142, 146, 147, 148, 188, 215, 217, 218, 219, 221, 222, 223, 226, 228, 233, 234, 235, 236, 238, 239, 242, 243, 253, 258, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 348, 351, 352, 358, 364, 365, 367, 372, 374, 377, 383, 386, 387], "Its": [128, 136, 338, 343, 345, 372], "No": [22, 23, 390], "Not": 229, "On": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 330, 332, 343, 345], "One": [254, 334, 341, 367, 368, 369, 370, 371, 372, 382], "Such": 373, "That": [343, 345, 369], "The": [5, 111, 117, 120, 123, 126, 127, 128, 131, 136, 138, 140, 141, 142, 146, 147, 148, 149, 153, 154, 155, 156, 157, 158, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185, 187, 194, 198, 201, 203, 204, 205, 207, 208, 210, 211, 213, 214, 215, 216, 217, 219, 220, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 247, 249, 250, 252, 254, 255, 257, 258, 259, 260, 261, 263, 264, 265, 267, 268, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387], "Then": [330, 332, 335, 339, 341, 373, 381, 382], "There": [334, 365, 377, 379, 380, 381], "These": [325, 332, 367, 368, 379, 381, 383], "To": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 235, 236, 237, 238, 239, 241, 244, 253, 315, 332, 335, 339, 344, 345, 346, 347, 348, 349, 351, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 370, 371, 373, 377, 378, 379, 380, 381, 382, 383], "Will": 315, "With": 372, "_": [334, 335, 339, 341, 343, 345, 347, 349, 367, 369, 371, 372, 378, 380, 381, 383], "__": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "__doc__": 57, "_build": [367, 369, 372], "_f": 339, "_i": [379, 380], "_j": [367, 368], "_predict": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "_sourc": [367, 369, 372], "_x": [367, 372], "a0": 334, "a_m": 372, "abil": [335, 336, 340, 368, 377, 378, 379, 380, 381, 382, 383], "abl": 385, "about": [214, 219, 221, 222, 223, 231, 233, 234, 253, 336, 345, 355, 367, 372, 380], "abov": [72, 73, 76, 77, 122, 124, 136, 138, 310, 330, 332, 336, 339, 343, 345, 346, 349, 350, 351, 373, 378, 382, 387], "abs_residu": [62, 63, 216, 231, 379], "abs_residual_perturb": [62, 63, 216, 231, 382], "absolut": [136, 187, 216, 231, 232, 335, 341, 351, 373, 379], "absorb": 368, "acc": [14, 16, 20, 22, 24, 26, 35, 44, 46, 47, 50, 66, 80, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 330, 362, 363, 364, 377, 386], "acc_rank": [44, 47], "accept": [214, 226, 344, 351, 361, 378], "access": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 231, 368, 370, 374, 388], "accommod": 371, "accomplish": 349, "accord": [279, 280, 367, 368, 369, 371, 372, 380, 381], "accordingli": 388, "account": [236, 241, 336, 340, 344, 351, 367, 368, 369, 370, 371, 372, 377, 378], "accumul": [241, 339, 342, 352], "accur": [216, 231, 328, 343, 345, 367, 372, 381, 382], "accuraci": [9, 14, 24, 25, 30, 31, 32, 35, 36, 53, 235, 241, 246, 329, 339, 344, 351, 361, 367, 368, 371, 372, 374, 377, 379, 381, 382], "accuracy_plot": 332, "accuracy_result": 58, "achiev": [279, 280, 336, 343, 350, 367, 371, 372, 373, 377, 379, 380], "acm": [336, 339, 344], "across": [68, 69, 72, 73, 148, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 231, 233, 236, 239, 241, 242, 254, 257, 258, 261, 334, 336, 343, 345, 347, 351, 359, 360, 361, 364, 370, 371, 374, 377, 378, 379, 381, 382, 383], "act": 242, "action": [352, 361, 371, 379], "activ": [4, 53, 140, 141, 142, 146, 172, 174, 179, 191, 193, 195, 196, 235, 279, 280, 292, 293, 296, 297, 334, 341, 373, 378, 380, 381, 388], "activation_func": [279, 280], "active_featur": 142, "active_interaction_index_": [279, 280], "active_main_effect_index_": [279, 280], "active_sampl": 142, "active_sample_index": 142, "active_samples_index": 6, "actual": [41, 220, 229, 230, 279, 280, 328, 330, 336, 359, 361, 377, 379], "ad": [279, 280, 330, 332, 334, 339, 368, 381, 382, 387], "adam": [279, 280, 347], "adapt": [336, 369, 371, 381], "add": [5, 31, 148, 180, 201, 216, 231, 234, 272, 334, 356, 357, 358, 363, 368, 378, 380, 382], "add_ind": [5, 11, 148, 334], "add_model": [50, 387], "add_step": [59, 272], "addit": [216, 231, 246, 279, 280, 292, 293, 330, 331, 332, 335, 336, 337, 340, 342, 343, 345, 348, 349, 352, 360, 364, 367, 368, 369, 372, 379, 380, 381, 387], "addition": [337, 345, 346, 349, 352, 379], "address": [371, 376, 377, 378, 383], "adjust": [88, 127, 228, 325, 328, 337, 345, 358, 362, 378, 379, 380, 381, 382], "adopt": [336, 340, 377], "advanc": [336, 344, 352, 361, 362, 368, 371, 376], "advantag": [336, 368, 380, 383], "advers": [88, 214, 226, 227, 228, 331], "adversari": [378, 381, 382], "affect": [142, 228, 253, 307, 308, 309, 310, 344, 351, 378, 381], "after": [216, 223, 227, 228, 231, 234, 239, 245, 281, 282, 283, 296, 297, 336, 339, 345, 354, 355, 361, 362, 364, 365, 368, 373, 382, 385], "ag": [2, 3, 5, 26, 68, 76, 88, 377, 383], "against": [76, 216, 218, 220, 227, 228, 230, 231, 235, 236, 237, 238, 239, 265, 307, 308, 309, 310, 330, 331, 332, 336, 348, 352, 361, 371, 377, 378, 379, 382], "age_missing_nan": 5, "aggreg": [215, 232, 336, 367, 369, 371, 372, 377], "aggress": 378, "agnost": [243, 244, 342, 343, 345, 349, 352, 360, 380], "agu": [367, 368, 369, 373, 382], "ai": [367, 369, 372], "aid": [367, 372], "aijun": [367, 368, 369, 373, 382], "aim": [216, 229, 231, 332, 336, 339, 343, 345, 369, 377], "air": [88, 214, 226, 227, 228, 236, 331], "al": [241, 342, 351, 352], "aletheia": 373, "alex": 347, "alex2015": 347, "alexand": 336, "algorithm": [122, 123, 128, 130, 136, 137, 216, 231, 243, 308, 309, 330, 332, 336, 340, 343, 344, 362, 363, 368, 369, 373, 374, 379, 380, 381, 386], "align": [57, 328, 335, 336, 337, 341, 343, 344, 345, 346, 347, 349, 351, 352, 367, 368, 372, 373, 377, 379], "alignwithlabel": 57, "all": [4, 22, 23, 30, 57, 68, 69, 72, 73, 76, 77, 84, 85, 88, 115, 116, 117, 119, 125, 126, 127, 128, 129, 130, 131, 140, 141, 142, 143, 146, 147, 148, 151, 157, 164, 167, 171, 172, 174, 205, 207, 208, 212, 213, 214, 215, 216, 218, 220, 223, 225, 226, 227, 228, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 244, 246, 252, 253, 254, 256, 261, 265, 266, 267, 279, 280, 290, 291, 296, 297, 307, 308, 309, 310, 312, 315, 330, 332, 334, 336, 339, 340, 343, 344, 345, 346, 347, 350, 351, 355, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 391], "all_bias_weight": 260, "allow": [119, 187, 214, 217, 218, 219, 220, 221, 223, 226, 239, 253, 308, 326, 327, 328, 336, 337, 341, 343, 344, 349, 351, 362, 363, 364, 367, 369, 370, 372, 375, 378, 379, 381, 382, 383, 386], "alon": 232, "along": [148, 225, 368, 370], "alongsid": [262, 377], "alpha": [15, 40, 41, 45, 76, 77, 124, 215, 216, 217, 222, 229, 231, 233, 238, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327, 330, 332, 336, 370, 378, 380, 386], "alpha_1": 369, "alpha_2": 369, "alpha_l": 369, "alreadi": [150, 313, 350, 385], "also": [120, 140, 141, 142, 146, 147, 187, 213, 215, 217, 218, 220, 225, 226, 227, 228, 236, 265, 279, 280, 309, 330, 331, 334, 335, 336, 337, 339, 340, 343, 344, 345, 347, 348, 349, 350, 351, 362, 367, 371, 375, 385, 386, 388], "alter": 335, "altern": [216, 231, 307, 313, 343, 345, 349, 351, 378, 380, 382], "although": [330, 336, 345], "alwai": [125, 307, 308, 309, 310, 338], "am": 348, "amazonaw": 30, "amer": [128, 136, 338], "among": [130, 236, 336, 339, 340, 344, 351, 379], "amount": 334, "an": [5, 31, 122, 123, 127, 138, 187, 226, 237, 242, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 293, 294, 296, 299, 301, 303, 305, 307, 308, 309, 310, 313, 315, 326, 327, 330, 332, 334, 336, 337, 338, 339, 340, 343, 344, 345, 347, 348, 349, 351, 355, 362, 363, 364, 365, 367, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 387, 388], "analogi": [344, 351], "analys": 50, "analysi": [1, 9, 12, 24, 25, 30, 35, 36, 50, 52, 55, 58, 61, 64, 65, 71, 74, 78, 82, 86, 89, 98, 119, 125, 126, 127, 128, 129, 130, 136, 138, 188, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 253, 254, 260, 261, 262, 263, 265, 292, 293, 324, 333, 339, 340, 343, 345, 346, 347, 349, 350, 355, 356, 357, 360, 361, 364, 370, 376, 377, 383, 391], "analyt": 352, "analyz": [68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 122, 123, 124, 125, 136, 138, 188, 216, 217, 220, 223, 227, 228, 230, 231, 232, 233, 235, 237, 238, 239, 241, 244, 253, 254, 258, 261, 262, 263, 265, 336, 358, 360, 364, 378, 379, 380, 381, 382, 383], "andrea": 336, "angiulli": 336, "angiulli2002": 336, "ani": [57, 128, 136, 166, 210, 269, 272, 290, 291, 292, 293, 315, 331, 338, 344, 347, 350, 351, 380, 388], "anim": 57, "animationdur": 57, "animationdurationupd": 57, "animationeas": 57, "animationeasingupd": 57, "animationthreshold": 57, "annal": [339, 343, 346], "annot": 338, "anomal": [233, 381], "anomali": [122, 336, 340], "anoth": [4, 20, 21, 76, 77, 335, 337, 343, 345, 377, 381], "anova": [232, 366], "anyon": [26, 27], "apart": 347, "api": [30, 31, 50, 330, 332, 336, 345, 346, 347, 348, 349, 350, 351, 352, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "aplei": 343, "apley2016": [343, 345], "appear": [350, 362, 365], "appli": [4, 8, 126, 130, 131, 171, 187, 216, 218, 223, 227, 228, 231, 234, 281, 282, 296, 297, 326, 327, 328, 330, 332, 335, 343, 344, 346, 351, 354, 356, 357, 367, 369, 372, 373, 377, 378, 380, 381, 382], "applic": [119, 215, 235, 326, 327, 339, 367, 368, 371, 372, 382], "appnam": 31, "approach": [124, 336, 339, 340, 344, 351, 352, 371, 379, 386], "appropri": [130, 148, 331, 336, 371, 377], "approv": [377, 382], "approx": [309, 378], "approxim": [130, 262, 339, 343, 344, 349, 351, 358, 380, 383], "april": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "ar": [4, 57, 119, 121, 122, 124, 129, 130, 136, 137, 138, 140, 141, 142, 146, 171, 213, 214, 215, 216, 218, 220, 223, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 246, 253, 254, 262, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 331, 332, 334, 335, 336, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 362, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 388], "arang": [7, 32, 33, 34, 35, 36, 41, 388], "arbitrari": [29, 37, 49, 273, 274, 275, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 298, 303, 304, 375, 385, 391], "arbmodel": 388, "architectur": [279, 280, 296, 297, 352, 366, 367, 380, 381, 382], "area": [378, 379, 380, 381, 383], "arg": [111, 153, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304], "argsort": 41, "argument": [57, 111, 153, 216, 231, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304, 308, 315, 330, 332, 335, 339, 345, 346, 347, 348, 349, 351, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "aris": 380, "around": [345, 347, 368, 370, 374, 379], "arrai": [2, 6, 8, 9, 10, 18, 19, 26, 31, 33, 34, 40, 241, 244, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 388], "array_of_bin_edg": [117, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239], "articl": 385, "arxiv": [336, 339, 344, 351, 367, 368, 369, 373, 382], "as_data_fram": 30, "ascend": [205, 336, 387], "asfactor": 30, "ask": 0, "aspect": [336, 370, 380, 381], "assembl": 31, "assess": [119, 128, 136, 221, 226, 229, 233, 234, 236, 331, 332, 335, 338, 341, 343, 350, 361, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 379, 381, 382, 383, 386], "assign": [265, 307, 308, 309, 310, 336, 344, 348, 368, 369, 371, 383], "assoc": [128, 136, 338], "associ": [57, 128, 136, 260, 315, 331, 338, 365, 372], "assum": [141, 241, 279, 280, 326, 327, 328, 343, 344, 349, 350, 351, 373, 379, 382], "assumpt": [335, 343, 349, 379, 380], "astyp": [68, 76, 77, 80, 88], "asymmetr": [335, 341], "asymptot": 339, "atemp": [4, 8, 9, 10, 11, 21, 25, 54, 57, 69, 73, 77, 85, 91, 345, 348, 350, 351, 378, 380, 382], "attempt": [227, 228, 241], "attract": [344, 351], "attribut": [56, 60, 230, 275, 298, 301, 302, 331, 339, 344, 348, 351, 354, 377, 391], "auc": [14, 16, 18, 20, 22, 24, 26, 35, 44, 46, 47, 50, 59, 62, 66, 68, 72, 80, 84, 88, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 259, 265, 307, 308, 309, 310, 311, 343, 350, 359, 361, 362, 363, 364, 373, 377, 379, 383, 386], "auc_rank": [44, 46, 47], "augment": [367, 372, 379, 380, 381], "august": 336, "auth": 53, "authent": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "author": 336, "auto": [54, 57, 68, 69, 72, 73, 84, 85, 88, 91, 117, 219, 220, 221, 222, 223, 227, 232, 235, 236, 237, 238, 239, 241, 242, 244, 279, 280, 311, 362, 364, 365, 377, 378, 382, 383], "auto_s": 57, "autom": [0, 59, 352, 378], "automat": [59, 131, 182, 219, 221, 222, 223, 313, 315, 337, 354, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 382], "avail": [9, 35, 36, 68, 69, 119, 126, 129, 140, 141, 142, 143, 146, 147, 152, 213, 214, 215, 216, 220, 225, 226, 227, 228, 231, 232, 235, 236, 237, 238, 239, 241, 242, 244, 249, 250, 253, 265, 278, 279, 280, 289, 296, 297, 307, 308, 309, 310, 315, 334, 337, 343, 344, 347, 349, 351, 356, 363, 370, 374, 379, 386], "averag": [215, 222, 229, 238, 244, 254, 332, 336, 340, 343, 345, 347, 348, 349, 350, 351, 367, 368, 369, 370, 372, 373, 374, 379, 380, 382], "avg": [9, 35, 36, 76, 77], "avoid": [279, 280, 328, 339, 363, 373, 381, 382], "awar": [377, 381], "ax": 357, "axi": [32, 33, 34, 88, 122, 123, 124, 126, 127, 213, 214, 217, 219, 221, 222, 223, 229, 230, 233, 234, 242, 243, 245, 246, 252, 255, 257, 261, 262, 263, 309, 330, 331, 332, 348, 351, 356, 361, 373, 388], "axis_nam": [39, 41], "axislabel": 57, "axislin": 57, "axispoint": 57, "axistick": 57, "b": [2, 335, 339, 341, 343, 373, 377, 382], "b140": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "back": 382, "backend": [49, 290, 291], "background": [246, 344, 351], "backgroundcolor": 57, "backpropag": 372, "backslash": [344, 351], "backward": [137, 339], "bad": 311, "bade28": 57, "bag": 382, "balanc": [228, 331, 334, 355, 356, 357, 367, 368, 372, 377, 378, 380, 381, 382], "bandwidth": 347, "bank": [380, 381, 382], "bar": [119, 125, 126, 136, 138, 212, 213, 214, 215, 216, 218, 226, 227, 231, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 261, 262, 263, 265, 307, 308, 309, 310, 315, 330, 331, 332, 338, 344, 345, 348, 349, 351, 355, 356, 359, 360, 361, 362, 363, 370, 373, 379], "basak": 339, "base": [122, 123, 124, 126, 128, 136, 137, 138, 163, 171, 187, 188, 214, 216, 218, 219, 221, 222, 223, 226, 227, 231, 234, 235, 237, 238, 239, 253, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 330, 331, 333, 334, 335, 337, 338, 339, 341, 343, 344, 345, 346, 348, 349, 350, 351, 352, 354, 356, 357, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387], "base_scor": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "baselin": [228, 246, 367, 369, 372, 381, 382], "baseline_dataset": [92, 246], "baseline_sample_index": [92, 246], "baseline_sample_s": [92, 246], "basi": [336, 382], "basic": [1, 12, 14, 24, 25, 30, 57, 112, 324, 333, 337, 354, 355, 369, 391], "batch": [68, 69, 76, 77, 84, 85, 88, 235, 236, 237, 238, 239, 244, 253, 279, 280, 292, 293, 296, 297, 386, 387], "batch_siz": [279, 280, 296, 297], "batch_size_infer": [279, 280], "bcbd22": 57, "becaus": [111, 242, 343, 345, 348, 367, 368, 369, 372], "becom": [344, 348, 351, 372, 381], "been": [156, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 373], "befor": [130, 166, 179, 187, 232, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 382, 383], "begin": [335, 336, 340, 341, 343, 344, 345, 346, 347, 349, 351, 362, 367, 369, 373, 377, 378, 380, 381], "behav": 381, "behavior": [233, 239, 336, 361, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 381, 383, 386], "behind": 336, "being": [123, 213, 215, 217, 218, 219, 221, 222, 223, 231, 258, 343, 344, 345, 350, 351], "belong": [336, 340], "below": [137, 330, 331, 332, 334, 336, 344, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 388], "benchmark": [62, 63, 352, 377, 382], "benefici": 339, "benefit": [344, 351, 370, 371, 374], "benign": 382, "bernhard": [336, 339], "best": [16, 17, 279, 280, 308, 330, 359, 362, 371, 379], "beta": [378, 380], "beta_": [369, 372], "beta_1": 369, "beta_2": 369, "beta_l": 369, "better": [5, 123, 228, 330, 332, 336, 343, 347, 350, 367, 368, 369, 370, 372, 373, 378, 379, 380, 386], "between": [3, 7, 11, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 119, 122, 123, 124, 126, 127, 128, 130, 136, 187, 214, 215, 221, 222, 225, 226, 227, 228, 229, 230, 235, 236, 237, 238, 239, 242, 257, 308, 330, 332, 335, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 355, 356, 357, 358, 360, 361, 364, 367, 370, 371, 372, 378, 379, 380, 381, 382, 383], "beyond": [343, 345], "bi_featur": [345, 349], "bia": [257, 260, 284, 331, 352, 369, 373, 377, 378, 379, 383], "bias": [343, 345, 373, 377, 383], "bigl": [367, 369, 371, 372], "bigr": [367, 369, 371, 372], "bike": 332, "bikeshar": [2, 4, 6, 8, 9, 10, 11, 15, 17, 19, 21, 23, 25, 27, 41, 45, 53, 54, 57, 62, 63, 66, 67, 69, 73, 77, 81, 85, 91, 152, 327, 334, 345, 346, 347, 348, 349, 350, 351, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382], "bikeshare_md_exp_bikeshar": 2, "bill_amt1": [2, 3, 5, 26, 68, 84, 88, 377, 383], "bill_amt2": [2, 3, 5, 26, 68, 84, 88], "bill_amt3": [2, 3, 5, 26, 68, 76, 84, 88], "bill_amt4": [2, 3, 5, 26, 68, 84, 88], "bill_amt5": [2, 3, 5, 26, 68], "bill_amt6": [2, 3, 5, 26, 68], "bin": [5, 11, 53, 54, 68, 69, 72, 73, 88, 117, 119, 125, 131, 219, 220, 221, 222, 223, 227, 228, 232, 235, 236, 237, 238, 239, 330, 335, 336, 341, 343, 345, 354, 355, 364, 365, 378, 379, 380, 381, 382], "bin_numer": [5, 11, 334], "binari": [30, 38, 42, 49, 58, 66, 68, 129, 130, 131, 183, 225, 241, 242, 244, 274, 277, 278, 280, 282, 283, 284, 286, 288, 291, 293, 295, 296, 297, 298, 300, 302, 304, 306, 328, 330, 336, 343, 344, 345, 346, 347, 348, 349, 350, 351, 373, 380, 391], "binaryclassifi": 30, "bind": 365, "binning_featur": 227, "binning_method": [88, 227, 377], "bird": 386, "bit": [344, 351], "bivari": [84, 85, 88, 126, 333, 377, 380, 382], "black": [343, 360, 368, 373], "blank": 57, "bleich": 347, "blend": 372, "block": [279, 280], "blue": 351, "blursiz": 57, "bogdan": [343, 346], "bolder": 57, "bonu": [344, 351], "bool": [122, 124, 142, 148, 166, 179, 187, 194, 201, 205, 207, 212, 214, 220, 226, 227, 228, 230, 236, 243, 261, 262, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315], "boolean": [150, 220, 221, 222, 223, 235, 236, 237, 238, 239], "boost": [222, 229, 274, 277, 278, 280, 281, 282, 284, 286, 288, 291, 292, 293, 295, 297, 298, 300, 302, 304, 306, 324, 343, 366, 367, 371, 372, 379, 382, 385], "booster": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "boosting_typ": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "borboudaki": 339, "borboudakis2019": 339, "bordercolor": 57, "bordertyp": 57, "borderwidth": 57, "both": [117, 123, 127, 128, 129, 130, 136, 148, 213, 225, 228, 235, 237, 243, 252, 253, 279, 280, 281, 282, 325, 331, 332, 336, 338, 340, 344, 345, 347, 351, 352, 356, 367, 368, 370, 371, 372, 373, 374, 377, 378, 380, 381, 382, 388], "botta": 336, "bottom": [57, 348], "bound": [214, 220, 226, 227, 228, 236, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 382], "boundari": [117, 131, 339, 359, 361, 378], "boundary_clip": [279, 280], "box": [84, 126, 234, 332, 338, 343, 354, 356, 360, 368, 373, 374], "boxplot": 332, "branch": 372, "break": [5, 9, 10, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 59, 88, 344, 351], "breiman": [343, 350], "bridg": 360, "brief": 336, "briefli": [336, 373], "brier": [14, 16, 20, 22, 24, 26, 35, 44, 46, 47, 50, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 330, 363, 379, 386], "brier_rank": 44, "broader": 377, "broken": [343, 350], "bruce": 339, "brush": 57, "brute": [343, 349, 386], "build": [13, 49, 52, 352, 367, 368, 369, 377, 378, 383, 385, 388], "builder": 31, "built": [98, 152, 271, 325, 344, 351, 387], "bundl": [367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "burden": [336, 339, 380], "busi": [352, 368, 379], "button": [354, 355, 356, 357, 359, 360, 361, 362, 363, 364], "by_weight": [214, 220, 226, 227, 228, 236], "c": [336, 343, 347, 349, 373, 377, 382], "c1": 358, "c2": 358, "c3": 358, "c_": 380, "c_1": 371, "c_2": 371, "c_j": 371, "c_k": 371, "cach": [112, 312], "cal": 380, "calcul": [57, 76, 77, 88, 119, 122, 123, 124, 128, 136, 213, 214, 216, 225, 226, 227, 229, 230, 231, 232, 236, 237, 238, 241, 242, 243, 244, 245, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 307, 308, 309, 310, 330, 332, 335, 336, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 368, 369, 371, 372, 373, 379, 380, 381, 382], "calhous": [2, 365], "calibr": [42, 76, 77, 98, 215, 216, 222, 229, 231, 238, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 324, 330, 361, 371, 377, 380, 391], "calibrate_interv": [40, 41, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327], "calibrate_proba": [39, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328], "calibrated_prob": 328, "california": [32, 33, 34, 385, 387], "californiah": [152, 334, 387], "call": [117, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315, 332, 337, 343, 345, 347, 349, 373], "callabl": [122, 123, 124, 272, 275, 298], "callback": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "can": [54, 58, 76, 98, 112, 117, 126, 128, 131, 136, 140, 141, 142, 146, 147, 148, 171, 180, 215, 216, 217, 218, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 241, 242, 244, 252, 265, 290, 291, 307, 309, 311, 313, 315, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 362, 363, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388], "candid": [284, 339, 367, 371, 379, 380, 386, 387], "cannot": [117, 187, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 331], "capabl": [336, 338, 339, 352, 368, 370, 374, 378], "capac": [378, 380], "capit": [332, 345, 346, 347, 348, 349, 350, 351], "capsul": 30, "captur": [128, 136, 281, 282, 336, 338, 348, 367, 368, 369, 371, 378, 379, 380, 381, 383], "card": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "care": 336, "carefulli": 377, "carlo": [308, 344], "cartesian2d": 57, "cascad": 368, "case": [218, 234, 334, 337, 343, 344, 348, 350, 361, 369, 378, 379, 380, 381, 382], "catboost": [112, 273, 274, 290, 291, 362, 368, 379, 381, 382], "catboost2": 50, "catboostclassifi": 273, "catboostregressor": 274, "categor": [2, 3, 5, 11, 20, 21, 24, 26, 27, 68, 69, 116, 117, 125, 126, 127, 128, 129, 130, 131, 133, 136, 148, 173, 188, 214, 219, 220, 221, 222, 223, 226, 227, 228, 235, 236, 237, 238, 239, 241, 244, 253, 254, 278, 279, 280, 289, 309, 330, 332, 338, 339, 345, 349, 354, 356, 357, 363, 365, 368, 369, 370, 371, 372, 377, 378, 379, 380, 381, 383], "categori": [3, 5, 11, 57, 127, 129, 130, 131, 214, 220, 226, 227, 228, 236, 309, 336, 337, 340, 345, 355, 356, 367, 368, 369, 370, 371, 372, 382], "categorical_encod": [129, 130], "caus": [340, 377, 382], "causal": [339, 352], "caution": 339, "cblof": [122, 333, 352], "cboost_model": 368, "ccc": 57, "ccp_alpha": [16, 17], "cdf": [336, 339, 381, 382], "cdot": [367, 368, 369, 372, 378, 379], "cell": [3, 5, 9, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 355], "center": [14, 15, 18, 19, 20, 21, 24, 25, 26, 27, 57, 92, 122, 171, 243, 261, 262, 265, 290, 291, 340, 343, 345, 348, 367, 368, 369, 370, 371, 372, 373, 381], "central": [365, 375, 387], "centroid": [265, 290, 291, 309, 336, 340, 371], "certain": [24, 332, 335, 336, 337, 343, 344, 349, 351, 367, 368, 369, 372, 377], "cezar": 336, "chain": 352, "challeng": [217, 233, 344, 351, 359, 361, 371, 377, 381], "chang": [16, 17, 84, 85, 142, 234, 244, 332, 335, 336, 339, 340, 341, 347, 348, 359, 361, 368, 370, 374, 377, 378, 379, 380, 381, 382, 383], "changed_name_kei": 57, "charact": 339, "character": [380, 383], "characterist": [218, 265, 336, 340, 371, 382], "chart": [125, 324, 330, 332, 338, 349, 353, 355, 357, 359], "chart_id": 57, "chatterje": [128, 136, 338], "chatterjee2021": 338, "chebyshev": 130, "check": [5, 88, 140, 141, 142, 146, 147, 157, 332, 354, 365, 367, 371, 372, 378, 379, 380, 381, 382, 383], "checkbox": 354, "chen": [336, 340, 369], "chi": 373, "child": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 336], "ching": [336, 340], "choic": [336, 368, 373, 374], "choos": [54, 215, 308, 336, 340, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 371, 378, 382], "chosen": [124, 222, 230, 330, 372, 381, 382], "circl": [332, 336], "circumst": 381, "clara": 336, "clariti": [230, 279, 280, 367], "class": [0, 50, 57, 187, 214, 220, 226, 227, 228, 230, 236, 241, 242, 244, 246, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 326, 334, 338, 375, 377, 379, 380, 388], "class_weight": [16, 24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "classif": [0, 13, 28, 30, 31, 49, 59, 61, 64, 65, 70, 71, 74, 75, 78, 79, 82, 83, 86, 87, 89, 94, 123, 124, 183, 190, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 307, 308, 309, 310, 324, 325, 328, 329, 334, 336, 337, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 359, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 380, 381, 382, 383, 386, 388, 391], "classifi": [29, 37, 38, 42, 49, 229, 264, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327, 328, 336, 340, 344, 368, 374, 379, 388, 391], "classmethod": 266, "clean": [112, 334, 378], "cleaner": 368, "clear": [345, 365, 367, 368, 371], "clear_mlflow_hom": [0, 112], "clearer": 368, "clearli": 336, "click": [57, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365], "client": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "clip": [57, 279, 280, 281, 282, 283, 284], "clip_predict": [24, 25, 281, 282, 283, 284], "close": [128, 136, 328, 332, 338, 348, 373, 377], "closer": 242, "cluster": [80, 81, 122, 216, 217, 218, 231, 233, 254, 265, 290, 291, 340, 352, 358, 359, 371, 376, 378, 379, 381], "cluster_featur": [290, 291], "cluster_i": 231, "cluster_id": [379, 380, 382], "cluster_label": 231, "cluster_method": [62, 63, 216, 231, 379, 380, 382], "cluster_no": 371, "cluster_perform": [62, 63, 216, 231, 265, 379], "cluster_pred_func": 231, "cluster_residu": [62, 63, 231, 379], "cluster_sample_weight": 231, "cluster_threshold": 122, "cluster_x": 231, "cma": [47, 308], "cmaessampl": 308, "cnt": [9, 10, 11, 15, 17, 19, 21, 23, 25, 27, 41, 45, 54, 63, 67, 69, 73, 77, 81, 85, 91, 332, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382], "coalit": [344, 351], "coarser": 377, "code": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 112, 126, 324, 330, 331, 332, 335, 336, 337, 345, 346, 347, 348, 349, 350, 351, 352, 356, 357, 365, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "coef": 351, "coeffcient": [370, 373], "coeffici": [128, 136, 232, 243, 252, 257, 260, 262, 333, 338, 344, 348, 351, 367, 369, 370, 372, 373, 379], "coefici": [370, 373], "col_nam": [30, 57], "colab": 98, "collect": [31, 378, 380, 381, 383], "color": [3, 57, 126, 127, 338, 356, 357, 358, 363], "colorbi": 57, "colsample_bylevel": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "colsample_bynod": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "colsample_bytre": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "colsiz": 57, "column": [2, 3, 5, 8, 9, 10, 11, 18, 19, 30, 31, 32, 33, 34, 35, 36, 54, 57, 68, 69, 72, 73, 76, 77, 84, 85, 88, 115, 116, 129, 130, 131, 142, 148, 161, 162, 164, 169, 175, 176, 181, 214, 220, 226, 227, 228, 236, 253, 301, 302, 334, 354, 355, 362, 363, 365, 388], "com": 30, "combin": [9, 137, 242, 246, 283, 284, 290, 291, 292, 293, 315, 336, 339, 340, 344, 351, 355, 356, 357, 359, 363, 369, 370, 371, 378, 379, 381, 383, 386], "come": [242, 344, 351, 377], "command": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 111, 112], "commiss": 377, "common": [344, 351, 355, 380, 381, 383, 386], "commonli": [335, 336, 343, 349, 377], "compar": [54, 69, 80, 81, 84, 85, 88, 119, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 228, 242, 329, 330, 331, 332, 335, 336, 345, 348, 359, 361, 363, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "compare_accuraci": 58, "compare_accuracy_t": [35, 36, 39, 59, 66, 67, 379], "compare_fair": [88, 377], "compare_reli": [76, 77, 380], "compare_residual_clust": [62, 63], "compare_resili": [80, 81, 381], "compare_robust": [59, 84, 85, 382], "compare_slicing_accuraci": [35, 36, 53, 54, 68, 69, 383], "compare_slicing_fair": [88, 377], "compare_slicing_overfit": [54, 72, 73, 378], "compare_slicing_reli": [54, 76, 77, 380], "compare_slicing_robust": [54, 84, 85, 382], "comparison": [0, 53, 119, 213, 219, 220, 221, 222, 226, 265, 324, 353, 364, 367, 368, 369, 370, 372, 373, 376], "compat": [148, 275, 298, 352, 370, 374], "compet": 377, "competit": 367, "complement": [187, 336, 343, 347, 349], "complementari": 379, "complet": [129, 188, 256, 280, 296, 297, 355, 362, 374], "complex": [281, 282, 283, 336, 343, 349, 357, 358, 360, 371, 373, 379], "compliant": 377, "complic": [373, 383], "compon": [117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 238, 239, 253, 255, 257, 258, 259, 260, 261, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 338, 340, 367, 368, 369, 370, 371, 372, 373, 377], "composit": 379, "comprehens": [128, 136, 188, 214, 217, 218, 336, 338, 340, 352, 357, 359, 368, 377, 386, 389], "compris": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "comput": [112, 122, 123, 124, 128, 129, 138, 171, 188, 219, 220, 221, 222, 226, 227, 235, 236, 237, 238, 239, 241, 245, 246, 253, 255, 258, 261, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 335, 336, 339, 340, 343, 344, 345, 346, 347, 349, 350, 351, 368, 369, 371, 372, 377, 378, 379, 380, 381, 383, 390], "computation": [380, 386], "concat": [32, 33, 34, 388], "concaten": [35, 36], "concept": [344, 351, 369, 379], "conceptu": [367, 372], "concern": 377, "conclus": [332, 377], "concord": [128, 136, 338], "conda": 98, "condit": [137, 215, 233, 239, 333, 336, 344, 351, 352, 361, 377, 379, 380, 381, 382, 383], "conduct": [4, 223, 339, 352], "confer": [336, 340, 344], "confid": [216, 229, 231, 325, 326, 327, 328, 359, 361, 379, 380, 381, 383], "config": [88, 224, 268], "configur": [5, 57, 58, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 131, 136, 137, 138, 148, 171, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 261, 262, 263, 264, 265, 307, 308, 309, 310, 315, 334, 347, 355, 359, 360, 361, 365, 377], "confin": 57, "conflict": [112, 377], "conform": [76, 77, 216, 229, 231, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 325, 352, 376], "confus": [66, 225, 229], "confusion_matrix": [58, 66, 225], "consecut": 381, "consequ": 331, "consid": [122, 124, 136, 234, 245, 281, 282, 283, 330, 331, 336, 340, 343, 344, 346, 349, 350, 351, 367, 368, 372, 373, 377, 378, 379], "consider": [148, 332, 380], "consist": [128, 136, 171, 216, 231, 332, 338, 344, 345, 346, 347, 348, 349, 350, 351, 352, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "const": 354, "constant": [11, 148, 334, 347, 368, 369, 378, 381, 382], "constrain": [368, 379], "constrainst": 378, "constraint": [279, 280, 292, 293, 366, 377, 379, 380, 381, 382], "construct": [284, 315, 326, 336, 340, 368, 380], "consum": 351, "contain": [0, 49, 98, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 156, 166, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 324, 326, 336, 340, 350, 369, 380, 383], "containlabel": 57, "content": [240, 312, 355], "context": [307, 308, 309, 310, 336, 343, 344, 349, 351, 377], "contextu": 377, "continu": [57, 117, 128, 136, 332, 336, 338, 345, 346, 347, 348, 349, 350, 351, 352, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 382, 383, 387], "contrast": [336, 340, 348], "contribut": [232, 243, 246, 262, 281, 282, 336, 340, 344, 347, 348, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 382], "control": [117, 124, 179, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 242, 244, 246, 253, 272, 283, 308, 336, 337, 349, 352, 367, 368, 370, 372, 373, 377, 382], "conveni": [332, 388], "convent": 372, "converg": [368, 371], "convers": [331, 336], "convert": [11, 30, 31, 129, 130, 131, 149, 198, 292, 293, 372, 382], "coordin": [257, 265, 357, 358, 363], "coordinatesystem": 57, "copi": 39, "copy_x": [15, 45], "coral": [336, 340], "core": [246, 279, 280, 296, 297], "correct": 368, "correctli": 379, "correl": [57, 128, 136, 333, 336, 340, 343, 344, 345, 349, 351, 352, 356, 378], "correspond": [217, 241, 244, 245, 252, 255, 308, 336, 340, 344, 351, 367, 371, 372, 373, 383, 386], "corrratio": 339, "corrupt": 340, "cosin": 130, "cost": [279, 280, 367, 372, 377, 378, 379, 380, 381], "could": [279, 280, 344, 351, 379], "count": [3, 11, 18, 19, 259, 260, 332, 337, 345, 346, 347, 348, 349, 350, 351, 355, 373, 379], "count_llm": 260, "covari": [336, 339, 340, 352, 380], "cover": 375, "coverag": [9, 35, 36, 76, 77, 215, 216, 222, 229, 231, 238, 359, 361, 380], "cp": 380, "cpu": [18, 19, 20, 21, 24, 25, 279, 280, 292, 293, 296, 297], "creat": [5, 11, 58, 117, 125, 126, 127, 129, 130, 131, 148, 156, 216, 222, 230, 231, 242, 244, 252, 253, 254, 255, 256, 257, 264, 290, 291, 292, 293, 313, 315, 334, 336, 344, 345, 348, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "createdatafram": 31, "credit": [5, 377], "criteria": 377, "criterion": [16, 17, 374, 377], "critic": [371, 373, 377, 378, 379], "cross": [290, 291, 307, 308, 309, 310, 339, 379, 386], "crowd": 332, "crqr": 380, "crucial": [340, 348, 386], "csur": 339, "csv": [30, 153, 157, 365], "cubicout": 57, "cuda": [292, 293, 296, 297], "cui": 382, "cui2023": 382, "cultur": 377, "cumul": [124, 226, 335, 341, 381, 382], "cumulative_variance_threshold": 124, "cup": [344, 351], "current": [126, 127, 210, 269, 368], "cursor": 57, "curv": [3, 66, 126, 225, 343, 345, 359, 379, 381], "custer": 381, "custom": [54, 68, 69, 119, 214, 220, 226, 228, 236, 281, 282, 283, 284, 290, 291, 292, 293, 337, 352, 354, 355, 362, 381, 382], "custom_tooltip": 57, "customiz": [125, 356], "customm": 383, "cutoff": 228, "cv": [44, 45, 46, 47, 290, 291, 307, 308, 309, 310, 386], "cyclic": [15, 45], "d": [2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 149, 156, 198, 214, 215, 217, 218, 226, 229, 231, 233, 234, 265, 309, 326, 327, 328, 334, 335, 339, 341, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387, 388], "d1": 3, "d2": 3, "d62728": 57, "d_": [335, 341, 343, 346, 380], "d_j": [343, 346], "d_k": [343, 346], "dag": 272, "dai": [345, 347, 349], "daniel": 343, "darker": 345, "dashboard": [112, 352, 365], "data": [0, 1, 4, 6, 8, 12, 54, 57, 58, 59, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 163, 164, 165, 166, 168, 171, 177, 178, 179, 180, 186, 187, 188, 194, 198, 199, 200, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 315, 324, 325, 330, 332, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 359, 360, 361, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 379, 383, 391], "data_drift": 119, "data_drift_test": [7, 22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 214, 215, 217, 218, 226, 229, 231, 233, 234, 265, 341, 371, 378, 379, 380, 381, 382, 383], "data_eda_1d": 125, "data_eda_2d": 126, "data_eda_3d": 127, "data_eda_correl": [57, 128], "data_eda_pca": 129, "data_eda_umap": 130, "data_fs_corr": 136, "data_fs_rcit": 137, "data_fs_xgbpfi": 138, "data_info": [22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 214, 215, 217, 218, 226, 229, 231, 233, 234, 265, 311, 371, 378, 379, 380, 381, 382, 383], "data_load": 365, "data_outlier_cblof": 122, "data_outlier_isolationforest": 123, "data_outlier_pca": 124, "data_path": [153, 158], "data_preprocess_bin": 117, "data_preprocess_encod": 131, "data_preprocess_imput": 148, "data_preprocess_sc": 171, "data_process": 354, "data_qu": 336, "data_result": [22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 214, 215, 217, 218, 226, 229, 231, 233, 234, 265, 371, 378, 379, 380, 381, 382, 383], "data_summari": [188, 337, 355], "databas": [266, 272, 334], "datafram": [5, 9, 10, 31, 32, 33, 34, 35, 36, 57, 118, 119, 122, 123, 124, 128, 129, 130, 136, 137, 138, 148, 149, 151, 154, 155, 165, 177, 178, 180, 188, 194, 198, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 237, 238, 239, 241, 242, 243, 244, 245, 252, 253, 255, 259, 261, 262, 265, 266, 315, 334, 346, 385, 388], "dataset": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 203, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 248, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 270, 279, 280, 281, 282, 296, 297, 301, 302, 307, 308, 309, 310, 311, 326, 327, 328, 330, 331, 332, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 352, 353, 354, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 391], "dataset1": [7, 119, 311], "dataset2": [7, 119, 311], "datazoom": 57, "date": [1, 3, 5, 12, 52, 55, 391], "date_missing_nan": 11, "date_special_sv1": 11, "dateutil": 112, "daytim": 349, "dde318": 57, "de": 373, "deactiv": [367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "deal": [1, 12, 279, 280, 382, 391], "debias": 377, "debug": [360, 379], "decid": [336, 382], "decis": [13, 28, 49, 241, 242, 244, 256, 264, 273, 275, 276, 279, 281, 283, 284, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 324, 344, 348, 351, 364, 366, 367, 369, 371, 372, 377, 378, 379, 382, 391], "decision_funct": [241, 242, 244, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 345, 346, 347, 349], "decisiontre": 387, "decisiontreeclassifi": [276, 374], "decisiontreeregressor": [277, 374], "declin": 381, "decompos": [344, 351, 367, 368, 369, 371, 372, 378], "decomposit": [372, 373], "decreas": [24, 25, 128, 136, 279, 280, 281, 282, 283, 284, 292, 293, 338, 367, 368, 372, 377], "dedegr": 352, "dedic": 331, "deep": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 352, 373, 388], "deepcopi": 39, "deeper": 371, "def": [30, 31, 33, 34, 59, 388], "default": [4, 57, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 151, 157, 166, 171, 172, 174, 179, 187, 188, 194, 205, 207, 208, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 313, 314, 315, 330, 332, 335, 336, 340, 344, 345, 346, 347, 348, 349, 350, 351, 354, 356, 357, 358, 364, 373, 377, 386], "defin": [30, 214, 219, 220, 222, 223, 226, 228, 236, 239, 290, 291, 307, 308, 334, 335, 336, 339, 341, 343, 344, 346, 347, 349, 351, 361, 363, 367, 368, 369, 371, 372, 373, 377, 378, 382, 383, 386, 388], "definit": [214, 219, 220, 221, 222, 223, 226, 235, 236, 237, 238, 239, 343, 345, 376], "degrad": [332, 343, 350, 352, 359, 361, 381, 382, 383], "delet": [120, 121, 203, 312, 334, 339, 365], "delete_extra_data": 10, "delete_registered_data": 334, "delinqu": 334, "deliv": 371, "delta": [378, 381, 382], "demo": [2, 9, 11, 35, 36, 334, 336, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365], "demograph": [177, 178, 214, 331, 377], "demonstr": [50, 57, 58, 59, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 330, 331, 332, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 385, 388], "deng": [336, 340], "dengel": 336, "denomin": 242, "denot": [343, 344, 347, 350, 351, 367, 369, 371, 372, 373, 377], "densiti": [3, 7, 22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 122, 123, 124, 125, 214, 215, 217, 218, 226, 229, 231, 233, 234, 265, 335, 336, 338, 345, 355, 356, 357, 378, 379, 380, 381, 382, 383], "depend": [112, 125, 128, 136, 241, 242, 244, 336, 338, 339, 342, 344, 346, 347, 352, 354, 360, 377, 379], "depict": 331, "deploi": [352, 367, 372, 383], "deploy": [359, 362, 381], "dept": [336, 340], "depth": [215, 216, 222, 229, 231, 232, 235, 236, 238, 239, 274, 277, 278, 280, 281, 282, 283, 284, 286, 288, 291, 292, 293, 295, 297, 298, 300, 302, 304, 306, 336, 364, 369, 371, 372, 379, 380, 382], "depth2": [386, 387], "depth5": 387, "deriv": [332, 336, 369], "descend": [339, 373], "descent": [24, 25, 372, 373], "describ": [166, 330, 336, 339, 343, 345, 349], "descript": [166, 188, 210, 269, 334, 354, 378, 383], "design": [142, 311, 336, 344, 351, 352, 367, 377, 382, 387], "desir": [335, 336, 340, 341, 367, 372, 380, 382, 383], "despit": [373, 381], "detail": [26, 57, 128, 136, 188, 213, 214, 215, 218, 219, 220, 221, 222, 229, 231, 233, 234, 253, 261, 266, 309, 310, 315, 326, 327, 330, 332, 336, 338, 339, 340, 343, 344, 352, 356, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "detect": [0, 1, 12, 98, 122, 123, 124, 128, 136, 217, 233, 235, 237, 324, 330, 332, 333, 338, 352, 354, 358, 376, 377, 379, 380, 391], "detect_outlier_cblof": [8, 340], "detect_outlier_isolation_forest": [8, 340], "detect_outlier_pca": [8, 340], "determin": [122, 229, 234, 253, 284, 291, 308, 309, 310, 335, 336, 337, 340, 341, 343, 344, 349, 351, 369, 371, 379, 380, 381, 382, 383, 386], "dev": 112, "develop": [98, 112, 260, 332, 334, 335, 345, 346, 347, 348, 349, 350, 351, 352, 371, 373, 379, 380, 381, 389], "deviat": [216, 231, 234, 257, 259, 334, 336, 337, 340, 378, 381, 382], "devic": [9, 18, 19, 20, 21, 22, 23, 24, 25, 39, 40, 41, 58, 66, 67, 68, 279, 280, 292, 293, 296, 297], "df": [31, 334], "di": 377, "diagnos": 378, "diagnose_accuracy_residual_fi": 383, "diagnose_accuracy_t": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 35, 36, 44, 45, 46, 47, 53, 58, 66, 67, 367, 368, 369, 370, 371, 372, 373, 374, 377, 379, 383, 388], "diagnose_fair": [88, 377], "diagnose_mitigate_unfair_bin": [88, 377], "diagnose_mitigate_unfair_threshold": [88, 377], "diagnose_reli": [9, 35, 36, 76, 77, 380], "diagnose_residu": 230, "diagnose_residual_analysi": [9, 35, 36, 54, 62, 63, 379], "diagnose_residual_clust": [62, 63, 379, 380, 382], "diagnose_residual_fi": 383, "diagnose_residual_interpret": [62, 63, 379], "diagnose_resili": [9, 35, 36, 80, 81, 381], "diagnose_resilience_clust": 231, "diagnose_robust": [84, 85, 382], "diagnose_slicing_accuraci": [9, 35, 36, 53, 54, 68, 69, 383], "diagnose_slicing_fair": [88, 377], "diagnose_slicing_overfit": [9, 35, 36, 54, 72, 73, 378], "diagnose_slicing_reli": [54, 76, 77, 380], "diagnose_slicing_robust": [54, 84, 85, 311, 382], "diagnost": [0, 52, 53, 55, 324, 329, 352, 359, 361, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 381, 382, 383, 391], "diagram": [256, 264, 374], "dict": [57, 117, 166, 210, 214, 216, 219, 220, 221, 222, 223, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 239, 253, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315], "dictionari": [117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 166, 171, 187, 188, 201, 209, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 283, 307, 308, 309, 310, 311, 386], "differ": [7, 22, 23, 49, 50, 58, 68, 69, 72, 73, 119, 136, 188, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 230, 231, 233, 234, 236, 239, 257, 258, 290, 291, 329, 330, 331, 332, 334, 335, 339, 340, 341, 343, 344, 345, 348, 349, 350, 351, 356, 364, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 386], "differenti": [371, 372], "difficult": [217, 233, 242, 381], "diistribut": 352, "dill": 112, "dimens": [57, 130, 336, 359, 361, 368], "dimension": [124, 130, 335, 336, 338, 340, 358, 378, 379], "direct": [128, 136, 338, 352, 359, 367, 368, 369, 370, 372, 373, 374, 379, 381, 388], "directli": [290, 291, 330, 331, 344, 350, 351, 370, 373, 374, 377, 378], "directori": [313, 314, 315], "disabl": [2, 334], "disadvantag": [339, 383], "discord": [128, 136, 338], "discov": [336, 340], "discoveri": [336, 339, 344, 358], "discrep": [335, 336, 381], "discret": [117, 335, 341, 372], "discrimin": [331, 377], "diseas": 377, "disentangl": [367, 373], "displai": [39, 41, 119, 207, 213, 214, 215, 216, 220, 225, 226, 227, 228, 231, 232, 235, 236, 237, 238, 239, 240, 241, 244, 252, 253, 265, 307, 308, 309, 310, 315, 330, 331, 332, 335, 336, 351, 354, 355, 356, 358, 361, 362, 364, 367, 368, 369, 370, 371, 372, 373, 374, 380, 381, 383], "display_plot": 240, "display_t": 240, "displaystyl": 369, "disproportion": [381, 382], "dissimilar": [335, 336, 340], "distanc": [119, 122, 124, 130, 214, 216, 226, 231, 336, 340, 341, 345, 352, 371, 379, 380, 382], "distance_metr": [7, 22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 335, 371, 378, 379, 380, 381, 382, 383], "distance_scor": 119, "distinct": [127, 331, 336, 368, 371], "distinguish": [122, 367, 379], "distribut": [22, 23, 68, 69, 88, 119, 125, 215, 217, 226, 229, 231, 233, 234, 258, 265, 308, 310, 311, 326, 327, 328, 330, 332, 333, 338, 339, 340, 344, 351, 352, 355, 356, 359, 361, 370, 371, 376, 377, 378, 379, 380, 383, 386], "divers": [352, 371, 375, 377], "divid": [241, 336, 340, 343, 345, 374, 378, 383], "divis": 374, "dnn": 366, "do": [9, 337, 343, 344, 345, 350, 351, 388], "document": [343, 347, 350, 356, 357], "doe": [24, 128, 136, 307, 308, 309, 310, 313, 336, 338, 340, 344, 345, 346, 347, 348, 349, 350, 377, 378], "doesn": [121, 281, 282], "doi": [336, 340], "domain": [367, 368, 372, 378, 380, 381, 382], "dominik": 339, "done": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 330, 345, 348, 378, 382], "dot": [332, 336, 369, 372], "down": [343, 344, 345, 351, 356, 357], "download": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 356, 357], "downsampl": [344, 351], "downstream": 180, "draw": [76, 345, 351], "drawn": [126, 246, 382], "drift": [0, 1, 12, 62, 63, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 311, 324, 333, 352, 371, 376, 379, 380, 382, 383, 391], "drill": 361, "drive": [369, 379, 383], "driven": [352, 371, 377, 379, 383], "driver": 371, "drop": [88, 137, 233, 339, 343, 350, 382], "dropdown": [354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364], "drug": 357, "ds_new": 50, "dsload": 2, "dt": 50, "dtype": [18, 19, 40, 148], "dual": 253, "due": [112, 235, 236, 238, 239, 334, 371, 373, 378, 381, 382], "duplic": [3, 5, 11, 334, 355, 363], "durat": [50, 362, 363], "dure": [212, 216, 231, 234, 292, 293, 296, 297, 335, 345, 347, 348, 349, 381, 386], "dx": [335, 341, 379, 381], "dx_": [343, 349], "dx_k": [367, 368], "dynam": [352, 371], "e": [26, 47, 120, 148, 149, 171, 177, 178, 180, 198, 215, 217, 218, 219, 220, 221, 222, 223, 226, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 265, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 308, 315, 335, 336, 339, 340, 341, 343, 344, 345, 346, 347, 349, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 386], "e377c2": 57, "e_": 378, "eaaa4301": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "each": [31, 62, 63, 76, 77, 117, 119, 129, 130, 131, 148, 171, 188, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 243, 244, 245, 255, 261, 262, 265, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 311, 315, 330, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 347, 348, 349, 350, 351, 354, 365, 367, 368, 369, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 387], "earli": [24, 137, 279, 280, 281, 282, 292, 293, 296, 297, 339, 378, 382], "early_stop_thr": [279, 280], "early_stopping_round": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "eas": [352, 368], "easi": [374, 377, 383], "easier": [334, 336, 340, 358, 368], "easili": [336, 340, 385], "ebm": 331, "ecod": 336, "econom": 381, "eda": [324, 338, 353, 355], "eda_1d": [3, 338], "eda_2d": [3, 11, 338, 356], "eda_3d": [3, 11, 338, 357], "eda_correl": [3, 57, 338], "eda_multivari": 358, "eda_pca": [3, 338], "eda_umap": 3, "edg": [219, 221, 222, 223, 227, 235, 236, 238, 239, 379, 381], "edit": 365, "educ": [2, 3, 5, 7, 14, 20, 24, 26, 68, 72, 76, 84, 88, 311, 383], "education_1": 5, "education_2": 5, "education_3": 5, "education_missing_nan": 5, "eeoc": 377, "effect": [24, 25, 50, 62, 63, 228, 232, 241, 242, 243, 244, 246, 250, 252, 253, 254, 261, 279, 280, 292, 293, 336, 340, 342, 347, 348, 349, 351, 352, 360, 369, 370, 373, 377, 378, 379, 380, 381, 382, 383], "effect_import": [62, 63, 232, 379], "effect_nam": [241, 244, 253], "effici": [254, 336, 340, 352, 354, 362, 365, 368, 377, 380, 386], "effort": [352, 362], "eigenvalu": [336, 340], "eight": 336, "eighth": [336, 340], "either": [58, 125, 131, 148, 246, 252, 343, 350, 387], "elabor": 336, "elasticnet": [278, 370, 387], "electr": [336, 340], "eleg": 373, "element": [220, 235, 236, 237, 238, 239, 345, 348], "elimin": [137, 336, 339], "ell": 371, "ellipsi": 57, "embed": 231, "emerg": 373, "emil": 347, "emphas": [336, 340], "empir": [215, 226, 335, 376, 380, 381, 382], "emploi": [332, 335, 367, 371, 372, 381], "employ": [377, 381], "empti": [315, 339, 380, 383], "enabl": [325, 334, 337, 352, 354, 356, 357, 358, 359, 361, 362, 365, 368, 371, 372, 375, 379], "enable_categor": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "encapsul": [217, 218, 253, 260], "encod": [5, 126, 129, 130, 131, 232, 278, 289, 354, 365, 367, 368, 369, 370, 371, 372, 377, 382, 383], "encode_categor": [5, 11, 59, 334, 377, 383], "encount": [112, 315], "end": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 111, 335, 336, 341, 343, 344, 345, 346, 347, 349, 351, 367, 369, 372, 373, 377, 378, 380, 381], "end_tim": 50, "enforc": [367, 372, 377], "engin": [1, 12, 117, 131, 148, 171, 334, 336, 340, 379, 380, 381, 382, 391], "enhanc": [126, 325, 336, 339, 352, 369, 370, 371, 373, 374, 378, 379, 380, 381, 382, 383], "enough": [54, 367, 373], "ensembl": [13, 28, 49, 123, 253, 255, 261, 285, 286, 290, 291, 294, 295, 336, 340, 343, 344, 346, 351, 369, 372, 378, 379, 380, 381, 382, 391], "ensur": [129, 130, 137, 187, 218, 308, 326, 327, 328, 334, 337, 352, 363, 367, 368, 370, 371, 372, 374, 377, 378, 379, 380, 382, 383], "enter": [57, 337, 360, 362, 363], "enterpris": 352, "entir": [128, 241, 245, 308, 331, 332, 344, 349, 351, 367, 371, 372], "entropi": [379, 381], "envelop": [343, 345, 349], "environ": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 313, 314, 381], "epoch": [18, 19, 24, 25, 279, 280, 292, 293, 296, 297], "epsilon": 381, "equal": [117, 129, 215, 219, 221, 222, 223, 227, 235, 236, 237, 238, 239, 242, 244, 279, 280, 335, 341, 344, 351, 373, 377, 381, 383], "equat": [371, 373], "equit": 377, "equiv": 373, "equival": [292, 293, 339, 368, 373, 382], "eric": 339, "erion": [344, 351], "errat": 378, "error": [124, 217, 232, 233, 245, 307, 308, 309, 310, 336, 340, 359, 361, 368, 371, 376, 377, 379, 381, 382], "error_scor": [307, 308, 309, 310], "especi": [332, 377, 382], "essenti": [348, 368, 377, 379, 382], "establish": [370, 377, 381], "estim": [24, 25, 30, 32, 33, 34, 50, 219, 220, 223, 235, 236, 237, 238, 239, 245, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 325, 326, 327, 332, 335, 336, 343, 344, 345, 349, 351, 379, 380, 388], "estimators_": [281, 282], "eta": [59, 309, 373], "eta_k": 368, "etc": [142, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 279, 280, 290, 291, 292, 293, 296, 297, 345, 364], "ethic": 377, "ethnic": 377, "euclidean": [130, 336, 340, 371], "european": 336, "eval_metr": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "evalu": [8, 54, 59, 62, 63, 66, 67, 76, 77, 119, 138, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 228, 229, 231, 233, 234, 236, 238, 239, 254, 283, 307, 308, 309, 310, 330, 331, 335, 339, 341, 343, 344, 348, 350, 351, 352, 359, 363, 364, 367, 371, 372, 376, 378, 380, 381, 382, 383, 386], "even": [336, 367, 371, 372, 373], "event": 57, "everi": 369, "evolv": [352, 381], "exact": 309, "exactli": [344, 351], "examin": [232, 347, 379, 380, 383], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 156, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 307, 308, 309, 310, 311, 325, 329, 333, 342, 357, 366, 375, 376, 391], "exce": 242, "exceed": 138, "excel": 368, "except": [30, 351, 367, 369, 372], "exchang": 380, "exclud": [216, 231, 345], "execut": [59, 111, 272, 307, 334, 352, 363, 377, 383, 391], "exhaust": 363, "exhibit": [235, 336, 373, 381], "exist": [112, 121, 140, 141, 142, 146, 147, 157, 163, 172, 174, 313, 347, 365, 367, 368, 370, 374, 377], "exp": [50, 59, 331, 337, 347, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 371], "expand": 313, "expect": [238, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 332, 336, 340, 344, 351, 359, 361, 378, 380], "expens": [380, 386], "experi": [50, 266, 334, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 381, 386], "experiment": [43, 48, 49, 308, 362, 391], "experiment_id": 50, "experiment_nam": 50, "expert": [13, 28, 49, 253, 254, 255, 261, 263, 265, 290, 291, 324, 352, 366, 378, 380, 381, 391], "expert_id": 265, "expert_nam": 371, "expert_no": 371, "expertis": 371, "explain": [53, 93, 98, 124, 129, 232, 241, 242, 243, 244, 245, 246, 258, 324, 336, 338, 340, 345, 347, 348, 349, 350, 351, 352, 353, 367, 368, 373, 378, 379, 391], "explain_al": 91, "explain_hstatist": 91, "explain_lim": [33, 34, 92], "explain_pdp": [32, 53, 91], "explain_pfi": [33, 34, 58, 91], "explain_shap": [32, 92], "explainableboostingclassifi": 331, "explan": [0, 33, 34, 241, 242, 243, 245, 246, 255, 257, 258, 259, 260, 261, 264, 329, 336, 342, 343, 345, 346, 347, 349, 350, 352, 368, 372, 385], "explicit": [219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 313], "explicitli": [337, 344, 351, 367, 372, 379], "explor": [0, 127, 307, 332, 352, 355, 356, 357, 364, 365, 386], "exploratori": [1, 12, 125, 126, 127, 128, 129, 130, 188, 324, 333, 352, 355, 356, 357, 358, 383, 391], "exponenti": 363, "export": 247, "expos": [381, 382], "express": [279, 280, 373, 379], "extend": [369, 370, 380], "extens": [352, 362, 372], "extent": [335, 341, 377, 381], "extern": [98, 271, 352, 379, 381, 387], "extra": [0, 1, 12, 111, 112, 140, 141, 144, 146, 163, 178, 332, 365, 391], "extract": [26, 31, 204, 252, 311, 369, 373, 379, 383, 385], "extrapol": [343, 345, 349, 368], "extrem": [242, 244, 373, 381], "f": [50, 335, 341, 343, 345, 346, 347, 349, 350, 351, 367, 368, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "f1": [14, 16, 20, 22, 24, 26, 35, 44, 46, 47, 50, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 363, 379, 381, 386], "f9f633c8bacb": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "f_": [367, 368, 369, 371, 372, 378, 380, 381], "f_0": [367, 368, 369, 372], "f_i": [367, 369, 372], "f_j": [336, 367, 368, 369, 371, 372], "f_k": [368, 371, 378], "f_m": 368, "f_n": 381, "fabrizio": 336, "face": [233, 371, 382], "facilit": 371, "factor": [30, 122, 340, 344, 351, 367, 371, 372, 377, 380, 381], "fail": [111, 379, 382], "fair": [89, 98, 214, 219, 220, 222, 223, 226, 227, 228, 236, 324, 329, 352, 376, 383, 391], "fairli": [344, 351, 377], "fall": [332, 336, 369, 371, 380], "fals": [9, 11, 15, 22, 23, 24, 25, 35, 36, 39, 40, 41, 45, 50, 57, 58, 59, 66, 67, 68, 69, 72, 73, 76, 77, 84, 85, 88, 92, 122, 124, 142, 150, 166, 187, 194, 201, 205, 207, 212, 230, 240, 272, 279, 280, 281, 282, 283, 284, 292, 293, 296, 297, 315, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 372, 373, 377, 379], "familiar": [370, 374], "fanova": [249, 250, 352], "fanovaar": 379, "far": [336, 340, 343, 349, 381], "fast": [336, 339, 367], "faster": [216, 231, 343, 345, 349], "favor": 377, "favorable_label": [88, 214, 220, 226, 227, 228, 236, 377], "fbedk": 137, "fde725": 57, "feasibl": 378, "featur": [0, 1, 2, 3, 9, 10, 11, 12, 17, 24, 25, 30, 31, 32, 33, 34, 35, 36, 41, 45, 50, 53, 54, 57, 59, 67, 68, 69, 76, 77, 80, 81, 84, 85, 88, 117, 119, 120, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 146, 148, 159, 171, 172, 173, 174, 175, 176, 177, 178, 181, 182, 187, 188, 189, 199, 200, 214, 216, 218, 219, 220, 221, 222, 223, 226, 227, 228, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 257, 258, 260, 261, 262, 263, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 311, 324, 330, 332, 333, 334, 335, 336, 338, 340, 342, 344, 345, 346, 347, 348, 349, 358, 359, 360, 361, 365, 368, 369, 370, 374, 379, 380, 381, 382, 383, 385, 388, 391], "feature1": [68, 72, 73, 76, 84, 85, 227], "feature2": [68, 72, 73, 76, 84, 85, 227], "feature_color": [3, 126, 127], "feature_exclud": 337, "feature_i": [3, 11, 126, 127], "feature_import": [62, 63, 216, 231, 232, 258, 260, 379], "feature_nam": [2, 4, 14, 15, 24, 25, 31, 32, 33, 34, 50, 117, 119, 171, 219, 220, 221, 222, 223, 227, 235, 236, 237, 238, 239, 242, 258, 260, 278, 279, 280, 289, 290, 291, 292, 293, 311, 334, 367, 370, 373, 377, 388], "feature_name1": [279, 280], "feature_name2": [279, 280], "feature_names_categor": [5, 334], "feature_names_mix": [5, 334], "feature_names_numer": [5, 334, 368, 369, 371, 372, 378, 379, 380, 381, 382], "feature_names_out": [117, 131, 148, 171], "feature_select_corr": [4, 339], "feature_select_rcit": [4, 339], "feature_select_xgbpfi": [4, 339], "feature_typ": [2, 9, 14, 15, 22, 23, 39, 40, 41, 50, 58, 66, 67, 68, 173, 278, 279, 280, 289, 337, 368, 369, 370, 371, 372, 378, 379, 380, 381, 382], "feature_x": [3, 11, 126, 127], "feature_z": [3, 11, 127], "features_nam": 377, "featurescol": 31, "feedforward": [367, 373], "fei": [336, 340], "femal": 88, "fetch": [315, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "fetch_california_h": [32, 34, 388], "few": [343, 349], "fewer": [122, 123, 235, 236, 238, 239, 279, 280, 336, 377], "ff7f0e": 57, "fidx": [26, 117, 131, 148, 171], "field": [362, 363], "fig": [315, 330], "fignam": 57, "figsiz": [3, 39, 41, 44, 45, 46, 47, 54, 57, 59, 68, 69, 73, 84, 85, 88, 315], "figur": [57, 68, 69, 315, 331, 373, 383], "file": [58, 153, 156, 157, 158, 170, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315, 365, 391], "file_nam": [58, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315], "filenam": [111, 315, 365], "fill": 365, "fill_valu": [11, 148], "filter": [151, 157, 207, 208, 219, 220, 221, 222, 223, 224, 236, 252, 267, 268, 315], "final": [216, 231, 232, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 336, 339, 340, 343, 344, 345, 347, 350, 351, 354, 365, 368, 371, 372, 373], "financ": 371, "find": [373, 380, 381, 386], "fine": [24, 25, 279, 280, 281, 282, 284, 292, 293, 352, 362, 367, 372, 377], "finer": 241, "finit": [339, 380], "finland": 336, "first": [7, 52, 55, 119, 122, 124, 137, 218, 232, 279, 280, 292, 293, 308, 309, 310, 330, 332, 337, 339, 340, 343, 345, 346, 347, 348, 349, 350, 351, 355, 365, 368, 372, 373, 380, 382, 385, 391], "fit": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 123, 131, 148, 229, 232, 235, 236, 238, 239, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 326, 327, 328, 336, 339, 340, 343, 344, 345, 346, 347, 348, 349, 351, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "fit_conform": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "fit_funct": [275, 298], "fit_intercept": [15, 45], "fitfailedwarn": [307, 308, 309, 310], "five": [344, 351], "fix": [335, 341, 343, 344, 345, 351, 363], "fl": [336, 340], "flag": [378, 380], "flagdefault": [2, 3, 5, 14, 16, 18, 20, 22, 24, 26, 62, 68, 88, 330, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "flat": 207, "flatten": [30, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "flexibl": [223, 283, 284, 337, 350, 352, 367, 368, 369, 372, 388], "float": [68, 76, 77, 80, 88, 122, 123, 124, 136, 137, 138, 148, 179, 187, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 242, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 309, 315, 373], "float32": [18, 19], "fluctuat": [368, 382], "fn": 379, "fn_": 377, "fname": 111, "focu": [347, 371], "focus": [128, 136, 331, 338, 377, 379, 381, 383], "fold": [290, 291, 307, 308, 309, 310, 379, 386], "folder": [313, 315], "follow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 230, 231, 232, 235, 236, 237, 238, 239, 241, 244, 253, 255, 257, 258, 259, 260, 261, 262, 265, 307, 308, 309, 310, 311, 330, 331, 332, 334, 335, 336, 337, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 356, 367, 368, 369, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 385, 388], "fontfamili": 57, "fontsiz": 57, "fontstyl": 57, "fontweight": 57, "footag": 368, "foral": 377, "forc": 386, "force_col_wis": 54, "force_row_wis": 54, "forest": [123, 216, 231, 333, 343, 350, 352, 368, 376, 379, 386], "form": [140, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 367, 369, 372, 373], "formal": 377, "format": [58, 117, 131, 142, 146, 147, 180, 207, 214, 219, 220, 221, 222, 223, 226, 228, 235, 236, 237, 238, 239, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 337, 385, 388], "former": [331, 344, 351], "formul": [366, 367, 369, 372, 380], "formula": [335, 336, 340, 343, 344, 345, 351, 377], "forward": [117, 137, 339], "found": [53, 111, 330, 331, 332, 335, 336, 337, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 390], "foundat": 352, "four": [334, 338, 345, 359, 361, 365, 387], "fourier": [137, 339], "fourth": [127, 338], "fp": 379, "fp_": 377, "fpr": [377, 379], "frac": [335, 341, 343, 344, 345, 346, 349, 351, 367, 368, 371, 372, 377, 378, 379, 381], "fraction": [217, 233, 382], "frame": [30, 207], "framework": [232, 334, 352, 367, 368, 369, 370, 371, 372, 374, 379, 380, 383, 388], "free": 380, "frequenc": [219, 221, 222, 223, 227, 235, 236, 237, 238, 239, 334, 335, 336, 337, 356, 382], "frequent": [0, 148, 354], "friedman": [8, 342], "friedman2001": [343, 349], "friedman2008": [343, 346], "friendli": 352, "from": [3, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 112, 119, 121, 128, 130, 136, 153, 154, 155, 156, 158, 182, 215, 227, 233, 242, 252, 261, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 310, 311, 315, 326, 327, 328, 330, 331, 332, 334, 335, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 379, 380, 381, 382, 383, 386, 387, 388, 391], "from_cod": 334, "fsc": 380, "full": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 124, 129, 138, 331, 335, 336, 337, 345, 346, 347, 348, 349, 351, 352, 356, 357, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383], "fulli": [343, 350, 372, 378], "func": [8, 57, 59, 122, 123, 124, 272, 315], "func_input": [59, 272], "function": [31, 57, 111, 117, 119, 122, 123, 124, 125, 127, 129, 130, 131, 138, 140, 141, 142, 146, 147, 148, 171, 182, 187, 188, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 231, 232, 236, 238, 239, 241, 242, 244, 252, 255, 257, 258, 260, 261, 262, 272, 273, 275, 276, 279, 280, 281, 283, 285, 287, 289, 290, 292, 294, 296, 297, 298, 299, 301, 303, 305, 315, 330, 331, 332, 334, 335, 336, 337, 338, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 366, 370, 373, 378, 380, 381, 382], "further": [62, 63, 215, 217, 226, 229, 231, 233, 234, 265, 311, 336, 339, 372, 377, 380, 381, 383, 385], "furthermor": [332, 371], "futur": [350, 355, 356, 357, 358, 363, 385], "g": [26, 47, 120, 148, 149, 171, 177, 178, 180, 198, 215, 217, 218, 219, 220, 221, 222, 223, 226, 229, 231, 233, 234, 235, 236, 237, 238, 239, 240, 265, 308, 315, 335, 336, 339, 341, 344, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 369, 370, 371, 372, 377, 378, 379, 380, 381, 382, 386], "g_": 371, "g_n": 381, "gabl": [336, 340], "gabriel": [344, 351], "gain": [369, 372, 379, 381], "galleri": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 52, 53, 54, 56, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 94, 391], "gam": [279, 280, 367, 368], "gam_sample_s": [279, 280], "game": [344, 351], "gami": [279, 280, 324, 352, 366, 368, 369, 371, 372], "gaminet": [13, 28, 49, 253, 255, 261, 280, 367, 391], "gaminetclassifi": 279, "gamma": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68, 339, 367, 372], "gamma_m": [368, 369, 372], "gap": [9, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 32, 35, 36, 39, 44, 45, 46, 47, 66, 67, 72, 73, 213, 221, 222, 225, 237, 330, 332, 360, 364, 376], "gate": [290, 291], "gaussian": [122, 216, 218, 231, 234, 308, 336, 339, 340, 359, 361], "gbdt": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 366, 367, 369, 372, 379, 382], "gbdt2": 50, "gblt": [366, 372], "gbm": [215, 238], "gender": [59, 88, 214, 226, 331, 334, 341, 355, 365, 377], "gener": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 52, 53, 54, 56, 57, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 94, 98, 117, 123, 125, 126, 127, 130, 131, 137, 187, 188, 216, 218, 225, 229, 231, 241, 243, 244, 246, 253, 256, 257, 258, 259, 260, 264, 279, 280, 284, 290, 291, 296, 297, 307, 308, 309, 310, 315, 324, 326, 327, 330, 332, 335, 338, 343, 345, 346, 347, 348, 349, 350, 351, 352, 356, 366, 367, 368, 371, 373, 374, 376, 377, 379, 380, 381, 382], "georg": 336, "geq": 380, "get": [2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 115, 116, 132, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 146, 147, 157, 159, 161, 162, 164, 168, 169, 189, 190, 191, 192, 193, 195, 196, 197, 199, 200, 238, 239, 240, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 325, 334, 345, 346, 348, 351, 379, 383], "get_data": 10, "get_data_info": [0, 68, 69, 72, 73, 76, 77, 84, 85, 88, 378, 382, 383], "get_data_list": [10, 140, 141, 142, 146, 147], "get_figure_nam": [58, 68, 69, 315, 383], "get_mlflow_hom": [0, 50], "get_model": [50, 386, 387], "get_param": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "get_start": 391, "get_x_y_data": 142, "getorcr": 31, "gg": 378, "gini": 16, "giorgo": 339, "github": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "give": [138, 241, 245, 279, 280, 313, 336, 340, 350], "given": [140, 141, 142, 146, 147, 155, 258, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 336, 339, 340, 341, 344, 348, 351, 368, 369, 371, 372, 373, 379, 380, 386], "glm": [14, 15, 45, 292, 293, 331, 332, 348, 352, 366, 373], "glmclassifi": 331, "glmt": 369, "glmtree": [281, 282, 292, 293], "global": [18, 19, 90, 93, 94, 130, 241, 242, 244, 245, 255, 256, 259, 324, 342, 349, 366, 373, 378, 380, 381, 391], "global_fi": 373, "global_ic": 347, "glossari": [309, 310], "gmm": 122, "go": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "goal": [336, 339, 344, 351, 369, 377, 382, 386], "goldstein": [336, 347], "goldstein2012": 336, "good": [311, 368, 373, 379, 380], "googl": 98, "gp": 308, "gpsampler": 308, "gradient": [24, 25, 127, 222, 229, 274, 277, 278, 280, 281, 282, 284, 286, 288, 291, 293, 295, 296, 297, 298, 300, 302, 304, 306, 324, 343, 356, 357, 366, 367, 371, 372, 373, 379, 382, 385], "gradientboostingclassifi": 285, "gradientboostingregressor": 286, "gradual": [367, 372, 378, 381], "grain": [281, 282, 284, 377], "grant": 377, "granular": [117, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 241, 377], "graphic": [57, 252, 347, 352], "greater": [242, 279, 280, 330, 336, 337, 339, 347], "greatest": [351, 381], "greatli": [344, 348, 351], "greedi": 343, "grid": [43, 47, 48, 49, 57, 228, 241, 242, 244, 253, 254, 281, 282, 283, 307, 308, 345, 346, 347, 349, 363, 391], "grid_resolut": [91, 241, 242, 244], "grid_siz": [253, 254, 345, 346, 347, 349], "gridsampl": 308, "gridsearchcv": 386, "ground": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 388], "group": [84, 85, 88, 120, 180, 214, 217, 220, 226, 227, 228, 233, 234, 236, 258, 265, 331, 348, 373, 376, 379, 381], "group_config": [88, 214, 220, 226, 227, 228, 236, 377], "group_nam": [214, 220, 226, 227, 228, 236], "grow": 378, "grow_polici": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "gt": 380, "guarante": [344, 351, 368, 377, 380], "guestrin": 344, "guid": [354, 373, 378, 383], "guidelin": 377, "guo": 339, "h": [242, 336, 342, 345, 352, 378], "h2o": [29, 37, 49, 388, 391], "h2o_model": 30, "h2ofram": 30, "h2ogradientboostingestim": 30, "h_": [343, 346, 367], "h_j": 367, "h_m": 368, "ha": [5, 232, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315, 330, 332, 335, 336, 339, 340, 341, 345, 348, 351, 367, 369, 372, 373, 382], "had": 351, "hand": [343, 345], "handl": [57, 127, 129, 130, 148, 280, 315, 336, 339, 340, 367, 368, 369, 378, 380, 381, 383], "hao": 339, "happen": 388, "hard": [80, 81, 217, 233, 359, 361, 372, 373, 381], "harder": 242, "hardest": 381, "hardwar": [279, 280], "harmon": 379, "hat": [330, 339, 343, 345, 346, 347, 349, 367, 371, 372, 377, 378, 379, 380], "have": [47, 112, 128, 136, 156, 177, 178, 180, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 330, 332, 336, 337, 338, 340, 343, 344, 345, 346, 347, 349, 350, 351, 367, 368, 369, 370, 372, 373, 377, 378, 381, 382, 385, 388], "hbo": 336, "he": [336, 340], "he2003": [336, 340], "head": [5, 11, 54, 334], "header": 354, "healthcar": [371, 377], "heatmap": [57, 128, 137, 241, 244, 253, 254, 333, 345, 349, 358, 367, 369], "heavi": 345, "heavili": 378, "height": [39, 41, 57, 315], "help": [225, 227, 228, 230, 233, 234, 237, 339, 343, 344, 349, 351, 358, 359, 370, 373, 377, 378, 379, 381, 382, 383], "helsinki": 336, "henc": [330, 373], "here": [5, 330, 332, 335, 336, 339, 341, 343, 345, 347, 349, 350, 369, 371, 385], "here_": 343, "hered": [279, 280, 367], "heterogen": [371, 380, 381, 383], "heteroscedast": [230, 379, 380], "hidden": [279, 280, 296, 297, 373, 386], "hidden_layer_s": [296, 297, 373, 388], "hidedelai": 57, "hierarch": [374, 379], "high": [242, 330, 332, 335, 336, 339, 340, 343, 345, 346, 347, 348, 349, 350, 351, 352, 355, 358, 359, 365, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "higher": [122, 123, 138, 214, 226, 227, 228, 232, 241, 245, 253, 331, 332, 335, 336, 340, 349, 367, 368, 369, 370, 371, 372, 378, 380], "highest": [337, 345, 351, 368], "highli": [343, 345, 349, 351, 368], "highlight": [264, 336, 358, 359, 371, 374, 378, 379, 381, 383], "hire": 377, "hist": 309, "histogram": [3, 122, 123, 124, 125, 338, 355, 379, 380, 381], "histori": [296, 297, 307, 308, 309, 310], "hoc": [0, 90, 94, 339, 350, 352, 360], "hold": [301, 302, 335, 367, 372, 379], "holder": [367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "holdout": 378, "holidai": [4, 8, 9, 10, 11, 54, 57, 69, 77, 91, 350], "home": [312, 313, 314, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "homogen": [336, 371], "homoscedast": 379, "honest": 380, "horizont": [57, 119, 136, 138, 242, 243, 245, 246, 252, 255, 261, 262], "hot": [131, 232, 278, 289, 334, 367, 368, 369, 370, 371, 372, 382], "hour": 345, "hourli": [332, 345, 346, 347, 348, 349, 350, 351], "hous": [32, 33, 34, 385, 387], "hover": [356, 357, 363], "hoverlink": 57, "how": [50, 58, 59, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 216, 223, 228, 231, 232, 233, 234, 241, 242, 244, 253, 330, 332, 335, 336, 337, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 359, 360, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 385], "howev": [331, 332, 336, 340, 343, 344, 347, 348, 349, 350, 351, 373, 377], "hpo": [44, 45, 46, 386], "hr": [4, 8, 9, 10, 11, 15, 19, 21, 23, 25, 27, 53, 54, 57, 63, 69, 73, 77, 81, 85, 91, 332, 345, 347, 348, 349, 350, 351, 367, 368, 369, 371, 372, 378, 379, 380, 381, 382], "hstack": 41, "hstat": 342, "html": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 247, 315, 367, 369, 372], "htmlstr": [39, 41], "http": [30, 367, 369, 372], "httpx": 112, "hu": [336, 369], "hu2023": 369, "hua": [336, 340], "hub": [324, 353], "hum": [4, 8, 9, 10, 11, 25, 54, 57, 69, 73, 85, 91, 348, 351, 371, 382], "hyperparamet": [0, 98, 232, 275, 298, 307, 308, 309, 310, 352, 362, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 386], "hypothesi": 339, "i": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 111, 112, 117, 122, 123, 124, 125, 126, 127, 128, 129, 131, 136, 141, 142, 146, 148, 150, 157, 166, 171, 187, 205, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 257, 261, 262, 263, 265, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 385, 386, 387, 388], "i_1": [367, 368], "i_j": 351, "i_t": [367, 368], "i_u": [367, 368], "icdm": [336, 340], "icon": 362, "id": [30, 50, 57, 170, 210, 224, 231, 263, 268, 269, 283, 311, 374, 379, 380, 382], "id_": 57, "idea": [336, 380, 381], "ideal": [356, 357, 382], "ident": [335, 373], "identif": [221, 352, 376, 379], "identifi": [119, 122, 123, 124, 137, 217, 221, 225, 228, 230, 233, 234, 235, 237, 238, 239, 273, 274, 276, 277, 278, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 303, 304, 336, 339, 340, 347, 351, 352, 358, 359, 361, 367, 368, 369, 370, 371, 372, 373, 376, 377, 379, 380, 381, 382, 383], "idx": [41, 341], "ieee": [336, 340], "ignor": [57, 230, 233, 344, 351], "ij": [367, 369, 371, 372], "ik": 371, "ikj": 371, "illustr": [244, 258, 330, 332, 344, 345, 347, 349, 351, 382, 385], "iloc": [5, 10, 11, 88], "im": 368, "imag": [58, 315, 356, 357], "imbal": 379, "imbalanc": 379, "imlbook": 351, "impact": [88, 214, 226, 227, 228, 331, 335, 336, 340, 343, 345, 351, 367, 368, 369, 370, 371, 372, 376, 378, 379, 381, 386], "implement": [123, 124, 137, 271, 296, 297, 308, 336, 339, 340, 344, 347, 348, 368, 370, 373, 374, 382, 386], "impli": [331, 373, 378], "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 24, 25, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 92, 112, 136, 137, 138, 216, 231, 232, 243, 244, 245, 253, 255, 257, 258, 260, 261, 262, 279, 280, 326, 327, 328, 330, 331, 332, 333, 334, 336, 342, 346, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 368, 369, 370, 374, 377, 378, 379, 380, 381, 382, 386, 387, 388], "import_fil": 30, "importance_typ": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "impos": [279, 280], "improv": [230, 245, 281, 282, 292, 293, 296, 297, 336, 352, 364, 368, 369, 371, 372, 377, 378, 379, 380, 381, 382, 383], "impur": [281, 282, 283, 284], "imput": [5, 148, 334, 354, 365], "impute_miss": [5, 11, 59, 334], "inaccur": [343, 349], "inact": [172, 174, 235, 377, 383], "inactive_featur": 59, "inch": 315, "includ": [26, 27, 116, 125, 126, 128, 129, 130, 138, 142, 148, 152, 183, 187, 190, 214, 215, 216, 229, 231, 233, 234, 235, 236, 237, 243, 257, 259, 260, 278, 279, 280, 289, 308, 309, 326, 327, 330, 332, 334, 335, 336, 337, 339, 343, 349, 354, 355, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 374, 377, 378, 382, 386], "include_interaction_list": [279, 280], "incom": [367, 368, 372, 377, 381, 382], "inconsist": [343, 349, 381], "incorpor": [367, 380, 381, 382], "incorrect": [379, 383], "increas": [123, 128, 136, 138, 241, 245, 253, 279, 280, 292, 293, 332, 335, 336, 338, 339, 343, 344, 347, 350, 351, 359, 367, 368, 372, 373, 377, 381, 382], "increasingli": 233, "increment": 382, "independ": [137, 241, 242, 333, 336, 340, 343, 344, 349, 351, 352, 368, 378], "index": [8, 11, 31, 54, 117, 119, 131, 141, 142, 148, 171, 243, 246, 261, 262, 263, 264, 279, 280, 335, 341, 343, 345, 348, 351, 352, 360, 368, 373, 379, 381], "indic": [5, 119, 128, 136, 141, 148, 150, 184, 185, 187, 214, 215, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 245, 253, 258, 265, 283, 290, 291, 307, 308, 309, 310, 330, 331, 334, 335, 336, 338, 340, 341, 343, 344, 345, 347, 349, 350, 351, 362, 363, 367, 368, 369, 370, 371, 372, 373, 377, 379, 380, 381, 382, 388], "indicatorimput": 148, "indicators": 57, "individu": [241, 242, 279, 280, 336, 343, 344, 345, 348, 350, 351, 356, 360, 370, 382, 387], "inf": [3, 5, 11, 26, 334], "infer": [182, 279, 280, 339], "infinit": [3, 5, 11, 334, 355], "influenc": [241, 253, 331, 343, 350, 367, 368, 369, 370, 371, 372], "info": [54, 157], "inform": [26, 137, 171, 214, 219, 221, 222, 223, 226, 231, 233, 234, 236, 246, 311, 330, 336, 337, 344, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "infrastructur": 352, "infti": 381, "inher": [0, 217, 233, 352, 360, 367, 368, 369, 371, 372, 373, 377, 380, 382, 385], "init": [30, 279, 280], "initi": [16, 24, 25, 30, 31, 279, 280, 281, 282, 283, 284, 292, 293, 334, 339, 353, 362, 368, 369, 371, 372], "inject": 382, "innat": [128, 136, 338], "input": [30, 57, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 272, 273, 275, 276, 279, 280, 281, 282, 283, 285, 287, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 303, 305, 307, 308, 309, 310, 315, 330, 332, 343, 344, 345, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 380, 381, 383, 388], "inputcol": 31, "inquiri": 334, "insight": [215, 239, 262, 336, 350, 352, 355, 360, 361, 364, 369, 371, 378, 379, 381, 383], "insignific": 339, "inspect": 365, "inspir": [344, 351, 386], "instal": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "instanc": [58, 148, 228, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 334, 336, 337, 340, 344, 347, 348, 351, 380, 381, 382], "instead": [124, 142, 330, 332, 337, 343, 344, 345, 346, 347, 349, 351, 379], "institut": 339, "insuffici": [377, 379], "insur": 377, "int": [31, 46, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 136, 137, 138, 148, 157, 171, 179, 184, 185, 187, 208, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 253, 254, 258, 261, 262, 263, 264, 274, 277, 278, 279, 280, 281, 282, 283, 284, 286, 288, 290, 291, 292, 293, 295, 296, 297, 298, 300, 302, 304, 306, 307, 308, 309, 310, 315, 335, 341, 343, 349, 367, 368, 381], "int_": [379, 381], "integ": [11, 129, 130, 131, 148, 296, 297, 307, 308, 309, 310], "integr": [336, 343, 348, 349, 352, 354, 371, 373, 375, 386, 388], "intend": 379, "interact": [69, 76, 77, 127, 235, 236, 237, 238, 239, 241, 242, 244, 249, 253, 254, 279, 280, 336, 338, 343, 344, 345, 346, 347, 349, 351, 352, 356, 357, 358, 364, 367, 369, 371, 372, 378, 379, 380, 381, 382, 383], "interact_num": [279, 280], "interaction_constraint": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "interaction_list_": [279, 280], "interaction_val_loss_": [279, 280], "intercept": [348, 367, 368, 369, 372, 373], "interest": [252, 330, 332, 336, 343, 345, 347, 348, 349, 361], "interfac": [352, 355, 368, 370, 374], "intern": [117, 163, 284, 292, 293, 336, 340, 344], "interpret": [0, 98, 242, 243, 281, 282, 283, 284, 292, 293, 324, 325, 336, 339, 342, 343, 345, 352, 360, 377, 380, 382, 383, 385, 387], "interpret_cluster_analysi": 265, "interpret_coef": [14, 15, 370], "interpret_effect": [14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 50, 62, 63, 367, 368, 369, 371, 372, 379], "interpret_ei": [22, 23, 26, 27, 255, 367, 368, 369, 371, 372], "interpret_fi": [14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 50, 367, 368, 369, 370, 371, 372, 373], "interpret_fi_loc": 261, "interpret_glm_coef": 252, "interpret_global_tre": [16, 17, 374], "interpret_llm_pc": [18, 19, 373], "interpret_llm_profil": [18, 19, 373], "interpret_llm_summari": [18, 19, 373], "interpret_local_ei": [20, 21, 22, 23, 26, 27, 367, 368, 369, 371, 372], "interpret_local_fi": [14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 62, 63, 367, 368, 369, 370, 371, 372, 379], "interpret_local_linear_fi": [14, 15, 18, 19, 370], "interpret_local_moe_weight": [22, 23, 371], "interpret_local_tre": [16, 17, 374], "interpret_moe_cluster_analysi": [22, 23, 371], "interpret_tree_glob": 256, "interpret_tree_loc": 264, "interv": [38, 42, 49, 57, 215, 216, 217, 222, 229, 231, 238, 241, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 324, 325, 330, 332, 343, 345, 359, 361, 364, 368, 380, 382, 383, 391], "interven": [344, 351], "intervent": [344, 351, 379], "intric": 331, "introduc": [334, 336, 344, 351, 369, 373, 377, 380, 381, 382, 387], "introduct": [324, 376], "intuit": [352, 355], "invalid": [315, 363], "invers": [57, 117, 370, 382], "investig": [377, 379, 380, 381, 382], "involv": [136, 330, 332, 334, 336, 337, 343, 350, 372, 377, 380, 381, 386], "ioanni": 339, "ionescu": 336, "ipynb": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "ipython": [39, 41, 112], "ipyvuetifi": 112, "ipywidget": 112, "iri": 334, "irisdata": 334, "irreduc": 378, "isol": [123, 333, 352, 367, 372, 383], "isolationforest": [336, 340], "isoton": [39, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328], "issu": [112, 121, 225, 233, 279, 280, 332, 364, 367, 368, 369, 370, 372, 373, 376, 378, 379, 381], "itali": [336, 340], "item": [57, 171, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 231, 233, 234, 236, 265], "itemgap": 57, "itemheight": 57, "items": 57, "itemwidth": 57, "iter": [24, 25, 137, 138, 279, 280, 281, 282, 290, 291, 307, 308, 309, 310, 336, 343, 350, 363, 368, 369, 371, 373, 378, 386], "its": [112, 188, 201, 223, 228, 231, 233, 239, 244, 245, 279, 280, 332, 336, 340, 344, 345, 346, 347, 348, 349, 350, 351, 355, 360, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 387], "itself": [301, 302, 348], "j": [128, 136, 335, 336, 338, 339, 343, 344, 345, 346, 351, 367, 368, 369, 371, 372, 378], "j_1": [367, 368], "j_m": [369, 372], "j_v": [367, 368], "janz": 339, "jerom": [343, 346], "jie": 369, "jingyu": 343, "jiuyong": 339, "jk": [343, 346, 367, 368, 372], "job": [307, 308, 309, 310], "joblib": [307, 308, 309, 310], "john": 336, "joint": [242, 349, 369], "jona": 339, "journal": [339, 343, 347], "jpg": 315, "jsd": 381, "jth": 336, "judgment": 348, "jupyt": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 352], "just": [343, 344, 345, 351], "justin": 347, "k": [80, 81, 119, 122, 214, 226, 290, 291, 335, 339, 340, 341, 343, 345, 346, 350, 367, 368, 371, 378, 379, 381, 382], "k_": [343, 345], "kai": [336, 340], "kanoksri": [336, 340], "kapeln": 347, "keep": [343, 345, 350, 373], "kei": [0, 50, 57, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 307, 308, 309, 310, 315, 324, 334, 336, 343, 349, 359, 361, 362, 363, 370, 371, 377, 378, 379, 380, 381, 382, 386], "kendal": [128, 136, 338], "kept": 382, "kernel": [246, 336, 339, 344, 351, 386], "keyword": [153, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304, 330, 332, 336, 345, 346, 348, 349, 351, 373], "kfold": [308, 309, 310], "ki": 336, "kj": [343, 346], "kl": [335, 341], "kmean": [8, 122, 381], "kmedoid": [216, 231], "knauth": 373, "knn": 336, "know": [324, 344, 351], "knowledg": [336, 344, 367, 368, 370, 372, 374, 378, 380, 381, 382], "known": [336, 368, 373, 379], "kolmogorov": [119, 335, 341], "ks_2samp": [335, 341], "kui": 339, "kullback": [335, 341], "kun": 339, "kwarg": [153, 273, 274, 275, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 303, 304], "kyuseok": 336, "l": [335, 341, 343, 350, 367, 368, 369, 371, 372, 373, 378], "l1": [281, 282, 283, 284, 296, 297, 370, 373, 378, 382], "l1_ratio": [15, 45, 370, 387], "l1_reg": [296, 297, 373], "l2": [232, 370, 378, 382], "l2001": [343, 350], "l_": [367, 368, 372, 378, 380, 381, 382], "l_m": 372, "lab": 379, "label": [31, 41, 57, 119, 214, 220, 226, 227, 228, 230, 231, 236, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 311, 330, 356, 357, 378, 379], "labelcol": 31, "lack": [373, 380, 383], "lambda": [367, 378, 380, 381, 382], "lambda_": [336, 340], "lambda_1": [378, 382], "lambda_2": [378, 382], "lambda_i": 339, "land": 379, "larg": [84, 85, 122, 125, 127, 128, 130, 234, 279, 280, 336, 339, 340, 344, 348, 351, 358, 367, 368, 372, 373, 378, 379], "larger": [127, 130, 214, 220, 226, 227, 228, 230, 233, 236, 245, 279, 280, 332, 336, 340, 343, 345, 346, 347, 349, 350, 351, 367, 372, 373, 378], "largest": [229, 330, 332, 336, 348, 373, 377, 382], "lasso": [344, 348, 378, 382], "last": [279, 280, 330, 335, 339, 343, 345, 354, 385], "latent": 381, "later": 387, "latest": [2, 50, 157], "latter": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 344, 351], "layer": [279, 280, 296, 297, 371, 372, 373, 386], "ldot": [344, 351, 373], "le": [367, 369, 372], "lead": [242, 332, 335, 343, 345, 348, 367, 368, 371, 372, 377, 380, 381, 382], "leaderboard": [324, 362, 363, 364, 375], "leaf": [281, 282, 283, 284, 344, 351, 368, 369, 379], "leaf_estimators_": 283, "learn": [112, 131, 244, 275, 279, 280, 292, 293, 298, 299, 300, 329, 331, 332, 335, 336, 339, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 360, 362, 363, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 381, 383, 385, 386, 388], "learner": [368, 369], "learning_r": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 281, 282, 296, 297, 362, 373, 386], "least": [367, 373, 380, 381], "leav": [283, 284, 336, 369], "lee": [344, 351], "left": [57, 331, 336, 339, 343, 344, 346, 351, 368, 369, 371, 372, 377, 379], "legal": 377, "legend": [57, 330], "legendhoverlink": 57, "legitim": 377, "leibler": [335, 341], "len": [35, 36, 378], "length": [57, 177, 178, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304, 336, 340, 373], "leq": [368, 378], "less": [214, 226, 227, 332, 337, 343, 344, 345, 347, 349, 351, 371, 378, 380, 381, 382], "let": [343, 345, 347, 373, 382], "letter": [336, 340], "level": [84, 214, 216, 218, 222, 226, 229, 231, 234, 236, 239, 284, 328, 331, 336, 339, 351, 355, 359, 361, 367, 368, 369, 370, 371, 372, 377, 378, 380, 381, 382], "leverag": [334, 336, 352, 370, 374, 377, 379], "lgbm": [32, 33, 34, 44, 46, 47, 50, 53, 54, 59, 62, 63, 68, 91, 92, 279, 280], "lgbm1": 54, "lgbm2": [50, 54], "lgbm_model": [368, 377, 378, 379, 380, 381, 382, 383], "lgbmclassifi": [33, 50, 287], "lgbmclassifierlgbmclassifi": 33, "lgbmregressor": [32, 34, 215, 288], "lgbmregressorlgbmregressor": [32, 34], "lgmb": [50, 59], "li": [336, 339, 368, 382], "li2021": 336, "librari": [57, 127, 308, 315, 352, 368], "licenc": [5, 9, 10, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 59, 88], "licens": 53, "lie": 381, "lifecycl": 352, "light": 345, "lighter": 345, "lightgbm": [32, 33, 34, 50, 54, 112, 287, 288, 290, 291, 362, 363, 368, 369, 377, 378, 379, 380, 381, 382, 383], "lightweight": [273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 294, 295, 303, 304], "like": [127, 180, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 331, 336, 340, 345, 352, 363, 365, 373, 377, 379, 380, 381, 382], "lime": [33, 34, 112, 243, 342, 352, 360], "limit": [171, 332, 343, 345, 349, 373, 377, 380], "limit_b": [2, 3, 5, 26, 68, 383], "limit_bal_special_sv1": 5, "limits_": 367, "lin": 339, "lindsai": 339, "lindsayl2000": 339, "line": [111, 112, 126, 138, 217, 219, 220, 221, 222, 223, 227, 228, 229, 233, 241, 244, 253, 254, 332, 336, 345, 347, 349, 356, 363, 367, 369, 373], "linear": [13, 28, 49, 128, 136, 232, 252, 253, 255, 257, 261, 262, 281, 282, 284, 324, 338, 339, 343, 344, 348, 349, 351, 363, 366, 372, 379, 382, 386, 391], "linear_model": [278, 289, 370], "linear_tre": [24, 25, 59], "linearshap": 351, "lineartre": 382, "lineplot": 41, "ling": [336, 339, 340], "link": [57, 331, 335, 336, 337, 361, 365, 370, 377, 383], "link_id": 57, "linspac": 386, "linwei": 369, "lipschitz": 378, "list": [5, 50, 68, 69, 115, 116, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 143, 144, 148, 151, 164, 171, 172, 174, 206, 207, 208, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 231, 232, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 249, 250, 252, 254, 255, 258, 260, 261, 262, 267, 273, 274, 276, 277, 278, 279, 280, 281, 282, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 303, 304, 307, 308, 309, 310, 311, 315, 332, 334, 337, 346, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386], "list_registered_data": [2, 334], "list_registered_model": 50, "liu": [336, 339, 340], "liu2008": [336, 340], "liwu": [336, 340], "ll": 351, "llm": [257, 258, 259, 260, 366], "llm_pc": 257, "llm_profil": 258, "llm_summari": 259, "llm_violin": 260, "ln": [335, 341], "load": [0, 3, 4, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 129, 153, 154, 155, 156, 157, 158, 224, 268, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327, 328, 330, 333, 337, 338, 354, 359, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "load_breast_canc": [31, 33], "load_builtin_data": [5, 10, 11, 54, 88], "load_csv": 334, "load_data": 59, "load_datafram": [5, 9, 10, 11, 30, 31, 32, 33, 34, 35, 36, 54, 88, 334, 388], "load_iri": 334, "load_registered_data": [2, 9], "load_registered_model": 50, "load_spark": 334, "loaded_model": 50, "loan": [377, 382], "local": [24, 25, 33, 34, 53, 62, 63, 90, 93, 94, 122, 130, 241, 243, 246, 257, 258, 259, 261, 262, 264, 324, 340, 342, 349, 351, 352, 366, 379, 380, 381, 382, 383, 391], "local_fi": 373, "local_linear_fi": 373, "local_model_zoo": 50, "localdataset": 270, "localgap": 378, "localmodelzoo": 50, "locat": [361, 365, 383], "lock": [354, 363], "log": [279, 280, 336, 343, 345, 346, 347, 349, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "log1p": [5, 15, 17, 19, 21, 23, 25, 27, 41, 45, 63, 67, 69, 73, 77, 81, 85, 91, 171, 334, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382], "logarithm": [171, 363], "logbas": 57, "logic": [360, 367, 368, 372], "logist": [13, 28, 39, 40, 49, 58, 66, 68, 252, 253, 255, 261, 262, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328, 370, 391], "logisticregress": [31, 289, 370], "logit": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305], "logit_predict": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305], "logloss": [14, 16, 20, 22, 24, 26, 35, 39, 44, 46, 47, 50, 59, 66, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 330, 363, 386], "logloss_rank": [44, 46, 47], "long": [358, 373], "longer": [335, 336, 340], "look": 379, "lose": 377, "loss": [18, 19, 24, 25, 238, 279, 280, 281, 282, 296, 297, 343, 350, 368, 371, 377, 378, 379, 380, 381, 382], "loss_threshold": [279, 280], "lot": [344, 351], "low": [41, 98, 235, 324, 351, 352, 377, 378, 380, 381], "lower": [88, 214, 220, 226, 227, 228, 236, 242, 244, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 331, 332, 336, 347, 368, 377, 379, 380], "lower_inclus": [88, 214, 220, 226, 227, 228, 236, 377], "lowest": [332, 371], "lpb": 339, "lr": [31, 50], "lr_model": 31, "lt": 368, "lundberg": [344, 351], "lundberg2017": [344, 351], "lundberg2018": [344, 351], "m": [335, 344, 351, 367, 368, 369, 372, 379, 381], "m0": [369, 372], "machin": [112, 131, 244, 329, 331, 332, 335, 336, 339, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 360, 362, 363, 369, 374, 376, 377, 378, 379, 383, 385, 386, 388], "made": [335, 368, 372], "mae": [9, 15, 17, 21, 23, 25, 27, 32, 36, 45, 63, 67, 69, 73, 85, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 332, 362, 363, 364, 378, 379, 380, 382, 386], "magnitud": [216, 218, 223, 231, 234, 367, 368, 369, 370, 372, 373, 378, 382], "mahalanobi": [124, 336, 340, 381], "mai": [26, 27, 112, 182, 221, 235, 236, 238, 239, 241, 309, 326, 327, 328, 334, 335, 336, 339, 341, 343, 344, 345, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 388], "main": [3, 6, 8, 9, 10, 24, 25, 35, 36, 57, 62, 63, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 250, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 279, 280, 307, 308, 309, 310, 341, 345, 352, 355, 356, 357, 358, 365, 367, 369, 371, 372, 380, 382], "main_effect_val_loss_": [279, 280], "mainli": 348, "maintain": [233, 281, 282, 352, 367, 368, 370, 371, 372, 374, 378, 381, 383], "major": 336, "make": [244, 256, 279, 280, 298, 334, 336, 340, 344, 347, 348, 350, 358, 360, 364, 367, 368, 371, 372, 373, 374, 377, 379, 380, 382, 383], "make_classif": 35, "make_friedman1": [8, 36], "male": 88, "manag": [0, 50, 334, 352, 375], "manhattan": 130, "mani": [130, 336, 343, 345, 358, 367, 368, 371, 372, 377, 381], "manifest": 335, "manifold": 358, "manner": [187, 375], "manual": [5, 117, 140, 141, 142, 146, 147, 182, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 337], "map": [59, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 379, 382], "map_rang": 57, "marco": 344, "margin": [57, 244, 279, 280, 341, 344, 348, 351, 364, 367, 368, 369, 370, 371, 372, 373, 380, 381], "mark": [229, 332, 336, 373], "market": 371, "markov": 339, "marku": 336, "marriag": [2, 3, 5, 26, 68, 88, 377, 383], "marriage_1": 2, "marriage_2": 2, "match": 359, "math": [369, 372], "mathbb": [343, 349, 367, 369, 371, 372, 373, 380, 381], "mathbf": [367, 368, 372], "mathcal": [371, 382], "mathemat": [339, 366, 380], "mathrm": [335, 339, 343, 347, 349, 369], "matplotlib": 40, "matric": [128, 379], "matrix": [66, 128, 216, 225, 231, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 336, 340, 345, 368, 373, 379], "max": [3, 5, 11, 57, 171, 279, 280, 284, 309, 336, 337, 363, 364, 367, 372, 373, 377, 379, 380, 382], "max_": [57, 381], "max_bin": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68, 117, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239], "max_cat_threshold": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "max_cat_to_onehot": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "max_delta_step": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "max_depth": [9, 16, 17, 22, 23, 24, 25, 26, 27, 35, 36, 39, 40, 41, 44, 46, 47, 50, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 215, 222, 229, 232, 238, 274, 277, 278, 280, 281, 282, 283, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 309, 326, 327, 328, 362, 365, 368, 369, 371, 374, 377, 378, 379, 380, 381, 382, 383, 387], "max_epoch": [18, 19, 24, 25, 279, 280, 296, 297, 367], "max_featur": [16, 17], "max_it": [15, 45], "max_iter_per_epoch": [279, 280], "max_leaf_nod": [16, 17], "max_leav": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "maxim": 386, "maximum": [112, 117, 126, 127, 215, 216, 219, 220, 221, 222, 223, 229, 230, 231, 232, 234, 235, 236, 237, 238, 239, 245, 254, 274, 277, 278, 280, 281, 282, 283, 284, 286, 288, 291, 292, 293, 295, 296, 297, 298, 300, 302, 304, 306, 334, 335, 336, 337, 340, 341, 355, 368, 371, 381, 382, 383], "maxopac": 57, "mb": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95, 391], "mbox": 373, "mc": [39, 41], "md": [336, 340], "mean": [3, 5, 11, 18, 19, 80, 81, 122, 131, 148, 171, 214, 220, 226, 227, 228, 236, 242, 243, 259, 261, 262, 279, 280, 308, 309, 310, 334, 336, 337, 340, 343, 344, 345, 348, 350, 351, 354, 355, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382], "mean_fit_tim": [46, 47], "meaning": [336, 379, 383], "measur": [128, 136, 188, 223, 234, 241, 242, 243, 245, 246, 326, 327, 335, 336, 338, 339, 340, 341, 343, 346, 350, 376, 377, 380, 382, 383], "mechan": 379, "medhousev": [367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 388], "median": [3, 5, 11, 148, 334, 336, 337, 354, 355, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "medic": [367, 372], "medinc": [32, 215, 217, 218, 226, 229, 231, 233, 234, 265], "medium": 377, "meet": [352, 360, 379], "mei": [336, 340], "mem": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95, 391], "member": [344, 351], "membership": [214, 220, 226, 227, 228, 229, 236, 371, 379], "memori": [54, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "mention": 336, "menu": 352, "mere": [344, 351], "met": 336, "meta": [157, 337], "metadata": 365, "metaheurist": 386, "metamodel": [217, 233], "method": [4, 5, 8, 11, 15, 17, 18, 19, 20, 21, 23, 25, 27, 39, 41, 45, 53, 54, 57, 59, 63, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 117, 119, 122, 123, 124, 126, 127, 128, 129, 130, 131, 136, 137, 148, 156, 171, 216, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 246, 253, 256, 259, 264, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 326, 327, 328, 329, 330, 332, 333, 334, 335, 338, 339, 341, 343, 344, 345, 349, 350, 351, 352, 354, 356, 358, 359, 360, 361, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 379, 380, 381, 382, 383, 386, 387], "methodologi": 343, "metric": [9, 35, 36, 39, 44, 45, 46, 47, 53, 59, 62, 63, 65, 68, 69, 70, 72, 73, 76, 77, 80, 81, 84, 85, 88, 94, 119, 130, 136, 188, 205, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 233, 234, 235, 236, 237, 238, 239, 265, 307, 308, 309, 310, 311, 329, 330, 332, 335, 336, 341, 343, 350, 352, 355, 359, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 381, 382, 383, 386, 391], "metric_nam": [213, 225], "mi": [369, 372, 379], "miami": [336, 340], "mid": [339, 367, 369, 372], "might": [336, 343, 345, 378, 379, 381], "mild": 378, "mimic": 381, "min": [3, 5, 11, 57, 130, 171, 279, 280, 309, 337, 363], "min_": 57, "min_child_sampl": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "min_child_weight": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "min_impurity_decreas": [16, 17, 24, 25, 281, 282, 283, 284], "min_samples_leaf": [16, 17, 24, 25, 281, 282, 283, 284], "min_samples_split": [16, 17], "min_split_gain": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "min_weight_fraction_leaf": [16, 17], "mind": 345, "mine": [336, 340, 344], "ming": [336, 340], "minim": [352, 362, 368, 371, 377, 378, 380], "minimum": [112, 136, 138, 281, 282, 283, 284, 334, 336, 337, 340, 355, 383], "minkowski": 130, "minmax": [5, 18, 19, 20, 21, 25, 59, 76, 80, 171, 334, 354, 373], "minmax_rang": 171, "minor": [377, 382], "minu": [129, 131], "minut": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "miscellan": 112, "misclassif": 379, "miscoverag": [215, 216, 229, 231, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 380], "misdiagnos": 377, "mislead": [377, 379], "misleadingli": 242, "mismatch": 335, "mispredict": 381, "miss": [3, 5, 9, 11, 22, 23, 39, 40, 41, 58, 66, 67, 68, 148, 337, 344, 351, 352, 354, 355, 379], "missing": [344, 351], "missing_valu": 148, "misspecif": 379, "misspecifi": 380, "mitig": [227, 228, 336, 339, 352, 376, 379, 381, 383], "mix": [3, 5, 11, 134, 188, 334, 339, 355], "mixtur": [13, 28, 49, 122, 253, 254, 255, 261, 263, 265, 290, 291, 324, 336, 339, 340, 352, 366, 378, 380, 381, 391], "mj": 368, "mk": 368, "ml": [31, 365], "mlflow": [0, 112, 121, 151, 166, 170, 210, 269, 334, 352, 355], "mlflow_hom": [50, 313, 314], "mlflowexcept": 121, "mlop": 352, "mlp_sample_s": [279, 280], "mlpregressor": 388, "mnth": [4, 8, 9, 10, 11, 54, 69, 73, 77, 337, 368, 369, 371, 372, 378, 379, 380, 381, 382], "mocatboostclassifi": [26, 50, 368], "mocatboostregressor": [27, 368], "mochart": [39, 41, 57, 112, 127, 315], "mocharts_plot": [39, 41], "moclassifi": [0, 33, 388], "mode": [68, 69, 76, 77, 84, 85, 88, 235, 236, 237, 238, 239, 244, 253, 279, 280, 330], "modecisiontreeclassifi": [16, 50, 374], "modecisiontreeclassifiermodecisiontreeclassifi": 16, "modecisiontreeregressor": [17, 374, 387], "modecisiontreeregressormodecisiontreeregressor": 17, "model": [0, 1, 2, 12, 28, 37, 43, 52, 53, 54, 57, 58, 59, 71, 75, 79, 80, 81, 83, 84, 87, 89, 91, 92, 98, 122, 123, 131, 138, 142, 201, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 271, 272, 315, 324, 330, 331, 332, 334, 335, 336, 339, 340, 343, 345, 346, 347, 349, 350, 352, 353, 354, 365, 367, 374, 376, 377, 383, 389, 391], "model1": [35, 36, 53, 54, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 383], "model2": [35, 36, 53, 54, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 383], "model_calibr": 39, "model_compar": [330, 332, 359], "model_dev": 391, "model_dtre": 374, "model_explain": [345, 346, 347, 348, 349, 350, 351], "model_fairness_compar": 331, "model_gami": 367, "model_gbdt": 368, "model_gblt": 369, "model_glm": 370, "model_glmt": 369, "model_lgbm": [377, 378, 379, 380, 381, 382, 383], "model_mo": 371, "model_nam": [213, 214, 215, 217, 218, 219, 220, 221, 222, 223], "model_neut": 372, "model_relunet": 373, "model_select": [32, 33, 34, 35, 36, 388], "model_test": 361, "model_train": 362, "model_tun": [44, 45, 46, 47, 59, 363], "model_tune_grid_search": 307, "model_tune_optuna": 308, "model_tune_pso": 309, "model_tune_random_search": 310, "model_valid": 391, "model_xgb": [377, 378, 379, 380, 381, 382, 383], "modelbas": 271, "modelnn": [24, 25], "modeltun": 375, "modeltunegridsearch": [0, 44, 386], "modeltuneoptuna": [0, 47], "modeltunepso": [0, 46, 386], "modeltunerandomsearch": [0, 45, 386], "modelzoo": [49, 51, 375, 387, 391], "modern": 371, "modeva": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 94, 112, 325, 326, 327, 328, 334, 338, 339, 340, 341, 343, 344, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 375, 376, 386, 387, 391], "modeva_arbitrary_classifi": [30, 31], "modeva_arbitrary_regressor": 388, "modeva_mlflow": [50, 313, 314], "modeva_sklearn_classifi": 50, "modeva_sklearn_regressor": 388, "modif": [380, 381, 382], "modifi": [182, 337, 362, 377], "modul": [2, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 296, 297, 324, 336, 337, 388], "moe": [13, 28, 49, 253, 254, 255, 261, 263, 265, 290, 291, 324, 352, 366, 378, 391], "moe_classif": 371, "moe_regress": 371, "moelasticnet": [15, 45, 370, 387], "moelasticnetmoelasticnet": [15, 45], "mogaminetclassifi": [20, 50, 367], "mogaminetclassifiermogaminetclassifi": 20, "mogaminetregressor": [21, 367], "mogaminetregressormogaminetregressor": 21, "moglmtreeboost": [24, 25], "moglmtreeboostclassifi": [24, 50, 292, 369], "moglmtreeboostclassifiermoglmtreeboostclassifi": 24, "moglmtreeboostregressor": [25, 292, 293, 369], "moglmtreeboostregressormoglmtreeboostregressor": 25, "moglmtreeclassifi": 369, "moglmtreeregressor": 369, "mogradientboostingclassifi": [26, 50], "mogradientboostingregressor": 27, "molgbmclassifi": [24, 26, 44, 46, 47, 50, 59, 62, 66, 68, 72, 76, 80, 84, 88, 92, 214, 368, 377, 383], "molgbmclassifiermolgbmclassifi": [24, 26, 44, 46, 47, 62, 66, 68, 72, 76, 80, 84, 88, 92], "molgbmregressor": [25, 27, 53, 54, 63, 67, 69, 73, 77, 81, 85, 91, 217, 218, 368, 378, 379, 380, 381, 382], "molgbmregressormolgbmregressor": [25, 27, 53, 54, 63, 67, 69, 73, 77, 81, 85, 91], "mologisticregress": [14, 50, 370], "moment": [339, 344, 351], "momentchi2": 112, "momoeclassifi": [22, 371], "momoeclassifiermomoeclassifi": 22, "momoeregressor": [23, 371], "momoeregressormomoeregressor": 23, "moneuraltre": [24, 25], "moneuraltreeclassifi": [24, 50, 372], "moneuraltreeclassifiermoneuraltreeclassifi": 24, "moneuraltreeregressor": [25, 372], "moneuraltreeregressormoneuraltreeregressor": 25, "monitor": [352, 362, 365, 377, 378, 382], "mono_decreasing_list": [25, 279, 280, 292, 293, 367, 372], "mono_increasing_list": [24, 25, 279, 280, 292, 293, 367, 372], "mono_sample_s": [24, 25, 279, 280, 292, 293, 367, 372], "monoton": [128, 136, 279, 280, 292, 293, 328, 338, 343, 349, 366, 373, 378, 382], "monotone_constraint": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "monotonically_increasing_id": 31, "mont": 308, "morandomforestclassifi": [26, 50], "morandomforestregressor": [27, 387], "more": [128, 130, 136, 138, 148, 216, 231, 245, 309, 310, 328, 330, 331, 332, 335, 336, 338, 341, 343, 347, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 386], "moregressor": [0, 34, 388], "moreludnn": [13, 28, 49, 257, 258, 259, 260, 262, 373, 391], "moreludnnclassifi": [18, 50, 367, 373], "moreludnnclassifiermoreludnnclassifi": 18, "moreludnnregressor": [19, 373], "moreludnnregressormoreludnnregressor": 19, "moreov": [339, 343, 344, 345, 351], "mortgag": [334, 355, 356, 357, 359, 361], "moscoredclassifi": [0, 35, 388], "moscoredregressor": [0, 9, 36, 388], "mosklearnclassifi": [0, 388], "mosklearnregressor": [0, 32, 388], "most": [148, 228, 233, 235, 236, 237, 238, 239, 279, 280, 281, 282, 339, 344, 347, 348, 350, 351, 354, 355, 358, 361, 373, 374, 379, 381, 382], "most_frequ": [5, 148, 334], "motiv": 371, "mous": 357, "mousemov": 57, "move": [343, 345], "moxgbclassifi": [26, 35, 39, 40, 50, 58, 66, 68, 72, 76, 80, 84, 88, 326, 328, 368, 377, 383], "moxgbclassifiermoxgbclassifi": [39, 40, 58, 66, 68], "moxgbregressor": [9, 23, 27, 36, 41, 53, 67, 69, 73, 77, 81, 85, 327, 368, 378, 379, 380, 381, 382, 387], "moxgbregressormoxgbregressor": [9, 41, 67], "mse": [9, 15, 17, 19, 21, 23, 25, 27, 32, 36, 45, 53, 63, 67, 81, 85, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 259, 265, 307, 308, 309, 310, 332, 343, 350, 359, 361, 362, 363, 364, 379, 381, 382, 386, 387], "mse_rank": 45, "mth": 372, "mu": [367, 368, 370], "mu_": 378, "mu_j": 371, "much": [232, 242, 332, 344, 345, 347, 351], "mulit": [217, 219, 221, 222, 223], "multi": [54, 296, 297], "multi_strategi": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "multidimension": 357, "multipl": [50, 58, 76, 77, 80, 81, 84, 85, 88, 98, 148, 213, 214, 215, 217, 218, 219, 221, 222, 235, 236, 237, 238, 239, 252, 290, 291, 307, 315, 329, 334, 336, 338, 340, 351, 358, 359, 363, 368, 371, 379, 380, 382, 387], "multipli": [216, 231, 234, 336, 340, 344, 382], "multivari": [324, 336, 338, 343, 349, 352, 353], "must": [119, 124, 148, 215, 222, 225, 229, 242, 244, 308, 310, 337, 345, 348, 368], "mutual": [336, 340, 368], "mz": [50, 386, 387], "mz_new": 50, "n": [95, 335, 339, 343, 345, 346, 349, 351, 369, 371, 378, 379, 380, 381, 382], "n_": [343, 345, 373, 377], "n_bar": [26, 27, 58, 91, 315, 371], "n_class": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305], "n_cluster": [62, 63, 80, 81, 122, 216, 217, 231, 233, 290, 291, 309, 371, 379, 380, 381, 382], "n_compon": [3, 129, 130, 358], "n_epoch_no_chang": [24, 25, 281, 282, 296, 297], "n_estim": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 123, 219, 220, 221, 222, 223, 232, 235, 236, 237, 238, 239, 281, 282, 309, 363, 365, 368, 369, 371, 372, 377, 378, 379, 380, 381, 382, 383, 386], "n_featur": [35, 36, 130, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "n_feature_search": [24, 25, 281, 282, 283, 284], "n_features_in_": [281, 282], "n_forward": 137, "n_forward_phas": 339, "n_fourier": 137, "n_fourier2": 137, "n_i": 381, "n_interactions_": [279, 280], "n_iter": [45, 46, 308, 309, 310, 386], "n_j": 381, "n_job": [9, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 296, 297, 307, 308, 309, 310], "n_l": 373, "n_miss": 337, "n_neighbor": [130, 358], "n_other": 337, "n_output": [273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 299, 300, 303, 304], "n_particl": [46, 309], "n_quantil": 171, "n_redund": 35, "n_repeat": [91, 138, 216, 218, 223, 231, 234, 239, 245, 350], "n_sampl": [35, 36, 130, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "n_screen_grid": [24, 25, 281, 282, 283, 284], "n_split_grid": [24, 25, 281, 282, 283, 284], "n_uniqu": 337, "na": [5, 11, 148], "nabla": 378, "nair": 369, "name": [2, 3, 5, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 147, 148, 151, 152, 157, 161, 162, 164, 166, 169, 171, 172, 173, 174, 175, 176, 178, 180, 181, 182, 187, 188, 189, 201, 203, 204, 206, 207, 208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 315, 326, 327, 328, 330, 332, 334, 335, 336, 337, 339, 340, 345, 347, 349, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388], "name1": [7, 119, 311], "name2": [7, 119, 311], "name_": 57, "name_list": 315, "namegap": 57, "nameloc": 57, "nametextstyl": 57, "nan": [3, 5, 9, 11, 18, 19, 22, 23, 35, 39, 40, 41, 58, 66, 67, 68, 72, 73, 76, 77, 84, 85, 88, 91, 148, 307, 308, 309, 310, 377], "natur": [171, 367, 371, 372, 379], "nbviewer": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "ndarrai": [119, 140, 141, 142, 146, 147, 154, 155, 177, 178, 180, 184, 185, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "ne": [367, 368], "nearest": 340, "necessari": [258, 326, 327, 328, 358, 371], "need": [5, 47, 324, 332, 336, 337, 339, 344, 345, 347, 349, 351, 352, 371, 379, 381, 385, 388], "neg": [128, 136, 338, 343, 345, 350, 367, 368, 370, 371, 372, 377, 378, 379], "neglig": [348, 378], "neighbor": [130, 340, 358], "neighborhood": 378, "neither": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "nest": [213, 214, 221, 222, 223, 226, 227, 228, 231, 233, 234, 236, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "net": [279, 280, 324, 352, 366, 369, 371, 372], "net_": [279, 280, 292, 293, 296, 297], "network": [279, 280, 290, 291, 292, 293, 296, 297, 324, 352, 366, 367, 372, 382, 386], "neural": [292, 293, 296, 297, 324, 336, 344, 352, 366, 367, 382, 386], "neural_network": 388, "neuraltre": [50, 372], "neuron": [296, 297, 373], "new": [122, 123, 124, 128, 131, 136, 171, 180, 201, 292, 293, 335, 336, 338, 340, 355, 365, 368, 378, 380, 381, 382, 388], "new_d": [9, 388], "next": [9, 343, 350, 354, 363], "nich": 381, "nicola": 336, "nighttim": 349, "nllm": 258, "nm": 335, "nn": [296, 297], "nn_batch_siz": [292, 293], "nn_lr": [292, 293], "nn_max_epoch": [24, 25, 50, 292, 293], "nn_n_epoch_no_chang": [292, 293], "nn_temperatur": [24, 25, 50, 292, 293], "nnede": [367, 372], "no_progress": 30, "node": [256, 264, 281, 282, 283, 284, 336, 340, 344, 351, 368, 369, 373, 374, 382], "noic": 352, "nois": [36, 84, 216, 218, 231, 234, 330, 332, 344, 348, 352, 359, 361, 368, 378, 383], "noise_level": [59, 84, 85, 216, 218, 223, 231, 234, 239, 311, 382], "noisi": [378, 379, 380, 382, 383], "nomin": 380, "non": [8, 76, 77, 122, 123, 124, 128, 136, 137, 223, 234, 239, 281, 282, 328, 336, 338, 339, 349, 355, 369, 371, 379, 382, 388], "nonconform": 229, "none": [3, 4, 6, 9, 15, 16, 17, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 45, 46, 47, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 117, 119, 125, 126, 127, 128, 129, 130, 131, 140, 146, 148, 151, 157, 166, 171, 172, 174, 187, 201, 205, 207, 208, 210, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 252, 253, 254, 258, 260, 265, 267, 268, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 314, 315, 378, 382], "nonlinear": [128, 136, 338, 358, 373, 378, 379, 380, 381], "noplot_3_h2o": [30, 37, 391], "noplot_4_spark": [31, 37, 391], "nor": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "norm": 377, "normal": [57, 122, 123, 124, 138, 216, 218, 223, 231, 232, 234, 239, 279, 280, 330, 332, 336, 339, 340, 344, 351, 354, 359, 361, 367, 368, 369, 370, 371, 372, 373, 379], "notabl": 331, "note": [5, 9, 35, 36, 57, 58, 117, 216, 219, 220, 221, 222, 223, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 241, 243, 244, 246, 253, 278, 279, 280, 289, 308, 309, 315, 330, 331, 332, 335, 336, 339, 340, 341, 343, 344, 345, 348, 349, 350, 351], "notebook": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112, 352], "notic": 336, "notin": 380, "novel": [336, 340], "now": [348, 385], "np": [7, 9, 31, 32, 33, 34, 35, 36, 40, 41, 119, 140, 141, 142, 146, 147, 148, 177, 178, 180, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 386, 388], "nuanc": [369, 371, 377], "null": 339, "nullabl": 148, "num": 364, "num_leav": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "num_parallel_tre": [9, 22, 23, 39, 40, 41, 58, 66, 67, 68], "number": [54, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 137, 138, 159, 171, 187, 216, 217, 218, 219, 220, 221, 222, 223, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 244, 245, 246, 254, 258, 265, 279, 280, 281, 282, 283, 284, 290, 291, 292, 293, 296, 297, 307, 308, 309, 310, 315, 328, 330, 332, 334, 335, 336, 337, 339, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 354, 355, 358, 368, 371, 373, 378, 379, 380, 381, 382, 383, 386], "numer": [2, 3, 5, 11, 20, 21, 24, 26, 27, 68, 69, 116, 117, 125, 126, 127, 128, 129, 130, 131, 135, 136, 148, 171, 173, 188, 214, 216, 219, 220, 221, 222, 223, 226, 227, 228, 231, 234, 235, 236, 237, 238, 239, 241, 244, 246, 253, 254, 278, 279, 280, 289, 307, 308, 309, 310, 330, 332, 338, 339, 343, 345, 349, 354, 356, 357, 358, 363, 365, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382, 383], "numpi": [7, 9, 31, 32, 33, 34, 35, 36, 40, 41, 112, 154, 155, 184, 185, 275, 298, 385, 388], "o7": 111, "object": [9, 24, 25, 26, 27, 35, 36, 39, 40, 41, 44, 46, 47, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 201, 202, 204, 211, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 226, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 248, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 264, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 362, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "observ": [328, 331, 335, 336, 340, 347, 349, 379, 381], "obtain": [76, 216, 231, 332, 336, 337, 339, 340, 343, 344, 349, 351, 371, 372, 373], "occur": [148, 242, 307, 308, 309, 310, 377, 379, 382], "occurr": 148, "ocsvm": 336, "od_marginal_outlier_distribut": 336, "od_score_distribut": 336, "od_tsne_comparison": 336, "odd": [343, 345, 346, 347, 349, 377], "off": [246, 308, 309, 310, 344, 351, 373], "offer": [331, 332, 337, 338, 343, 344, 345, 351, 352, 355, 362, 367, 368, 379, 380, 381, 383], "often": [367, 368, 371, 372, 373, 377, 379, 383, 386, 388], "old": [112, 201], "omega": [367, 371], "onc": [117, 345, 362, 373], "one": [73, 76, 77, 119, 128, 129, 131, 136, 148, 171, 213, 214, 215, 216, 220, 225, 226, 227, 228, 231, 232, 235, 236, 237, 238, 239, 241, 244, 253, 265, 278, 289, 307, 308, 309, 310, 315, 332, 334, 335, 336, 337, 338, 339, 340, 343, 345, 347, 349, 350, 356, 362, 367, 371, 373, 377, 381], "oneclasssvm": 336, "onehot": [5, 129, 130, 131, 334, 354], "ones": [137, 235, 339, 343, 349, 367, 368], "ongo": 352, "onli": [57, 117, 119, 124, 126, 127, 132, 133, 134, 135, 139, 140, 142, 146, 148, 159, 189, 199, 200, 215, 216, 218, 219, 220, 221, 222, 223, 229, 231, 235, 236, 237, 238, 239, 249, 250, 252, 274, 277, 278, 279, 280, 282, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 308, 309, 315, 332, 336, 340, 343, 348, 350, 351, 354, 355, 356, 359, 360, 365, 367, 368, 371, 373, 377, 379, 380, 385, 386, 388], "ood": 381, "oot": [88, 120, 180], "op": 112, "open": [334, 354, 362], "oper": [1, 12, 129, 292, 293, 324, 333, 352, 354, 355, 367, 372, 373, 374, 377, 379, 391], "operatio": 334, "opportun": 377, "optim": [43, 48, 49, 111, 279, 280, 292, 293, 296, 297, 307, 308, 309, 310, 336, 352, 358, 362, 363, 368, 371, 372, 374, 375, 378, 383, 391], "optimisticbia": 378, "option": [9, 39, 41, 57, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 187, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 252, 253, 254, 255, 256, 257, 258, 261, 262, 263, 264, 265, 272, 275, 278, 289, 296, 297, 298, 299, 300, 307, 308, 309, 310, 315, 330, 335, 336, 337, 338, 340, 341, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 356, 357, 358, 362, 363, 364, 365, 367, 368, 369, 370, 372, 373, 386], "optuna": [43, 48, 49, 308, 391], "order": [57, 126, 128, 136, 205, 336, 338, 339, 345, 356, 368, 373], "order_bi": [50, 205, 387], "ordin": [11, 59, 128, 129, 130, 131, 136, 334, 338, 354, 377, 383], "org": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "orient": 57, "origin": [9, 229, 261, 262, 279, 280, 336, 340, 341, 343, 344, 345, 348, 349, 350, 351, 354, 378, 380, 381, 382], "original_scal": 349, "orthogon": [367, 368], "other": [128, 130, 136, 140, 141, 142, 146, 147, 226, 232, 233, 236, 244, 331, 335, 336, 337, 338, 340, 343, 344, 345, 347, 349, 351, 352, 355, 356, 362, 375, 377, 380, 381, 387], "otherwis": [150, 194, 241, 242, 244, 246, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 330, 332, 336, 337, 344, 345, 346, 347, 348, 349, 350, 351, 365, 378, 380, 381], "our": [344, 347, 348, 350, 380], "out": [120, 180, 227, 244, 265, 279, 280, 380, 381], "outcom": [220, 244, 336, 359, 377, 379, 382], "outer": [80, 81, 217, 233, 359, 361, 381], "outlier": [0, 1, 12, 122, 123, 124, 128, 136, 217, 233, 324, 332, 333, 338, 352, 356, 378, 379, 383, 391], "outlier_detect": 336, "outliers_sample_index": 8, "outlin": [336, 382], "outpupt": 387, "output": [33, 34, 59, 117, 119, 131, 148, 171, 231, 241, 242, 244, 253, 275, 279, 280, 290, 298, 328, 336, 343, 344, 345, 347, 348, 349, 351, 352, 355, 359, 361, 367, 368, 369, 370, 371, 372, 373, 374, 380, 388], "outputcol": 31, "outsid": [231, 233, 284, 332, 343, 345, 349, 380], "over": [235, 236, 237, 238, 239, 244, 335, 337, 343, 345, 351, 356, 357, 363, 369, 371, 380, 381], "overal": [188, 331, 334, 336, 339, 340, 345, 367, 368, 370, 371, 372, 377, 378, 379, 380, 381, 382], "overcom": [343, 345], "overconfid": 380, "overfit": [9, 35, 36, 74, 98, 221, 225, 237, 324, 328, 329, 339, 352, 364, 368, 370, 373, 376, 377, 379, 382, 391], "overflow": [57, 336], "overhead": 54, "overli": [377, 382, 383], "overrid": [2, 9, 166, 334, 365], "overridden": [172, 174], "overview": [336, 337], "overwrit": 117, "own": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98], "p": [41, 59, 137, 330, 335, 336, 341, 343, 344, 346, 349, 351, 377, 378, 379, 380, 381, 382], "p_": 371, "p_i": [335, 341, 379, 381], "p_j": 371, "p_k": 371, "p_valu": 339, "packag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112, 308, 343, 344, 345, 347, 348, 349, 351, 373], "pad": 57, "page": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 336], "pair": [76, 136, 171, 214, 217, 218, 219, 220, 221, 222, 223, 226, 227, 228, 236, 242, 265, 279, 280, 338, 339, 367, 369, 372, 378], "pairwis": [241, 244, 249, 253, 279, 280, 338, 345, 367, 369, 371, 372, 379], "pam": [62, 63, 216, 231, 379, 380, 382], "panda": [5, 10, 11, 31, 32, 33, 34, 35, 36, 54, 112, 128, 148, 154, 155, 194, 213, 219, 252, 334, 388], "panel": [337, 352, 353, 362], "paper": [128, 136, 338, 343, 345], "paragraph": [344, 351], "parallel": [44, 45, 46, 47, 257, 279, 280, 296, 297, 307, 308, 309, 310, 363, 368], "parallel_backend": [307, 308, 309, 310], "parallelaxi": 57, "param": [44, 45, 46, 47, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "param_bound": [46, 309], "param_distribut": [45, 47, 308, 310, 386], "param_grid": [44, 45, 307], "param_spac": 386, "param_typ": [46, 309], "paramet": [111, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 188, 194, 198, 201, 203, 204, 205, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 315, 332, 336, 337, 339, 341, 345, 347, 348, 349, 350, 351, 365, 367, 370, 371, 372, 374, 378, 386], "parametr": [137, 328, 336, 339], "parent": [59, 272, 365, 367, 368], "pariti": 377, "parsimoni": 367, "part": [335, 371, 378], "partial": [241, 242, 244, 281, 282, 284, 339, 342, 346, 352, 360, 367, 368, 372, 378], "partial_depend": [343, 349], "particl": [43, 48, 49, 309, 371, 391], "particular": [335, 344, 348, 351, 373], "particularli": [128, 136, 326, 327, 328, 335, 336, 338, 344, 351, 367, 368, 372, 380, 381], "partit": [117, 122, 123, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 188, 217, 218, 220, 227, 228, 253, 262, 283, 284, 336, 340, 343, 347, 349, 371], "partitionto": 230, "parzen": 308, "pass": [30, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 303, 304, 308, 370, 374], "past": 334, "path": [153, 156, 158, 170, 247, 264, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 313, 314, 315, 336, 340, 344, 351, 368, 369, 374], "path_or_buf": [156, 170], "patienc": [292, 293], "pattern": [128, 136, 230, 335, 336, 338, 340, 347, 356, 358, 367, 368, 369, 371, 373, 379, 380, 381, 382, 383], "pay_1": [2, 3, 5, 7, 14, 18, 20, 22, 24, 26, 50, 62, 68, 72, 76, 80, 84, 88, 214, 311, 330, 373, 377, 383], "pay_1_special_sv2": 5, "pay_2": [2, 3, 5, 14, 20, 26, 68, 72, 76, 84], "pay_3": [2, 3, 5, 14, 26, 68, 72, 84, 373], "pay_4": [2, 3, 5, 26, 68, 84, 88], "pay_5": [2, 3, 5, 26, 68, 72, 76], "pay_6": [2, 3, 5, 26, 68, 72, 76, 84, 88], "pay_amt1": [2, 3, 5, 26, 68, 88, 373, 383], "pay_amt2": [2, 3, 5, 26, 68], "pay_amt3": [2, 3, 5, 26, 68], "pay_amt4": [2, 3, 5, 26, 68], "pay_amt5": [2, 3, 5, 26, 68], "pay_amt6": [2, 3, 5, 26, 68], "pc1": 358, "pc2": 358, "pc3": 358, "pca": [124, 129, 217, 233, 333, 336], "pd": [5, 11, 31, 32, 33, 34, 35, 36, 54, 57, 118, 148, 149, 151, 153, 165, 177, 178, 180, 198, 234, 235, 237, 244, 266, 315, 334, 343, 349, 388], "pd_": [343, 346], "pdf": 351, "pdp": [32, 53, 244, 342, 345, 346, 347, 351, 352, 360], "peak": 345, "pearson": [57, 128, 136, 338, 339], "penal": [367, 372, 373, 379], "penalti": [367, 372, 373, 378, 382], "per": [127, 138, 222, 231, 279, 280, 281, 282, 292, 293, 343, 345, 351, 360, 367, 368, 369, 370, 371, 372, 373], "percent": [380, 381, 382], "percentag": [179, 238, 334, 355], "percentil": [91, 242, 244, 334], "perfect": [128, 136, 335, 338, 377, 379], "perforamnc": [227, 228], "perform": [50, 54, 59, 62, 63, 70, 80, 81, 84, 85, 88, 98, 117, 122, 123, 124, 129, 130, 137, 148, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 227, 228, 231, 232, 233, 234, 235, 237, 238, 239, 265, 279, 280, 307, 308, 309, 310, 324, 331, 335, 336, 339, 340, 341, 343, 350, 352, 355, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 376, 378, 380, 381, 382, 383, 386, 387, 391], "performance_metr": [88, 227, 228, 377], "period": 347, "peripheri": 381, "perman": [339, 365], "permiss": 121, "permut": [33, 34, 138, 245, 339, 342, 352, 360], "permutation_import": [343, 350], "perorm": 381, "perp": 339, "perspect": 331, "perturb": [216, 218, 223, 231, 234, 239, 243, 330, 332, 344, 348, 352, 359, 361, 364, 376, 378, 383], "perturb_featur": [84, 85, 216, 218, 223, 231, 234, 239, 311, 330, 332, 382], "perturb_method": [59, 84, 85, 216, 218, 223, 231, 234, 239, 330, 332, 382], "perturb_s": [330, 332, 382], "perturbaion": 382, "peter": 339, "pfi": [58, 245, 342, 352, 360], "pfi_result": 58, "phase": [339, 354, 382], "phenomenon": [335, 336], "phi_": [344, 351], "phi_0": [344, 351], "phi_j": [344, 351], "pi": 41, "pi_i": 380, "pi_width": [62, 63, 216, 231, 380], "pick": [359, 360, 361, 364], "pilla": 339, "piml": [330, 332, 335, 336, 337, 345, 346, 347, 348, 349, 350, 351, 385], "pinpoint": [336, 352, 379, 380, 381, 383], "pip": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112], "pipelin": [0, 56, 60, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 352, 388, 391], "pipeline1": [2, 59], "pisa": [336, 340], "pitkin": 347, "pizzuti": 336, "pkdd": 336, "pkl": 156, "place": [111, 351], "placehold": 148, "plai": [344, 351], "platt": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328, 336], "player": [344, 351], "pleas": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 336, 343, 345, 347, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374], "plot": [3, 4, 7, 8, 11, 16, 17, 20, 21, 22, 23, 24, 25, 32, 33, 34, 44, 45, 46, 47, 49, 50, 53, 54, 57, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 92, 119, 122, 123, 124, 125, 126, 127, 128, 129, 136, 137, 138, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 307, 308, 309, 310, 315, 330, 331, 332, 333, 335, 336, 342, 345, 346, 347, 348, 350, 352, 355, 356, 357, 358, 359, 360, 361, 363, 364, 369, 370, 374, 377, 378, 379, 380, 381, 382, 383], "plot_0_accuracy_table_cl": [66, 70, 391], "plot_0_accuracy_table_reg": [67, 70, 391], "plot_0_calibrate_proba": [39, 42, 391], "plot_0_data_oper": [2, 12, 391], "plot_0_demo": [53, 55, 391], "plot_0_diagnostics_d": [54, 55, 391], "plot_0_fairness_cl": [88, 89, 391], "plot_0_glm_cl": [14, 28, 391], "plot_0_glm_reg": [15, 28, 391], "plot_0_global_explain": [91, 93, 391], "plot_0_grid": [44, 48, 391], "plot_0_modelzoo": [50, 51, 391], "plot_0_reliability_cl": [76, 78, 391], "plot_0_residual_cl": [62, 64, 391], "plot_0_residual_reg": [63, 64, 391], "plot_0_resilience_cl": [80, 82, 391], "plot_0_robustness_cl": [84, 86, 391], "plot_0_sklearn": [32, 37, 391], "plot_0_slice_overfit_cl": [72, 74, 391], "plot_0_valres_attribut": [57, 60, 391], "plot_1_arbitrary_cl": [33, 37, 391], "plot_1_arbitrary_reg": [34, 37, 391], "plot_1_calibrate_interval_cl": [40, 42, 391], "plot_1_calibrate_interval_reg": [41, 42, 391], "plot_1_dt_cl": [16, 28, 391], "plot_1_dt_reg": [17, 28, 391], "plot_1_eda": [3, 12, 391], "plot_1_local_explain": [92, 93, 391], "plot_1_random": [45, 48, 391], "plot_1_reliability_reg": [77, 78, 391], "plot_1_resilience_reg": [81, 82, 391], "plot_1_robustness_reg": [85, 86, 391], "plot_1_slice_accuracy_cl": [68, 70, 391], "plot_1_slice_accuracy_reg": [69, 70, 391], "plot_1_slice_overfit_reg": [73, 74, 391], "plot_1_valres_sav": [58, 60, 391], "plot_2_feature_select": [4, 12, 391], "plot_2_pipelin": [59, 60, 391], "plot_2_pso": [46, 48, 391], "plot_2_reludnn_cl": [18, 28, 391], "plot_2_reludnn_reg": [19, 28, 391], "plot_2_scored_cl": [35, 37, 391], "plot_2_scored_reg": [36, 37, 391], "plot_3_feature_engin": [5, 12, 391], "plot_3_gaminet_cl": [20, 28, 391], "plot_3_gaminet_reg": [21, 28, 391], "plot_3_optuna": [47, 48, 391], "plot_4_moe_cl": [22, 28, 391], "plot_4_moe_reg": [23, 28, 391], "plot_4_subsampl": [6, 12, 391], "plot_5_drift_test": [7, 12, 391], "plot_5_lineartree_cl": [24, 28, 391], "plot_5_lineartree_reg": [25, 28, 391], "plot_6_const_tree_cl": [26, 28, 391], "plot_6_const_tree_reg": [27, 28, 391], "plot_6_outlier_detect": [8, 12, 391], "plot_7_data_with_predict": [9, 12, 391], "plot_8_extra_data": [10, 12, 391], "plot_9_date_vari": [11, 12, 391], "plot_sav": [58, 315], "plot_typ": [3, 125], "plt": 40, "plu": [171, 388], "png": [58, 111, 315], "point": [26, 54, 122, 127, 130, 187, 216, 228, 230, 231, 242, 244, 246, 253, 254, 279, 280, 281, 282, 283, 284, 335, 336, 340, 343, 345, 346, 347, 348, 349, 351, 356, 357, 358, 369, 371, 373, 378, 379, 380, 382, 383], "pointer": 57, "pointsiz": 57, "polynomi": [126, 336, 356], "poor": [373, 380, 381, 383], "poorest": 381, "poorli": [379, 380, 383], "popescu": [343, 346], "popul": [119, 235, 236, 237, 238, 239, 259, 335, 341, 348, 352, 367, 368, 369, 370, 372, 373, 381, 386], "popular": [374, 383, 388], "popup": [57, 315], "posit": [15, 45, 57, 128, 136, 153, 230, 241, 242, 244, 246, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 338, 367, 370, 371, 372, 373, 377, 379], "possess": [344, 351], "possibl": [242, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 331, 344, 351, 379, 386], "post": [0, 90, 94, 339, 350, 352, 360], "poster": 336, "potenti": [137, 221, 225, 233, 237, 336, 339, 340, 364, 372, 377, 379, 381], "power": [127, 352, 364, 367, 368, 369, 372, 373, 377], "pp": [336, 339, 340], "pr": [214, 226, 227, 228, 236], "practic": [331, 344, 351, 372, 373, 377, 379], "practition": [367, 372, 377, 378, 379, 383], "prasanta": 339, "pre": [219, 221, 222, 223, 227, 235, 236, 238, 239, 290, 291, 292, 293, 339, 344, 351, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "prebin": 227, "precis": [57, 66, 214, 225, 226, 227, 228, 336, 340, 377, 379, 382], "precision_recal": [58, 66, 225], "precomput": [15, 45, 54, 68, 69, 117, 219, 220, 221, 222, 223, 227, 232, 235, 236, 237, 238, 239, 334, 383], "pred": [378, 382], "pred_xgb1": 36, "pred_xgb2": 36, "predecessor": 368, "predefin": [119, 225, 237, 339, 363, 386], "predict": [1, 12, 30, 31, 34, 38, 42, 49, 50, 65, 84, 85, 88, 94, 161, 162, 175, 176, 213, 214, 215, 216, 217, 220, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 238, 241, 242, 243, 244, 245, 246, 253, 255, 257, 262, 264, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 325, 330, 332, 336, 339, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 359, 360, 361, 364, 370, 374, 375, 376, 377, 378, 379, 381, 382, 383, 387, 388, 391], "predict_func": [30, 31, 34, 388], "predict_funct": [30, 31, 34, 298, 388], "predict_interv": [40, 41, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327], "predict_last_hidden_lay": [18, 19], "predict_proba": [33, 35, 39, 50, 241, 242, 244, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328, 344, 345, 346, 347, 348, 349, 388], "predict_proba_func": [30, 31, 33, 388], "predict_proba_funct": [30, 31, 33, 275, 388], "prediction1": 36, "prediction2": 36, "prediction_nam": [9, 36, 302], "prediction_proba": 301, "prediction_proba_nam": [35, 301, 302], "predictor": [232, 331, 343, 347, 348, 349, 350, 370, 371, 380], "prefer": [119, 125, 213, 214, 215, 216, 220, 225, 226, 227, 228, 231, 232, 235, 236, 237, 238, 239, 241, 244, 253, 265, 307, 308, 309, 310], "prefix": 315, "prepar": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 57, 58, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 325, 333, 336, 350, 354], "preprint": [339, 344, 351, 367, 368, 369, 373, 382], "preprocess": [0, 11, 17, 18, 19, 20, 21, 23, 25, 27, 41, 45, 59, 63, 67, 69, 73, 76, 77, 80, 81, 85, 91, 115, 116, 117, 118, 123, 129, 130, 140, 142, 146, 149, 156, 167, 168, 170, 191, 193, 194, 195, 196, 198, 199, 200, 278, 280, 289, 330, 333, 340, 354, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "preprocessor": 145, "presenc": 336, "present": [330, 331, 332, 337, 344, 351, 371, 381], "preserv": [358, 367, 368, 370, 372, 374, 382], "preval": 336, "prevent": [336, 370, 377], "preview": 365, "previou": [59, 117, 167, 332, 345, 347, 368, 388], "price": [367, 372, 377], "prime": [344, 351], "princip": [124, 129, 338, 340], "principl": 336, "print": [41, 50, 57, 281, 282, 292, 293, 296, 297, 377], "priorit": [378, 381], "privileg": 377, "proba": [88, 325], "proba1": 35, "proba2": 35, "proba_cutoff": [88, 228, 377], "proba_xgb1": 35, "proba_xgb2": 35, "probabilist": [214, 220, 226, 227, 228, 236, 371], "probabl": [30, 31, 162, 176, 214, 220, 226, 227, 228, 230, 236, 241, 242, 244, 246, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 324, 325, 326, 330, 335, 343, 345, 346, 347, 349, 351, 370, 371, 373, 377, 379, 380, 381, 382], "problem": [68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 330, 332, 344, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "problemat": [217, 233, 344, 351], "proceed": [336, 344], "process": [1, 12, 59, 117, 130, 131, 137, 148, 171, 243, 245, 260, 296, 297, 308, 315, 324, 332, 334, 336, 339, 340, 344, 348, 349, 353, 359, 360, 361, 362, 363, 364, 365, 367, 369, 373, 377, 378, 383, 386, 387, 391], "processor": [307, 308, 309, 310], "prod_j": 368, "produc": [130, 347, 371, 379, 380], "product": [352, 367, 372, 383], "profil": 258, "program": [5, 9, 10, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 59, 88], "programmat": 313, "progress": [57, 212, 281, 282, 292, 293, 296, 297, 362, 363, 381], "progressivethreshold": 57, "project": [358, 365], "promot": [378, 382], "proper": [352, 378, 379, 380], "properti": [0, 115, 116, 118, 132, 133, 134, 135, 139, 159, 160, 161, 162, 164, 165, 168, 169, 186, 189, 190, 191, 192, 193, 195, 196, 197, 199, 200, 202, 209, 335, 344, 351, 368, 378, 382], "proport": [76, 77, 122, 187, 215, 222, 229, 234, 281, 282, 292, 293, 296, 297, 330, 332, 335, 341, 354, 356, 357, 358, 361, 379, 381], "propos": [336, 340], "propto": 378, "prostat": 30, "protect": [0, 88, 120, 146, 177, 178, 214, 220, 226, 227, 228, 236, 331, 365, 377], "protected_data": 88, "prototyp": 362, "provid": [57, 123, 125, 127, 128, 136, 157, 187, 188, 214, 215, 223, 226, 238, 243, 246, 253, 254, 256, 262, 273, 274, 275, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 315, 325, 326, 327, 331, 334, 335, 336, 337, 338, 340, 341, 343, 344, 347, 349, 350, 351, 352, 355, 358, 360, 361, 362, 364, 365, 367, 368, 369, 370, 371, 372, 374, 375, 377, 378, 379, 380, 381, 382, 383, 385, 388], "proxim": [216, 231, 344, 348, 379, 380, 382], "prune": [279, 280, 367], "pseudo": [368, 388], "psi": [7, 22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 335, 341, 352, 361, 371, 378, 379, 380, 382, 383], "psi_bin": [22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 371, 378, 379, 380, 381, 382, 383], "psi_bucket": 335, "psi_method": [22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 371, 378, 379, 380, 381, 382, 383], "pso": [308, 309, 371, 386], "public": [30, 336], "purif": [369, 372], "purifi": 368, "purpos": [11, 222, 238, 334, 336, 345, 349, 351, 365, 385], "put": [344, 351], "py": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 89, 91, 92, 93, 330, 331, 332, 335, 336, 337, 345, 346, 347, 348, 349, 350, 351, 379, 385, 391], "pyal": [343, 345], "pylab": 40, "pyspark": [29, 37, 49, 388, 391], "pyswarm": 112, "python": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 112, 308, 343, 344, 345, 351, 373, 388], "pytorch": [292, 293], "q": [335, 341, 379, 380, 381, 382], "q1": [337, 355], "q2": 355, "q3": [337, 355], "q_": [378, 380, 381, 382], "q_1": 380, "q_i": [335, 341, 381], "q_k": 378, "q_l": 378, "qmc": [47, 308], "qmcsampler": 308, "qr": 380, "quad": 377, "qualiti": [308, 309, 310, 352, 355, 379, 382], "quantif": [352, 380], "quantifi": [242, 330, 335, 336, 340, 344, 351, 377, 379, 380, 381, 382], "quantil": [5, 53, 59, 68, 69, 72, 73, 84, 85, 117, 119, 122, 123, 124, 171, 215, 216, 218, 219, 220, 221, 222, 223, 227, 229, 231, 232, 234, 235, 236, 237, 238, 239, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 334, 335, 336, 341, 343, 345, 352, 354, 359, 361, 364, 377, 378, 379, 380], "quantiti": [367, 372], "quartil": [337, 354, 355], "quasi": 308, "queri": 379, "question": 0, "quicker": [343, 345], "quit": 345, "r": [369, 371, 372, 373, 377, 378, 379, 380, 381, 382], "r2": [9, 15, 17, 21, 23, 25, 27, 32, 36, 45, 67, 213, 216, 217, 218, 219, 220, 221, 223, 225, 227, 228, 231, 233, 234, 235, 237, 239, 265, 307, 308, 309, 310, 332, 363, 379, 386], "r_": [368, 378, 380, 381], "r_1": 371, "r_2": 371, "r_i": 380, "r_j": 378, "race": [59, 331, 334, 355, 377], "radar": 57, "radial": 336, "radio": [355, 356, 357], "rahul": 373, "rain": 345, "rais": [121, 241, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 377], "rajeev": 336, "ramani": 339, "ramaswami": 336, "ramaswamy2000": 336, "randint": [47, 386], "random": [43, 47, 48, 49, 122, 124, 125, 126, 127, 128, 129, 130, 136, 137, 138, 179, 187, 215, 216, 217, 218, 222, 223, 229, 230, 231, 233, 234, 238, 239, 241, 242, 243, 244, 245, 246, 254, 279, 280, 281, 282, 283, 284, 292, 293, 296, 297, 308, 309, 310, 336, 339, 340, 341, 343, 348, 350, 352, 354, 356, 357, 359, 363, 364, 368, 376, 379, 391], "random_st": [15, 16, 17, 20, 21, 24, 25, 26, 27, 32, 33, 34, 35, 36, 44, 45, 46, 47, 50, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 122, 124, 125, 126, 127, 128, 129, 130, 136, 137, 138, 179, 187, 215, 216, 217, 218, 222, 223, 229, 230, 231, 233, 234, 238, 239, 241, 242, 243, 244, 245, 246, 254, 279, 280, 281, 282, 283, 284, 292, 293, 296, 297, 308, 309, 310, 365, 380, 388], "randomforestclassifi": 294, "randomforestregressor": 295, "randomizedsearchcv": 386, "randomli": [127, 130, 187, 246, 332, 335, 336, 340, 341, 343, 344, 348, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386], "randomsampl": 308, "randomsplit": 31, "rang": [35, 36, 44, 45, 57, 128, 130, 136, 171, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 241, 244, 253, 281, 282, 283, 336, 338, 340, 343, 345, 348, 351, 352, 354, 363, 373, 380, 382, 383, 386], "range_": 57, "range_dai": 11, "rank": [128, 136, 217, 233, 330, 332, 338, 343, 350, 363, 378, 379, 380, 381, 382], "rapid": 362, "rare": 336, "rastogi": 336, "rate": [215, 216, 222, 229, 231, 279, 280, 281, 282, 292, 293, 367, 368, 372, 373, 377, 379, 380, 381, 386], "rather": [241, 348], "ratio": [30, 88, 128, 136, 214, 217, 226, 227, 228, 233, 279, 280, 331, 332, 339, 354, 361, 378], "rational": [336, 381], "ravel": [20, 21, 24, 25, 26, 27, 41, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 309, 367, 373], "raw": [39, 146, 147, 149, 154, 155, 163, 164, 165, 177, 180, 188, 194, 198, 273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328, 330, 332, 334, 352, 354, 367, 368, 369, 370, 372, 373], "raw_data": [194, 198, 377], "raw_extra_data": 10, "rbf": 386, "rcit": 137, "re": [334, 371, 388], "reach": [18, 19, 24, 25, 336, 345, 371], "read": 157, "read_csv": 153, "readi": [334, 388], "real": [361, 368, 371, 379, 381, 382], "realist": 382, "realtim": 57, "reason": 340, "recal": [66, 214, 225, 226, 227, 228, 377, 379, 382], "recalibr": [326, 327, 328], "receiv": [231, 371], "reclassifi": [355, 356, 357], "recogn": [344, 351, 374], "recognit": [336, 340], "recommend": [339, 373], "recomput": 371, "reconst_error": [8, 124], "reconstruct": [124, 336, 340], "record": [330, 332, 336, 343, 347, 350, 355, 365, 369], "recur": 383, "recurs": [283, 284, 336, 340, 343, 349, 368, 373, 374], "red": [336, 351], "reduc": [128, 130, 227, 228, 241, 336, 339, 340, 344, 345, 351, 356, 357, 358, 363, 367, 368, 369, 371, 372, 373, 377, 380, 381, 382], "reduct": [124, 130, 336, 338, 340, 344, 351, 358, 378, 379, 380], "redund": [137, 339], "refer": [88, 129, 131, 214, 220, 226, 227, 228, 236, 246, 281, 282, 331, 333, 335, 342, 345, 349, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 370, 371, 372, 377, 378, 379, 380, 381, 382, 383], "refin": [371, 372, 379, 380, 381, 382, 383], "refit": [307, 308, 309, 310, 380], "reflect": [328, 355, 382], "reg": [9, 41, 67], "reg_alpha": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "reg_clar": [279, 280], "reg_lambda": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 281, 282, 283, 284], "reg_mono": [24, 25, 279, 280, 292, 293, 367, 372], "regard": 337, "regardless": 383, "region": [221, 222, 223, 235, 237, 238, 239, 290, 291, 330, 332, 367, 368, 369, 371, 372, 373, 379, 380, 381, 382, 383], "regist": [9, 121, 140, 141, 142, 146, 147, 151, 157, 203, 207, 208, 224, 240, 267, 268, 272, 334, 355, 359, 360, 361, 364, 365, 375], "register_nam": [210, 269], "registered_model": 50, "registr": [333, 362, 365], "registri": [0, 324, 352, 353], "registry_hub": 365, "regress": [0, 13, 22, 28, 49, 61, 64, 65, 70, 71, 74, 75, 78, 79, 82, 83, 86, 94, 183, 190, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 243, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 324, 325, 328, 329, 334, 336, 343, 345, 346, 347, 348, 349, 350, 351, 352, 354, 359, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 380, 381, 382, 383, 386, 388, 391], "regressor": [29, 37, 38, 42, 49, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 326, 327, 368, 391], "regular": [232, 279, 280, 281, 282, 283, 284, 292, 293, 296, 297, 336, 367, 370, 372, 373, 378, 382], "regulatori": [352, 360, 377, 381], "rel": [332, 336, 339, 340, 367, 368, 369, 370, 372, 373], "relat": [142, 215, 217, 229, 236, 330, 332, 335, 339, 341, 347, 364], "relationship": [126, 127, 128, 136, 230, 232, 244, 257, 281, 282, 292, 293, 335, 336, 338, 339, 343, 345, 347, 349, 350, 351, 356, 357, 358, 367, 368, 369, 370, 372, 373, 378, 379, 383], "releas": 350, "relev": [226, 339, 345, 346, 347, 349, 371, 386], "reli": [245, 336, 337, 340, 378, 383], "reliability_coverag": 332, "reliability_perf": 330, "reliabl": [9, 35, 36, 78, 98, 215, 216, 217, 222, 229, 231, 238, 245, 324, 325, 326, 327, 329, 336, 343, 345, 352, 364, 367, 368, 372, 376, 378, 379, 381, 382, 383, 391], "relianc": [343, 350], "reload": 9, "reload_d": 9, "relu": [279, 280, 296, 297, 324, 352, 366], "relu_net": 373, "reludnn": [50, 296, 297, 345], "remain": [80, 81, 218, 234, 330, 332, 339, 344, 347, 348, 351, 369, 371, 380, 382], "remark": [368, 373], "remedi": [376, 377, 381], "remov": [8, 54, 137, 167, 336, 339, 343, 344, 350, 351, 365, 368, 373, 378, 382], "remove_outli": 336, "render": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 358, 372], "rendermod": 57, "rental": [332, 345, 346, 347, 348, 349, 350, 351], "repai": 377, "repaid": 377, "repeat": [84, 216, 218, 223, 231, 234, 245, 309, 336, 339, 340, 343, 348, 350, 368, 371], "repetit": [239, 350], "replac": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 131, 148, 201, 228, 344, 351, 365, 369, 372, 388], "report": [216, 231, 247, 352, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "repositori": [330, 332, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383, 387], "repres": [127, 187, 228, 296, 297, 326, 327, 328, 330, 331, 332, 335, 336, 338, 340, 343, 345, 346, 347, 348, 349, 351, 363, 365, 367, 368, 369, 371, 373, 374, 379, 381, 386], "represent": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 119, 243, 252, 254, 336, 340, 366, 368, 373, 377, 383], "reproduc": [122, 124, 125, 126, 128, 129, 130, 136, 137, 138, 187, 215, 216, 217, 218, 222, 223, 229, 230, 231, 233, 234, 238, 239, 241, 243, 244, 245, 246, 254, 281, 282, 283, 292, 293, 296, 297, 308, 309, 310, 352, 354, 359], "requir": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 131, 136, 281, 282, 283, 328, 330, 336, 337, 340, 343, 344, 345, 349, 351, 352, 360, 365, 373, 377, 380], "rerun": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "res_valu": [68, 69, 72, 73, 76, 77, 84, 85, 88, 311, 378, 382, 383], "research": 339, "resect": [335, 341], "resembl": 381, "reset": 365, "reset_calibrate_interv": [40, 41], "reset_calibrate_proba": 39, "reset_preprocess": [5, 11, 59, 334], "reshap": [35, 36, 309], "reshuffl": [279, 280], "residu": [9, 35, 36, 64, 66, 67, 68, 69, 98, 216, 229, 230, 231, 232, 235, 236, 238, 239, 274, 277, 278, 280, 281, 282, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 324, 352, 361, 364, 368, 369, 376, 378, 380, 382, 383, 391], "resili": [9, 35, 36, 82, 84, 85, 98, 217, 233, 324, 329, 352, 371, 376, 383, 391], "resilience_dist": [330, 332], "resilience_perf": [330, 332], "resilreli": 380, "resiz": [315, 356, 357], "resolut": 253, "respect": [138, 236, 279, 280, 335, 339, 341, 343, 346, 348, 351, 367, 368, 369, 371, 372, 373, 377, 380, 382], "respons": [18, 19, 216, 229, 231, 232, 259, 279, 296, 297, 330, 332, 335, 339, 343, 344, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "response_kwarg": [216, 231], "response_method": [91, 241, 242, 244, 345, 346, 347, 349], "response_typ": [62, 63, 216, 231, 379, 380, 382], "rest": [68, 69, 242, 336, 340, 343, 345, 347, 350, 371, 380, 382, 383], "restrict": 371, "result": [0, 3, 4, 5, 6, 7, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 44, 45, 46, 47, 50, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 119, 122, 123, 124, 125, 126, 127, 128, 129, 136, 137, 138, 187, 188, 205, 207, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 269, 272, 284, 307, 308, 309, 310, 311, 329, 330, 331, 332, 336, 339, 340, 343, 344, 345, 348, 349, 350, 351, 362, 363, 365, 367, 369, 370, 371, 372, 373, 374, 377, 378, 380, 381, 382, 383, 386], "result1": 59, "result2": 59, "retain": 137, "retrain": [367, 371], "retriev": [252, 258, 315, 378, 382, 383, 387], "return": [30, 31, 33, 34, 59, 111, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 157, 160, 165, 171, 180, 186, 187, 188, 194, 198, 202, 204, 206, 207, 208, 209, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 315, 334, 341, 344, 346, 351, 388], "return_data": [346, 348], "return_html": [39, 41], "reus": 334, "reveal": [330, 332, 336, 343, 350, 381, 383], "revert": 4, "reweight": 381, "rewritten": 368, "rf": [379, 387], "rf2": 50, "rf_max_depth": [62, 63, 216, 231, 379, 380, 382], "rf_n_estim": [62, 63, 216, 231, 379, 380, 382], "rgba": 57, "ribeiro": 344, "ribeiro2016": [344, 348], "rich": 352, "ridg": [232, 378, 382], "right": [57, 331, 336, 339, 343, 344, 346, 348, 351, 368, 369, 371, 372, 377, 378, 379], "right_inclus": 26, "rightarrow": 378, "rigor": 352, "risk": [326, 327, 367, 368, 372, 376, 377, 380, 383], "robsut": 382, "robust": [9, 35, 36, 80, 86, 88, 98, 128, 136, 171, 216, 218, 223, 231, 234, 239, 324, 329, 338, 352, 363, 364, 368, 369, 370, 371, 372, 374, 376, 379, 381, 383, 391], "robustness_perf": [330, 332], "robustness_perf_worst": [330, 332], "roc": [66, 225, 379], "roc_auc": [58, 66, 225], "role": [344, 351], "root": 330, "rotat": [57, 357], "rough": [279, 280, 284], "roughli": 373, "round": [4, 281, 282], "row": [2, 3, 5, 8, 9, 11, 18, 19, 31, 35, 36, 54, 68, 69, 72, 73, 76, 77, 84, 85, 88, 142, 253, 355, 362, 363, 364, 365, 373], "row_nam": 57, "royal": 343, "rr": [214, 226, 227, 228, 236], "rule": [343, 346, 374, 377], "run": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 50, 53, 54, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 111, 119, 122, 123, 124, 125, 126, 127, 128, 129, 136, 137, 138, 170, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 261, 262, 263, 264, 265, 268, 269, 272, 307, 308, 309, 310, 334, 338, 339, 354, 386], "run_id": [170, 210, 224, 240, 268, 269], "runtim": [308, 309, 310], "runz": 382, "rush": 345, "rv": 310, "s3": 30, "s_1": 367, "s_2": 367, "s_i": 380, "s_l": 336, "s_m": [368, 372], "s_r": 336, "said": 373, "same": [177, 178, 180, 201, 210, 243, 269, 332, 336, 340, 365, 373, 377, 379, 382, 383], "sameer": 344, "samesign": 57, "sampl": [0, 2, 3, 5, 7, 8, 11, 20, 21, 30, 41, 68, 69, 72, 73, 76, 77, 80, 81, 117, 119, 122, 123, 124, 125, 126, 127, 128, 130, 136, 140, 141, 142, 146, 168, 169, 171, 175, 176, 179, 181, 184, 185, 187, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 229, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 254, 258, 261, 262, 263, 264, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 310, 311, 328, 334, 335, 336, 337, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 356, 357, 358, 359, 360, 361, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 388], "sample_dataset": [219, 220, 221, 222, 223, 235, 236, 237, 238, 239], "sample_id": [219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 348, 351], "sample_idx": [6, 8, 187, 341], "sample_idx1": [7, 119, 311], "sample_idx2": [7, 119, 311], "sample_idx_by_llm": 258, "sample_index": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 62, 63, 92, 243, 246, 261, 262, 263, 264, 367, 368, 369, 370, 371, 372, 374, 379], "sample_method": [126, 127], "sample_s": [3, 6, 11, 57, 62, 63, 91, 125, 126, 127, 128, 129, 130, 187, 216, 230, 231, 241, 242, 244, 245, 254, 279, 280, 341, 345, 346, 347, 349, 351, 379, 380, 382], "sample_weight": [140, 142, 191, 195, 231, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305], "sampler": [47, 308], "sampler_arg": 308, "san": 57, "sarinnapakorn": [336, 340], "satisfi": [368, 377], "save": [57, 156, 170, 266, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315, 362], "save_data": [59, 272], "save_img": 57, "save_model": [59, 272], "save_preprocess": 156, "save_testsuit": [59, 272], "saveasimag": 57, "scalabl": [279, 280], "scale": [5, 130, 171, 216, 231, 234, 328, 332, 349, 352, 354, 363, 365, 367, 368, 369, 370, 371, 372, 374, 382], "scale_numer": [5, 15, 17, 18, 19, 20, 21, 23, 25, 27, 41, 45, 59, 63, 67, 69, 73, 76, 77, 80, 81, 85, 91, 334, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382], "scaler": 171, "scatter": [126, 127, 230, 324, 351, 353, 356, 358, 379], "scatterplot": 39, "scenario": [233, 330, 332, 336, 352, 379, 381, 382], "schema": 31, "scheme": [335, 336, 340, 341], "schoelkopf": 339, "sch\u00f6lkopf": 336, "sch\u00f6lkopf2001": 336, "scientist": 352, "scikit": [112, 275, 298, 299, 300, 336, 343, 347, 349, 350, 352, 370, 374, 386, 388], "scikitlearn": 388, "scipi": [47, 112, 308, 310, 335, 341, 386], "score": [2, 8, 9, 29, 37, 49, 54, 76, 77, 119, 122, 123, 124, 136, 138, 216, 217, 218, 226, 227, 228, 229, 231, 232, 233, 234, 239, 257, 258, 260, 261, 262, 265, 301, 302, 307, 308, 309, 310, 340, 343, 344, 345, 350, 351, 367, 368, 372, 375, 377, 379, 381, 382, 391], "scored_model1": [35, 36], "scored_model2": [35, 36], "scoredmodel_californiah": 388, "scott": [344, 351], "screen": [279, 280, 281, 282, 283, 284, 356, 357], "script": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 385], "scroll": [356, 357], "seamless": [352, 375], "search": [43, 48, 49, 281, 282, 284, 307, 308, 309, 310, 391], "season": [4, 8, 9, 10, 11, 15, 27, 53, 54, 57, 69, 73, 77, 85, 91, 349, 351, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "seciton": 375, "second": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 119, 279, 280, 330, 337, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "section": [0, 49, 98, 324, 330, 331, 332, 334, 335, 336, 337, 344, 345, 347, 351, 363, 373, 377, 378, 381, 382, 383], "see": [128, 136, 309, 310, 326, 327, 331, 332, 336, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 356, 357, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "seed": [30, 31, 122, 124, 125, 126, 127, 128, 129, 130, 136, 137, 138, 179, 187, 215, 216, 217, 218, 222, 223, 229, 230, 231, 233, 234, 238, 239, 241, 242, 243, 244, 245, 246, 254, 279, 280, 281, 282, 283, 292, 293, 296, 297, 308, 309, 310, 359], "seem": [350, 351], "segment": [9, 35, 36, 68, 69, 72, 73, 76, 77, 84, 85, 88, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 329, 352, 371, 380, 381, 383], "segment1": [68, 72, 73, 76, 84, 85], "segment2": [68, 72, 73, 76, 84, 85], "segment_info": [219, 220, 221, 222, 223, 235, 236, 237, 238, 239], "select": [0, 1, 12, 15, 31, 45, 119, 124, 131, 132, 133, 134, 135, 136, 137, 138, 139, 159, 168, 169, 171, 173, 189, 199, 200, 219, 221, 222, 223, 230, 233, 235, 236, 237, 238, 239, 241, 243, 244, 246, 253, 259, 261, 262, 263, 264, 279, 280, 284, 324, 330, 332, 333, 336, 340, 343, 345, 352, 365, 367, 369, 370, 371, 377, 378, 379, 380, 381, 382, 386, 391], "self": [182, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315], "sens": 348, "sensit": [128, 136, 234, 326, 327, 332, 336, 337, 338, 351, 358, 377, 379, 382, 383], "separ": [234, 235, 236, 237, 238, 239, 244, 253, 336, 337, 340, 367, 368, 379], "septemb": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "sequenc": [272, 368], "sequenti": [279, 280, 339, 368, 369], "seri": [57, 343], "seriesasc": 57, "serieslayoutbi": 57, "serif": 57, "serv": [315, 330, 336, 340, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 387], "session": 31, "set": [1, 2, 4, 7, 12, 20, 21, 30, 31, 54, 68, 69, 72, 73, 76, 77, 84, 85, 88, 117, 119, 124, 127, 130, 137, 148, 155, 163, 172, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 215, 216, 217, 219, 220, 221, 222, 223, 225, 229, 231, 235, 236, 237, 238, 239, 243, 245, 255, 257, 258, 259, 260, 261, 264, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 313, 314, 326, 327, 330, 332, 334, 335, 336, 337, 339, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 388, 391], "set_active_featur": [4, 334], "set_active_sampl": 341, "set_feature_typ": [368, 369, 371, 372, 378, 379, 380, 381, 382], "set_inactive_featur": [2, 9, 10, 11, 35, 36, 54, 59, 68, 334, 367, 368, 369, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "set_inactive_sampl": 8, "set_legend": 41, "set_mlflow_hom": [0, 50], "set_param": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "set_predict": 388, "set_protected_data": [88, 377], "set_protected_extra_data": 88, "set_random_split": [2, 4, 5, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 326, 327, 328, 334, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "set_raw_extra_data": [10, 88], "set_sample_weight": [2, 334], "set_target": [2, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 54, 59, 62, 63, 67, 68, 69, 88, 334, 370, 374, 377, 383, 388], "set_task_typ": [30, 59, 182], "set_test_idx": [9, 30, 31, 32, 33, 34, 35, 36, 388], "set_train_idx": [9, 30, 31, 32, 33, 34, 35, 36, 388], "set_xaxi": [39, 41], "set_yaxi": [39, 41], "setminu": [367, 369, 372], "setup": [367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "sever": [49, 341, 344, 351, 368, 377, 378, 379, 380, 381, 382, 383, 386], "sex": [2, 3, 5, 14, 26, 68, 88, 377, 383], "sex_2": [2, 5], "shade": 345, "shadowcolor": 57, "shallow": 371, "shap": [112, 246, 342, 352, 360, 368], "shap_": 351, "shap_fi": 351, "shap_scatt": 351, "shap_summari": 351, "shap_waterfal": 351, "shapblog": 351, "shape": [6, 8, 32, 33, 34, 35, 36, 41, 50, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 355, 367, 368, 388], "shaplei": [32, 246, 342, 352, 360], "share": [356, 357], "shaw": 336, "shengchun": [336, 340], "shift": [215, 216, 217, 231, 234, 326, 327, 328, 330, 332, 335, 352, 361, 371, 380, 381, 382, 383], "shiji": 382, "shim": 336, "short": 371, "shorter": [336, 340], "should": [33, 34, 130, 156, 177, 178, 180, 187, 228, 235, 236, 237, 238, 239, 252, 279, 280, 292, 293, 343, 344, 345, 346, 349, 350, 367, 368, 372, 377, 382, 388], "show": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 56, 57, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 119, 122, 123, 124, 125, 126, 127, 128, 129, 136, 137, 138, 205, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 261, 262, 263, 264, 265, 266, 307, 308, 309, 310, 315, 330, 332, 336, 338, 345, 346, 347, 348, 349, 350, 351, 359, 368, 370, 373, 374, 378, 379, 380, 381, 382, 385], "show_featur": 335, "showcas": 387, "showcont": 57, "showminlabel": 57, "shown": [252, 309, 330, 335, 345, 346, 351, 373, 377, 379], "showtitl": 57, "shrink": 373, "shrinkag": [281, 282], "shu": [336, 340], "shuffl": [11, 179, 187, 341, 343, 350], "shutdown": 30, "shyam": 339, "shyu": [336, 340], "shyu2003": [336, 340], "side": [338, 378, 381], "sigkdd": 344, "sigma": [339, 372, 373, 378, 382], "sigma_": [339, 378], "sigmod": 336, "sigmoid": [273, 275, 276, 279, 280, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 328, 372, 373], "signifi": 331, "signific": [128, 136, 137, 332, 338, 339, 343, 344, 350, 351, 361, 367, 368, 377, 380, 381], "significantli": [326, 327, 328, 332, 335, 336, 340, 345, 348, 377, 378], "silent": [39, 41, 50, 212], "similar": [219, 220, 221, 222, 223, 228, 235, 236, 237, 238, 239, 279, 280, 330, 335, 336, 343, 345, 347, 348, 351, 371, 377, 378, 379, 381, 382, 386], "similarli": [332, 336], "simpl": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 336, 345, 377, 379, 383], "simpler": 373, "simplest": 378, "simpli": 369, "simplif": [373, 377], "simplifi": [24, 25, 281, 282, 284, 352, 354, 365, 368, 373, 377, 387], "simucredit": [2, 44, 47, 59, 152, 210, 331, 334, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365], "simucredit_md": [354, 359, 360, 361, 362, 363, 364], "simul": [8, 344, 348, 351, 379, 381, 382], "simultan": [358, 367], "sinc": [331, 332], "singh": [344, 373], "singl": [57, 58, 72, 73, 76, 77, 80, 81, 84, 85, 88, 125, 216, 218, 231, 234, 235, 236, 237, 238, 239, 241, 243, 244, 252, 253, 261, 264, 315, 330, 332, 343, 345, 349, 351, 368, 373, 374, 378, 386], "site": 350, "size": [9, 35, 36, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 122, 125, 129, 171, 187, 216, 219, 220, 221, 222, 223, 230, 231, 235, 236, 237, 238, 239, 245, 265, 279, 280, 281, 282, 296, 297, 315, 330, 332, 335, 336, 340, 349, 359, 363, 365, 367, 368, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 386], "skew": [336, 378, 379, 383], "skip": [290, 291], "sklearn": [8, 29, 31, 33, 34, 35, 36, 37, 49, 276, 277, 278, 285, 286, 289, 294, 295, 334, 336, 340, 367, 368, 369, 370, 371, 372, 373, 374, 375, 378, 379, 380, 381, 382, 383, 385, 391], "skmlp": 388, "slice": [9, 35, 36, 53, 65, 70, 94, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 311, 330, 332, 345, 349, 352, 364, 376, 380, 382, 391], "slice_featur": [330, 332], "sliced_lin": [345, 349], "slicing_util": [0, 68, 69, 72, 73, 76, 77, 84, 85, 88, 378, 382, 383], "slight": [332, 382], "slightli": [330, 339, 367, 372], "slow": [358, 363], "slower": [344, 351], "small": [84, 85, 122, 234, 336, 340, 343, 344, 345, 351, 367, 369, 372, 373, 378, 381, 382], "smalldata": 30, "smaller": [129, 214, 220, 226, 227, 228, 236, 241, 279, 280, 367, 372, 373, 374, 383], "smallest": [148, 332], "smd": [214, 226, 227, 228, 236, 377], "smirnov": [119, 335, 341], "smola": 336, "smooth": [3, 126, 227, 292, 293, 367, 377, 378], "smoother": [253, 368], "smoother_ord": [3, 126], "sne": 336, "snippet": 347, "so": [5, 216, 231, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 332, 337, 339, 343, 344, 348, 350, 351], "soccer": [344, 351], "social": [377, 386], "societ": 377, "societi": 343, "soft": [371, 372], "softmax": 371, "sole": [337, 344, 351], "solid": [57, 352], "solut": [308, 309, 310, 380, 381], "some": [11, 279, 280, 330, 334, 336, 343, 349, 350, 367, 368, 369, 371, 372, 373, 377, 378, 379, 380, 381, 382], "sometim": 388, "sort": [336, 339, 381], "sound": [367, 372], "sourc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 194, 334], "space": [124, 130, 216, 231, 234, 242, 244, 279, 280, 283, 284, 290, 291, 336, 340, 363, 371, 378, 379, 380, 381, 382, 383, 386], "spap": 351, "spark": [31, 158], "spark_df": 31, "sparksess": 31, "spars": [124, 367, 368, 372, 380, 383], "sparse_pca": 124, "sparsiti": [124, 367, 370, 382], "spearman": [128, 136, 338], "speci": 334, "special": [5, 11, 148, 290, 291, 324, 334, 371, 373, 378, 380, 381], "special_valu": [5, 11, 148, 334], "specif": [62, 63, 84, 117, 171, 218, 219, 220, 221, 222, 223, 233, 235, 236, 237, 238, 239, 243, 246, 252, 258, 261, 262, 263, 264, 330, 331, 332, 335, 336, 337, 340, 341, 343, 344, 345, 347, 349, 350, 358, 359, 360, 361, 363, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "specifi": [57, 117, 119, 120, 122, 123, 125, 126, 127, 128, 129, 130, 131, 136, 138, 171, 187, 188, 213, 215, 217, 219, 220, 221, 222, 223, 225, 226, 227, 230, 235, 236, 237, 238, 239, 241, 244, 246, 253, 260, 261, 262, 281, 282, 296, 297, 307, 308, 309, 310, 315, 326, 330, 332, 337, 339, 341, 344, 345, 349, 350, 351, 363, 367, 372, 373, 379, 380, 382, 386], "spectral": 379, "speed": [241, 242, 244, 245, 246, 335, 345, 346, 347, 349, 351, 368], "speedup": [216, 231], "sphinx": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 52, 53, 54, 56, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 94], "sphx_glr__source_auto_galleries_val_0_residual_plot_1_residual_cl": 379, "sphx_glr__source_auto_galleries_val_0_residual_plot_1_residual_reg": 379, "sphx_glr_auto_examples_0_data_plot_1_data_summari": 337, "sphx_glr_auto_examples_0_data_plot_4_data_qu": [335, 336], "sphx_glr_auto_examples_1_train_plot_2_register_1_h2o": 385, "sphx_glr_auto_examples_2_explain_plot_0_pfi": 350, "sphx_glr_auto_examples_2_explain_plot_1_pdp": 349, "sphx_glr_auto_examples_2_explain_plot_1_pdp_hstat": 346, "sphx_glr_auto_examples_2_explain_plot_2_ic": 347, "sphx_glr_auto_examples_2_explain_plot_3_al": 345, "sphx_glr_auto_examples_2_explain_plot_4_lim": 348, "sphx_glr_auto_examples_2_explain_plot_5_shap": 351, "sphx_glr_auto_examples_2_explain_plot_6_data_dependent_explain": [345, 346, 347, 348, 349, 350, 351], "sphx_glr_auto_examples_5_compare_plot_0_compare_classif": 330, "sphx_glr_auto_examples_5_compare_plot_0_compare_regress": 332, "sphx_glr_auto_examples_5_compare_plot_1_compare_fair": 331, "split": [0, 2, 24, 25, 26, 27, 30, 31, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 138, 140, 141, 142, 143, 144, 146, 147, 150, 178, 179, 180, 187, 215, 216, 225, 229, 231, 238, 256, 274, 277, 278, 280, 281, 282, 283, 284, 286, 288, 290, 291, 293, 295, 297, 298, 300, 302, 304, 306, 307, 308, 309, 310, 334, 336, 340, 343, 345, 352, 355, 356, 357, 358, 359, 360, 361, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383], "split_conform": [326, 327], "split_custom": [24, 25, 281, 282, 283, 284], "split_fram": 30, "splitarea": 57, "splite": 235, "splitlin": 57, "splitnumb": 57, "splitter": [16, 17, 307, 308, 309, 310], "sport": [344, 351], "sq_residu": [216, 231], "sq_residual_perturb": [216, 231], "sql": 31, "squar": [5, 171, 216, 231, 330, 334, 336, 340, 368, 371, 373, 379, 382], "squared_error": 17, "squarederror": [9, 41, 67], "sridhar": 336, "stabil": [119, 123, 223, 234, 335, 341, 352, 359, 361, 370, 371, 378, 381, 382], "stabl": [138, 367, 368, 369, 370, 372, 373, 378, 382], "stack": [126, 338], "stackstrategi": 57, "stage": [24, 25, 137, 279, 280, 339, 372], "stake": [377, 380], "stand": [120, 180], "standalon": 365, "standard": [124, 129, 171, 214, 216, 226, 227, 228, 231, 234, 257, 259, 334, 337, 339, 343, 345, 354, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382], "start": [54, 98, 362, 363, 367, 368, 372, 373, 378], "start_tim": 50, "stat": [47, 308, 310, 335, 341, 386], "state": [344, 351, 354, 359, 364, 373], "static": 373, "statist": [128, 136, 188, 217, 219, 222, 233, 242, 257, 259, 260, 292, 293, 296, 297, 334, 335, 338, 339, 341, 342, 347, 352, 355, 373, 377, 379, 380, 382, 383], "statu": [59, 136, 137, 138, 334, 356, 357, 362, 363, 365, 377], "std": [3, 5, 11, 18, 19, 171, 259, 337, 378], "std_dev": 257, "steep": [233, 372], "stem": [243, 261, 262, 348, 370, 373], "step": [117, 137, 142, 156, 167, 170, 272, 290, 291, 296, 297, 307, 308, 309, 310, 334, 336, 339, 340, 343, 344, 350, 351, 365, 368, 373, 380, 381, 382, 386, 388], "step_log": 137, "still": [336, 345, 347, 367, 372, 388], "stop": [24, 25, 279, 280, 281, 282, 292, 293, 296, 297, 339, 378, 382], "storag": 53, "store": [57, 117, 275, 298, 315, 355, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "str": [35, 36, 57, 111, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 151, 152, 153, 156, 157, 158, 166, 170, 171, 172, 173, 174, 175, 176, 178, 180, 181, 182, 183, 187, 188, 201, 203, 204, 205, 207, 208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315], "straightforward": [344, 348, 349, 382], "strategi": [117, 119, 148, 217, 233, 290, 291, 307, 308, 309, 310, 339, 340, 352, 376], "stratif": [187, 341], "stratifi": [187, 308, 309, 310, 341, 378], "streamlin": [352, 358, 362, 363], "strength": [128, 136, 242, 279, 280, 281, 282, 283, 284, 292, 293, 296, 297, 338, 339, 343, 346, 359, 361, 367, 369, 370, 372, 373, 377], "stress": 233, "strict": [367, 372], "strike": 378, "string": [58, 148, 279, 280, 290, 291, 292, 293, 296, 297, 330, 332, 337, 386], "strobl": 339, "strobl2019": 339, "strong": [128, 136, 338], "stronger": [232, 242, 343, 346, 367, 368, 369, 370, 371, 372, 382], "strongli": [343, 345, 367, 372], "structur": [130, 188, 219, 253, 256, 261, 283, 284, 307, 308, 309, 310, 311, 336, 340, 344, 351, 355, 358, 365, 367, 368, 372, 373, 374, 379, 382], "struggl": [379, 381, 383], "stump": 369, "style": [29, 37, 49, 57, 375, 385, 388, 391], "su": [344, 351], "sub": [279, 280, 380, 382], "sub_item": 214, "subgroup": [358, 371, 377, 381], "subitem": 213, "subject": [218, 279, 280, 339, 378, 383], "sublink": 57, "submodul": 336, "subnet_size_interact": [279, 280], "subnet_size_main_effect": [279, 280], "subnetwork": [279, 280, 367], "subobject": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306], "suboptim": 371, "subpopul": [371, 381], "subsampl": [1, 12, 24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 127, 129, 130, 140, 146, 187, 230, 242, 244, 324, 333, 336, 344, 345, 346, 347, 349, 351, 391], "subsample_for_bin": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "subsample_freq": [24, 25, 26, 27, 44, 46, 47, 53, 54, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "subsample_random": [6, 341], "subscript": 377, "subsect": [336, 385], "subsequ": [117, 336, 368, 372], "subset": [216, 231, 233, 245, 308, 331, 336, 339, 343, 345, 346, 347, 349, 351, 358, 374, 378, 379, 381, 383], "subseteq": [344, 351], "substanti": 349, "subtarget": 57, "subtext": 57, "subtract": [243, 261, 262, 345, 348, 368, 369], "success": [344, 351], "successfulli": 53, "sudjianto": [367, 368, 369, 373, 382], "sudjianto2020": 373, "suffer": 332, "suffici": 328, "suffix": 354, "suggest": [242, 332, 335, 336, 343, 345, 349, 351, 377, 379], "suit": [0, 270, 271, 324, 337, 338, 352, 359, 361, 365], "suitabl": [336, 340, 352, 379, 382], "sum": [242, 291, 335, 336, 339, 340, 341, 367, 368, 369, 370, 371, 372, 373], "sum_": [335, 336, 339, 341, 343, 344, 345, 346, 349, 351, 367, 368, 369, 371, 372, 373, 378, 379, 381, 382], "sum_i": 371, "sum_j": [368, 381], "sum_k": [367, 368, 372], "sum_m": 368, "summar": [235, 237, 239, 265, 332, 337, 356, 377, 379, 382, 383], "summari": [7, 22, 23, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 119, 214, 215, 217, 218, 226, 229, 231, 233, 234, 246, 259, 265, 324, 333, 352, 353, 356, 361, 371, 378, 379, 380, 381, 382, 383], "sup_": 381, "sup_x": [335, 341], "supabas": 112, "superior": 331, "supervis": [343, 376], "supplement": 365, "support": [125, 126, 127, 130, 131, 183, 214, 220, 226, 228, 235, 236, 237, 238, 239, 241, 243, 244, 253, 292, 293, 296, 297, 315, 332, 334, 336, 338, 341, 344, 345, 351, 352, 363, 364, 368, 371, 377, 382, 386], "suppos": [343, 344, 349, 351, 388], "surfac": 369, "surpris": 350, "surrog": [344, 348, 351], "survei": 339, "sv1": [5, 11, 334], "sv2": [5, 11, 334], "svg": 315, "swarm": [43, 48, 49, 309, 371, 391], "switch": [355, 360], "symbol": 313, "symmetr": [128, 343, 346], "system": [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 332, 344, 345, 346, 347, 348, 349, 350, 351, 352, 377], "systemat": [377, 379, 382, 383], "t": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 44, 45, 46, 47, 50, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 121, 281, 282, 311, 336, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "t_k": 368, "t_m": [368, 372], "tab": [355, 358, 360, 365], "tabl": [3, 5, 8, 9, 11, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 35, 36, 39, 44, 45, 46, 47, 57, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 84, 85, 88, 91, 119, 122, 123, 124, 128, 129, 130, 136, 137, 138, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 259, 261, 262, 265, 266, 307, 308, 309, 310, 315, 334, 335, 354, 355, 361, 367, 368, 369, 370, 371, 372, 374, 377, 378, 379, 380, 382, 383, 386, 388], "tabular": [246, 252, 254, 307, 308, 309, 310], "tag": [166, 210, 269, 343, 344, 345, 346, 349, 351, 367, 373], "tailor": [371, 380, 381], "taiwancredit": [2, 3, 5, 7, 14, 16, 18, 20, 22, 24, 26, 39, 40, 46, 50, 58, 62, 66, 68, 72, 76, 80, 84, 88, 92, 152, 326, 328, 330, 334, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383], "taiwancreditdata": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "take": [236, 275, 298, 336, 340, 344, 351, 358], "taken": 332, "tang": 373, "tanh": [279, 280, 388], "target": [2, 5, 30, 31, 32, 33, 34, 57, 131, 136, 171, 182, 189, 200, 215, 216, 222, 229, 230, 231, 242, 244, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 334, 335, 339, 341, 343, 345, 349, 350, 354, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388], "target_featur": 59, "target_nam": [32, 33, 34, 334, 388], "task": [182, 183, 190, 214, 215, 222, 226, 227, 229, 230, 238, 241, 242, 243, 244, 246, 274, 277, 278, 280, 282, 284, 286, 288, 290, 291, 293, 295, 296, 297, 298, 300, 302, 304, 306, 328, 330, 334, 336, 340, 343, 345, 346, 347, 349, 350, 351, 352, 354, 359, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386, 388], "task_typ": [59, 183, 229, 274, 277, 278, 280, 282, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 385], "tau": [128, 136, 338, 371, 380], "tau_1": 380, "tau_2": 380, "taylor": 336, "teacher": [279, 280], "team": [344, 351], "technic": 345, "techniqu": [325, 336, 340, 352, 358, 377, 378, 380, 381, 382, 383, 386], "tell": 345, "temp": [4, 8, 9, 10, 11, 54, 57, 69, 73, 77, 85, 337, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "temperatur": 371, "templat": [299, 300], "tempor": 379, "temporari": 339, "temporarili": 339, "tend": [349, 373, 378], "tendenc": [367, 372], "term": [257, 260, 331, 344, 348, 351, 367, 368, 369, 371, 372, 373, 378, 380, 381, 383], "termin": [18, 19, 24, 25, 369, 372, 382], "test": [0, 1, 2, 9, 10, 12, 14, 15, 16, 17, 20, 21, 24, 25, 26, 27, 39, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 71, 72, 73, 76, 77, 88, 91, 92, 94, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 155, 171, 179, 180, 184, 187, 188, 191, 192, 193, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 290, 291, 307, 308, 309, 310, 311, 324, 326, 327, 328, 330, 332, 334, 336, 341, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 365, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 379, 380, 381, 383, 387, 388, 391], "test1": 240, "test2": 240, "test_dataset": [9, 35, 36, 39, 59, 66, 67, 72, 73, 76, 77, 213, 215, 221, 222, 225, 229, 237, 238, 377, 378, 379, 380, 383], "test_explain": 360, "test_i": [2, 39, 40, 41], "test_idx": [9, 32, 33, 34, 35, 36, 184, 388], "test_indic": [31, 35, 36], "test_list": 240, "test_model": 59, "test_ratio": [59, 179], "test_result": 269, "test_sample_s": [348, 351], "test_sample_weight": 2, "test_scor": [213, 225], "test_siz": [32, 33, 34, 35, 36, 76, 77, 215, 222, 229, 238, 380, 388], "test_weak": 364, "test_x": [2, 39, 40, 41], "testsuit": [0, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 44, 45, 46, 47, 50, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "testsuite_nam": 240, "text": [57, 369, 371, 377, 378, 379, 380, 381, 382], "textalign": 57, "textbf": [343, 345, 367, 373], "textbordertyp": 57, "textgap": 57, "textshadowcolor": 57, "textstyl": 57, "textverticalalign": 57, "th": [231, 336, 340, 343, 344, 345, 346, 349, 351, 368, 369, 372, 373], "than": [128, 136, 148, 232, 241, 242, 279, 280, 330, 331, 332, 336, 337, 338, 339, 343, 344, 345, 346, 347, 348, 349, 351, 369, 373, 378, 386], "thei": [244, 334, 336, 340, 343, 344, 349, 351, 368, 373, 377], "theil": [128, 136, 339], "theilsu": 339, "them": [50, 119, 128, 136, 225, 334, 338, 339, 369, 375, 377, 378, 381, 388], "theoret": 381, "theori": 339, "therebi": [336, 371], "therefor": [343, 344, 345, 348, 351, 373], "theta": [367, 371, 372], "thi": [0, 5, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 160, 166, 173, 180, 186, 187, 188, 205, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 269, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 315, 324, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 385, 386, 388], "third": [126, 279, 280, 337, 355, 356, 357, 373], "thorough": 382, "those": [310, 331, 332, 377, 382], "thread": 54, "three": [127, 214, 220, 226, 228, 236, 279, 280, 330, 332, 335, 337, 338, 339, 340, 357, 367, 371, 372, 382, 383], "threre": 377, "threshold": [4, 8, 9, 35, 36, 68, 69, 72, 73, 76, 77, 84, 85, 88, 122, 123, 124, 136, 137, 138, 214, 219, 220, 221, 222, 223, 226, 228, 229, 234, 235, 236, 237, 238, 239, 279, 280, 311, 336, 339, 340, 361, 368, 369, 372, 378, 379, 380, 382, 383], "through": [126, 129, 138, 227, 253, 264, 292, 293, 296, 297, 332, 338, 356, 363, 366, 367, 369, 370, 371, 372, 373, 374, 378, 380, 381, 382, 383, 386], "throuput": 352, "ti": [235, 236, 238, 239], "tild": 373, "time": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 120, 123, 128, 138, 180, 216, 218, 223, 231, 234, 241, 245, 253, 279, 280, 335, 339, 344, 350, 351, 362, 363, 365, 373, 380, 381], "time_cost_": [279, 280], "ting": [336, 340], "titl": [57, 272], "tn": 379, "to_datetim": [11, 54], "to_df": [5, 9, 11], "to_timedelta": [11, 54], "toarrai": 31, "togeth": [201, 367, 372, 377], "token": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "tol": [15, 45], "toler": [279, 280], "tolist": [31, 54], "toni": [336, 340], "too": [332, 343, 344, 345, 351, 358, 373, 378], "tool": [244, 338, 343, 344, 348, 349, 351, 352, 355, 364, 379, 385, 389], "toolbox": 57, "tooltip": [57, 127], "top": [57, 258, 259, 279, 280, 283, 315, 330, 332, 334, 336, 337, 339, 346, 348, 367, 371, 373, 380], "top1": [3, 11, 337], "top2": [3, 11, 337], "top3": [3, 11, 337], "torch": [112, 279, 280, 296, 297], "total": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 355, 367, 368, 372, 373, 378, 382, 391], "toward": [373, 377, 381], "tp": 379, "tp_": 377, "tpe": [47, 308], "tpesampl": 308, "tpr": [377, 379], "tqdm": 112, "track": [148, 336, 352, 381, 382], "trade": [246, 308, 309, 310, 380], "tradeoff": [228, 378], "tradit": [336, 367, 369, 370, 371, 372, 379], "train": [0, 2, 5, 7, 9, 10, 24, 25, 30, 31, 32, 35, 36, 39, 44, 45, 46, 47, 54, 58, 59, 62, 63, 66, 67, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 155, 171, 179, 180, 185, 187, 188, 195, 196, 197, 203, 205, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 303, 304, 307, 308, 309, 310, 324, 330, 332, 334, 335, 336, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 361, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 379, 380, 381, 382, 383, 386, 388], "train_al": [50, 387], "train_dataset": [9, 35, 36, 39, 59, 66, 67, 72, 73, 76, 77, 213, 215, 221, 222, 225, 229, 237, 238, 377, 378, 379, 380, 383], "train_epoch_loss_": [296, 297], "train_i": [2, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 326, 327, 328, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "train_idx": [9, 32, 33, 34, 35, 36, 185, 388], "train_indic": [31, 35, 36], "train_model": 59, "train_sample_s": [348, 351], "train_sample_weight": 2, "train_scor": [213, 225], "train_siz": 187, "train_test_split": [32, 33, 34, 35, 36, 388], "train_x": [2, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 309, 326, 327, 328, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383], "training_fram": 30, "transfom": [367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "transform": [31, 117, 124, 129, 131, 171, 232, 328, 334, 336, 339, 340, 344, 351, 365, 372, 373, 378, 379, 380, 381, 382, 385], "transitiondur": 57, "translat": 379, "transpar": [57, 368, 373], "travers": [264, 374], "treat": [148, 180, 309, 339], "treatment": [228, 352], "tree": [13, 28, 49, 123, 215, 216, 221, 222, 229, 231, 232, 253, 255, 256, 261, 264, 274, 276, 277, 278, 280, 281, 282, 283, 284, 286, 288, 291, 292, 293, 295, 297, 298, 300, 302, 304, 306, 308, 324, 330, 336, 340, 343, 344, 348, 349, 351, 352, 366, 367, 371, 379, 380, 382, 386, 391], "tree_": [283, 284], "tree_method": 309, "treeclassifi": 351, "treeregressor": 351, "treeshap": 351, "trend": [126, 356, 369, 378, 379], "trial": [5, 9, 10, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 59, 88], "trigger": [57, 349], "triggeron": 57, "trivial": [367, 373], "troubleshoot": 353, "true": [2, 5, 9, 11, 14, 15, 18, 19, 20, 21, 24, 25, 26, 27, 30, 35, 36, 39, 41, 45, 50, 54, 57, 59, 62, 63, 68, 69, 72, 73, 76, 77, 84, 85, 88, 124, 142, 148, 150, 179, 187, 194, 214, 220, 226, 227, 228, 230, 236, 240, 243, 261, 262, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315, 326, 328, 334, 336, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 387], "truncat": [343, 350], "trust": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 344], "trustworthi": [367, 372, 377, 380, 383], "truth": [273, 275, 276, 279, 281, 283, 285, 287, 289, 290, 292, 294, 296, 299, 301, 303, 305, 388], "try": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 307, 308, 310], "ts_residu": [62, 63, 379], "tsamardino": 339, "tsc": [35, 36, 39, 53, 54, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 377, 378, 379, 381, 382, 383], "tset_task_typ": 334, "tulio": 344, "tune": [0, 24, 25, 48, 50, 59, 98, 275, 279, 280, 292, 293, 298, 307, 308, 309, 310, 324, 336, 352, 353, 359, 362, 365, 367, 372, 375, 391], "tupl": [58, 111, 117, 119, 128, 129, 130, 131, 148, 171, 172, 174, 213, 216, 217, 218, 223, 225, 227, 228, 231, 233, 234, 235, 236, 237, 238, 239, 241, 242, 244, 252, 253, 254, 279, 280, 292, 293, 296, 297, 307, 308, 309, 310, 315, 370, 373, 377], "tutori": 388, "tw": 5, "twcredit": [2, 365], "twice": 339, "two": [3, 119, 124, 126, 128, 136, 137, 237, 238, 239, 241, 242, 244, 253, 254, 331, 335, 336, 337, 338, 339, 340, 341, 343, 344, 346, 347, 348, 351, 356, 365, 368, 369, 372, 373, 377, 378, 379, 380, 381, 382], "type": [2, 11, 57, 116, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 134, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 171, 173, 182, 183, 187, 188, 190, 194, 198, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 315, 334, 336, 338, 339, 340, 354, 362, 363, 364, 365, 369, 370, 377, 379, 380, 382, 385], "type_": 57, "typic": [128, 130, 136, 336, 338, 343, 350, 368, 379, 380, 381, 386], "u": [112, 128, 136, 336, 339, 340, 343, 345, 349, 350, 377, 379, 382], "u_": 368, "uci": [330, 332, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "ultim": [260, 379], "umap": [112, 130], "umer": 334, "unabl": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "unbias": [343, 345], "uncent": [343, 345, 348, 367, 368, 369, 370, 372, 373], "uncertain": [381, 383], "uncertainti": [326, 327, 332, 339, 352, 380, 381, 382, 383], "unchang": [343, 348, 350, 382], "uncom": 11, "uncov": [356, 357, 371, 379, 383], "under": [72, 73, 76, 77, 84, 85, 88, 215, 217, 218, 223, 232, 233, 234, 239, 260, 330, 332, 336, 339, 340, 352, 361, 363, 377, 379, 380, 381, 382, 383], "underbrac": 378, "underestim": 378, "underfit": [225, 324, 339, 376, 379], "undergo": [330, 332], "underli": [273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304, 336, 368, 370, 374, 379], "underperform": [379, 381, 383], "understand": [233, 244, 336, 338, 347, 355, 371, 373, 377, 379, 380, 381, 383], "understood": 378, "uneven": 383, "unfair": [214, 226, 227, 228, 331, 377], "unfit": [292, 293], "uni_featur": [345, 347, 349], "unifi": [344, 368], "uniform": [22, 23, 47, 53, 54, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 117, 119, 216, 219, 220, 221, 222, 223, 227, 228, 231, 232, 234, 235, 236, 237, 238, 239, 330, 332, 334, 335, 354, 358, 364, 371, 377, 378, 379, 380, 381, 386], "uniformli": [279, 280, 308, 310, 364, 371, 383], "union": [235, 236, 237, 238, 239], "uniqu": [3, 5, 11, 334, 336, 337, 340, 354, 355, 362, 368, 371, 373, 381], "unit": [11, 54, 171], "univ": [336, 340], "univari": [125, 333, 336, 352, 377, 380, 381, 382], "unless": [307, 308, 309, 310, 330, 332], "unlik": [330, 332, 336, 344, 351, 368, 379], "unmodel": 379, "unnecessarili": 373, "unpen": 373, "unprivileg": 377, "unreli": [76, 215, 217, 222, 229, 238, 239, 343, 345, 377, 380], "unseen": [335, 378, 379], "unstabl": 373, "unsupervis": [336, 379], "unsupport": 315, "until": [336, 340, 367, 368, 371, 372], "unus": 365, "unusu": 379, "unwrap": 373, "unwrapp": 259, "up": [41, 112, 241, 242, 244, 335, 343, 345, 346, 347, 349, 351, 356, 357, 368], "updat": [2, 112, 173, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 355, 365, 368, 369, 371], "upon": 373, "upper": [88, 214, 220, 226, 227, 228, 236, 242, 244, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 377], "upper_inclus": [88, 214, 220, 226, 227, 228, 236, 377], "us": [2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 49, 50, 52, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 140, 141, 142, 146, 147, 148, 151, 156, 157, 166, 171, 175, 176, 180, 181, 182, 187, 188, 194, 205, 207, 208, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 325, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 385, 386, 387, 388], "usag": [56, 335, 336, 375], "use_multi_thread": 30, "use_predict": [62, 63, 230], "use_test": [345, 346, 347, 348, 349, 350, 351], "use_weight": 122, "user": [125, 217, 308, 313, 326, 327, 328, 334, 336, 337, 339, 352, 358, 362, 363, 364, 365, 368, 370, 374, 375, 383], "user_guid": [367, 369, 372], "usual": [343, 344, 345, 350, 351, 386], "util": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 112, 221, 222, 331, 332, 334, 336, 340, 365, 378, 382, 391], "v": [214, 226, 246, 308, 309, 310, 339, 341, 356, 361, 379, 380, 381, 382], "v_": 371, "v_m": 368, "val": [344, 351], "val_ratio": [279, 280, 281, 282, 292, 293, 296, 297], "valid": [0, 9, 18, 19, 24, 25, 52, 53, 57, 98, 229, 236, 261, 269, 272, 279, 280, 281, 282, 290, 291, 292, 293, 296, 297, 307, 308, 309, 310, 315, 328, 348, 351, 352, 360, 367, 372, 378, 379, 385, 386, 389], "validation_epoch_loss_": [296, 297], "validationresult": [0, 56, 60, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 269, 307, 308, 309, 310, 391], "valu": [4, 5, 6, 11, 22, 23, 26, 30, 32, 44, 45, 46, 47, 57, 62, 63, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 117, 119, 122, 123, 124, 128, 129, 130, 131, 136, 137, 138, 148, 171, 187, 188, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 257, 258, 260, 261, 262, 263, 265, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 331, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 359, 363, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 386], "valuabl": [244, 336, 350, 381], "valueerror": [241, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 315], "var": 378, "vari": [242, 244, 347, 348, 371, 377, 383], "variabl": [1, 3, 7, 12, 84, 85, 88, 128, 129, 130, 131, 136, 142, 230, 232, 235, 244, 273, 274, 276, 277, 278, 285, 286, 287, 288, 289, 290, 291, 294, 295, 303, 304, 313, 314, 330, 331, 332, 335, 336, 338, 339, 340, 341, 343, 347, 350, 351, 352, 358, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 381, 383, 391], "varialb": 232, "varianc": [124, 129, 171, 232, 242, 336, 338, 340, 351, 367, 368, 369, 370, 371, 372, 378, 379], "variat": [234, 381, 382], "variou": [50, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 117, 119, 126, 148, 171, 188, 214, 215, 218, 221, 222, 223, 226, 236, 239, 330, 332, 335, 336, 340, 344, 351, 367, 377, 382], "vdot": 369, "vector": [31, 336, 344, 345, 351, 368, 369, 371, 372, 373], "vectorassembl": 31, "veloc": 371, "vendor": 388, "verbos": [18, 19, 24, 25, 26, 27, 32, 33, 34, 44, 46, 47, 50, 53, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 279, 280, 281, 282, 292, 293, 296, 297], "veri": [279, 280, 331, 343, 345, 348, 350, 367], "verifi": [367, 372], "versa": 373, "version": [2, 50, 112, 118, 142, 146, 147, 157, 168, 194, 199, 200, 208, 261, 335, 341], "vertic": 57, "via": [24, 25, 231, 343, 346, 367, 371, 372, 375, 380, 381, 382], "vice": 373, "vicin": 336, "victori": [344, 351], "view": [2, 128, 136, 256, 338, 343, 345, 349, 350, 351, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374], "viewport": 127, "vijayan": 369, "violat": [367, 372, 377, 380], "violin": 260, "visual": [56, 60, 72, 73, 112, 119, 122, 123, 124, 125, 126, 127, 128, 129, 136, 137, 138, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 246, 252, 253, 254, 255, 256, 257, 258, 261, 262, 263, 264, 265, 307, 308, 309, 310, 315, 336, 338, 343, 345, 347, 349, 352, 359, 361, 363, 367, 368, 369, 373, 374, 378, 379, 380, 382, 383, 391], "visualmap": 57, "visualmap_typ": 57, "visweswaran": 339, "vulner": [233, 352, 371, 381], "w": [343, 373, 380, 381, 382], "w_": 378, "w_1": 370, "w_2": 370, "w_d": 370, "w_i": [378, 382], "wa": 54, "wai": [244, 249, 332, 335, 336, 343, 344, 347, 351, 373, 379, 380, 388], "wang": 339, "want": [337, 344, 347, 349, 351, 354], "warm_start": [15, 45, 279, 280], "wasserstein": [119, 335, 341, 352], "wasserstein_dist": [335, 341], "wd": 352, "wd1": [119, 335, 341], "we": [9, 76, 77, 279, 280, 308, 309, 310, 330, 331, 332, 335, 336, 337, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 373, 377, 379, 381, 382, 385, 387, 388], "weak": [9, 35, 36, 68, 69, 72, 73, 76, 77, 84, 85, 88, 220, 221, 222, 223, 235, 236, 237, 238, 239, 242, 324, 330, 332, 352, 353, 359, 376, 379], "weakspot": 329, "weathersit": [4, 8, 9, 10, 11, 15, 54, 69, 73, 77, 85, 345], "websit": [330, 367, 368, 369, 370, 371, 372, 373, 378, 379, 380, 381, 382, 383], "weekdai": [4, 8, 9, 10, 11, 54, 69, 77, 85, 367, 380, 382], "weight": [2, 122, 168, 169, 175, 176, 181, 254, 257, 260, 263, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 334, 340, 344, 348, 351, 354, 365, 368, 369, 371, 372, 373, 378, 380, 381], "well": [233, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 335, 336, 359, 371, 377, 379, 380, 381, 382, 383], "went": [344, 351], "were": 148, "what": 324, "when": [119, 124, 125, 128, 136, 148, 201, 205, 215, 216, 217, 218, 219, 220, 221, 222, 223, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 246, 264, 274, 277, 278, 279, 280, 281, 282, 284, 286, 288, 291, 293, 295, 297, 298, 300, 302, 304, 306, 330, 331, 335, 336, 339, 343, 344, 345, 347, 348, 350, 351, 367, 368, 371, 372, 373, 374, 377, 378, 379, 382, 383, 386], "where": [122, 123, 124, 128, 136, 148, 213, 214, 217, 219, 221, 222, 223, 229, 230, 233, 234, 235, 238, 239, 242, 243, 245, 246, 252, 255, 257, 261, 262, 263, 290, 291, 296, 297, 307, 308, 328, 331, 335, 336, 338, 339, 340, 343, 344, 345, 346, 349, 351, 367, 368, 369, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 386], "wherea": 373, "whether": [122, 124, 179, 187, 201, 207, 220, 221, 222, 223, 230, 235, 236, 237, 238, 239, 243, 261, 272, 279, 280, 281, 282, 283, 284, 290, 291, 315, 336, 339, 343, 349, 371, 379, 381], "which": [98, 117, 122, 123, 125, 126, 127, 128, 129, 130, 131, 187, 188, 214, 215, 216, 217, 218, 220, 221, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 253, 262, 265, 296, 297, 307, 308, 309, 310, 314, 330, 332, 334, 335, 336, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 383, 388], "while": [216, 231, 241, 244, 281, 282, 336, 343, 345, 347, 350, 351, 358, 367, 368, 370, 371, 372, 373, 374, 377, 378, 382, 383, 386], "who": [344, 351, 377], "whole": [235, 236, 237, 238, 239, 335, 360], "whose": [252, 380, 381], "why": [344, 379], "wide": [373, 374], "widest": [229, 380], "width": [9, 35, 36, 39, 41, 57, 76, 77, 117, 215, 216, 219, 221, 222, 223, 227, 229, 231, 235, 236, 237, 238, 239, 315, 335, 341, 359, 361, 380, 383], "width_threshold": 229, "wiggli": 378, "wikipedia": 339, "william": 373, "windspe": [4, 8, 9, 10, 11, 54, 69, 77, 85, 371], "winner": [344, 351], "wise": [54, 119, 239], "withcolumn": 31, "within": [216, 217, 228, 231, 233, 246, 261, 279, 280, 330, 331, 335, 336, 340, 352, 354, 358, 371, 377, 380], "without": [9, 35, 36, 292, 293, 301, 302, 344, 351, 367, 372], "won": [344, 351], "word": [335, 343, 345], "work": [228, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 336, 349, 351, 367, 368, 372, 377, 380, 383], "workflow": [129, 352, 353, 375, 385, 388], "workingdai": [4, 8, 9, 10, 11, 15, 54, 69, 349, 350, 367, 372, 378], "world": [361, 368, 371, 379, 381, 382], "worst": [80, 81, 217, 218, 233, 352, 359, 361, 380, 381, 382], "worth": [336, 344, 351], "would": [76, 77, 279, 280, 345, 346, 347, 349], "wrap": [29, 37, 49, 299, 300, 324, 325, 387, 391], "wrap_estim": 50, "wraparbmodel": 388, "wrapper": [0, 30, 31, 50, 273, 274, 275, 276, 277, 278, 285, 286, 287, 288, 289, 294, 295, 298, 299, 300, 301, 302, 303, 304, 324, 336, 340, 368, 370, 374, 375], "wrapscoredmodel": 388, "wrapskmlp": 388, "written": 368, "wu": 339, "x": [6, 8, 9, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 119, 122, 123, 124, 126, 127, 132, 133, 134, 135, 139, 140, 142, 159, 192, 196, 213, 214, 216, 217, 219, 221, 222, 223, 229, 230, 231, 233, 234, 235, 236, 238, 239, 241, 242, 243, 244, 245, 246, 252, 255, 257, 261, 262, 263, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 330, 332, 335, 336, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 356, 357, 358, 361, 364, 367, 368, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382, 388], "x0": [117, 219, 220, 221, 222, 223, 235, 236, 237, 238, 239, 279, 280, 290, 291, 346], "x1": [35, 36, 235, 236, 237, 238, 239, 244, 253, 279, 280, 290, 291, 346], "x2": [235, 236, 237, 238, 239, 244, 253, 279, 280, 290, 291, 346], "x27": [9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39, 40, 41, 44, 45, 46, 47, 53, 54, 58, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "x3": 346, "x4": 346, "x5": 346, "x6": 346, "x7": 346, "x8": 346, "x9": 346, "x_": [335, 336, 340, 343, 345, 347, 349, 367, 368, 369, 371, 372, 378, 380, 382], "x_1": [369, 370, 372], "x_2": [369, 370, 372], "x_c": [343, 349], "x_column": 30, "x_d": [369, 370, 372], "x_h2o": 30, "x_i": [367, 368, 369, 371, 372, 378, 380, 381], "x_j": [343, 346, 367, 368, 369, 372, 378], "x_k": [343, 346, 367, 368, 371, 372], "x_n": 380, "x_spark": 31, "x_test": [35, 36, 326, 327, 328], "x_train": [35, 36], "xaxi": 57, "xgb": [9, 39, 53, 69, 235, 328, 339, 352, 363, 386, 387], "xgb1": [68, 69, 72, 73, 84, 85, 88, 117, 219, 220, 221, 222, 223, 227, 232, 235, 236, 237, 238, 239, 311, 364, 377, 378, 382, 383], "xgb2": [50, 330, 332, 346, 347, 348, 349, 351], "xgb7": 332, "xgb_kwarg": 232, "xgb_model": [368, 377, 378, 379, 380, 381, 382, 383], "xgbclassifi": 303, "xgboost": [50, 68, 112, 117, 138, 219, 220, 221, 222, 223, 227, 232, 235, 236, 237, 238, 239, 290, 291, 303, 304, 336, 339, 340, 359, 360, 361, 362, 363, 364, 365, 368, 371, 377, 378, 379, 380, 381, 382], "xgbregressor": 304, "xi": [128, 136, 338], "xianji": 339, "xiaofei": [336, 340], "xiaom": 368, "xicor": [4, 128, 136, 338], "xindong": 339, "xiyang": 336, "xu": [336, 340], "xxx": [119, 213, 214, 215, 216, 220, 225, 226, 227, 228, 231, 232, 235, 236, 237, 238, 239, 240, 241, 244, 253, 265, 307, 308, 309, 310], "xxxxxx": 334, "y": [5, 30, 32, 33, 34, 35, 36, 39, 40, 41, 119, 122, 123, 124, 126, 127, 140, 142, 189, 193, 197, 213, 214, 217, 219, 221, 222, 223, 229, 230, 231, 233, 234, 242, 243, 245, 246, 252, 255, 257, 261, 262, 263, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 330, 331, 332, 335, 339, 344, 348, 351, 356, 357, 358, 367, 370, 371, 372, 373, 377, 378, 379, 380, 381, 382], "y_": [335, 380], "y_column": 30, "y_hat": 230, "y_i": [368, 371, 378, 379, 380, 381], "y_n": 380, "y_test": [35, 36, 326, 327, 328], "y_train": [35, 36], "yang": [367, 368], "yang2020": 367, "yang2024": 368, "yaxi": 57, "yet": 383, "yield": [290, 291, 307, 308, 309, 310, 386], "you": [5, 9, 10, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 47, 54, 59, 88, 98, 112, 182, 324, 336, 337, 339, 344, 345, 346, 347, 348, 349, 351, 354, 356, 359, 381, 385, 386], "your": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92, 98, 337, 355, 356, 357, 358, 362, 363], "yr": [4, 8, 9, 10, 11, 15, 21, 54, 69, 337, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "yu": 339, "yu2020": 339, "yue": 336, "z": [57, 127, 339, 344, 351, 357, 358, 372, 373], "z_": [336, 340, 343, 345], "z_i": 339, "z_j": [344, 351, 367, 372], "zebin": [367, 368, 373], "zengyou": [336, 340], "zero": [128, 136, 171, 335, 338, 339, 343, 345, 350, 367, 368, 373, 379], "zhang": [339, 367, 368, 369, 373, 382], "zhang2012": 339, "zhao": 336, "zhaolong": 339, "zheng": 336, "zhi": [336, 340], "zhou": [336, 340], "zhu": 343, "zip": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 46, 47, 50, 53, 54, 57, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 91, 92], "zoo": [0, 324, 362, 375], "\u03b1": 380, "\u03b2": [380, 381], "\u03b5": 381, "\u03c4": 380}, "titles": ["API Reference", "Dataset", "Basic Dataset Operations", "Exploratory Data Analysis", "Feature Selection", "Data Processing and Feature Engineering", "Subsampling", "Data Drift Test", "Outlier Detection", "Data with Model Predictions", "Dealing with Extra Data Sets", "Dealing with Date Variables", "Computation times", "Built-in Interpretable Models", "Logistic Regression (Classification)", "Linear Regression (Regression)", "Decision Tree Classification", "Decision Tree Regression", "MoReLUDNN Classification", "MoReLUDNN Regression", "GAMINet Classification", "GAMINet Regression", "Mixture of Expert (MoE) Classification", "Mixture of Expert (MoE) Regression", "Linear Tree Classification", "Linear Tree Regression", "Tree Ensemble Models (Classification)", "Tree Ensemble Models (Regression)", "Computation times", "External Models", "Wrapping H2O Models", "Wrapping PySpark Models", "Wrapping sklearn-style Models", "Wrapping Arbitrary Classifier", "Wrapping Arbitrary Regressor", "Wrapping Scored Classifier", "Wrapping Scored Regressor", "Computation times", "Model Calibration", "Calibrating Binary Classifier", "Calibrating Binary Classifier Prediction Interval", "Calibrating Regressor Prediction Interval", "Computation times", "Hyperparameter Tuning", "Grid Search", "Random Search", "Particle Swarm Optimization Search", "Tuning with optuna (Experimental)", "Computation times", "Model Development", "ModelZoo", "Computation times", "Get Started", "First Example with Modeva", "Diagnostics Analysis with Date", "Computation times", "Utilities", "ValidationResult - Attributes", "ValidationResult - Visualization", "Pipeline", "Computation times", "Model Residual", "Residual Analysis (Classification)", "Residual Analysis (Regression)", "Computation times", "Model Performance", "Performance Metrics (Classification)", "Performance Metrics (Regression)", "Sliced Performance (Classification)", "Sliced Performance (Regression)", "Computation times", "Overfit Detection", "Overfitting Analysis (Classification)", "Overfitting Analysis (Regression)", "Computation times", "Reliability Analysis", "Reliability Analysis (Classification)", "Reliability Analysis (Regression)", "Computation times", "Resilience Analysis", "Resilience Analysis (Classification)", "Resilience Analysis (Regression)", "Computation times", "Robustness Analysis", "Robustness Analysis (Classification)", "Robustness Analysis (Regression)", "Computation times", "Fairness Analysis", "Model Fairness Analysis (Classification)", "Computation times", "Explainability", "Global Explainability", "Local Explainability", "Computation times", "Model Validation", "Computation times", "Change Log", "Frequently Asked Questions", "Gallery of Modeva Examples", "sphinx_gallery.backreferences", "sphinx_gallery.block_parser", "sphinx_gallery.directives", "sphinx_gallery.docs_resolv", "sphinx_gallery.downloads", "sphinx_gallery.gen_gallery", "sphinx_gallery.gen_rst", "sphinx_gallery.interactive_example", "sphinx_gallery.notebook", "sphinx_gallery.py_source_parser", "sphinx_gallery.scrapers", "sphinx_gallery.sorting", "sphinx_gallery.utils.optipng", "Installation", "Low Code", "DataSet", "modeva.DataSet.all_feature_names", "modeva.DataSet.all_feature_types", "modeva.DataSet.bin_numerical", "modeva.DataSet.data", "modeva.DataSet.data_drift_test", "modeva.DataSet.delete_extra_data", "modeva.DataSet.delete_registered_data", "modeva.DataSet.detect_outlier_cblof", "modeva.DataSet.detect_outlier_isolation_forest", "modeva.DataSet.detect_outlier_pca", "modeva.DataSet.eda_1d", "modeva.DataSet.eda_2d", "modeva.DataSet.eda_3d", "modeva.DataSet.eda_correlation", "modeva.DataSet.eda_pca", "modeva.DataSet.eda_umap", "modeva.DataSet.encode_categorical", "modeva.DataSet.feature_names", "modeva.DataSet.feature_names_categorical", "modeva.DataSet.feature_names_mixed", "modeva.DataSet.feature_names_numerical", "modeva.DataSet.feature_select_corr", "modeva.DataSet.feature_select_rcit", "modeva.DataSet.feature_select_xgbpfi", "modeva.DataSet.feature_types", "modeva.DataSet.get_X_y_data", "modeva.DataSet.get_active_sample_idx", "modeva.DataSet.get_data", "modeva.DataSet.get_data_list", "modeva.DataSet.get_extra_data_list", "modeva.DataSet.get_preprocessor", "modeva.DataSet.get_protected_data", "modeva.DataSet.get_raw_data", "modeva.DataSet.impute_missing", "modeva.DataSet.inverse_transform", "modeva.DataSet.is_splitted", "modeva.DataSet.list_registered_data", "modeva.DataSet.load", "modeva.DataSet.load_csv", "modeva.DataSet.load_dataframe", "modeva.DataSet.load_dataframe_train_test", "modeva.DataSet.load_preprocessing", "modeva.DataSet.load_registered_data", "modeva.DataSet.load_spark", "modeva.DataSet.n_features", "modeva.DataSet.name", "modeva.DataSet.prediction_name", "modeva.DataSet.prediction_proba_name", "modeva.DataSet.preprocess", "modeva.DataSet.protected_feature_names", "modeva.DataSet.raw_data", "modeva.DataSet.register", "modeva.DataSet.reset_preprocess", "modeva.DataSet.sample_weight", "modeva.DataSet.sample_weight_name", "modeva.DataSet.save_preprocessing", "modeva.DataSet.scale_numerical", "modeva.DataSet.set_active_features", "modeva.DataSet.set_feature_type", "modeva.DataSet.set_inactive_features", "modeva.DataSet.set_prediction", "modeva.DataSet.set_prediction_proba", "modeva.DataSet.set_protected_data", "modeva.DataSet.set_protected_extra_data", "modeva.DataSet.set_random_split", "modeva.DataSet.set_raw_extra_data", "modeva.DataSet.set_sample_weight", "modeva.DataSet.set_target", "modeva.DataSet.set_task_type", "modeva.DataSet.set_test_idx", "modeva.DataSet.set_train_idx", "modeva.DataSet.shape", "modeva.DataSet.subsample_random", "modeva.DataSet.summary", "modeva.DataSet.target_feature_name", "modeva.DataSet.task_type", "modeva.DataSet.test_sample_weight", "modeva.DataSet.test_x", "modeva.DataSet.test_y", "modeva.DataSet.to_df", "modeva.DataSet.train_sample_weight", "modeva.DataSet.train_x", "modeva.DataSet.train_y", "modeva.DataSet.transform", "modeva.DataSet.x", "modeva.DataSet.y", "modeva.ModelZoo.add_model", "modeva.ModelZoo.dataset", "modeva.ModelZoo.delete_registered_model", "modeva.ModelZoo.get_model", "modeva.ModelZoo.leaderboard", "modeva.ModelZoo.list_model_names", "modeva.ModelZoo.list_registered_models", "modeva.ModelZoo.load_registered_model", "modeva.ModelZoo.models", "modeva.ModelZoo.register", "modeva.ModelZoo.train", "modeva.ModelZoo.train_all", "modeva.TestSuite.compare_accuracy_table", "modeva.TestSuite.compare_fairness", "modeva.TestSuite.compare_reliability", "modeva.TestSuite.compare_residual_cluster", "modeva.TestSuite.compare_resilience", "modeva.TestSuite.compare_robustness", "modeva.TestSuite.compare_slicing_accuracy", "modeva.TestSuite.compare_slicing_fairness", "modeva.TestSuite.compare_slicing_overfit", "modeva.TestSuite.compare_slicing_reliability", "modeva.TestSuite.compare_slicing_robustness", "modeva.TestSuite.delete_registed_test", "modeva.TestSuite.diagnose_accuracy_table", "modeva.TestSuite.diagnose_fairness", "modeva.TestSuite.diagnose_mitigate_unfair_binning", "modeva.TestSuite.diagnose_mitigate_unfair_thresholding", "modeva.TestSuite.diagnose_reliability", "modeva.TestSuite.diagnose_residual_analysis", "modeva.TestSuite.diagnose_residual_cluster", "modeva.TestSuite.diagnose_residual_interpret", "modeva.TestSuite.diagnose_resilience", "modeva.TestSuite.diagnose_robustness", "modeva.TestSuite.diagnose_slicing_accuracy", "modeva.TestSuite.diagnose_slicing_fairness", "modeva.TestSuite.diagnose_slicing_overfit", "modeva.TestSuite.diagnose_slicing_reliability", "modeva.TestSuite.diagnose_slicing_robustness", "modeva.TestSuite.display_test_results", "modeva.TestSuite.explain_ale", "modeva.TestSuite.explain_hstatistic", "modeva.TestSuite.explain_lime", "modeva.TestSuite.explain_pdp", "modeva.TestSuite.explain_pfi", "modeva.TestSuite.explain_shap", "modeva.TestSuite.export_report", "modeva.TestSuite.get_dataset", "modeva.TestSuite.get_interactions", "modeva.TestSuite.get_main_effects", "modeva.TestSuite.get_model", "modeva.TestSuite.interpret_coef", "modeva.TestSuite.interpret_effects", "modeva.TestSuite.interpret_effects_moe_average", "modeva.TestSuite.interpret_fi", "modeva.TestSuite.interpret_global_tree", "modeva.TestSuite.interpret_llm_pc", "modeva.TestSuite.interpret_llm_profile", "modeva.TestSuite.interpret_llm_summary", "modeva.TestSuite.interpret_llm_violin", "modeva.TestSuite.interpret_local_fi", "modeva.TestSuite.interpret_local_linear_fi", "modeva.TestSuite.interpret_local_moe_weights", "modeva.TestSuite.interpret_local_tree", "modeva.TestSuite.interpret_moe_cluster_analysis", "modeva.TestSuite.list", "modeva.TestSuite.list_registered_tests", "modeva.TestSuite.load_registered_test", "modeva.TestSuite.register", "modeva.TestSuite.set_dataset", "modeva.TestSuite.set_model", "modeva.automation.pipeline.Pipeline", "modeva.models.MoCatBoostClassifier", "modeva.models.MoCatBoostRegressor", "modeva.models.MoClassifier", "modeva.models.MoDecisionTreeClassifier", "modeva.models.MoDecisionTreeRegressor", "modeva.models.MoElasticNet", "modeva.models.MoGAMINetClassifier", "modeva.models.MoGAMINetRegressor", "modeva.models.MoGLMTreeBoostClassifier", "modeva.models.MoGLMTreeBoostRegressor", "modeva.models.MoGLMTreeClassifier", "modeva.models.MoGLMTreeRegressor", "modeva.models.MoGradientBoostingClassifier", "modeva.models.MoGradientBoostingRegressor", "modeva.models.MoLGBMClassifier", "modeva.models.MoLGBMRegressor", "modeva.models.MoLogisticRegression", "modeva.models.MoMoEClassifier", "modeva.models.MoMoERegressor", "modeva.models.MoNeuralTreeClassifier", "modeva.models.MoNeuralTreeRegressor", "modeva.models.MoRandomForestClassifier", "modeva.models.MoRandomForestRegressor", "modeva.models.MoReLUDNNClassifier", "modeva.models.MoReLUDNNRegressor", "modeva.models.MoRegressor", "modeva.models.MoSKLearnClassifier", "modeva.models.MoSKLearnRegressor", "modeva.models.MoScoredClassifier", "modeva.models.MoScoredRegressor", "modeva.models.MoXGBClassifier", "modeva.models.MoXGBRegressor", "modeva.models.ModelBaseClassifier", "modeva.models.ModelBaseRegressor", "modeva.models.ModelTuneGridSearch", "modeva.models.ModelTuneOptuna", "modeva.models.ModelTunePSO", "modeva.models.ModelTuneRandomSearch", "modeva.testsuite.utils.slicing_utils.get_data_info", "modeva.utils.mlflow.clear_mlflow_home", "modeva.utils.mlflow.get_mlflow_home", "modeva.utils.mlflow.set_mlflow_home", "modeva.utils.results.ValidationResult", "Hyperparameter Tuning", "Interpretable Models", "Model Zoo", "Pipeline", "Validation Result", "Test Suite", "Utilities", "Model Wrappers", "Using Modeva", "Model Calibration", "Interval Calibration for Classification", "Interval Calibration for Regression", "Model Probability Calibration", "Model Comparison", "Comparison for Classification", "Fairness Comparison", "Comparison for Regression", "Data Processing", "Basic Data Operations", "Data Quality (Drift Test)", "Data Quality (Outlier Detection)", "Data Summary", "Exploratory Data Analysis", "Feature Selection", "Outlier Detection", "Subsampling and Data Drift", "Model Explainability", "Global Explainability", "Local Explainability", "ALE (Accumulated Local Effects)", "Hstats (Friedman\u2019s H-statistic)", "ICE (Individual Conditional Expectation)", "LIME (Local Interpretable Model-Agnostic Explanation)", "PDP (Partial Dependence Plot)", "PFI (Permutation Feature Importance)", "SHAP (SHapley Additive exPlanations)", "Introduction", "Low code", "Data Processing", "Data Summary", "EDA 2D Charts", "EDA 3D Scatter", "EDA Multivariate", "Model Comparison", "Model Explainability", "Model Test", "Model Training", "Model Tuning", "Weakness Test", "Registry Hub", "Interpretable Models", "GAMI-Net", "Gradient Boosted Decision Trees", "Linear Tree and Gradient Boosted Linear Trees", "Generalized Linear Models", "Mixture of Experts (MoE)", "Neural Tree", "ReLU Neural Network", "Decision Tree", "Model Wrapping", "Diagnostic Suite", "Fairness", "Underfitting and Overfitting", "Performance and Residual Analysis", "Reliability", "Resilience", "Robustness", "Weakness Detection", "Model Training", "Register H2O Models", "Model Tuning", "Model Zoo and Leaderboard", "Model Wrappers", "MoDeVa.ai", "Unused API Entries", "Computation times"], "titleterms": {"": [343, 346], "0": 95, "00": [12, 37, 42, 48, 51, 55, 60, 70, 74, 78, 82, 86, 89, 93, 95], "000": 95, "01": [42, 64], "03": 37, "04": [28, 82, 89], "045": 82, "046": 28, "07": 60, "09": 93, "1": [22, 23, 51, 89, 326, 327, 328, 330, 332, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388], "10": [12, 70], "11": 55, "12": 86, "139": 74, "14": [28, 74, 78], "1d": [3, 72, 73, 91, 338], "2": [55, 62, 63, 64, 74, 78, 82, 86, 93, 326, 327, 328, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 386, 388], "276": 64, "2d": [3, 11, 72, 73, 91, 338, 356], "3": [42, 60, 326, 327, 328, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 378, 383, 386, 388], "32": 64, "3d": [3, 11, 338, 357], "4": [48, 70, 355, 356, 357, 358, 359, 360, 361, 362, 363, 388], "405": 48, "41": 12, "414": 51, "44": 48, "445": 93, "5": [355, 358, 359, 361, 388], "5000": 10, "52": 28, "524": 89, "557": 70, "56": 51, "561": 86, "6": [355, 359, 361], "7": 37, "731": 60, "758": 12, "8000": 10, "825": 42, "829": 37, "851": 55, "9000": 10, "951": 78, "If": [355, 356, 357], "One": [336, 345, 349], "The": 351, "_sourceauto_galleriesdata": 12, "_sourceauto_galleriesdev": 51, "_sourceauto_galleriesdev0_model": 28, "_sourceauto_galleriesdev1_extmodel": 37, "_sourceauto_galleriesdev2_calibr": 42, "_sourceauto_galleriesdev3_hpo": 48, "_sourceauto_galleriesget_start": 55, "_sourceauto_galleriesutil": 60, "_sourceauto_galleriesv": 95, "_sourceauto_galleriesval0_residu": 64, "_sourceauto_galleriesval1_perform": 70, "_sourceauto_galleriesval2_overfit": 74, "_sourceauto_galleriesval3_reli": 78, "_sourceauto_galleriesval4_resili": 82, "_sourceauto_galleriesval5_robust": 86, "_sourceauto_galleriesval6_fair": 89, "_sourceauto_galleriesval7_explain": 93, "abov": [5, 15], "absolut": [62, 63, 332], "access": 114, "accumul": [343, 345], "accuraci": [15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 54, 66, 67, 68, 69, 330, 332], "activ": 6, "add": 50, "add_model": 201, "addit": [344, 351, 383], "address": [380, 381, 382], "adjust": [355, 356, 357, 377], "advanc": [50, 68, 69, 358, 383], "advantag": 369, "advers": 377, "after": 39, "against": [18, 19, 54, 62, 63], "aggreg": 368, "agnost": [344, 348], "ai": 389, "air": 377, "al": [91, 343, 345], "algorithm": [339, 345, 346, 347, 348, 349, 350, 351], "all": 50, "all_feature_nam": 115, "all_feature_typ": 116, "analysi": [3, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 54, 62, 63, 66, 67, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 83, 84, 85, 87, 88, 94, 336, 338, 352, 358, 367, 368, 369, 371, 372, 373, 378, 379, 380, 381, 382], "analyz": [62, 63, 355], "anova": [367, 368, 369, 371, 372], "api": [0, 390], "appli": [6, 358], "applic": [377, 378, 379], "approach": [378, 380, 381, 382, 383], "arbitrari": [33, 34, 388], "architectur": [371, 372, 373], "ask": 97, "assess": [378, 380], "attribut": [57, 367, 371, 372], "auc": 330, "autom": 272, "automat": 383, "avail": [10, 58], "backrefer": 99, "bandwidth": [330, 332], "bar": 58, "base": [4, 62, 63, 336, 340], "baselin": 92, "basic": [2, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 66, 67, 68, 69, 76, 77, 80, 81, 84, 85, 88, 334, 367], "batch": [72, 73], "befor": 39, "benefit": 368, "best": [44, 45, 46, 47, 363], "between": [22, 23, 377], "bike": [345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "bikeshar": 332, "bin": [334, 377, 383], "bin_numer": 117, "binari": [39, 40, 326], "bivari": 338, "block_pars": 100, "boost": [24, 25, 368, 369], "build": [30, 31, 32, 33, 34, 35, 36, 39, 40, 41], "built": [2, 13, 49, 334], "calibr": [38, 39, 40, 41, 49, 325, 326, 327, 328], "case": 368, "categor": [334, 337, 355, 367, 382], "cblof": [8, 336, 340], "centric": [378, 380, 381, 382], "challeng": 379, "chang": [96, 337], "character": 378, "chart": 356, "check": 39, "class": 336, "classif": [14, 16, 18, 20, 22, 24, 26, 62, 66, 68, 72, 76, 80, 84, 88, 317, 326, 330, 379], "classifi": [33, 35, 39, 40], "clear_mlflow_hom": 312, "cluster": [22, 23, 62, 63, 336, 380, 382], "code": [113, 353], "coeffici": [14, 15, 339], "combin": 377, "compar": [35, 36, 39, 62, 63, 66, 67, 362], "compare_accuracy_t": 213, "compare_fair": 214, "compare_reli": 215, "compare_residual_clust": 216, "compare_resili": 217, "compare_robust": 218, "compare_slicing_accuraci": 219, "compare_slicing_fair": 220, "compare_slicing_overfit": 221, "compare_slicing_reli": 222, "compare_slicing_robust": 223, "comparison": [68, 69, 72, 73, 76, 77, 80, 81, 84, 85, 88, 321, 329, 330, 331, 332, 336, 359, 377, 378, 379, 380, 381, 382, 383], "complex": 378, "compon": [336, 358], "comput": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95, 367, 391], "conceptu": 352, "condit": [339, 347], "conduct": [72, 73], "configur": [50, 356, 357, 363], "conform": [326, 327, 380], "connect": 378, "consider": [367, 372, 382], "constraint": [24, 25, 367, 368, 372], "continu": 381, "convert": [35, 36], "coordin": [18, 19, 373], "correl": [3, 4, 338, 339, 358], "coverag": 332, "creat": [30, 31, 32, 33, 34, 35, 36, 365, 388], "credit": [330, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "cumul": 336, "curvatur": 378, "d": 6, "data": [2, 3, 5, 7, 9, 10, 11, 22, 23, 30, 31, 32, 33, 34, 35, 36, 114, 118, 326, 327, 328, 333, 334, 335, 336, 337, 338, 341, 354, 355, 365, 378, 380, 381, 382, 388], "data_drift_test": 119, "dataset": [1, 2, 50, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 334, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365], "date": [11, 54], "deal": [10, 11], "decis": [16, 17, 368, 374], "decomposit": [367, 368, 369, 371, 378], "defin": [5, 15], "definit": 377, "delet": 10, "delete_extra_data": 120, "delete_registed_test": 224, "delete_registered_data": 121, "delete_registered_model": 203, "depend": [91, 343, 349, 351], "depth": [62, 63, 368, 383], "detail": [345, 346, 347, 348, 349, 350, 351], "detect": [8, 71, 94, 114, 336, 340, 364, 378, 383], "detect_outlier_cblof": 122, "detect_outlier_isolation_forest": 123, "detect_outlier_pca": 124, "develop": 49, "diagnos": [44, 45, 46, 47], "diagnose_accuracy_t": 225, "diagnose_fair": 226, "diagnose_mitigate_unfair_bin": 227, "diagnose_mitigate_unfair_threshold": 228, "diagnose_reli": 229, "diagnose_residual_analysi": 230, "diagnose_residual_clust": 231, "diagnose_residual_interpret": 232, "diagnose_resili": 233, "diagnose_robust": 234, "diagnose_slicing_accuraci": 235, "diagnose_slicing_fair": 236, "diagnose_slicing_overfit": 237, "diagnose_slicing_reli": 238, "diagnose_slicing_robust": 239, "diagnost": [30, 31, 32, 33, 34, 35, 36, 54, 321, 376, 377, 380, 385], "diagram": 330, "differ": 336, "direct": 101, "discret": 381, "dispar": 377, "displai": 58, "display_test_result": 240, "distanc": [330, 332, 335, 381], "distribut": [335, 336, 341, 381, 382], "diverg": 381, "dnn": 373, "docs_resolv": 102, "download": 103, "drift": [7, 22, 23, 114, 335, 341, 381], "eda": [3, 11, 356, 357, 358], "eda_1d": 125, "eda_2d": 126, "eda_3d": 127, "eda_correl": 128, "eda_pca": 129, "eda_umap": 130, "effect": [14, 15, 20, 21, 22, 23, 26, 27, 343, 345, 367, 368, 371, 372], "empir": [336, 368, 378], "encod": 334, "encode_categor": 131, "energi": 335, "engin": [5, 378], "enhanc": 368, "ensembl": [26, 27, 368], "entri": 390, "error": [332, 378, 383], "estim": 378, "evalu": [361, 362, 377, 379], "exact": [344, 351], "exampl": [50, 53, 98, 326, 327, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388], "execut": [5, 12, 15, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95], "expect": 347, "experi": 365, "experiment": 47, "expert": [22, 23, 371], "explain": [90, 91, 92, 94, 342, 343, 344, 360], "explain_al": 241, "explain_hstatist": 242, "explain_lim": 243, "explain_pdp": 244, "explain_pfi": 245, "explain_shap": 246, "explan": [321, 344, 348, 351, 360, 367], "explor": [114, 338], "exploratori": [3, 338], "export": [355, 358], "export_report": 247, "extern": [29, 49, 334, 388], "extra": [10, 114], "extract": [18, 19], "f": 369, "f1": 330, "factor": 336, "fair": [87, 88, 94, 331, 377], "fbedk": 339, "featur": [4, 5, 14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 62, 63, 72, 73, 91, 114, 337, 339, 343, 350, 351, 352, 354, 355, 356, 357, 364, 367, 371, 372, 373, 377, 378], "feature_nam": 132, "feature_names_categor": 133, "feature_names_mix": 134, "feature_names_numer": 135, "feature_select_corr": 136, "feature_select_rcit": 137, "feature_select_xgbpfi": 138, "feature_typ": 139, "figur": 58, "file": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95], "first": [10, 53], "fit": 385, "forest": [8, 62, 63, 336, 340, 380, 382], "formul": [368, 371, 381], "framework": 378, "frequent": 97, "friedman": [343, 346], "from": [2, 10, 12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95, 378], "full": 380, "function": [367, 368, 369, 371, 372], "galleri": 98, "gami": 367, "gaminet": [20, 21], "gap": 378, "gate": 371, "gbdt": 368, "gblt": 369, "gen_galleri": 104, "gen_rst": 105, "gener": [58, 370, 378], "get": [10, 40, 41, 52, 326, 327, 328], "get_active_sample_idx": 141, "get_data": 142, "get_data_info": 311, "get_data_list": 143, "get_dataset": 248, "get_extra_data_list": 144, "get_interact": 249, "get_main_effect": 250, "get_mlflow_hom": 313, "get_model": [204, 251], "get_preprocessor": 145, "get_protected_data": 146, "get_raw_data": 147, "get_x_y_data": 140, "glm": 370, "glmtree": [24, 25], "global": [16, 17, 20, 91, 343, 354, 360, 367, 368, 369, 370, 371, 372, 374], "gradient": [368, 369, 378], "grid": [44, 386], "group": [92, 377], "h": [91, 343, 346], "h2o": [30, 385], "handl": 334, "heatmap": 338, "hidden": [18, 19], "histogram": 336, "hoc": 321, "hpo": 47, "hstat": [343, 346], "hub": 365, "hyperparamet": [43, 44, 45, 46, 47, 49, 316], "i": 383, "ic": 347, "identif": [380, 382], "identifi": 378, "impact": [377, 380, 382], "implement": [367, 372, 378], "import": [14, 15, 18, 19, 20, 21, 22, 23, 26, 27, 62, 63, 91, 339, 343, 350, 351, 367, 371, 372, 373, 383], "impute_miss": 148, "independ": 339, "index": 10, "individu": [347, 367, 368, 369, 371, 372, 373], "inher": 321, "initi": [50, 59, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365], "input": 382, "instal": 112, "interact": [72, 73, 368], "interactive_exampl": 106, "interpret": [13, 14, 15, 16, 17, 20, 21, 22, 23, 49, 50, 62, 63, 317, 321, 344, 348, 366, 367, 368, 369, 370, 371, 372, 373, 374, 379], "interpret_coef": 252, "interpret_effect": 253, "interpret_effects_moe_averag": 254, "interpret_fi": 255, "interpret_global_tre": 256, "interpret_llm_pc": 257, "interpret_llm_profil": 258, "interpret_llm_summari": 259, "interpret_llm_violin": 260, "interpret_local_fi": 261, "interpret_local_linear_fi": 262, "interpret_local_moe_weight": 263, "interpret_local_tre": 264, "interpret_moe_cluster_analysi": 265, "interv": [40, 41, 62, 63, 326, 327], "introduct": [352, 379, 383], "inverse_transform": 149, "is_split": 150, "isol": [8, 336, 340], "issu": [380, 382], "its": 58, "jensen": 381, "k": 336, "kei": [352, 383], "kernel": 92, "kernelshap": [344, 351], "kmeanstre": 336, "kolmogorov": 381, "last": [10, 18, 19], "layer": [18, 19], "leaderboard": [50, 205, 387], "learn": [50, 379, 380, 382], "lgbm": [24, 25, 39, 66, 67], "lime": [92, 344, 348], "limit": [58, 368], "linear": [14, 15, 24, 25, 369, 370, 373], "linearshap": 344, "list": [58, 266], "list_model_nam": 206, "list_registered_data": 151, "list_registered_model": 207, "list_registered_test": 267, "llm": [18, 19, 373], "load": [2, 5, 10, 50, 114, 152, 334, 355, 356, 357, 358, 360, 385], "load_csv": 153, "load_datafram": 154, "load_dataframe_train_test": 155, "load_preprocess": 156, "load_registered_data": 157, "load_registered_model": 208, "load_registered_test": 268, "load_spark": 158, "local": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 92, 336, 343, 344, 345, 348, 360, 367, 368, 369, 370, 371, 372, 373, 374, 378], "log": 96, "logist": 14, "loss": [367, 372], "low": [113, 353], "machin": [380, 382], "main": [14, 15, 26, 27, 368], "manag": [114, 318, 365, 387], "manifest": 378, "manipul": 337, "margin": [335, 336], "mathbf": 369, "mathemat": [368, 371], "mean": 332, "measur": [378, 379, 381], "method": [336, 340, 363, 378], "methodologi": [336, 379], "metric": [66, 67, 331, 377, 379], "miss": 334, "mitig": [88, 377], "mixtur": [22, 23, 371], "ml": 50, "mlflow": [2, 50, 312, 313, 314], "mocatboostclassifi": 273, "mocatboostregressor": 274, "moclassifi": 275, "mode": [72, 73], "modecisiontreeclassifi": 276, "modecisiontreeregressor": 277, "model": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 49, 50, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 76, 77, 85, 88, 94, 209, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 317, 318, 321, 323, 325, 326, 327, 328, 329, 342, 344, 348, 351, 359, 360, 361, 362, 363, 364, 366, 368, 369, 370, 371, 372, 373, 375, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388], "modelbaseclassifi": 305, "modelbaseregressor": 306, "modeltun": 386, "modeltunegridsearch": 307, "modeltuneoptuna": 308, "modeltunepso": 309, "modeltunerandomsearch": 310, "modelzoo": [50, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212], "modeva": [10, 30, 31, 32, 33, 34, 35, 36, 53, 98, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 324, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 388, 389], "modul": 352, "moe": [22, 23, 371], "moelasticnet": 278, "mogaminetclassifi": 279, "mogaminetregressor": 280, "moglmtreeboostclassifi": 281, "moglmtreeboostregressor": 282, "moglmtreeclassifi": 283, "moglmtreeregressor": 284, "mogradientboostingclassifi": 285, "mogradientboostingregressor": 286, "molgbmclassifi": 287, "molgbmregressor": 288, "mologisticregress": 289, "momoeclassifi": 290, "momoeregressor": 291, "moneuraltreeclassifi": 292, "moneuraltreeregressor": 293, "monoton": [24, 25, 367, 368, 372], "morandomforestclassifi": 294, "morandomforestregressor": 295, "moregressor": 298, "moreludnn": [18, 19], "moreludnnclassifi": 296, "moreludnnregressor": 297, "moscoredclassifi": 301, "moscoredregressor": 302, "mosklearnclassifi": 299, "mosklearnregressor": 300, "moxgbclassifi": 303, "moxgbregressor": 304, "multipl": [62, 63], "multivari": [358, 378], "n_featur": 159, "name": [10, 58, 160], "nearest": 336, "necessari": [355, 356, 357], "need": [10, 39, 40, 41], "neighbor": 336, "net": 367, "network": 373, "neural": [24, 25, 372, 373], "nois": 382, "nonconform": 380, "normal": 382, "notebook": 107, "number": 58, "numer": [334, 337, 355], "one": [10, 58], "oot1": 10, "oot2": 10, "oot3": 10, "oper": [2, 4, 334], "optim": [46, 386], "option": 59, "optipng": 111, "optuna": 47, "outcom": 352, "outlier": [8, 114, 336, 340], "output": [18, 19], "overal": 369, "overfit": [54, 71, 72, 73, 94, 330, 332, 378], "overview": 355, "pairwis": 368, "panel": [354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365], "parallel": [18, 19, 373], "paramet": 363, "partial": [91, 343, 349], "particl": [46, 386], "partit": 378, "pca": [3, 8, 338, 340, 358], "pdp": [343, 349], "perform": [22, 23, 65, 66, 67, 68, 69, 94, 330, 332, 358, 359, 361, 377, 379], "permut": [91, 343, 350], "perturb": [62, 63, 382], "pfi": [4, 343, 350], "pipelin": [59, 272, 319], "plot": [14, 15, 18, 19, 26, 27, 58, 91, 338, 343, 349, 351, 367, 368, 371, 372, 373], "post": 321, "practic": [378, 382], "predict": [9, 35, 36, 40, 41, 62, 63, 326, 327, 328, 367, 368, 369, 371, 372, 373, 380], "prediction_nam": 161, "prediction_proba_nam": 162, "predictor": [62, 63], "prepar": [50, 326, 327, 328, 334, 388], "preprocess": [5, 15, 114, 163, 334], "prerequisit": 112, "princip": [336, 358], "proba": [39, 62, 328], "probabl": 328, "problemat": 378, "process": [5, 333, 354, 368, 371, 372], "profil": [18, 19, 373], "properti": [114, 318], "protect": 114, "protected_feature_nam": 164, "psi": 381, "pso": 46, "purif": [367, 368], "purpos": 379, "py_source_pars": 108, "pyspark": 31, "qualiti": [335, 336, 368], "quantil": [382, 383], "question": 97, "r": 332, "random": [6, 45, 62, 63, 380, 382, 386], "ratio": 377, "raw_data": 165, "rcit": [4, 339], "refer": [0, 336, 338, 339, 340, 343, 344, 346, 347, 350, 351, 367, 368, 369, 373], "region": [72, 73, 378], "regist": [2, 50, 166, 210, 269, 354, 356, 357, 362, 363, 385], "registr": [50, 334], "registri": [318, 365], "regress": [14, 15, 17, 19, 21, 23, 25, 27, 63, 67, 69, 73, 77, 81, 85, 317, 327, 332, 379], "regressor": [34, 36, 41], "reliabl": [54, 75, 76, 77, 94, 330, 332, 359, 361, 380], "relu": 373, "remedi": 378, "remov": 337, "represent": [367, 371, 372], "reset": [5, 6], "reset_preprocess": 167, "residu": [54, 61, 62, 63, 94, 379], "resili": [79, 80, 81, 94, 330, 332, 359, 361, 381], "respons": [62, 63], "rest": [22, 23, 39, 40, 41], "result": [8, 59, 315, 320, 355, 358, 359, 360, 361, 364, 368, 379], "retrain": [44, 45, 46, 47], "review": 355, "risk": 378, "robust": [54, 83, 84, 85, 94, 330, 332, 359, 361, 378, 382], "row": 10, "run": [44, 45, 46, 47, 59, 363, 385], "sampl": [6, 10, 22, 23, 92, 114, 330, 332, 354], "sample_weight": 168, "sample_weight_nam": 169, "save": [35, 36, 58, 59, 355, 356, 357, 358, 359, 360, 361, 364, 385], "save_preprocess": 170, "scale": 334, "scale_numer": 171, "scatter": [338, 357], "scikit": 50, "score": [35, 36, 330, 332, 336, 380, 388], "scraper": 109, "script": [30, 31, 33, 34], "search": [44, 45, 46, 363, 386], "segment": [331, 364], "select": [4, 114, 339, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364], "sensit": 378, "set": [5, 6, 10, 50, 354, 356, 357], "set_active_featur": 172, "set_active_sampl": 6, "set_dataset": 270, "set_feature_typ": 173, "set_inactive_featur": 174, "set_mlflow_hom": 314, "set_model": 271, "set_predict": 175, "set_prediction_proba": 176, "set_protected_data": 177, "set_protected_extra_data": 178, "set_random_split": 179, "set_raw_extra_data": 180, "set_sample_weight": 181, "set_target": 182, "set_task_typ": 183, "set_test_idx": 184, "set_train_idx": 185, "shannon": 381, "shap": [92, 344, 351], "shape": 186, "shaplei": [344, 351], "share": [345, 346, 347, 348, 349, 350, 351, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "shoot": 112, "show": [10, 50], "simpl": 382, "simucredit": [345, 346, 347, 348, 349, 350, 351], "singl": 92, "sklearn": [32, 388], "slice": [54, 68, 69, 72, 73, 76, 77, 84, 85, 88, 377, 378, 383], "slicing_util": 311, "smirnov": 381, "solut": [344, 351, 378], "sort": 110, "sound": 352, "sparsiti": 378, "special": [352, 368], "specif": 351, "sphinx_galleri": [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111], "split": [10, 114, 354, 380], "squar": 332, "stage": 368, "start": 52, "statist": [91, 337, 343, 346, 381], "step": [5, 15, 59, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 369, 371, 372, 379], "strategi": [378, 380, 381, 382], "structur": 369, "style": 32, "sub": 58, "subplot": 58, "subsampl": [6, 341], "subsample_random": 187, "suit": [30, 31, 32, 33, 34, 35, 36, 321, 376], "summari": [3, 5, 11, 18, 19, 188, 334, 337, 351, 355, 373], "supervis": [379, 380, 382], "svm": 336, "swarm": [46, 386], "t_m": 369, "tabl": [18, 19, 373], "taiwan": [330, 367, 368, 369, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383], "taiwancredit": 338, "target_feature_nam": 189, "task_typ": 190, "techniqu": 379, "test": [7, 22, 23, 30, 31, 32, 33, 34, 35, 36, 114, 321, 335, 339, 361, 364, 378, 382, 385], "test_i": 193, "test_sample_weight": 191, "test_x": 192, "testsuit": [213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 311, 388], "theoret": 378, "threshold": 377, "through": 368, "time": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95, 391], "to_df": 194, "total": [12, 28, 37, 42, 48, 51, 55, 60, 64, 70, 74, 78, 82, 86, 89, 93, 95], "track": 365, "tradeoff": 377, "tradit": 50, "train": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 50, 114, 211, 318, 362, 378, 384, 385, 387], "train_al": 212, "train_i": 197, "train_sample_weight": 195, "train_x": 196, "transform": [198, 369], "tree": [16, 17, 24, 25, 26, 27, 368, 369, 372, 374, 383], "treeshap": 344, "troubl": 112, "troubleshoot": [358, 363], "tune": [43, 44, 45, 46, 47, 49, 316, 363, 386], "two": [35, 36, 345, 349], "type": [337, 355, 356, 357], "umap": [3, 358], "uncertainti": 378, "underfit": 378, "unfair": 88, "uniform": [382, 383], "univari": [338, 378], "unus": 390, "upload": 365, "us": [8, 324, 383], "usag": [345, 346, 347, 348, 349, 350, 351, 386], "util": [56, 111, 311, 312, 313, 314, 315, 321, 322, 383], "valid": [94, 320, 388], "validationresult": [57, 58, 315], "valu": 334, "variabl": [11, 62, 63, 334, 354, 367, 380, 382], "verifi": 50, "view": 8, "visual": [41, 54, 58, 62, 63, 356, 357, 358], "wai": [345, 349], "wasserstein": 381, "waterfal": 351, "weak": [364, 378, 380, 381, 382, 383], "weakspot": [330, 332], "weight": [22, 23], "when": [39, 40, 41], "why": 383, "width": [62, 63], "workflow": [354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365], "worst": [330, 332], "wrap": [30, 31, 32, 33, 34, 35, 36, 50, 375, 388], "wrapper": [323, 388], "x": [199, 369], "xgb": [4, 62, 63], "xgboost": [39, 66, 67, 383], "y": 200, "zoo": [318, 387]}})