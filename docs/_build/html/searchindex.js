Search.setIndex({"alltitles": {"00:00.000 total execution time for 0 files from _sourceauto_galleriesval:": [[90, "total-execution-time-for-0-files-from-sourceauto-galleriesval"]], "00:05.624 total execution time for 3 files from _sourceauto_galleriesdev2_calibration:": [[41, "total-execution-time-for-3-files-from-sourceauto-galleriesdev2-calibration"]], "00:09.806 total execution time for 2 files from _sourceauto_galleriesval4_resilience:": [[77, "total-execution-time-for-2-files-from-sourceauto-galleriesval4-resilience"]], "00:10.364 total execution time for 1 file from _sourceauto_galleriesval6_fairness:": [[84, "total-execution-time-for-1-file-from-sourceauto-galleriesval6-fairness"]], "00:12.846 total execution time for 3 files from _sourceauto_galleriesutil:": [[55, "total-execution-time-for-3-files-from-sourceauto-galleriesutil"]], "00:13.544 total execution time for 2 files from _sourceauto_galleriesval7_explainability:": [[88, "total-execution-time-for-2-files-from-sourceauto-galleriesval7-explainability"]], "00:13.733 total execution time for 7 files from _sourceauto_galleriesdev1_extmodels:": [[36, "total-execution-time-for-7-files-from-sourceauto-galleriesdev1-extmodels"]], "00:22.785 total execution time for 2 files from _sourceauto_galleriesval5_robustness:": [[81, "total-execution-time-for-2-files-from-sourceauto-galleriesval5-robustness"]], "00:23.343 total execution time for 2 files from _sourceauto_galleriesval3_reliability:": [[73, "total-execution-time-for-2-files-from-sourceauto-galleriesval3-reliability"]], "00:23.444 total execution time for 2 files from _sourceauto_galleriesval2_overfitting:": [[69, "total-execution-time-for-2-files-from-sourceauto-galleriesval2-overfitting"]], "00:25.895 total execution time for 4 files from _sourceauto_galleriesval1_performance:": [[65, "total-execution-time-for-4-files-from-sourceauto-galleriesval1-performance"]], "01:16.725 total execution time for 9 files from _sourceauto_galleriesdata:": [[11, "total-execution-time-for-9-files-from-sourceauto-galleriesdata"]], "01:23.718 total execution time for 1 file from _sourceauto_galleriesdev:": [[50, "total-execution-time-for-1-file-from-sourceauto-galleriesdev"]], "01:50.095 total execution time for 2 files from _sourceauto_galleriesval0_residual:": [[59, "total-execution-time-for-2-files-from-sourceauto-galleriesval0-residual"]], "03:40.577 total execution time for 4 files from _sourceauto_galleriesdev3_hpo:": [[47, "total-execution-time-for-4-files-from-sourceauto-galleriesdev3-hpo"]], "09:41.221 total execution time for 14 files from _sourceauto_galleriesdev0_models:": [[27, "total-execution-time-for-14-files-from-sourceauto-galleriesdev0-models"]], "1. Aggregation Stage": [[356, "aggregation-stage"]], "1. Data Sparsity:": [[366, "data-sparsity"]], "1. Gradient Sensitivity:": [[366, "gradient-sensitivity"]], "1. Prepare external data and model": [[376, "prepare-external-data-and-model"]], "1. Uniform Binning": [[371, "uniform-binning"]], "1. Univariate Partitioning:": [[366, "univariate-partitioning"]], "1D ALE": [[86, "d-ale"]], "1D Partial dependency plots": [[86, "d-partial-dependency-plots"]], "2. Complexity Measure:": [[366, "complexity-measure"]], "2. Local Curvature:": [[366, "local-curvature"]], "2. Multivariate Region Detection:": [[366, "multivariate-region-detection"]], "2. Purification Stage": [[356, "purification-stage"]], "2. Quantile Binning": [[371, "quantile-binning"]], "2. Wrapping data into Modeva": [[376, "wrapping-data-into-modeva"]], "2D ALE": [[86, "id2"]], "2D Partial dependency plots": [[86, "id1"]], "2D feature interaction analysis": [[67, "d-feature-interaction-analysis"], [68, "d-feature-interaction-analysis"]], "3. Automatic Binning Using a Depth-1 or 2 XGBoost Tree": [[371, "automatic-binning-using-a-depth-1-or-2-xgboost-tree"]], "3. Generalization Gap Connection:": [[366, "generalization-gap-connection"]], "3. Uncertainty Assessment:": [[366, "uncertainty-assessment"]], "3. Wrapping Sklearn model into Modeva": [[376, "wrapping-sklearn-model-into-modeva"]], "3D Scatter Plot": [[326, "d-scatter-plot"]], "4. Create TestSuite for model validation": [[376, "create-testsuite-for-model-validation"]], "ALE (Accumulated Local Effects)": [[331, "ale-accumulated-local-effects"], [333, null]], "API Reference": [[0, null]], "AUC Score": [[318, "auc-score"]], "Accuracy Comparison": [[318, "accuracy-comparison"], [320, "accuracy-comparison"]], "Accuracy Score": [[318, "accuracy-score"]], "Add advanced ML models": [[49, "add-advanced-ml-models"]], "Add traditional ML models": [[49, "add-traditional-ml-models"]], "Add wrapped scikit-learn model": [[49, "add-wrapped-scikit-learn-model"]], "Additional Utilities for Slicing": [[371, "additional-utilities-for-slicing"]], "Advanced Slicing": [[371, "advanced-slicing"]], "Advanced slicing analysis": [[63, "advanced-slicing-analysis"], [64, "advanced-slicing-analysis"]], "Advantages": [[357, "advantages"]], "Adverse Impact Ratio (AIR) for Disparate Impact": [[365, "adverse-impact-ratio-air-for-disparate-impact"]], "Algorithm Details": [[333, "algorithm-details"], [334, "algorithm-details"], [335, "algorithm-details"], [336, "algorithm-details"], [337, "algorithm-details"], [338, "algorithm-details"], [339, "algorithm-details"]], "Algorithms for specific models": [[339, "algorithms-for-specific-models"]], "Analysis and Comparison": [[324, "analysis-and-comparison"]], "Analyzes residuals feature importance": [[57, "analyzes-residuals-feature-importance"], [58, "analyzes-residuals-feature-importance"]], "Applications of Residual Analysis": [[367, "applications-of-residual-analysis"]], "Apply subsampling by setting active samples": [[6, "apply-subsampling-by-setting-active-samples"]], "Arbitrary Model Wrapper": [[376, "arbitrary-model-wrapper"]], "Attributes": [[52, "attributes"]], "Bandwidth Comparison": [[318, "bandwidth-comparison"], [320, "bandwidth-comparison"]], "Base Model: GBLT Depth-1": [[360, "base-model-gblt-depth-1"]], "Baseline-(Kernel) SHAP (a group of baseline samples)": [[87, "baseline-kernel-shap-a-group-of-baseline-samples"]], "Baseline-(Kernel) SHAP (a single baseline sample)": [[87, "baseline-kernel-shap-a-single-baseline-sample"]], "Basic Data Operations": [[322, null]], "Basic Dataset Operations": [[2, null]], "Basic Decomposition": [[355, "basic-decomposition"], [360, "basic-decomposition"]], "Basic accuracy analysis": [[14, "basic-accuracy-analysis"], [15, "basic-accuracy-analysis"], [16, "basic-accuracy-analysis"], [17, "basic-accuracy-analysis"], [18, "basic-accuracy-analysis"], [19, "basic-accuracy-analysis"], [20, "basic-accuracy-analysis"], [21, "basic-accuracy-analysis"], [22, "basic-accuracy-analysis"], [25, "basic-accuracy-analysis"], [26, "basic-accuracy-analysis"], [61, "basic-accuracy-analysis"], [62, "basic-accuracy-analysis"]], "Basic data operations": [[2, "basic-data-operations"]], "Basic fairness analysis": [[83, "basic-fairness-analysis"]], "Basic reliability analysis": [[71, "basic-reliability-analysis"], [72, "basic-reliability-analysis"]], "Basic resilience analysis": [[75, "basic-resilience-analysis"], [76, "basic-resilience-analysis"]], "Basic robustness analysis": [[79, "basic-robustness-analysis"], [80, "basic-robustness-analysis"]], "Basic slice accuracy analysis": [[63, "basic-slice-accuracy-analysis"], [64, "basic-slice-accuracy-analysis"]], "Batch mode 1D slicing analysis": [[67, "batch-mode-1d-slicing-analysis"], [68, "batch-mode-1d-slicing-analysis"]], "Benefits": [[356, "benefits"]], "Bivariate (2D) Plots": [[326, "bivariate-2d-plots"]], "Boosted GLMTree model": [[23, "boosted-glmtree-model"], [24, "boosted-glmtree-model"]], "Build a model": [[38, "build-a-model"], [39, "build-a-model"], [40, "build-a-model"]], "Build a model and save the prediction": [[34, "build-a-model-and-save-the-prediction"], [35, "build-a-model-and-save-the-prediction"]], "Build a sklearn style model": [[31, "build-a-sklearn-style-model"]], "Built-in Dataset": [[322, "built-in-dataset"]], "Built-in Interpretable Models": [[12, null], [48, "built-in-interpretable-models"]], "CBLOF": [[328, "cblof"]], "Calibrate the model": [[38, "calibrate-the-model"], [39, "calibrate-the-model"], [40, "calibrate-the-model"]], "Calibrating Binary Classifier": [[38, null]], "Calibrating Binary Classifier Prediction Interval": [[39, null]], "Calibrating Regressor Prediction Interval": [[40, null]], "Categorical Features": [[325, "categorical-features"]], "Categorical Variable Encoding": [[322, "categorical-variable-encoding"]], "Categorical Variables": [[322, "categorical-variables"], [355, "categorical-variables"]], "Challenges in Measuring Model Performance": [[367, "challenges-in-measuring-model-performance"]], "Change Feature Types": [[325, "change-feature-types"]], "Change Log": [[91, null]], "Characterization of Weak Regions": [[366, "characterization-of-weak-regions"]], "Check proba before and after calibration": [[38, "check-proba-before-and-after-calibration"]], "Classification": [[309, "classification"]], "Classification Metrics": [[367, "classification-metrics"]], "Cluster-Based Local Outlier Factor (CBLOF)": [[324, "cluster-based-local-outlier-factor-cblof"]], "Coefficient interpretation": [[13, "coefficient-interpretation"], [14, "coefficient-interpretation"]], "Combined Application of Threshold Adjustment and Feature Binning": [[365, "combined-application-of-threshold-adjustment-and-feature-binning"]], "Compare residuals cluster of multiple models": [[57, "compare-residuals-cluster-of-multiple-models"], [58, "compare-residuals-cluster-of-multiple-models"]], "Compare the XGBoost model with LGBM model": [[38, "compare-the-xgboost-model-with-lgbm-model"], [61, "compare-the-xgboost-model-with-lgbm-model"], [62, "compare-the-xgboost-model-with-lgbm-model"]], "Comparison for Classification": [[318, null]], "Comparison for Regression": [[320, null]], "Comparison of Different Methods": [[324, "comparison-of-different-methods"]], "Computation times": [[11, null], [27, null], [36, null], [41, null], [47, null], [50, null], [55, null], [59, null], [65, null], [69, null], [73, null], [77, null], [81, null], [84, null], [88, null], [90, null], [379, null]], "Conceptual Soundness": [[340, "conceptual-soundness"]], "Conditional Independence": [[327, "conditional-independence"]], "Conduct slicing analysis for overfit regions": [[67, "conduct-slicing-analysis-for-overfit-regions"], [68, "conduct-slicing-analysis-for-overfit-regions"]], "Configure MLflow settings": [[49, "configure-mlflow-settings"]], "Conformal Prediction": [[368, "conformal-prediction"]], "Continuous Formulation:": [[369, "continuous-formulation"], [369, "id1"], [369, "id2"]], "Convert the model into Modeva": [[34, "convert-the-model-into-modeva"], [35, "convert-the-model-into-modeva"]], "Correlation": [[3, "correlation"]], "Correlation Coefficient": [[327, "correlation-coefficient"]], "Correlation Heatmap": [[326, "correlation-heatmap"]], "Correlation based feature selection": [[4, "correlation-based-feature-selection"]], "Coverage Comparison": [[320, "coverage-comparison"]], "Create test suite for diagnostics": [[29, "create-test-suite-for-diagnostics"], [30, "create-test-suite-for-diagnostics"], [31, "create-test-suite-for-diagnostics"], [32, "create-test-suite-for-diagnostics"], [33, "create-test-suite-for-diagnostics"], [34, "create-test-suite-for-diagnostics"], [35, "create-test-suite-for-diagnostics"]], "Creating & Managing Experiments": [[353, "creating-managing-experiments"]], "Data Access and Properties": [[109, "data-access-and-properties"]], "Data Drift Test": [[7, null]], "Data Drift and Sampling": [[109, "data-drift-and-sampling"]], "Data Exploration": [[109, "data-exploration"]], "Data Loading": [[322, "data-loading"]], "Data Loading and Management": [[109, "data-loading-and-management"]], "Data Preparation": [[322, "data-preparation"]], "Data Preprocessing": [[322, "data-preprocessing"]], "Data Processing": [[321, null], [342, null]], "Data Processing and Feature Engineering": [[5, null]], "Data Quality (Drift Test)": [[323, null]], "Data Quality (Outlier Detection)": [[324, null]], "Data Registration": [[322, "data-registration"]], "Data Summary": [[322, "data-summary"], [325, null], [343, null]], "Data drift test between cluster \u201c1\u201d with the rest samples": [[21, "data-drift-test-between-cluster-1-with-the-rest-samples"], [22, "data-drift-test-between-cluster-1-with-the-rest-samples"]], "Data load and summary": [[5, "data-load-and-summary"]], "Data summary": [[3, "data-summary"]], "Data with Model Predictions": [[9, null]], "Data-Centric Approaches": [[368, "data-centric-approaches"], [369, "data-centric-approaches"], [370, "data-centric-approaches"]], "Data-Centric Solutions": [[366, "data-centric-solutions"]], "DataSet": [[109, null]], "Dataset": [[1, null]], "Dataset Workflow": [[353, "dataset-workflow"]], "Dealing with Extra Data Sets": [[10, null]], "Decision Tree": [[362, null]], "Decision Tree Classification": [[15, null]], "Decision Tree Regression": [[16, null]], "Decision Tree in MoDeVa": [[362, "decision-tree-in-modeva"]], "Definitions of Group Fairness": [[365, "definitions-of-group-fairness"]], "Delete data split (if needed)": [[10, "delete-data-split-if-needed"]], "Diagnose the tuned model": [[43, "diagnose-the-tuned-model"], [44, "diagnose-the-tuned-model"], [45, "diagnose-the-tuned-model"], [46, "diagnose-the-tuned-model"]], "Diagnostic Suite": [[364, null]], "Diagnostics": [[313, "diagnostics"]], "Discrete Formulation (PSI):": [[369, "discrete-formulation-psi"]], "Discrete Formulation:": [[369, "discrete-formulation"], [369, "id3"]], "Display one subplot by its name": [[53, "display-one-subplot-by-its-name"]], "Distribution Drift": [[329, "distribution-drift"]], "EDA 1D": [[3, "eda-1d"]], "EDA 2D": [[3, "eda-2d"]], "EDA 2D Charts": [[344, null]], "EDA 3D": [[3, "eda-3d"]], "EDA 3D Scatter": [[345, null]], "EDA Multivariate": [[346, null]], "Effect Attribution": [[355, "effect-attribution"], [359, "effect-attribution"], [360, "effect-attribution"]], "Effect Computation": [[355, "effect-computation"], [360, "effect-computation"]], "Effect Importance": [[355, "effect-importance"], [359, "effect-importance"], [360, "effect-importance"]], "Effect importance analysis": [[25, "effect-importance-analysis"], [26, "effect-importance-analysis"]], "Effects interpretation": [[20, "effects-interpretation"]], "Empirical Cumulative Distribution-based Outlier Detection": [[324, "empirical-cumulative-distribution-based-outlier-detection"]], "Empirical Results": [[356, "empirical-results"]], "Empirical Risk Decomposition": [[366, "empirical-risk-decomposition"]], "Empirical Risk and Generalization Gap": [[366, "empirical-risk-and-generalization-gap"]], "Energy Distance": [[323, "energy-distance"]], "Error Slicing for Weakness Detection": [[371, "error-slicing-for-weakness-detection"]], "Estimation from Training and Test Errors": [[366, "estimation-from-training-and-test-errors"]], "Exact Solution": [[332, "exact-solution"], [339, "exact-solution"]], "Example": [[319, null], [323, null], [324, null], [325, null], [331, null], [332, null], [338, "example"], [365, null]], "Example 1:": [[373, null], [375, null], [376, null]], "Example 1: Bike Sharing": [[333, null], [334, null], [335, null], [336, null], [337, null], [338, null], [339, null], [355, null], [356, null], [357, null], [358, null], [359, null], [360, null], [361, null], [362, null], [366, null], [367, null], [368, null], [369, null], [370, null], [371, null]], "Example 1: BikeSharing": [[320, null]], "Example 1: Grid Search": [[374, null]], "Example 2:": [[376, null]], "Example 2: Randomized Search": [[374, null]], "Example 2: SimuCredit": [[333, null], [334, null], [335, null], [336, null], [337, null], [338, null], [339, null]], "Example 3:": [[376, null]], "Example 3: Particle Swarm Optimization Search": [[374, null]], "Example 4:": [[376, null]], "Example 5:": [[376, null]], "Example of TaiwanCredit Data Exploration": [[326, null]], "Example: Feature Selection": [[327, null]], "Example: Outlier Detection": [[328, null]], "Example: Subsampling": [[329, null]], "Examples": [[318, "examples"], [319, "examples"], [320, "examples"], [322, "examples"], [323, "examples"], [324, "examples"], [325, "examples"], [326, "examples"], [327, "examples"], [328, "examples"], [329, "examples"], [331, "examples"], [332, "examples"], [333, "examples"], [334, "examples"], [335, "examples"], [336, "examples"], [337, "examples"], [339, "examples"], [355, "examples"], [356, "examples"], [357, "examples"], [358, "examples"], [359, "examples"], [360, "examples"], [361, "examples"], [362, "examples"], [365, "examples"], [366, "examples"], [367, "examples"], [368, "examples"], [369, "examples"], [370, "examples"], [371, "examples"], [373, "examples"], [374, "examples"], [375, "examples"], [376, "examples"]], "Examples 1: Taiwan Credit": [[318, null]], "Examples 2: Taiwan Credit": [[355, null], [356, null], [357, null], [358, null], [359, null], [360, null], [361, null], [362, null], [366, null], [367, null], [368, null], [369, null], [370, null], [371, null]], "Example\uff1a Basic Data Operations": [[322, null]], "Execute the preprocessing steps defined above": [[5, "execute-the-preprocessing-steps-defined-above"], [14, "execute-the-preprocessing-steps-defined-above"]], "Experiment Workflow": [[353, "experiment-workflow"]], "Expert Decomposition": [[359, "expert-decomposition"]], "Explainability": [[85, null], [89, "explainability"]], "Explanation": [[355, "explanation"]], "Exploratory Data Analysis": [[3, null], [326, null]], "External Dataset": [[322, "external-dataset"]], "External Models": [[28, null], [48, "external-models"]], "Extra and Protected Data Management": [[109, "extra-and-protected-data-management"]], "Extract the last hidden layer outputs": [[17, "extract-the-last-hidden-layer-outputs"], [18, "extract-the-last-hidden-layer-outputs"]], "F1 Score": [[318, "f1-score"]], "FBEDk Algorithm": [[327, "fbedk-algorithm"]], "Fairness": [[365, null]], "Fairness Analysis": [[82, null], [89, "fairness-analysis"]], "Fairness Comparison": [[319, null], [365, "fairness-comparison"]], "Fairness Evaluation in MoDeVa": [[365, "fairness-evaluation-in-modeva"]], "Fairness Metrics": [[319, "fairness-metrics"]], "Fairness Metrics in MoDeVa": [[365, "fairness-metrics-in-modeva"]], "Fairness Mitigation": [[365, "fairness-mitigation"]], "Fairness comparison": [[83, "fairness-comparison"]], "Feature Binning": [[365, "feature-binning"]], "Feature Engineering Solutions": [[366, "feature-engineering-solutions"]], "Feature Importance": [[327, "feature-importance"], [355, "feature-importance"], [359, "feature-importance"], [360, "feature-importance"]], "Feature Importance Plot": [[361, "feature-importance-plot"]], "Feature Manipulation": [[325, "feature-manipulation"]], "Feature Selection": [[4, null], [327, null]], "Feature Selection and Management": [[109, "feature-selection-and-management"]], "Feature importance": [[13, "feature-importance"], [14, "feature-importance"]], "Feature importance analysis": [[19, "feature-importance-analysis"], [20, "feature-importance-analysis"], [25, "feature-importance-analysis"], [26, "feature-importance-analysis"]], "Feature selection operations": [[4, "feature-selection-operations"]], "Frequently Asked Questions": [[92, null]], "Full Conformal Prediction": [[368, "full-conformal-prediction"]], "Functional ANOVA Decomposition Process for Tree Ensembles": [[356, "functional-anova-decomposition-process-for-tree-ensembles"]], "Functional ANOVA Representation": [[355, "functional-anova-representation"], [360, "functional-anova-representation"]], "GAMI-Net": [[355, null]], "GAMI-Net in MoDeVa": [[355, "gami-net-in-modeva"]], "GAMINet Classification": [[19, null]], "GAMINet Regression": [[20, null]], "GBDT in MoDeVa": [[356, "gbdt-in-modeva"]], "GBLT in MoDeVa": [[357, "gblt-in-modeva"]], "GLM in MoDeVa": [[358, "glm-in-modeva"]], "Gallery of Modeva Examples": [[93, null]], "Gating Decomposition": [[359, "gating-decomposition"]], "Generalization Gap": [[366, "generalization-gap"]], "Generalized Linear Models": [[358, null]], "Generate and save plots": [[53, "generate-and-save-plots"]], "Get data split by name": [[10, "get-data-split-by-name"]], "Get prediction interval": [[39, "get-prediction-interval"], [40, "get-prediction-interval"]], "Global Effect Plot": [[355, "global-effect-plot"], [356, "global-effect-plot"], [359, "global-effect-plot"], [360, "global-effect-plot"]], "Global Explainability": [[86, null], [331, null]], "Global Interpretation": [[355, "global-interpretation"], [356, "global-interpretation"], [357, "global-interpretation"], [358, "global-interpretation"], [359, "global-interpretation"], [360, "global-interpretation"], [362, "global-interpretation"]], "Global effects interpretation": [[19, "global-effects-interpretation"]], "Global tree interpretation": [[15, "global-tree-interpretation"], [16, "global-tree-interpretation"]], "Gradient Boosted Decision Trees": [[356, null]], "Gradient Boosted Linear Tree (GBLT)": [[357, "gradient-boosted-linear-tree-gblt"]], "Grid Search": [[43, null]], "H-statistic": [[86, "h-statistic"]], "Handling Missing Values": [[322, "handling-missing-values"]], "Histogram-based outlier detection": [[324, "histogram-based-outlier-detection"]], "Hstats (Friedman\u2019s H-statistic)": [[331, "hstats-friedman-s-h-statistic"], [334, null]], "Hyperparameter Tuning": [[42, null], [48, "hyperparameter-tuning"], [308, null]], "ICE (Individual Conditional Expectation)": [[335, null]], "Identification of Reliability Issue and Impactful Variables": [[368, "identification-of-reliability-issue-and-impactful-variables"]], "Identification of Robustness Issue and Impactful Variables": [[370, "identification-of-robustness-issue-and-impactful-variables"]], "Identifying Problematic Regions": [[366, "identifying-problematic-regions"]], "Implementation Considerations": [[355, "implementation-considerations"], [360, "implementation-considerations"]], "Implementation Framework": [[366, "implementation-framework"]], "Individual Prediction Analysis": [[355, "individual-prediction-analysis"], [356, "individual-prediction-analysis"], [357, "individual-prediction-analysis"], [359, "individual-prediction-analysis"], [360, "individual-prediction-analysis"], [361, "individual-prediction-analysis"]], "Inherent Interpretation": [[313, "inherent-interpretation"]], "Initialize ModelZoo": [[49, "initialize-modelzoo"]], "Initialize the Panel": [[342, "initialize-the-panel"], [343, "initialize-the-panel"], [344, "initialize-the-panel"], [345, "initialize-the-panel"], [346, "initialize-the-panel"], [347, "initialize-the-panel"], [348, "initialize-the-panel"], [349, "initialize-the-panel"], [351, "initialize-the-panel"], [352, "initialize-the-panel"], [353, "initialize-the-panel"]], "Initialize the pipeline with steps": [[54, "initialize-the-pipeline-with-steps"]], "Input Perturbation for Robustness Test": [[370, "input-perturbation-for-robustness-test"]], "Installation": [[107, null], [107, "id1"]], "Interaction with ANOVA Decomposition": [[356, "interaction-with-anova-decomposition"]], "Interpret effect importance": [[21, "interpret-effect-importance"], [22, "interpret-effect-importance"]], "Interpret effects": [[21, "interpret-effects"], [22, "interpret-effects"]], "Interpret feature importance": [[21, "interpret-feature-importance"], [22, "interpret-feature-importance"]], "Interpret residual by a XGB depth-2 model": [[57, "interpret-residual-by-a-xgb-depth-2-model"], [58, "interpret-residual-by-a-xgb-depth-2-model"]], "Interpretability Enhancement": [[356, "interpretability-enhancement"]], "Interpretability Through Functional ANOVA": [[356, "interpretability-through-functional-anova"]], "Interpretable GBLT with Depth-1 Trees": [[357, "interpretable-gblt-with-depth-1-trees"]], "Interpretable Models": [[309, null], [354, null]], "Interpretation: Functional ANOVA Representation": [[359, "interpretation-functional-anova-representation"]], "Interpreting Residual Analysis Results": [[367, "interpreting-residual-analysis-results"]], "Introduction": [[340, null], [367, "introduction"], [371, "introduction"]], "Isolation Forest": [[324, "isolation-forest"], [328, "isolation-forest"]], "Jensen-Shannon Divergence": [[369, "jensen-shannon-divergence"]], "K-Nearest Neighbor": [[324, "k-nearest-neighbor"]], "KernelSHAP": [[332, "kernelshap"], [339, "kernelshap"]], "Key Approaches to Weakness Detection": [[371, "key-approaches-to-weakness-detection"]], "Key Modules": [[340, "key-modules"]], "KmeansTree": [[324, "kmeanstree"]], "Kolmogorov-Smirnov Statistic": [[369, "kolmogorov-smirnov-statistic"]], "LGBM Linear Tree model": [[23, "lgbm-linear-tree-model"], [24, "lgbm-linear-tree-model"]], "LIME": [[87, "lime"]], "LIME (Local Interpretable Model-Agnostic Explanation)": [[332, "lime-local-interpretable-model-agnostic-explanation"], [336, null]], "LLM Summary Table": [[361, "llm-summary-table"]], "LLM parallel coordinate plot": [[17, "llm-parallel-coordinate-plot"], [18, "llm-parallel-coordinate-plot"]], "LLM profile plot": [[361, "llm-profile-plot"]], "LLM profile plot against a feature": [[17, "llm-profile-plot-against-a-feature"], [18, "llm-profile-plot-against-a-feature"]], "LLM summary table": [[17, "llm-summary-table"], [18, "llm-summary-table"]], "Limit the number of bars in bar plots": [[53, "limit-the-number-of-bars-in-bar-plots"]], "Linear Regression (Regression)": [[14, null]], "Linear Tree": [[357, "linear-tree"]], "Linear Tree Classification": [[23, null]], "Linear Tree Regression": [[24, null]], "Linear Tree and Gradient Boosted Linear Trees": [[357, null]], "Linear Tree in MoDeVa": [[357, "linear-tree-in-modeva"]], "LinearSHAP and TreeSHAP": [[332, "linearshap-and-treeshap"]], "List the available sub-figure names": [[53, "list-the-available-sub-figure-names"]], "Load and Register Fitted Models": [[373, "load-and-register-fitted-models"]], "Load and prepare dataset": [[49, "load-and-prepare-dataset"]], "Load and verify registered models": [[49, "load-and-verify-registered-models"]], "Load data from MLFlow": [[2, "load-data-from-mlflow"]], "Load the built-in data": [[2, "load-the-built-in-data"]], "Load the first 5000 rows into Modeva": [[10, "load-the-first-5000-rows-into-modeva"]], "Load the samples indexed from 5000 to 8000 as \u201coot1\u201d data split": [[10, "load-the-samples-indexed-from-5000-to-8000-as-oot1-data-split"]], "Load the samples indexed from 8000 to 9000 as \u201coot2\u201d data split": [[10, "load-the-samples-indexed-from-8000-to-9000-as-oot2-data-split"]], "Load the samples indexed from 9000 to the last one as \u201coot3\u201d data split": [[10, "load-the-samples-indexed-from-9000-to-the-last-one-as-oot3-data-split"]], "Local Explainability": [[87, null], [332, null]], "Local Interpretation": [[355, "local-interpretation"], [356, "local-interpretation"], [357, "local-interpretation"], [358, "local-interpretation"], [359, "local-interpretation"], [360, "local-interpretation"], [361, "local-interpretation"], [362, "local-interpretation"]], "Local Linear Models (LLM)": [[361, "local-linear-models-llm"]], "Local MOE weights interpretation": [[21, "local-moe-weights-interpretation"], [22, "local-moe-weights-interpretation"]], "Local effect importance analysis": [[21, "local-effect-importance-analysis"], [22, "local-effect-importance-analysis"], [25, "local-effect-importance-analysis"], [26, "local-effect-importance-analysis"]], "Local feature importance analysis": [[13, "local-feature-importance-analysis"], [14, "local-feature-importance-analysis"], [17, "local-feature-importance-analysis"], [18, "local-feature-importance-analysis"], [19, "local-feature-importance-analysis"], [20, "local-feature-importance-analysis"], [21, "local-feature-importance-analysis"], [22, "local-feature-importance-analysis"], [25, "local-feature-importance-analysis"], [26, "local-feature-importance-analysis"]], "Local feature importance with linear coefficients": [[13, "local-feature-importance-with-linear-coefficients"], [14, "local-feature-importance-with-linear-coefficients"]], "Local tree interpretation": [[15, "local-tree-interpretation"], [16, "local-tree-interpretation"]], "Logistic Regression (Classification)": [[13, null]], "Loss Function with Monotonicity Constraint": [[360, "loss-function-with-monotonicity-constraint"]], "Loss Function with Monotonicity Constraint in GAMI-Net": [[355, "loss-function-with-monotonicity-constraint-in-gami-net"]], "Low Code": [[108, null]], "Low code": [[341, null]], "Main Effects": [[356, "main-effects"]], "Main effect plot": [[13, "main-effect-plot"], [14, "main-effect-plot"], [25, "main-effect-plot"], [26, "main-effect-plot"]], "Managing Datasets": [[353, "managing-datasets"]], "Manifestations": [[366, "manifestations"]], "Marginal Distribution Drift": [[323, "marginal-distribution-drift"]], "Marginal Distribution of Outliers": [[324, "marginal-distribution-of-outliers"]], "Mathematical Formulation": [[356, "mathematical-formulation"], [359, "mathematical-formulation"]], "Mean Absolute Error": [[320, "mean-absolute-error"]], "Mean Squared Error": [[320, "mean-squared-error"]], "Measuring Distribution Drift": [[369, "measuring-distribution-drift"]], "Methodology": [[324, "methodology"], [367, "methodology"]], "Metrics for Group Fairness": [[365, "metrics-for-group-fairness"]], "Mixture of Expert (MoE) Classification": [[21, null]], "Mixture of Expert (MoE) Regression": [[22, null]], "Mixture of Experts (MoE)": [[359, null]], "MoDeVa.ai": [[377, null]], "MoE in MoDeVa": [[359, "moe-in-modeva"]], "MoReLUDNN Classification": [[17, null]], "MoReLUDNN Regression": [[18, null]], "Model Architecture": [[359, "model-architecture"]], "Model Calibration": [[37, null], [48, "model-calibration"]], "Model Comparison": [[313, "model-comparison"], [317, null], [347, null]], "Model Development": [[48, null]], "Model Explainability": [[330, null], [348, null]], "Model Fairness Analysis (Classification)": [[83, null]], "Model Interpretation": [[361, "model-interpretation"]], "Model Management": [[310, "model-management"], [375, "model-management"]], "Model Performance": [[60, null], [89, "model-performance"]], "Model Quality": [[356, "model-quality"]], "Model Registry": [[310, "model-registry"]], "Model Residual": [[56, null], [89, "model-residual"]], "Model Test": [[349, null]], "Model Training": [[310, "model-training"], [350, null], [372, null]], "Model Tuning": [[351, null], [374, null]], "Model Validation": [[89, null]], "Model Wrappers": [[315, null], [376, null]], "Model Wrapping": [[363, null]], "Model Zoo": [[310, null]], "Model Zoo and Leaderboard": [[375, null]], "Model architecture": [[360, "model-architecture"], [361, "model-architecture"]], "Model comparison": [[63, "model-comparison"], [64, "model-comparison"], [67, "model-comparison"], [68, "model-comparison"]], "Model interpretation examples": [[49, "model-interpretation-examples"]], "Model registration and loading": [[49, "model-registration-and-loading"]], "Model reliability comparison": [[71, "model-reliability-comparison"], [72, "model-reliability-comparison"]], "Model robustness comparison": [[80, "model-robustness-comparison"]], "Model-Centric Approaches": [[366, "model-centric-approaches"], [369, "model-centric-approaches"], [370, "model-centric-approaches"]], "ModelTune Usage": [[374, "modeltune-usage"]], "ModelZoo": [[49, null]], "Monotonicity Constraint in GBDT": [[356, "monotonicity-constraint-in-gbdt"]], "Monotonicity Constraints in GAMI-Net": [[355, "monotonicity-constraints-in-gami-net"]], "Monotonicity Constraints in Neural Tree": [[360, "monotonicity-constraints-in-neural-tree"]], "Neural Tree": [[360, null]], "Neural Tree Transformation": [[360, "neural-tree-transformation"]], "Neural Tree in MoDeVa": [[360, "neural-tree-in-modeva"]], "Neural Tree model with Monotonicity Constraints": [[23, "neural-tree-model-with-monotonicity-constraints"], [24, "neural-tree-model-with-monotonicity-constraints"]], "Nonconformity Score:": [[368, "nonconformity-score"]], "Numerical Features": [[325, "numerical-features"]], "Numerical Variable Binning": [[322, "numerical-variable-binning"]], "Numerical Variable Scaling": [[322, "numerical-variable-scaling"]], "Numerical Variables": [[322, "numerical-variables"]], "One Class SVM": [[324, "one-class-svm"]], "One-way ALE": [[333, "one-way-ale"]], "One-way PDPs": [[337, "one-way-pdps"]], "Outcome Analysis": [[340, "outcome-analysis"]], "Outlier Detection": [[8, null], [109, "outlier-detection"], [328, null]], "Outlier Score distribution": [[324, "outlier-score-distribution"]], "Outlier detection by CBLOF": [[8, "outlier-detection-by-cblof"]], "Outlier detection by Isolation forest": [[8, "outlier-detection-by-isolation-forest"]], "Outlier detection by PCA": [[8, "outlier-detection-by-pca"]], "Overfit Comparison": [[318, "overfit-comparison"], [320, "overfit-comparison"], [366, "overfit-comparison"]], "Overfit Detection": [[66, null], [89, "overfit-detection"]], "Overfitting Analysis (Classification)": [[67, null]], "Overfitting Analysis (Regression)": [[68, null]], "Overfitting Characterization": [[366, "overfitting-characterization"]], "Overfitting Slicing in MoDeVa": [[366, "overfitting-slicing-in-modeva"]], "Overfitting and Model Robustness": [[366, "overfitting-and-model-robustness"]], "PCA": [[3, "pca"]], "PCA Plot": [[326, "pca-plot"]], "PCA-based Method": [[328, "pca-based-method"]], "PDP (Partial Dependence Plot)": [[331, "pdp-partial-dependence-plot"], [337, null]], "PFI (Permutation Feature Importance)": [[331, "pfi-permutation-feature-importance"], [338, null]], "Pairwise Interactions": [[356, "pairwise-interactions"]], "Parallel Coordinate Plot": [[361, "parallel-coordinate-plot"]], "Particle Swarm Optimization Search": [[45, null]], "Performance Comparison": [[367, "performance-comparison"]], "Performance Evaluation in MoDeVa": [[367, "performance-evaluation-in-modeva"]], "Performance Metrics (Classification)": [[61, null]], "Performance Metrics (Regression)": [[62, null]], "Performance and Residual Analysis": [[367, null]], "Permutation feature importance": [[86, "permutation-feature-importance"]], "Perturbation for Categorical Variable": [[370, "perturbation-for-categorical-variable"]], "Pipeline": [[54, null], [311, null]], "Post-hoc Explanation": [[313, "post-hoc-explanation"]], "Practical Applications": [[366, "practical-applications"]], "Practical Considerations": [[370, "practical-considerations"]], "Preprocessing": [[109, "preprocessing"]], "Prerequisite": [[107, "prerequisite"]], "Principal Component Analysis": [[324, "principal-component-analysis"]], "Properties": [[310, "properties"]], "Purification Constraints": [[355, "purification-constraints"], [360, "purification-constraints"]], "Purpose of Residual Analysis": [[367, "purpose-of-residual-analysis"]], "Quantile Perturbation with Uniform Noise": [[370, "quantile-perturbation-with-uniform-noise"]], "R-squared Score": [[320, "r-squared-score"]], "RCIT Test": [[327, "rcit-test"]], "RCIT based feature selection": [[4, "rcit-based-feature-selection"]], "Random Search": [[44, null]], "Random forest-based residual clustering analysis (absolute residual)": [[57, "random-forest-based-residual-clustering-analysis-absolute-residual"], [58, "random-forest-based-residual-clustering-analysis-absolute-residual"]], "Random forest-based residual clustering analysis (perturbed residual)": [[57, "random-forest-based-residual-clustering-analysis-perturbed-residual"], [58, "random-forest-based-residual-clustering-analysis-perturbed-residual"]], "Random forest-based residual clustering analysis (prediction interval width)": [[57, "random-forest-based-residual-clustering-analysis-prediction-interval-width"], [58, "random-forest-based-residual-clustering-analysis-prediction-interval-width"]], "Random subsampling": [[6, "random-subsampling"]], "ReLU DNN in MoDeVa": [[361, "relu-dnn-in-modeva"]], "ReLU Neural Network": [[361, null]], "References": [[324, null], [326, "references"], [326, null], [327, "references"], [327, null], [328, "references"], [328, null], [331, "references"], [331, null], [332, "references"], [332, null], [334, null], [335, null], [338, null], [339, null]], "Register H2O Models": [[373, null]], "Register data into MLFlow": [[2, "register-data-into-mlflow"]], "Registry Hub": [[353, null]], "Regression": [[309, "regression"]], "Regression Metrics": [[367, "regression-metrics"]], "Reliability": [[368, null]], "Reliability Analysis": [[70, null], [89, "reliability-analysis"]], "Reliability Analysis (Classification)": [[71, null]], "Reliability Analysis (Regression)": [[72, null]], "Reliability Analysis in MoDeVa": [[368, "reliability-analysis-in-modeva"]], "Reliability Assessment:": [[368, "reliability-assessment"]], "Reliability Comparison": [[318, "reliability-comparison"], [320, "reliability-comparison"], [368, "reliability-comparison"]], "Reliability Diagnostics in MoDeVa": [[368, "reliability-diagnostics-in-modeva"]], "Reliability Diagram Comparison": [[318, "reliability-diagram-comparison"]], "Remediation Strategies for Model Weaknesses Identified by Gap Analysis": [[366, "remediation-strategies-for-model-weaknesses-identified-by-gap-analysis"]], "Remove Features": [[325, "remove-features"]], "Reset preprocessing": [[5, "reset-preprocessing"]], "Reset subsampling by ds.set_active_samples()": [[6, "reset-subsampling-by-ds-set-active-samples"]], "Residual Analysis": [[367, "residual-analysis"]], "Residual Analysis (Classification)": [[57, null]], "Residual Analysis (Regression)": [[58, null]], "Residual Analysis in MoDeVa": [[367, "residual-analysis-in-modeva"]], "Resilience": [[369, null]], "Resilience Analysis": [[74, null], [89, "resilience-analysis"]], "Resilience Analysis (Classification)": [[75, null]], "Resilience Analysis (Regression)": [[76, null]], "Resilience Analysis in MoDeVa": [[369, "resilience-analysis-in-modeva"]], "Resilience Comparison": [[318, "resilience-comparison"], [320, "resilience-comparison"], [369, "resilience-comparison"]], "Resilience Distance": [[318, "resilience-distance"], [320, "resilience-distance"]], "Resilience Performance": [[318, "resilience-performance"], [320, "resilience-performance"]], "Resilience Through Supervised Clustering Analysis": [[369, "resilience-through-supervised-clustering-analysis"]], "Resilience comparison": [[75, "resilience-comparison"], [76, "resilience-comparison"]], "Rest calibration when needed": [[38, "rest-calibration-when-needed"], [39, "rest-calibration-when-needed"], [40, "rest-calibration-when-needed"]], "Retrain model with best hyperparameter": [[43, "retrain-model-with-best-hyperparameter"], [44, "retrain-model-with-best-hyperparameter"], [45, "retrain-model-with-best-hyperparameter"], [46, "retrain-model-with-best-hyperparameter"]], "Robustness": [[370, null]], "Robustness Analysis": [[78, null], [89, "robustness-analysis"]], "Robustness Analysis (Classification)": [[79, null]], "Robustness Analysis (Regression)": [[80, null]], "Robustness Analysis in MoDeVa": [[370, "robustness-analysis-in-modeva"]], "Robustness Comparison": [[318, "robustness-comparison"], [320, "robustness-comparison"], [370, "robustness-comparison"]], "Robustness Performance": [[318, "robustness-performance"], [320, "robustness-performance"]], "Robustness Performance on Worst Samples": [[318, "robustness-performance-on-worst-samples"], [320, "robustness-performance-on-worst-samples"]], "Robustness comparison": [[79, "robustness-comparison"]], "Run Diagnostic Tests": [[373, "run-diagnostic-tests"]], "Run HPO": [[46, "run-hpo"]], "Run PSO search": [[45, "run-pso-search"]], "Run grid search": [[43, "run-grid-search"]], "Run random search": [[44, "run-random-search"]], "Run the pipeline": [[54, "run-the-pipeline"]], "SHAP (SHapley Additive exPlanations)": [[332, "shap-shapley-additive-explanations"], [339, null]], "SHAP Dependence Plot": [[339, "shap-dependence-plot"]], "SHAP Feature importance": [[339, "shap-feature-importance"]], "SHAP Summary plot": [[339, "shap-summary-plot"]], "Save Fitted Models": [[373, "save-fitted-models"]], "Save figures": [[53, "save-figures"]], "Save the pipeline results (optional)": [[54, "save-the-pipeline-results-optional"]], "Scored Model Wrapper": [[376, "scored-model-wrapper"]], "Scripts for building a H2O model": [[29, "scripts-for-building-a-h2o-model"]], "Scripts for building a pyspark model": [[30, "scripts-for-building-a-pyspark-model"]], "Scripts to build a model": [[32, "scripts-to-build-a-model"], [33, "scripts-to-build-a-model"]], "Segmented": [[319, "segmented"]], "Set the data steps": [[5, "set-the-data-steps"]], "Show the available data splits": [[10, "show-the-available-data-splits"]], "Simple Perturbation with Normally Distributed Random Noise": [[370, "simple-perturbation-with-normally-distributed-random-noise"]], "Sklearn Model Wrapper": [[376, "sklearn-model-wrapper"]], "Sliced Performance (Classification)": [[63, null]], "Sliced Performance (Regression)": [[64, null]], "Slicing Generalization Gap": [[366, "slicing-generalization-gap"]], "Slicing fairness analysis": [[83, "slicing-fairness-analysis"]], "Slicing for Fairness Diagnostics": [[365, "slicing-for-fairness-diagnostics"]], "Slicing reliability": [[71, "slicing-reliability"], [72, "slicing-reliability"]], "Slicing robustness analysis": [[79, "slicing-robustness-analysis"], [80, "slicing-robustness-analysis"]], "Special Cases with Limited Depth": [[356, "special-cases-with-limited-depth"]], "Special Features": [[340, "special-features"]], "Split Conformal Prediction": [[368, "split-conformal-prediction"]], "Step 1: Dataset & Model Selection": [[350, "step-1-dataset-model-selection"]], "Step 1: Load and Select Dataset": [[343, "step-1-load-and-select-dataset"], [344, "step-1-load-and-select-dataset"], [345, "step-1-load-and-select-dataset"], [346, "step-1-load-and-select-dataset"], [348, "step-1-load-and-select-dataset"]], "Step 1: Select Dataset & Model": [[349, "step-1-select-dataset-model"]], "Step 1: Select Dataset & Models": [[347, "step-1-select-dataset-models"], [352, "step-1-select-dataset-models"]], "Step 1: Select Dataset, Model, and Search Method": [[351, "step-1-select-dataset-model-and-search-method"]], "Step 1: Select variables and global settings": [[342, "step-1-select-variables-and-global-settings"]], "Step 2: Configure Tuning Parameters": [[351, "step-2-configure-tuning-parameters"]], "Step 2: Configure Visualization Settings": [[344, "step-2-configure-visualization-settings"], [345, "step-2-configure-visualization-settings"]], "Step 2: Detect Weak Features and Segments": [[352, "step-2-detect-weak-features-and-segments"]], "Step 2: Global Explanations": [[348, "step-2-global-explanations"]], "Step 2: Perform Correlation Analysis": [[346, "step-2-perform-correlation-analysis"]], "Step 2: Performance Comparison": [[347, "step-2-performance-comparison"]], "Step 2: Performance Evaluation": [[349, "step-2-performance-evaluation"]], "Step 2: Process Features": [[342, "step-2-process-features"]], "Step 2: Review Dataset Overview": [[343, "step-2-review-dataset-overview"]], "Step 2: Train a Model": [[350, "step-2-train-a-model"]], "Step 3: Adjust Feature Types (If Necessary)": [[344, "step-3-adjust-feature-types-if-necessary"], [345, "step-3-adjust-feature-types-if-necessary"]], "Step 3: Analyze Numerical Features": [[343, "step-3-analyze-numerical-features"]], "Step 3: Apply Principal Component Analysis (PCA)": [[346, "step-3-apply-principal-component-analysis-pca"]], "Step 3: Evaluate and Compare Models": [[350, "step-3-evaluate-and-compare-models"]], "Step 3: Local Explanations": [[348, "step-3-local-explanations"]], "Step 3: Reliability Comparison": [[347, "step-3-reliability-comparison"]], "Step 3: Reliability Testing": [[349, "step-3-reliability-testing"]], "Step 3: Run Tuning": [[351, "step-3-run-tuning"]], "Step 3: Saving Results": [[352, "step-3-saving-results"]], "Step 3: Splitting, Sampling & Registering": [[342, "step-3-splitting-sampling-registering"]], "Step 4: Analyze Categorical Features": [[343, "step-4-analyze-categorical-features"]], "Step 4: Apply UMAP for Advanced Visualization": [[346, "step-4-apply-umap-for-advanced-visualization"]], "Step 4: Register a Model": [[350, "step-4-register-a-model"]], "Step 4: Register and Save the Visualization:": [[344, "step-4-register-and-save-the-visualization"], [345, "step-4-register-and-save-the-visualization"]], "Step 4: Register the Best Model": [[351, "step-4-register-the-best-model"]], "Step 4: Robustness Comparison": [[347, "step-4-robustness-comparison"]], "Step 4: Robustness Testing": [[349, "step-4-robustness-testing"]], "Step 4: Saving Results": [[348, "step-4-saving-results"]], "Step 5: Adjust Data Types (If Necessary)": [[343, "step-5-adjust-data-types-if-necessary"]], "Step 5: Resilience Comparison": [[347, "step-5-resilience-comparison"]], "Step 5: Resilience Testing": [[349, "step-5-resilience-testing"]], "Step 5: Save and Export Results": [[346, "step-5-save-and-export-results"]], "Step 6: Save and Export Results": [[343, "step-6-save-and-export-results"]], "Step 6: Saving Results": [[347, "step-6-saving-results"], [349, "step-6-saving-results"]], "Step-by-Step Process": [[359, "step-by-step-process"]], "Steps in Residual Analysis": [[367, "steps-in-residual-analysis"]], "Strategies for Addressing Model Weaknesses": [[368, "strategies-for-addressing-model-weaknesses"], [369, "strategies-for-addressing-model-weaknesses"], [370, "strategies-for-addressing-model-weaknesses"]], "Subsampling": [[6, null], [329, "subsampling"]], "Subsampling and Data Drift": [[329, null]], "Summary Statistics": [[325, "summary-statistics"]], "Supervised Learning for Residual Analysis": [[367, "supervised-learning-for-residual-analysis"]], "Supervised Machine Learning: Random Forest Clustering": [[368, "supervised-machine-learning-random-forest-clustering"], [370, "supervised-machine-learning-random-forest-clustering"]], "Techniques for Residual Analysis": [[367, "techniques-for-residual-analysis"]], "Test Error:": [[366, "test-error"]], "Test Suite": [[313, null]], "The Waterfall plot": [[339, "the-waterfall-plot"]], "Theoretical Framework": [[366, "theoretical-framework"]], "Threshold Adjustment": [[365, "threshold-adjustment"]], "Track Experiments": [[353, "track-experiments"]], "Tradeoffs Between Performance and Fairness": [[365, "tradeoffs-between-performance-and-fairness"]], "Train all models and show leaderboard": [[49, "train-all-models-and-show-leaderboard"]], "Train and Register Models": [[373, "train-and-register-models"]], "Train model": [[13, "train-model"], [14, "train-model"], [15, "train-model"], [16, "train-model"], [17, "train-model"], [18, "train-model"], [19, "train-model"], [20, "train-model"], [25, "train-model"], [26, "train-model"]], "Train models": [[21, "train-models"], [22, "train-models"]], "Train-Test Split Management": [[109, "train-test-split-management"]], "Training Error:": [[366, "training-error"]], "Training and Leaderboard": [[375, "training-and-leaderboard"]], "Tree Ensemble Models (Classification)": [[25, null]], "Tree Ensemble Models (Regression)": [[26, null]], "Trouble Shooting": [[107, "trouble-shooting"]], "Troubleshooting": [[346, "troubleshooting"], [351, "troubleshooting"]], "Tuning with optuna (Experimental)": [[46, null]], "Two-way ALE": [[333, "two-way-ale"]], "Two-way PDPs": [[337, "two-way-pdps"]], "Umap": [[3, "umap"]], "Underfitting and Overfitting": [[366, null]], "Unfairness mitigation": [[83, "unfairness-mitigation"]], "Univariate (1D) Plots": [[326, "univariate-1d-plots"]], "Unused API Entries": [[378, null]], "Uploading Data": [[353, "uploading-data"]], "Usage": [[333, "usage"], [334, "usage"], [335, "usage"], [336, "usage"], [337, "usage"], [338, "usage"], [339, "usage"]], "Using Modeva": [[316, null]], "Utilities": [[51, null], [313, "utilities"], [314, null]], "Validation Result": [[312, null]], "ValidationResult - Attributes": [[52, null]], "ValidationResult - Visualization": [[53, null]], "View and use outlier detection results": [[8, "view-and-use-outlier-detection-results"]], "Visualize prediction interval": [[40, "visualize-prediction-interval"]], "Visualize the residual against model prediction": [[58, "visualize-the-residual-against-model-prediction"]], "Visualize the residual against model prediction (predict proba)": [[57, "visualize-the-residual-against-model-prediction-predict-proba"]], "Visualize the residual against predictor": [[57, "visualize-the-residual-against-predictor"], [58, "visualize-the-residual-against-predictor"]], "Visualize the residual against response variable": [[57, "visualize-the-residual-against-response-variable"], [58, "visualize-the-residual-against-response-variable"]], "Wasserstein Distance": [[369, "wasserstein-distance"]], "Weakness Comparison": [[371, "weakness-comparison"]], "Weakness Detection": [[371, null]], "Weakness Detection Methods": [[366, "weakness-detection-methods"]], "Weakness Detection in MoDeVa": [[371, "weakness-detection-in-modeva"]], "Weakness Test": [[352, null]], "Weakspot Comparison": [[318, "weakspot-comparison"], [320, "weakspot-comparison"]], "Why Weakness Detection is Important": [[371, "why-weakness-detection-is-important"]], "Workflow": [[342, "workflow"], [343, "workflow"], [344, "workflow"], [345, "workflow"], [346, "workflow"], [347, "workflow"], [348, "workflow"], [349, "workflow"], [350, "workflow"], [351, "workflow"], [352, "workflow"]], "Wrap the PySpark model into Modeva": [[30, "wrap-the-pyspark-model-into-modeva"]], "Wrap the data": [[30, "wrap-the-data"]], "Wrap the data into Modeva": [[29, "wrap-the-data-into-modeva"], [31, "wrap-the-data-into-modeva"], [32, "wrap-the-data-into-modeva"], [33, "wrap-the-data-into-modeva"], [34, "wrap-the-data-into-modeva"], [35, "wrap-the-data-into-modeva"]], "Wrap the model into Modeva": [[29, "wrap-the-model-into-modeva"], [31, "wrap-the-model-into-modeva"], [32, "wrap-the-model-into-modeva"], [33, "wrap-the-model-into-modeva"]], "Wrapping Arbitrary Classifier": [[32, null]], "Wrapping Arbitrary Regressor": [[33, null]], "Wrapping H2O Models": [[29, null]], "Wrapping PySpark Models": [[30, null]], "Wrapping Scored Classifier": [[34, null]], "Wrapping Scored Regressor": [[35, null]], "Wrapping sklearn-style Models": [[31, null]], "XGB-PFI based feature selection": [[4, "xgb-pfi-based-feature-selection"]], "XI Correlation": [[3, "xi-correlation"]], "modeva.DataSet.all_feature_names": [[110, null]], "modeva.DataSet.all_feature_types": [[111, null]], "modeva.DataSet.bin_numerical": [[112, null]], "modeva.DataSet.data": [[113, null]], "modeva.DataSet.data_drift_test": [[114, null]], "modeva.DataSet.delete_extra_data": [[115, null]], "modeva.DataSet.delete_registered_data": [[116, null]], "modeva.DataSet.detect_outlier_cblof": [[117, null]], "modeva.DataSet.detect_outlier_isolation_forest": [[118, null]], "modeva.DataSet.detect_outlier_pca": [[119, null]], "modeva.DataSet.eda_1d": [[120, null]], "modeva.DataSet.eda_2d": [[121, null]], "modeva.DataSet.eda_3d": [[122, null]], "modeva.DataSet.eda_correlation": [[123, null]], "modeva.DataSet.eda_pca": [[124, null]], "modeva.DataSet.eda_umap": [[125, null]], "modeva.DataSet.encode_categorical": [[126, null]], "modeva.DataSet.feature_names": [[127, null]], "modeva.DataSet.feature_names_categorical": [[128, null]], "modeva.DataSet.feature_names_mixed": [[129, null]], "modeva.DataSet.feature_names_numerical": [[130, null]], "modeva.DataSet.feature_select_corr": [[131, null]], "modeva.DataSet.feature_select_rcit": [[132, null]], "modeva.DataSet.feature_select_xgbpfi": [[133, null]], "modeva.DataSet.feature_types": [[134, null]], "modeva.DataSet.get_X_y_data": [[135, null]], "modeva.DataSet.get_data": [[136, null]], "modeva.DataSet.get_data_list": [[137, null]], "modeva.DataSet.get_extra_data_list": [[138, null]], "modeva.DataSet.get_prediction_data": [[139, null]], "modeva.DataSet.get_prediction_proba_data": [[140, null]], "modeva.DataSet.get_preprocessor": [[141, null]], "modeva.DataSet.get_protected_data": [[142, null]], "modeva.DataSet.get_raw_data": [[143, null]], "modeva.DataSet.impute_missing": [[144, null]], "modeva.DataSet.inverse_transform": [[145, null]], "modeva.DataSet.is_splitted": [[146, null]], "modeva.DataSet.list_registered_data": [[147, null]], "modeva.DataSet.load": [[148, null]], "modeva.DataSet.load_csv": [[149, null]], "modeva.DataSet.load_dataframe": [[150, null]], "modeva.DataSet.load_dataframe_train_test": [[151, null]], "modeva.DataSet.load_preprocessing": [[152, null]], "modeva.DataSet.load_registered_data": [[153, null]], "modeva.DataSet.load_spark": [[154, null]], "modeva.DataSet.n_features": [[155, null]], "modeva.DataSet.name": [[156, null]], "modeva.DataSet.prediction": [[157, null]], "modeva.DataSet.preprocess": [[158, null]], "modeva.DataSet.raw_data": [[159, null]], "modeva.DataSet.register": [[160, null]], "modeva.DataSet.reset_preprocess": [[161, null]], "modeva.DataSet.sample_weight": [[162, null]], "modeva.DataSet.save_preprocessing": [[163, null]], "modeva.DataSet.scale_numerical": [[164, null]], "modeva.DataSet.set_active_features": [[165, null]], "modeva.DataSet.set_feature_type": [[166, null]], "modeva.DataSet.set_inactive_features": [[167, null]], "modeva.DataSet.set_prediction": [[168, null]], "modeva.DataSet.set_prediction_proba": [[169, null]], "modeva.DataSet.set_protected_data": [[170, null]], "modeva.DataSet.set_protected_extra_data": [[171, null]], "modeva.DataSet.set_random_split": [[172, null]], "modeva.DataSet.set_raw_extra_data": [[173, null]], "modeva.DataSet.set_sample_weight": [[174, null]], "modeva.DataSet.set_target": [[175, null]], "modeva.DataSet.set_task_type": [[176, null]], "modeva.DataSet.set_test_idx": [[177, null]], "modeva.DataSet.set_train_idx": [[178, null]], "modeva.DataSet.shape": [[179, null]], "modeva.DataSet.subsample_random": [[180, null]], "modeva.DataSet.summary": [[181, null]], "modeva.DataSet.task_type": [[182, null]], "modeva.DataSet.test_prediction": [[183, null]], "modeva.DataSet.test_sample_weight": [[184, null]], "modeva.DataSet.test_x": [[185, null]], "modeva.DataSet.test_y": [[186, null]], "modeva.DataSet.to_df": [[187, null]], "modeva.DataSet.train_prediction": [[188, null]], "modeva.DataSet.train_sample_weight": [[189, null]], "modeva.DataSet.train_x": [[190, null]], "modeva.DataSet.train_y": [[191, null]], "modeva.DataSet.transform": [[192, null]], "modeva.DataSet.x": [[193, null]], "modeva.DataSet.y": [[194, null]], "modeva.ModelZoo.add_model": [[195, null]], "modeva.ModelZoo.dataset": [[196, null]], "modeva.ModelZoo.delete_registered_model": [[197, null]], "modeva.ModelZoo.get_model": [[198, null]], "modeva.ModelZoo.leaderboard": [[199, null]], "modeva.ModelZoo.list_model_names": [[200, null]], "modeva.ModelZoo.list_registered_models": [[201, null]], "modeva.ModelZoo.load_registered_model": [[202, null]], "modeva.ModelZoo.models": [[203, null]], "modeva.ModelZoo.register": [[204, null]], "modeva.ModelZoo.train": [[205, null]], "modeva.ModelZoo.train_all": [[206, null]], "modeva.TestSuite.compare_accuracy_table": [[207, null]], "modeva.TestSuite.compare_fairness": [[208, null]], "modeva.TestSuite.compare_reliability": [[209, null]], "modeva.TestSuite.compare_residual_cluster": [[210, null]], "modeva.TestSuite.compare_resilience": [[211, null]], "modeva.TestSuite.compare_robustness": [[212, null]], "modeva.TestSuite.compare_slicing_accuracy": [[213, null]], "modeva.TestSuite.compare_slicing_fairness": [[214, null]], "modeva.TestSuite.compare_slicing_overfit": [[215, null]], "modeva.TestSuite.compare_slicing_reliability": [[216, null]], "modeva.TestSuite.compare_slicing_robustness": [[217, null]], "modeva.TestSuite.delete_registed_test": [[218, null]], "modeva.TestSuite.diagnose_accuracy_table": [[219, null]], "modeva.TestSuite.diagnose_fairness": [[220, null]], "modeva.TestSuite.diagnose_mitigate_unfair_binning": [[221, null]], "modeva.TestSuite.diagnose_mitigate_unfair_thresholding": [[222, null]], "modeva.TestSuite.diagnose_reliability": [[223, null]], "modeva.TestSuite.diagnose_residual_analysis": [[224, null]], "modeva.TestSuite.diagnose_residual_cluster": [[225, null]], "modeva.TestSuite.diagnose_residual_interpret": [[226, null]], "modeva.TestSuite.diagnose_resilience": [[227, null]], "modeva.TestSuite.diagnose_robustness": [[228, null]], "modeva.TestSuite.diagnose_slicing_accuracy": [[229, null]], "modeva.TestSuite.diagnose_slicing_fairness": [[230, null]], "modeva.TestSuite.diagnose_slicing_overfit": [[231, null]], "modeva.TestSuite.diagnose_slicing_reliability": [[232, null]], "modeva.TestSuite.diagnose_slicing_robustness": [[233, null]], "modeva.TestSuite.display_test_results": [[234, null]], "modeva.TestSuite.explain_ale": [[235, null]], "modeva.TestSuite.explain_hstatistic": [[236, null]], "modeva.TestSuite.explain_lime": [[237, null]], "modeva.TestSuite.explain_pdp": [[238, null]], "modeva.TestSuite.explain_pfi": [[239, null]], "modeva.TestSuite.explain_shap": [[240, null]], "modeva.TestSuite.export_report": [[241, null]], "modeva.TestSuite.get_dataset": [[242, null]], "modeva.TestSuite.get_interactions": [[243, null]], "modeva.TestSuite.get_main_effects": [[244, null]], "modeva.TestSuite.get_model": [[245, null]], "modeva.TestSuite.interpret_coef": [[246, null]], "modeva.TestSuite.interpret_effects": [[247, null]], "modeva.TestSuite.interpret_effects_moe_average": [[248, null]], "modeva.TestSuite.interpret_fi": [[249, null]], "modeva.TestSuite.interpret_global_tree": [[250, null]], "modeva.TestSuite.interpret_llm_pc": [[251, null]], "modeva.TestSuite.interpret_llm_profile": [[252, null]], "modeva.TestSuite.interpret_llm_summary": [[253, null]], "modeva.TestSuite.interpret_llm_violin": [[254, null]], "modeva.TestSuite.interpret_local_fi": [[255, null]], "modeva.TestSuite.interpret_local_linear_fi": [[256, null]], "modeva.TestSuite.interpret_local_moe_weights": [[257, null]], "modeva.TestSuite.interpret_local_tree": [[258, null]], "modeva.TestSuite.interpret_moe_cluster_analysis": [[259, null]], "modeva.TestSuite.list": [[260, null]], "modeva.TestSuite.list_registered_tests": [[261, null]], "modeva.TestSuite.load_registered_test": [[262, null]], "modeva.TestSuite.register": [[263, null]], "modeva.TestSuite.set_dataset": [[264, null]], "modeva.TestSuite.set_model": [[265, null]], "modeva.automation.pipeline.Pipeline": [[266, null]], "modeva.models.MoCatBoostClassifier": [[267, null]], "modeva.models.MoCatBoostRegressor": [[268, null]], "modeva.models.MoClassifier": [[269, null]], "modeva.models.MoDecisionTreeClassifier": [[270, null]], "modeva.models.MoDecisionTreeRegressor": [[271, null]], "modeva.models.MoElasticNet": [[272, null]], "modeva.models.MoGAMINetClassifier": [[273, null]], "modeva.models.MoGAMINetRegressor": [[274, null]], "modeva.models.MoGLMTreeBoostClassifier": [[275, null]], "modeva.models.MoGLMTreeBoostRegressor": [[276, null]], "modeva.models.MoGLMTreeClassifier": [[277, null]], "modeva.models.MoGLMTreeRegressor": [[278, null]], "modeva.models.MoGradientBoostingClassifier": [[279, null]], "modeva.models.MoGradientBoostingRegressor": [[280, null]], "modeva.models.MoLGBMClassifier": [[281, null]], "modeva.models.MoLGBMRegressor": [[282, null]], "modeva.models.MoLogisticRegression": [[283, null]], "modeva.models.MoMoEClassifier": [[284, null]], "modeva.models.MoMoERegressor": [[285, null]], "modeva.models.MoNeuralTreeClassifier": [[286, null]], "modeva.models.MoNeuralTreeRegressor": [[287, null]], "modeva.models.MoRandomForestClassifier": [[288, null]], "modeva.models.MoRandomForestRegressor": [[289, null]], "modeva.models.MoReLUDNNClassifier": [[290, null]], "modeva.models.MoReLUDNNRegressor": [[291, null]], "modeva.models.MoRegressor": [[292, null]], "modeva.models.MoSKLearnClassifier": [[293, null]], "modeva.models.MoSKLearnRegressor": [[294, null]], "modeva.models.MoScoredClassifier": [[295, null]], "modeva.models.MoScoredRegressor": [[296, null]], "modeva.models.MoXGBClassifier": [[297, null]], "modeva.models.MoXGBRegressor": [[298, null]], "modeva.models.ModelTuneGridSearch": [[299, null]], "modeva.models.ModelTuneOptuna": [[300, null]], "modeva.models.ModelTunePSO": [[301, null]], "modeva.models.ModelTuneRandomSearch": [[302, null]], "modeva.testsuite.utils.slicing_utils.get_data_info": [[303, null]], "modeva.utils.mlflow.clear_mlflow_home": [[304, null]], "modeva.utils.mlflow.get_mlflow_home": [[305, null]], "modeva.utils.mlflow.set_mlflow_home": [[306, null]], "modeva.utils.results.ValidationResult": [[307, null]], "sphinx_gallery.backreferences": [[94, null]], "sphinx_gallery.block_parser": [[95, null]], "sphinx_gallery.directives": [[96, null]], "sphinx_gallery.docs_resolv": [[97, null]], "sphinx_gallery.downloads": [[98, null]], "sphinx_gallery.gen_gallery": [[99, null]], "sphinx_gallery.gen_rst": [[100, null]], "sphinx_gallery.interactive_example": [[101, null]], "sphinx_gallery.notebook": [[102, null]], "sphinx_gallery.py_source_parser": [[103, null]], "sphinx_gallery.scrapers": [[104, null]], "sphinx_gallery.sorting": [[105, null]], "sphinx_gallery.utils.optipng": [[106, null]]}, "docnames": ["_source/api_ref", "_source/auto_galleries/data/index", "_source/auto_galleries/data/plot_0_data_operations", "_source/auto_galleries/data/plot_1_eda", "_source/auto_galleries/data/plot_2_feature_selection", "_source/auto_galleries/data/plot_3_feature_engineering", "_source/auto_galleries/data/plot_4_subsampling", "_source/auto_galleries/data/plot_5_drift_test", "_source/auto_galleries/data/plot_6_outlier_detection", "_source/auto_galleries/data/plot_7_data_with_prediction", "_source/auto_galleries/data/plot_8_extra_data", "_source/auto_galleries/data/sg_execution_times", "_source/auto_galleries/dev/0_models/index", "_source/auto_galleries/dev/0_models/plot_0_glm_cls", "_source/auto_galleries/dev/0_models/plot_0_glm_reg", "_source/auto_galleries/dev/0_models/plot_1_dt_cls", "_source/auto_galleries/dev/0_models/plot_1_dt_reg", "_source/auto_galleries/dev/0_models/plot_2_reludnn_cls", "_source/auto_galleries/dev/0_models/plot_2_reludnn_reg", "_source/auto_galleries/dev/0_models/plot_3_gaminet_cls", "_source/auto_galleries/dev/0_models/plot_3_gaminet_reg", "_source/auto_galleries/dev/0_models/plot_4_moe_cls", "_source/auto_galleries/dev/0_models/plot_4_moe_reg", "_source/auto_galleries/dev/0_models/plot_5_lineartree_cls", "_source/auto_galleries/dev/0_models/plot_5_lineartree_reg", "_source/auto_galleries/dev/0_models/plot_6_const_tree_cls", "_source/auto_galleries/dev/0_models/plot_6_const_tree_reg", "_source/auto_galleries/dev/0_models/sg_execution_times", "_source/auto_galleries/dev/1_extmodels/index", "_source/auto_galleries/dev/1_extmodels/noplot_3_h2o", "_source/auto_galleries/dev/1_extmodels/noplot_4_spark", "_source/auto_galleries/dev/1_extmodels/plot_0_sklearn", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_cls", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_reg", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_cls", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_reg", "_source/auto_galleries/dev/1_extmodels/sg_execution_times", "_source/auto_galleries/dev/2_calibration/index", "_source/auto_galleries/dev/2_calibration/plot_0_calibrate_proba", "_source/auto_galleries/dev/2_calibration/plot_0_pred_interval_cls", "_source/auto_galleries/dev/2_calibration/plot_0_pred_interval_reg", "_source/auto_galleries/dev/2_calibration/sg_execution_times", "_source/auto_galleries/dev/3_hpo/index", "_source/auto_galleries/dev/3_hpo/plot_0_grid", "_source/auto_galleries/dev/3_hpo/plot_1_random", "_source/auto_galleries/dev/3_hpo/plot_2_pso", "_source/auto_galleries/dev/3_hpo/plot_3_optuna", "_source/auto_galleries/dev/3_hpo/sg_execution_times", "_source/auto_galleries/dev/index", "_source/auto_galleries/dev/plot_0_modelzoo", "_source/auto_galleries/dev/sg_execution_times", "_source/auto_galleries/util/index", "_source/auto_galleries/util/plot_0_valres_attributes", "_source/auto_galleries/util/plot_1_valres_save", "_source/auto_galleries/util/plot_2_pipeline", "_source/auto_galleries/util/sg_execution_times", "_source/auto_galleries/val/0_residual/index", "_source/auto_galleries/val/0_residual/plot_1_residual_cls", "_source/auto_galleries/val/0_residual/plot_1_residual_reg", "_source/auto_galleries/val/0_residual/sg_execution_times", "_source/auto_galleries/val/1_performance/index", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_cls", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_reg", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_cls", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_reg", "_source/auto_galleries/val/1_performance/sg_execution_times", "_source/auto_galleries/val/2_overfitting/index", "_source/auto_galleries/val/2_overfitting/plot_0_slice_overfit_cls", "_source/auto_galleries/val/2_overfitting/plot_1_slice_overfit_reg", "_source/auto_galleries/val/2_overfitting/sg_execution_times", "_source/auto_galleries/val/3_reliability/index", "_source/auto_galleries/val/3_reliability/plot_0_reliability_cls", "_source/auto_galleries/val/3_reliability/plot_1_reliability_reg", "_source/auto_galleries/val/3_reliability/sg_execution_times", "_source/auto_galleries/val/4_resilience/index", "_source/auto_galleries/val/4_resilience/plot_0_resilience_cls", "_source/auto_galleries/val/4_resilience/plot_1_resilience_reg", "_source/auto_galleries/val/4_resilience/sg_execution_times", "_source/auto_galleries/val/5_robustness/index", "_source/auto_galleries/val/5_robustness/plot_0_robustness_cls", "_source/auto_galleries/val/5_robustness/plot_1_robustness_reg", "_source/auto_galleries/val/5_robustness/sg_execution_times", "_source/auto_galleries/val/6_fairness/index", "_source/auto_galleries/val/6_fairness/plot_0_fairness_cls", "_source/auto_galleries/val/6_fairness/sg_execution_times", "_source/auto_galleries/val/7_explainability/index", "_source/auto_galleries/val/7_explainability/plot_0_global_explain", "_source/auto_galleries/val/7_explainability/plot_1_local_explain", "_source/auto_galleries/val/7_explainability/sg_execution_times", "_source/auto_galleries/val/index", "_source/auto_galleries/val/sg_execution_times", "_source/changes", "_source/faq", "_source/galleries", "_source/gen_modules/sphinx_gallery.backreferences", "_source/gen_modules/sphinx_gallery.block_parser", "_source/gen_modules/sphinx_gallery.directives", "_source/gen_modules/sphinx_gallery.docs_resolv", "_source/gen_modules/sphinx_gallery.downloads", "_source/gen_modules/sphinx_gallery.gen_gallery", "_source/gen_modules/sphinx_gallery.gen_rst", "_source/gen_modules/sphinx_gallery.interactive_example", "_source/gen_modules/sphinx_gallery.notebook", "_source/gen_modules/sphinx_gallery.py_source_parser", "_source/gen_modules/sphinx_gallery.scrapers", "_source/gen_modules/sphinx_gallery.sorting", "_source/gen_modules/sphinx_gallery.utils.optipng", "_source/install", "_source/lowcode-gallery", "_source/modules/data", "_source/modules/generated/modeva.DataSet.all_feature_names", "_source/modules/generated/modeva.DataSet.all_feature_types", "_source/modules/generated/modeva.DataSet.bin_numerical", "_source/modules/generated/modeva.DataSet.data", "_source/modules/generated/modeva.DataSet.data_drift_test", "_source/modules/generated/modeva.DataSet.delete_extra_data", "_source/modules/generated/modeva.DataSet.delete_registered_data", "_source/modules/generated/modeva.DataSet.detect_outlier_cblof", "_source/modules/generated/modeva.DataSet.detect_outlier_isolation_forest", "_source/modules/generated/modeva.DataSet.detect_outlier_pca", "_source/modules/generated/modeva.DataSet.eda_1d", "_source/modules/generated/modeva.DataSet.eda_2d", "_source/modules/generated/modeva.DataSet.eda_3d", "_source/modules/generated/modeva.DataSet.eda_correlation", "_source/modules/generated/modeva.DataSet.eda_pca", "_source/modules/generated/modeva.DataSet.eda_umap", "_source/modules/generated/modeva.DataSet.encode_categorical", "_source/modules/generated/modeva.DataSet.feature_names", "_source/modules/generated/modeva.DataSet.feature_names_categorical", "_source/modules/generated/modeva.DataSet.feature_names_mixed", "_source/modules/generated/modeva.DataSet.feature_names_numerical", "_source/modules/generated/modeva.DataSet.feature_select_corr", "_source/modules/generated/modeva.DataSet.feature_select_rcit", "_source/modules/generated/modeva.DataSet.feature_select_xgbpfi", "_source/modules/generated/modeva.DataSet.feature_types", "_source/modules/generated/modeva.DataSet.get_X_y_data", "_source/modules/generated/modeva.DataSet.get_data", "_source/modules/generated/modeva.DataSet.get_data_list", "_source/modules/generated/modeva.DataSet.get_extra_data_list", "_source/modules/generated/modeva.DataSet.get_prediction_data", "_source/modules/generated/modeva.DataSet.get_prediction_proba_data", "_source/modules/generated/modeva.DataSet.get_preprocessor", "_source/modules/generated/modeva.DataSet.get_protected_data", "_source/modules/generated/modeva.DataSet.get_raw_data", "_source/modules/generated/modeva.DataSet.impute_missing", "_source/modules/generated/modeva.DataSet.inverse_transform", "_source/modules/generated/modeva.DataSet.is_splitted", "_source/modules/generated/modeva.DataSet.list_registered_data", "_source/modules/generated/modeva.DataSet.load", "_source/modules/generated/modeva.DataSet.load_csv", "_source/modules/generated/modeva.DataSet.load_dataframe", "_source/modules/generated/modeva.DataSet.load_dataframe_train_test", "_source/modules/generated/modeva.DataSet.load_preprocessing", "_source/modules/generated/modeva.DataSet.load_registered_data", "_source/modules/generated/modeva.DataSet.load_spark", "_source/modules/generated/modeva.DataSet.n_features", "_source/modules/generated/modeva.DataSet.name", "_source/modules/generated/modeva.DataSet.prediction", "_source/modules/generated/modeva.DataSet.preprocess", "_source/modules/generated/modeva.DataSet.raw_data", "_source/modules/generated/modeva.DataSet.register", "_source/modules/generated/modeva.DataSet.reset_preprocess", "_source/modules/generated/modeva.DataSet.sample_weight", "_source/modules/generated/modeva.DataSet.save_preprocessing", "_source/modules/generated/modeva.DataSet.scale_numerical", "_source/modules/generated/modeva.DataSet.set_active_features", "_source/modules/generated/modeva.DataSet.set_feature_type", "_source/modules/generated/modeva.DataSet.set_inactive_features", "_source/modules/generated/modeva.DataSet.set_prediction", "_source/modules/generated/modeva.DataSet.set_prediction_proba", "_source/modules/generated/modeva.DataSet.set_protected_data", "_source/modules/generated/modeva.DataSet.set_protected_extra_data", "_source/modules/generated/modeva.DataSet.set_random_split", "_source/modules/generated/modeva.DataSet.set_raw_extra_data", "_source/modules/generated/modeva.DataSet.set_sample_weight", "_source/modules/generated/modeva.DataSet.set_target", "_source/modules/generated/modeva.DataSet.set_task_type", "_source/modules/generated/modeva.DataSet.set_test_idx", "_source/modules/generated/modeva.DataSet.set_train_idx", "_source/modules/generated/modeva.DataSet.shape", "_source/modules/generated/modeva.DataSet.subsample_random", "_source/modules/generated/modeva.DataSet.summary", "_source/modules/generated/modeva.DataSet.task_type", "_source/modules/generated/modeva.DataSet.test_prediction", "_source/modules/generated/modeva.DataSet.test_sample_weight", "_source/modules/generated/modeva.DataSet.test_x", "_source/modules/generated/modeva.DataSet.test_y", "_source/modules/generated/modeva.DataSet.to_df", "_source/modules/generated/modeva.DataSet.train_prediction", "_source/modules/generated/modeva.DataSet.train_sample_weight", "_source/modules/generated/modeva.DataSet.train_x", "_source/modules/generated/modeva.DataSet.train_y", "_source/modules/generated/modeva.DataSet.transform", "_source/modules/generated/modeva.DataSet.x", "_source/modules/generated/modeva.DataSet.y", "_source/modules/generated/modeva.ModelZoo.add_model", "_source/modules/generated/modeva.ModelZoo.dataset", "_source/modules/generated/modeva.ModelZoo.delete_registered_model", "_source/modules/generated/modeva.ModelZoo.get_model", "_source/modules/generated/modeva.ModelZoo.leaderboard", "_source/modules/generated/modeva.ModelZoo.list_model_names", "_source/modules/generated/modeva.ModelZoo.list_registered_models", "_source/modules/generated/modeva.ModelZoo.load_registered_model", "_source/modules/generated/modeva.ModelZoo.models", "_source/modules/generated/modeva.ModelZoo.register", "_source/modules/generated/modeva.ModelZoo.train", "_source/modules/generated/modeva.ModelZoo.train_all", "_source/modules/generated/modeva.TestSuite.compare_accuracy_table", "_source/modules/generated/modeva.TestSuite.compare_fairness", "_source/modules/generated/modeva.TestSuite.compare_reliability", "_source/modules/generated/modeva.TestSuite.compare_residual_cluster", "_source/modules/generated/modeva.TestSuite.compare_resilience", "_source/modules/generated/modeva.TestSuite.compare_robustness", "_source/modules/generated/modeva.TestSuite.compare_slicing_accuracy", "_source/modules/generated/modeva.TestSuite.compare_slicing_fairness", "_source/modules/generated/modeva.TestSuite.compare_slicing_overfit", "_source/modules/generated/modeva.TestSuite.compare_slicing_reliability", "_source/modules/generated/modeva.TestSuite.compare_slicing_robustness", "_source/modules/generated/modeva.TestSuite.delete_registed_test", "_source/modules/generated/modeva.TestSuite.diagnose_accuracy_table", "_source/modules/generated/modeva.TestSuite.diagnose_fairness", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_binning", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_thresholding", "_source/modules/generated/modeva.TestSuite.diagnose_reliability", "_source/modules/generated/modeva.TestSuite.diagnose_residual_analysis", "_source/modules/generated/modeva.TestSuite.diagnose_residual_cluster", "_source/modules/generated/modeva.TestSuite.diagnose_residual_interpret", "_source/modules/generated/modeva.TestSuite.diagnose_resilience", "_source/modules/generated/modeva.TestSuite.diagnose_robustness", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_accuracy", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_fairness", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_overfit", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_reliability", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_robustness", "_source/modules/generated/modeva.TestSuite.display_test_results", "_source/modules/generated/modeva.TestSuite.explain_ale", "_source/modules/generated/modeva.TestSuite.explain_hstatistic", "_source/modules/generated/modeva.TestSuite.explain_lime", "_source/modules/generated/modeva.TestSuite.explain_pdp", "_source/modules/generated/modeva.TestSuite.explain_pfi", "_source/modules/generated/modeva.TestSuite.explain_shap", "_source/modules/generated/modeva.TestSuite.export_report", "_source/modules/generated/modeva.TestSuite.get_dataset", "_source/modules/generated/modeva.TestSuite.get_interactions", "_source/modules/generated/modeva.TestSuite.get_main_effects", "_source/modules/generated/modeva.TestSuite.get_model", "_source/modules/generated/modeva.TestSuite.interpret_coef", "_source/modules/generated/modeva.TestSuite.interpret_effects", "_source/modules/generated/modeva.TestSuite.interpret_effects_moe_average", "_source/modules/generated/modeva.TestSuite.interpret_fi", "_source/modules/generated/modeva.TestSuite.interpret_global_tree", "_source/modules/generated/modeva.TestSuite.interpret_llm_pc", "_source/modules/generated/modeva.TestSuite.interpret_llm_profile", "_source/modules/generated/modeva.TestSuite.interpret_llm_summary", "_source/modules/generated/modeva.TestSuite.interpret_llm_violin", "_source/modules/generated/modeva.TestSuite.interpret_local_fi", "_source/modules/generated/modeva.TestSuite.interpret_local_linear_fi", "_source/modules/generated/modeva.TestSuite.interpret_local_moe_weights", "_source/modules/generated/modeva.TestSuite.interpret_local_tree", "_source/modules/generated/modeva.TestSuite.interpret_moe_cluster_analysis", "_source/modules/generated/modeva.TestSuite.list", "_source/modules/generated/modeva.TestSuite.list_registered_tests", "_source/modules/generated/modeva.TestSuite.load_registered_test", "_source/modules/generated/modeva.TestSuite.register", "_source/modules/generated/modeva.TestSuite.set_dataset", "_source/modules/generated/modeva.TestSuite.set_model", "_source/modules/generated/modeva.automation.pipeline.Pipeline", "_source/modules/generated/modeva.models.MoCatBoostClassifier", "_source/modules/generated/modeva.models.MoCatBoostRegressor", "_source/modules/generated/modeva.models.MoClassifier", "_source/modules/generated/modeva.models.MoDecisionTreeClassifier", "_source/modules/generated/modeva.models.MoDecisionTreeRegressor", "_source/modules/generated/modeva.models.MoElasticNet", "_source/modules/generated/modeva.models.MoGAMINetClassifier", "_source/modules/generated/modeva.models.MoGAMINetRegressor", "_source/modules/generated/modeva.models.MoGLMTreeBoostClassifier", "_source/modules/generated/modeva.models.MoGLMTreeBoostRegressor", "_source/modules/generated/modeva.models.MoGLMTreeClassifier", "_source/modules/generated/modeva.models.MoGLMTreeRegressor", "_source/modules/generated/modeva.models.MoGradientBoostingClassifier", "_source/modules/generated/modeva.models.MoGradientBoostingRegressor", "_source/modules/generated/modeva.models.MoLGBMClassifier", "_source/modules/generated/modeva.models.MoLGBMRegressor", "_source/modules/generated/modeva.models.MoLogisticRegression", "_source/modules/generated/modeva.models.MoMoEClassifier", "_source/modules/generated/modeva.models.MoMoERegressor", "_source/modules/generated/modeva.models.MoNeuralTreeClassifier", "_source/modules/generated/modeva.models.MoNeuralTreeRegressor", "_source/modules/generated/modeva.models.MoRandomForestClassifier", "_source/modules/generated/modeva.models.MoRandomForestRegressor", "_source/modules/generated/modeva.models.MoReLUDNNClassifier", "_source/modules/generated/modeva.models.MoReLUDNNRegressor", "_source/modules/generated/modeva.models.MoRegressor", "_source/modules/generated/modeva.models.MoSKLearnClassifier", "_source/modules/generated/modeva.models.MoSKLearnRegressor", "_source/modules/generated/modeva.models.MoScoredClassifier", "_source/modules/generated/modeva.models.MoScoredRegressor", "_source/modules/generated/modeva.models.MoXGBClassifier", "_source/modules/generated/modeva.models.MoXGBRegressor", "_source/modules/generated/modeva.models.ModelTuneGridSearch", "_source/modules/generated/modeva.models.ModelTuneOptuna", "_source/modules/generated/modeva.models.ModelTunePSO", "_source/modules/generated/modeva.models.ModelTuneRandomSearch", "_source/modules/generated/modeva.testsuite.utils.slicing_utils.get_data_info", "_source/modules/generated/modeva.utils.mlflow.clear_mlflow_home", "_source/modules/generated/modeva.utils.mlflow.get_mlflow_home", "_source/modules/generated/modeva.utils.mlflow.set_mlflow_home", "_source/modules/generated/modeva.utils.results.ValidationResult", "_source/modules/hpo", "_source/modules/models", "_source/modules/modelzoo", "_source/modules/pipeline", "_source/modules/results", "_source/modules/testsuite", "_source/modules/utilities", "_source/modules/wrappers", "_source/usage", "_source/user_guide/compare", "_source/user_guide/compare/compare_classification", "_source/user_guide/compare/compare_fairness", "_source/user_guide/compare/compare_regression", "_source/user_guide/data", "_source/user_guide/data/data_basic_operations", "_source/user_guide/data/data_quality_drift", "_source/user_guide/data/data_quality_outlier", "_source/user_guide/data/data_summary", "_source/user_guide/data/eda", "_source/user_guide/data/feature_select", "_source/user_guide/data/outlier_detect", "_source/user_guide/data/subsample", "_source/user_guide/explain", "_source/user_guide/explain/Global", "_source/user_guide/explain/Local", "_source/user_guide/explain/ale", "_source/user_guide/explain/hstats", "_source/user_guide/explain/ice", "_source/user_guide/explain/lime", "_source/user_guide/explain/pdp", "_source/user_guide/explain/pfi", "_source/user_guide/explain/shap", "_source/user_guide/introduction", "_source/user_guide/low_code", "_source/user_guide/low_code/data_process", "_source/user_guide/low_code/data_summary", "_source/user_guide/low_code/eda_2d", "_source/user_guide/low_code/eda_3d", "_source/user_guide/low_code/eda_multivariate", "_source/user_guide/low_code/model_compare", "_source/user_guide/low_code/model_explainability", "_source/user_guide/low_code/model_test", "_source/user_guide/low_code/model_train", "_source/user_guide/low_code/model_tune", "_source/user_guide/low_code/model_weakness", "_source/user_guide/low_code/registry_hub", "_source/user_guide/models", "_source/user_guide/models/gaminet", "_source/user_guide/models/gbdt", "_source/user_guide/models/gblt", "_source/user_guide/models/glm", "_source/user_guide/models/moe", "_source/user_guide/models/neuraltree", "_source/user_guide/models/reludnn", "_source/user_guide/models/tree", "_source/user_guide/modelwrapping", "_source/user_guide/testing", "_source/user_guide/testing/fairness", "_source/user_guide/testing/overfit", "_source/user_guide/testing/performance", "_source/user_guide/testing/reliability", "_source/user_guide/testing/resilience", "_source/user_guide/testing/robustness", "_source/user_guide/testing/weakspot", "_source/user_guide/train", "_source/user_guide/wrapping/h2o", "_source/user_guide/wrapping/hpo", "_source/user_guide/wrapping/modelzoo", "_source/user_guide/wrapping/wrappers", "index", "sg_api_usage", "sg_execution_times"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2}, "filenames": ["_source/api_ref.rst", "_source/auto_galleries/data/index.rst", "_source/auto_galleries/data/plot_0_data_operations.rst", "_source/auto_galleries/data/plot_1_eda.rst", "_source/auto_galleries/data/plot_2_feature_selection.rst", "_source/auto_galleries/data/plot_3_feature_engineering.rst", "_source/auto_galleries/data/plot_4_subsampling.rst", "_source/auto_galleries/data/plot_5_drift_test.rst", "_source/auto_galleries/data/plot_6_outlier_detection.rst", "_source/auto_galleries/data/plot_7_data_with_prediction.rst", "_source/auto_galleries/data/plot_8_extra_data.rst", "_source/auto_galleries/data/sg_execution_times.rst", "_source/auto_galleries/dev/0_models/index.rst", "_source/auto_galleries/dev/0_models/plot_0_glm_cls.rst", "_source/auto_galleries/dev/0_models/plot_0_glm_reg.rst", "_source/auto_galleries/dev/0_models/plot_1_dt_cls.rst", "_source/auto_galleries/dev/0_models/plot_1_dt_reg.rst", "_source/auto_galleries/dev/0_models/plot_2_reludnn_cls.rst", "_source/auto_galleries/dev/0_models/plot_2_reludnn_reg.rst", "_source/auto_galleries/dev/0_models/plot_3_gaminet_cls.rst", "_source/auto_galleries/dev/0_models/plot_3_gaminet_reg.rst", "_source/auto_galleries/dev/0_models/plot_4_moe_cls.rst", "_source/auto_galleries/dev/0_models/plot_4_moe_reg.rst", "_source/auto_galleries/dev/0_models/plot_5_lineartree_cls.rst", "_source/auto_galleries/dev/0_models/plot_5_lineartree_reg.rst", "_source/auto_galleries/dev/0_models/plot_6_const_tree_cls.rst", "_source/auto_galleries/dev/0_models/plot_6_const_tree_reg.rst", "_source/auto_galleries/dev/0_models/sg_execution_times.rst", "_source/auto_galleries/dev/1_extmodels/index.rst", "_source/auto_galleries/dev/1_extmodels/noplot_3_h2o.rst", "_source/auto_galleries/dev/1_extmodels/noplot_4_spark.rst", "_source/auto_galleries/dev/1_extmodels/plot_0_sklearn.rst", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_cls.rst", "_source/auto_galleries/dev/1_extmodels/plot_1_arbitrary_reg.rst", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_cls.rst", "_source/auto_galleries/dev/1_extmodels/plot_2_scored_reg.rst", "_source/auto_galleries/dev/1_extmodels/sg_execution_times.rst", "_source/auto_galleries/dev/2_calibration/index.rst", "_source/auto_galleries/dev/2_calibration/plot_0_calibrate_proba.rst", "_source/auto_galleries/dev/2_calibration/plot_0_pred_interval_cls.rst", "_source/auto_galleries/dev/2_calibration/plot_0_pred_interval_reg.rst", "_source/auto_galleries/dev/2_calibration/sg_execution_times.rst", "_source/auto_galleries/dev/3_hpo/index.rst", "_source/auto_galleries/dev/3_hpo/plot_0_grid.rst", "_source/auto_galleries/dev/3_hpo/plot_1_random.rst", "_source/auto_galleries/dev/3_hpo/plot_2_pso.rst", "_source/auto_galleries/dev/3_hpo/plot_3_optuna.rst", "_source/auto_galleries/dev/3_hpo/sg_execution_times.rst", "_source/auto_galleries/dev/index.rst", "_source/auto_galleries/dev/plot_0_modelzoo.rst", "_source/auto_galleries/dev/sg_execution_times.rst", "_source/auto_galleries/util/index.rst", "_source/auto_galleries/util/plot_0_valres_attributes.rst", "_source/auto_galleries/util/plot_1_valres_save.rst", "_source/auto_galleries/util/plot_2_pipeline.rst", "_source/auto_galleries/util/sg_execution_times.rst", "_source/auto_galleries/val/0_residual/index.rst", "_source/auto_galleries/val/0_residual/plot_1_residual_cls.rst", "_source/auto_galleries/val/0_residual/plot_1_residual_reg.rst", "_source/auto_galleries/val/0_residual/sg_execution_times.rst", "_source/auto_galleries/val/1_performance/index.rst", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_cls.rst", "_source/auto_galleries/val/1_performance/plot_0_accuracy_table_reg.rst", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_cls.rst", "_source/auto_galleries/val/1_performance/plot_1_slice_accuracy_reg.rst", "_source/auto_galleries/val/1_performance/sg_execution_times.rst", "_source/auto_galleries/val/2_overfitting/index.rst", "_source/auto_galleries/val/2_overfitting/plot_0_slice_overfit_cls.rst", "_source/auto_galleries/val/2_overfitting/plot_1_slice_overfit_reg.rst", "_source/auto_galleries/val/2_overfitting/sg_execution_times.rst", "_source/auto_galleries/val/3_reliability/index.rst", "_source/auto_galleries/val/3_reliability/plot_0_reliability_cls.rst", "_source/auto_galleries/val/3_reliability/plot_1_reliability_reg.rst", "_source/auto_galleries/val/3_reliability/sg_execution_times.rst", "_source/auto_galleries/val/4_resilience/index.rst", "_source/auto_galleries/val/4_resilience/plot_0_resilience_cls.rst", "_source/auto_galleries/val/4_resilience/plot_1_resilience_reg.rst", "_source/auto_galleries/val/4_resilience/sg_execution_times.rst", "_source/auto_galleries/val/5_robustness/index.rst", "_source/auto_galleries/val/5_robustness/plot_0_robustness_cls.rst", "_source/auto_galleries/val/5_robustness/plot_1_robustness_reg.rst", "_source/auto_galleries/val/5_robustness/sg_execution_times.rst", "_source/auto_galleries/val/6_fairness/index.rst", "_source/auto_galleries/val/6_fairness/plot_0_fairness_cls.rst", "_source/auto_galleries/val/6_fairness/sg_execution_times.rst", "_source/auto_galleries/val/7_explainability/index.rst", "_source/auto_galleries/val/7_explainability/plot_0_global_explain.rst", "_source/auto_galleries/val/7_explainability/plot_1_local_explain.rst", "_source/auto_galleries/val/7_explainability/sg_execution_times.rst", "_source/auto_galleries/val/index.rst", "_source/auto_galleries/val/sg_execution_times.rst", "_source/changes.rst", "_source/faq.rst", "_source/galleries.rst", "_source/gen_modules/sphinx_gallery.backreferences.rst", "_source/gen_modules/sphinx_gallery.block_parser.rst", "_source/gen_modules/sphinx_gallery.directives.rst", "_source/gen_modules/sphinx_gallery.docs_resolv.rst", "_source/gen_modules/sphinx_gallery.downloads.rst", "_source/gen_modules/sphinx_gallery.gen_gallery.rst", "_source/gen_modules/sphinx_gallery.gen_rst.rst", "_source/gen_modules/sphinx_gallery.interactive_example.rst", "_source/gen_modules/sphinx_gallery.notebook.rst", "_source/gen_modules/sphinx_gallery.py_source_parser.rst", "_source/gen_modules/sphinx_gallery.scrapers.rst", "_source/gen_modules/sphinx_gallery.sorting.rst", "_source/gen_modules/sphinx_gallery.utils.optipng.rst", "_source/install.rst", "_source/lowcode-gallery.rst", "_source/modules/data.rst", "_source/modules/generated/modeva.DataSet.all_feature_names.rst", "_source/modules/generated/modeva.DataSet.all_feature_types.rst", "_source/modules/generated/modeva.DataSet.bin_numerical.rst", "_source/modules/generated/modeva.DataSet.data.rst", "_source/modules/generated/modeva.DataSet.data_drift_test.rst", "_source/modules/generated/modeva.DataSet.delete_extra_data.rst", "_source/modules/generated/modeva.DataSet.delete_registered_data.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_cblof.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_isolation_forest.rst", "_source/modules/generated/modeva.DataSet.detect_outlier_pca.rst", "_source/modules/generated/modeva.DataSet.eda_1d.rst", "_source/modules/generated/modeva.DataSet.eda_2d.rst", "_source/modules/generated/modeva.DataSet.eda_3d.rst", "_source/modules/generated/modeva.DataSet.eda_correlation.rst", "_source/modules/generated/modeva.DataSet.eda_pca.rst", "_source/modules/generated/modeva.DataSet.eda_umap.rst", "_source/modules/generated/modeva.DataSet.encode_categorical.rst", "_source/modules/generated/modeva.DataSet.feature_names.rst", "_source/modules/generated/modeva.DataSet.feature_names_categorical.rst", "_source/modules/generated/modeva.DataSet.feature_names_mixed.rst", "_source/modules/generated/modeva.DataSet.feature_names_numerical.rst", "_source/modules/generated/modeva.DataSet.feature_select_corr.rst", "_source/modules/generated/modeva.DataSet.feature_select_rcit.rst", "_source/modules/generated/modeva.DataSet.feature_select_xgbpfi.rst", "_source/modules/generated/modeva.DataSet.feature_types.rst", "_source/modules/generated/modeva.DataSet.get_X_y_data.rst", "_source/modules/generated/modeva.DataSet.get_data.rst", "_source/modules/generated/modeva.DataSet.get_data_list.rst", "_source/modules/generated/modeva.DataSet.get_extra_data_list.rst", "_source/modules/generated/modeva.DataSet.get_prediction_data.rst", "_source/modules/generated/modeva.DataSet.get_prediction_proba_data.rst", "_source/modules/generated/modeva.DataSet.get_preprocessor.rst", "_source/modules/generated/modeva.DataSet.get_protected_data.rst", "_source/modules/generated/modeva.DataSet.get_raw_data.rst", "_source/modules/generated/modeva.DataSet.impute_missing.rst", "_source/modules/generated/modeva.DataSet.inverse_transform.rst", "_source/modules/generated/modeva.DataSet.is_splitted.rst", "_source/modules/generated/modeva.DataSet.list_registered_data.rst", "_source/modules/generated/modeva.DataSet.load.rst", "_source/modules/generated/modeva.DataSet.load_csv.rst", "_source/modules/generated/modeva.DataSet.load_dataframe.rst", "_source/modules/generated/modeva.DataSet.load_dataframe_train_test.rst", "_source/modules/generated/modeva.DataSet.load_preprocessing.rst", "_source/modules/generated/modeva.DataSet.load_registered_data.rst", "_source/modules/generated/modeva.DataSet.load_spark.rst", "_source/modules/generated/modeva.DataSet.n_features.rst", "_source/modules/generated/modeva.DataSet.name.rst", "_source/modules/generated/modeva.DataSet.prediction.rst", "_source/modules/generated/modeva.DataSet.preprocess.rst", "_source/modules/generated/modeva.DataSet.raw_data.rst", "_source/modules/generated/modeva.DataSet.register.rst", "_source/modules/generated/modeva.DataSet.reset_preprocess.rst", "_source/modules/generated/modeva.DataSet.sample_weight.rst", "_source/modules/generated/modeva.DataSet.save_preprocessing.rst", "_source/modules/generated/modeva.DataSet.scale_numerical.rst", "_source/modules/generated/modeva.DataSet.set_active_features.rst", "_source/modules/generated/modeva.DataSet.set_feature_type.rst", "_source/modules/generated/modeva.DataSet.set_inactive_features.rst", "_source/modules/generated/modeva.DataSet.set_prediction.rst", "_source/modules/generated/modeva.DataSet.set_prediction_proba.rst", "_source/modules/generated/modeva.DataSet.set_protected_data.rst", "_source/modules/generated/modeva.DataSet.set_protected_extra_data.rst", "_source/modules/generated/modeva.DataSet.set_random_split.rst", "_source/modules/generated/modeva.DataSet.set_raw_extra_data.rst", "_source/modules/generated/modeva.DataSet.set_sample_weight.rst", "_source/modules/generated/modeva.DataSet.set_target.rst", "_source/modules/generated/modeva.DataSet.set_task_type.rst", "_source/modules/generated/modeva.DataSet.set_test_idx.rst", "_source/modules/generated/modeva.DataSet.set_train_idx.rst", "_source/modules/generated/modeva.DataSet.shape.rst", "_source/modules/generated/modeva.DataSet.subsample_random.rst", "_source/modules/generated/modeva.DataSet.summary.rst", "_source/modules/generated/modeva.DataSet.task_type.rst", "_source/modules/generated/modeva.DataSet.test_prediction.rst", "_source/modules/generated/modeva.DataSet.test_sample_weight.rst", "_source/modules/generated/modeva.DataSet.test_x.rst", "_source/modules/generated/modeva.DataSet.test_y.rst", "_source/modules/generated/modeva.DataSet.to_df.rst", "_source/modules/generated/modeva.DataSet.train_prediction.rst", "_source/modules/generated/modeva.DataSet.train_sample_weight.rst", "_source/modules/generated/modeva.DataSet.train_x.rst", "_source/modules/generated/modeva.DataSet.train_y.rst", "_source/modules/generated/modeva.DataSet.transform.rst", "_source/modules/generated/modeva.DataSet.x.rst", "_source/modules/generated/modeva.DataSet.y.rst", "_source/modules/generated/modeva.ModelZoo.add_model.rst", "_source/modules/generated/modeva.ModelZoo.dataset.rst", "_source/modules/generated/modeva.ModelZoo.delete_registered_model.rst", "_source/modules/generated/modeva.ModelZoo.get_model.rst", "_source/modules/generated/modeva.ModelZoo.leaderboard.rst", "_source/modules/generated/modeva.ModelZoo.list_model_names.rst", "_source/modules/generated/modeva.ModelZoo.list_registered_models.rst", "_source/modules/generated/modeva.ModelZoo.load_registered_model.rst", "_source/modules/generated/modeva.ModelZoo.models.rst", "_source/modules/generated/modeva.ModelZoo.register.rst", "_source/modules/generated/modeva.ModelZoo.train.rst", "_source/modules/generated/modeva.ModelZoo.train_all.rst", "_source/modules/generated/modeva.TestSuite.compare_accuracy_table.rst", "_source/modules/generated/modeva.TestSuite.compare_fairness.rst", "_source/modules/generated/modeva.TestSuite.compare_reliability.rst", "_source/modules/generated/modeva.TestSuite.compare_residual_cluster.rst", "_source/modules/generated/modeva.TestSuite.compare_resilience.rst", "_source/modules/generated/modeva.TestSuite.compare_robustness.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_accuracy.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_fairness.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_overfit.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_reliability.rst", "_source/modules/generated/modeva.TestSuite.compare_slicing_robustness.rst", "_source/modules/generated/modeva.TestSuite.delete_registed_test.rst", "_source/modules/generated/modeva.TestSuite.diagnose_accuracy_table.rst", "_source/modules/generated/modeva.TestSuite.diagnose_fairness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_binning.rst", "_source/modules/generated/modeva.TestSuite.diagnose_mitigate_unfair_thresholding.rst", "_source/modules/generated/modeva.TestSuite.diagnose_reliability.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_analysis.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_cluster.rst", "_source/modules/generated/modeva.TestSuite.diagnose_residual_interpret.rst", "_source/modules/generated/modeva.TestSuite.diagnose_resilience.rst", "_source/modules/generated/modeva.TestSuite.diagnose_robustness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_accuracy.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_fairness.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_overfit.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_reliability.rst", "_source/modules/generated/modeva.TestSuite.diagnose_slicing_robustness.rst", "_source/modules/generated/modeva.TestSuite.display_test_results.rst", "_source/modules/generated/modeva.TestSuite.explain_ale.rst", "_source/modules/generated/modeva.TestSuite.explain_hstatistic.rst", "_source/modules/generated/modeva.TestSuite.explain_lime.rst", "_source/modules/generated/modeva.TestSuite.explain_pdp.rst", "_source/modules/generated/modeva.TestSuite.explain_pfi.rst", "_source/modules/generated/modeva.TestSuite.explain_shap.rst", "_source/modules/generated/modeva.TestSuite.export_report.rst", "_source/modules/generated/modeva.TestSuite.get_dataset.rst", "_source/modules/generated/modeva.TestSuite.get_interactions.rst", "_source/modules/generated/modeva.TestSuite.get_main_effects.rst", "_source/modules/generated/modeva.TestSuite.get_model.rst", "_source/modules/generated/modeva.TestSuite.interpret_coef.rst", "_source/modules/generated/modeva.TestSuite.interpret_effects.rst", "_source/modules/generated/modeva.TestSuite.interpret_effects_moe_average.rst", "_source/modules/generated/modeva.TestSuite.interpret_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_global_tree.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_pc.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_profile.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_summary.rst", "_source/modules/generated/modeva.TestSuite.interpret_llm_violin.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_linear_fi.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_moe_weights.rst", "_source/modules/generated/modeva.TestSuite.interpret_local_tree.rst", "_source/modules/generated/modeva.TestSuite.interpret_moe_cluster_analysis.rst", "_source/modules/generated/modeva.TestSuite.list.rst", "_source/modules/generated/modeva.TestSuite.list_registered_tests.rst", "_source/modules/generated/modeva.TestSuite.load_registered_test.rst", "_source/modules/generated/modeva.TestSuite.register.rst", "_source/modules/generated/modeva.TestSuite.set_dataset.rst", "_source/modules/generated/modeva.TestSuite.set_model.rst", "_source/modules/generated/modeva.automation.pipeline.Pipeline.rst", "_source/modules/generated/modeva.models.MoCatBoostClassifier.rst", "_source/modules/generated/modeva.models.MoCatBoostRegressor.rst", "_source/modules/generated/modeva.models.MoClassifier.rst", "_source/modules/generated/modeva.models.MoDecisionTreeClassifier.rst", "_source/modules/generated/modeva.models.MoDecisionTreeRegressor.rst", "_source/modules/generated/modeva.models.MoElasticNet.rst", "_source/modules/generated/modeva.models.MoGAMINetClassifier.rst", "_source/modules/generated/modeva.models.MoGAMINetRegressor.rst", "_source/modules/generated/modeva.models.MoGLMTreeBoostClassifier.rst", "_source/modules/generated/modeva.models.MoGLMTreeBoostRegressor.rst", "_source/modules/generated/modeva.models.MoGLMTreeClassifier.rst", "_source/modules/generated/modeva.models.MoGLMTreeRegressor.rst", "_source/modules/generated/modeva.models.MoGradientBoostingClassifier.rst", "_source/modules/generated/modeva.models.MoGradientBoostingRegressor.rst", "_source/modules/generated/modeva.models.MoLGBMClassifier.rst", "_source/modules/generated/modeva.models.MoLGBMRegressor.rst", "_source/modules/generated/modeva.models.MoLogisticRegression.rst", "_source/modules/generated/modeva.models.MoMoEClassifier.rst", "_source/modules/generated/modeva.models.MoMoERegressor.rst", "_source/modules/generated/modeva.models.MoNeuralTreeClassifier.rst", "_source/modules/generated/modeva.models.MoNeuralTreeRegressor.rst", "_source/modules/generated/modeva.models.MoRandomForestClassifier.rst", "_source/modules/generated/modeva.models.MoRandomForestRegressor.rst", "_source/modules/generated/modeva.models.MoReLUDNNClassifier.rst", "_source/modules/generated/modeva.models.MoReLUDNNRegressor.rst", "_source/modules/generated/modeva.models.MoRegressor.rst", "_source/modules/generated/modeva.models.MoSKLearnClassifier.rst", "_source/modules/generated/modeva.models.MoSKLearnRegressor.rst", "_source/modules/generated/modeva.models.MoScoredClassifier.rst", "_source/modules/generated/modeva.models.MoScoredRegressor.rst", "_source/modules/generated/modeva.models.MoXGBClassifier.rst", "_source/modules/generated/modeva.models.MoXGBRegressor.rst", "_source/modules/generated/modeva.models.ModelTuneGridSearch.rst", "_source/modules/generated/modeva.models.ModelTuneOptuna.rst", "_source/modules/generated/modeva.models.ModelTunePSO.rst", "_source/modules/generated/modeva.models.ModelTuneRandomSearch.rst", "_source/modules/generated/modeva.testsuite.utils.slicing_utils.get_data_info.rst", "_source/modules/generated/modeva.utils.mlflow.clear_mlflow_home.rst", "_source/modules/generated/modeva.utils.mlflow.get_mlflow_home.rst", "_source/modules/generated/modeva.utils.mlflow.set_mlflow_home.rst", "_source/modules/generated/modeva.utils.results.ValidationResult.rst", "_source/modules/hpo.rst", "_source/modules/models.rst", "_source/modules/modelzoo.rst", "_source/modules/pipeline.rst", "_source/modules/results.rst", "_source/modules/testsuite.rst", "_source/modules/utilities.rst", "_source/modules/wrappers.rst", "_source/usage.rst", "_source/user_guide/compare.rst", "_source/user_guide/compare/compare_classification.rst", "_source/user_guide/compare/compare_fairness.rst", "_source/user_guide/compare/compare_regression.rst", "_source/user_guide/data.rst", "_source/user_guide/data/data_basic_operations.rst", "_source/user_guide/data/data_quality_drift.rst", "_source/user_guide/data/data_quality_outlier.rst", "_source/user_guide/data/data_summary.rst", "_source/user_guide/data/eda.rst", "_source/user_guide/data/feature_select.rst", "_source/user_guide/data/outlier_detect.rst", "_source/user_guide/data/subsample.rst", "_source/user_guide/explain.rst", "_source/user_guide/explain/Global.rst", "_source/user_guide/explain/Local.rst", "_source/user_guide/explain/ale.rst", "_source/user_guide/explain/hstats.rst", "_source/user_guide/explain/ice.rst", "_source/user_guide/explain/lime.rst", "_source/user_guide/explain/pdp.rst", "_source/user_guide/explain/pfi.rst", "_source/user_guide/explain/shap.rst", "_source/user_guide/introduction.rst", "_source/user_guide/low_code.rst", "_source/user_guide/low_code/data_process.rst", "_source/user_guide/low_code/data_summary.rst", "_source/user_guide/low_code/eda_2d.rst", "_source/user_guide/low_code/eda_3d.rst", "_source/user_guide/low_code/eda_multivariate.rst", "_source/user_guide/low_code/model_compare.rst", "_source/user_guide/low_code/model_explainability.rst", "_source/user_guide/low_code/model_test.rst", "_source/user_guide/low_code/model_train.rst", "_source/user_guide/low_code/model_tune.rst", "_source/user_guide/low_code/model_weakness.rst", "_source/user_guide/low_code/registry_hub.rst", "_source/user_guide/models.rst", "_source/user_guide/models/gaminet.rst", "_source/user_guide/models/gbdt.rst", "_source/user_guide/models/gblt.rst", "_source/user_guide/models/glm.rst", "_source/user_guide/models/moe.rst", "_source/user_guide/models/neuraltree.rst", "_source/user_guide/models/reludnn.rst", "_source/user_guide/models/tree.rst", "_source/user_guide/modelwrapping.rst", "_source/user_guide/testing.rst", "_source/user_guide/testing/fairness.rst", "_source/user_guide/testing/overfit.rst", "_source/user_guide/testing/performance.rst", "_source/user_guide/testing/reliability.rst", "_source/user_guide/testing/resilience.rst", "_source/user_guide/testing/robustness.rst", "_source/user_guide/testing/weakspot.rst", "_source/user_guide/train.rst", "_source/user_guide/wrapping/h2o.rst", "_source/user_guide/wrapping/hpo.rst", "_source/user_guide/wrapping/modelzoo.rst", "_source/user_guide/wrapping/wrappers.rst", "index.rst", "sg_api_usage.rst", "sg_execution_times.rst"], "indexentries": {"active_interaction_index_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.active_interaction_index_", false]], "active_interaction_index_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.active_interaction_index_", false]], "active_main_effect_index_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.active_main_effect_index_", false]], "active_main_effect_index_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.active_main_effect_index_", false]], "add_model() (modeva.modelzoo method)": [[195, "modeva.ModelZoo.add_model", false]], "add_step() (modeva.automation.pipeline.pipeline method)": [[266, "modeva.automation.pipeline.Pipeline.add_step", false]], "all_feature_names (modeva.dataset property)": [[110, "modeva.DataSet.all_feature_names", false]], "all_feature_types (modeva.dataset property)": [[111, "modeva.DataSet.all_feature_types", false]], "bin_numerical() (modeva.dataset method)": [[112, "modeva.DataSet.bin_numerical", false]], "calibrate_interval() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.calibrate_interval", false]], "calibrate_interval() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.calibrate_interval", false]], "calibrate_interval() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.calibrate_interval", false]], "calibrate_interval() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.calibrate_interval", false]], "calibrate_proba() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.calibrate_proba", false]], "calibrate_proba() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.calibrate_proba", false]], "calibrate_proba() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.calibrate_proba", false]], "clear_mlflow_home() (in module modeva.utils.mlflow)": [[304, "modeva.utils.mlflow.clear_mlflow_home", false]], "compare_accuracy_table() (modeva.testsuite method)": [[207, "modeva.TestSuite.compare_accuracy_table", false]], "compare_fairness() (modeva.testsuite method)": [[208, "modeva.TestSuite.compare_fairness", false]], "compare_reliability() (modeva.testsuite method)": [[209, "modeva.TestSuite.compare_reliability", false]], "compare_residual_cluster() (modeva.testsuite method)": [[210, "modeva.TestSuite.compare_residual_cluster", false]], "compare_resilience() (modeva.testsuite method)": [[211, "modeva.TestSuite.compare_resilience", false]], "compare_robustness() (modeva.testsuite method)": [[212, "modeva.TestSuite.compare_robustness", false]], "compare_slicing_accuracy() (modeva.testsuite method)": [[213, "modeva.TestSuite.compare_slicing_accuracy", false]], "compare_slicing_fairness() (modeva.testsuite method)": [[214, "modeva.TestSuite.compare_slicing_fairness", false]], "compare_slicing_overfit() (modeva.testsuite method)": [[215, "modeva.TestSuite.compare_slicing_overfit", false]], "compare_slicing_reliability() (modeva.testsuite method)": [[216, "modeva.TestSuite.compare_slicing_reliability", false]], "compare_slicing_robustness() (modeva.testsuite method)": [[217, "modeva.TestSuite.compare_slicing_robustness", false]], "data (modeva.dataset property)": [[113, "modeva.DataSet.data", false]], "data (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.data", false]], "data_drift_test() (modeva.dataset method)": [[114, "modeva.DataSet.data_drift_test", false]], "dataset (modeva.modelzoo property)": [[196, "modeva.ModelZoo.dataset", false]], "decision_function() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.decision_function", false]], "decision_function() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.decision_function", false]], "decision_function() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.decision_function", false]], "decision_function() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.decision_function", false]], "decision_function() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.decision_function", false]], "decision_function() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.decision_function", false]], "decision_function() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.decision_function", false]], "decision_function() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.decision_function", false]], "decision_function() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.decision_function", false]], "decision_function() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.decision_function", false]], "decision_function() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.decision_function", false]], "decision_function() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.decision_function", false]], "decision_function() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.decision_function", false]], "decision_function() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.decision_function", false]], "decision_function() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.decision_function", false]], "decision_function() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.decision_function", false]], "delete_extra_data() (modeva.dataset method)": [[115, "modeva.DataSet.delete_extra_data", false]], "delete_registed_test() (modeva.testsuite method)": [[218, "modeva.TestSuite.delete_registed_test", false]], "delete_registered_data() (modeva.dataset method)": [[116, "modeva.DataSet.delete_registered_data", false]], "delete_registered_model() (modeva.modelzoo method)": [[197, "modeva.ModelZoo.delete_registered_model", false]], "detect_outlier_cblof() (modeva.dataset method)": [[117, "modeva.DataSet.detect_outlier_cblof", false]], "detect_outlier_isolation_forest() (modeva.dataset method)": [[118, "modeva.DataSet.detect_outlier_isolation_forest", false]], "detect_outlier_pca() (modeva.dataset method)": [[119, "modeva.DataSet.detect_outlier_pca", false]], "diagnose_accuracy_table() (modeva.testsuite method)": [[219, "modeva.TestSuite.diagnose_accuracy_table", false]], "diagnose_fairness() (modeva.testsuite method)": [[220, "modeva.TestSuite.diagnose_fairness", false]], "diagnose_mitigate_unfair_binning() (modeva.testsuite method)": [[221, "modeva.TestSuite.diagnose_mitigate_unfair_binning", false]], "diagnose_mitigate_unfair_thresholding() (modeva.testsuite method)": [[222, "modeva.TestSuite.diagnose_mitigate_unfair_thresholding", false]], "diagnose_reliability() (modeva.testsuite method)": [[223, "modeva.TestSuite.diagnose_reliability", false]], "diagnose_residual_analysis() (modeva.testsuite method)": [[224, "modeva.TestSuite.diagnose_residual_analysis", false]], "diagnose_residual_cluster() (modeva.testsuite method)": [[225, "modeva.TestSuite.diagnose_residual_cluster", false]], "diagnose_residual_interpret() (modeva.testsuite method)": [[226, "modeva.TestSuite.diagnose_residual_interpret", false]], "diagnose_resilience() (modeva.testsuite method)": [[227, "modeva.TestSuite.diagnose_resilience", false]], "diagnose_robustness() (modeva.testsuite method)": [[228, "modeva.TestSuite.diagnose_robustness", false]], "diagnose_slicing_accuracy() (modeva.testsuite method)": [[229, "modeva.TestSuite.diagnose_slicing_accuracy", false]], "diagnose_slicing_fairness() (modeva.testsuite method)": [[230, "modeva.TestSuite.diagnose_slicing_fairness", false]], "diagnose_slicing_overfit() (modeva.testsuite method)": [[231, "modeva.TestSuite.diagnose_slicing_overfit", false]], "diagnose_slicing_reliability() (modeva.testsuite method)": [[232, "modeva.TestSuite.diagnose_slicing_reliability", false]], "diagnose_slicing_robustness() (modeva.testsuite method)": [[233, "modeva.TestSuite.diagnose_slicing_robustness", false]], "display_test_results() (modeva.testsuite method)": [[234, "modeva.TestSuite.display_test_results", false]], "eda_1d() (modeva.dataset method)": [[120, "modeva.DataSet.eda_1d", false]], "eda_2d() (modeva.dataset method)": [[121, "modeva.DataSet.eda_2d", false]], "eda_3d() (modeva.dataset method)": [[122, "modeva.DataSet.eda_3d", false]], "eda_correlation() (modeva.dataset method)": [[123, "modeva.DataSet.eda_correlation", false]], "eda_pca() (modeva.dataset method)": [[124, "modeva.DataSet.eda_pca", false]], "eda_umap() (modeva.dataset method)": [[125, "modeva.DataSet.eda_umap", false]], "encode_categorical() (modeva.dataset method)": [[126, "modeva.DataSet.encode_categorical", false]], "estimators_ (modeva.models.moglmtreeboostclassifier attribute)": [[275, "modeva.models.MoGLMTreeBoostClassifier.estimators_", false]], "estimators_ (modeva.models.moglmtreeboostregressor attribute)": [[276, "modeva.models.MoGLMTreeBoostRegressor.estimators_", false]], "explain_ale() (modeva.testsuite method)": [[235, "modeva.TestSuite.explain_ale", false]], "explain_hstatistic() (modeva.testsuite method)": [[236, "modeva.TestSuite.explain_hstatistic", false]], "explain_lime() (modeva.testsuite method)": [[237, "modeva.TestSuite.explain_lime", false]], "explain_pdp() (modeva.testsuite method)": [[238, "modeva.TestSuite.explain_pdp", false]], "explain_pfi() (modeva.testsuite method)": [[239, "modeva.TestSuite.explain_pfi", false]], "explain_shap() (modeva.testsuite method)": [[240, "modeva.TestSuite.explain_shap", false]], "export_report() (modeva.testsuite method)": [[241, "modeva.TestSuite.export_report", false]], "feature_names (modeva.dataset property)": [[127, "modeva.DataSet.feature_names", false]], "feature_names_categorical (modeva.dataset property)": [[128, "modeva.DataSet.feature_names_categorical", false]], "feature_names_mixed (modeva.dataset property)": [[129, "modeva.DataSet.feature_names_mixed", false]], "feature_names_numerical (modeva.dataset property)": [[130, "modeva.DataSet.feature_names_numerical", false]], "feature_select_corr() (modeva.dataset method)": [[131, "modeva.DataSet.feature_select_corr", false]], "feature_select_rcit() (modeva.dataset method)": [[132, "modeva.DataSet.feature_select_rcit", false]], "feature_select_xgbpfi() (modeva.dataset method)": [[133, "modeva.DataSet.feature_select_xgbpfi", false]], "feature_types (modeva.dataset property)": [[134, "modeva.DataSet.feature_types", false]], "fit() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.fit", false]], "fit() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.fit", false]], "fit() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.fit", false]], "fit() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.fit", false]], "fit() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.fit", false]], "fit() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.fit", false]], "fit() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.fit", false]], "fit() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.fit", false]], "fit() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.fit", false]], "fit() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.fit", false]], "fit() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.fit", false]], "fit() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.fit", false]], "fit() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.fit", false]], "fit() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.fit", false]], "fit() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.fit", false]], "fit() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.fit", false]], "fit() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.fit", false]], "fit() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.fit", false]], "fit() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.fit", false]], "fit() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.fit", false]], "fit() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.fit", false]], "fit() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.fit", false]], "fit() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.fit", false]], "fit() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.fit", false]], "fit() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.fit", false]], "fit() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.fit", false]], "func (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.func", false]], "get_data() (modeva.dataset method)": [[136, "modeva.DataSet.get_data", false]], "get_data_info() (in module modeva.testsuite.utils.slicing_utils)": [[303, "modeva.testsuite.utils.slicing_utils.get_data_info", false]], "get_data_list() (modeva.dataset method)": [[137, "modeva.DataSet.get_data_list", false]], "get_dataset() (modeva.testsuite method)": [[242, "modeva.TestSuite.get_dataset", false]], "get_extra_data_list() (modeva.dataset method)": [[138, "modeva.DataSet.get_extra_data_list", false]], "get_figure_names() (modeva.utils.results.validationresult method)": [[307, "modeva.utils.results.ValidationResult.get_figure_names", false]], "get_interactions() (modeva.testsuite method)": [[243, "modeva.TestSuite.get_interactions", false]], "get_main_effects() (modeva.testsuite method)": [[244, "modeva.TestSuite.get_main_effects", false]], "get_mlflow_home() (in module modeva.utils.mlflow)": [[305, "modeva.utils.mlflow.get_mlflow_home", false]], "get_model() (modeva.modelzoo method)": [[198, "modeva.ModelZoo.get_model", false]], "get_model() (modeva.testsuite method)": [[245, "modeva.TestSuite.get_model", false]], "get_params() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.get_params", false]], "get_params() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.get_params", false]], "get_params() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.get_params", false]], "get_params() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.get_params", false]], "get_params() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.get_params", false]], "get_params() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.get_params", false]], "get_params() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.get_params", false]], "get_params() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.get_params", false]], "get_params() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.get_params", false]], "get_params() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.get_params", false]], "get_params() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.get_params", false]], "get_params() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.get_params", false]], "get_params() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.get_params", false]], "get_params() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.get_params", false]], "get_params() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.get_params", false]], "get_params() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.get_params", false]], "get_params() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.get_params", false]], "get_params() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.get_params", false]], "get_params() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.get_params", false]], "get_params() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.get_params", false]], "get_params() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.get_params", false]], "get_params() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.get_params", false]], "get_params() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.get_params", false]], "get_params() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.get_params", false]], "get_params() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.get_params", false]], "get_params() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.get_params", false]], "get_params() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.get_params", false]], "get_params() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.get_params", false]], "get_params() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.get_params", false]], "get_params() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.get_params", false]], "get_params() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.get_params", false]], "get_params() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.get_params", false]], "get_prediction_data() (modeva.dataset method)": [[139, "modeva.DataSet.get_prediction_data", false]], "get_prediction_proba_data() (modeva.dataset method)": [[140, "modeva.DataSet.get_prediction_proba_data", false]], "get_preprocessor() (modeva.dataset method)": [[141, "modeva.DataSet.get_preprocessor", false]], "get_protected_data() (modeva.dataset method)": [[142, "modeva.DataSet.get_protected_data", false]], "get_raw_data() (modeva.dataset method)": [[143, "modeva.DataSet.get_raw_data", false]], "get_x_y_data() (modeva.dataset method)": [[135, "modeva.DataSet.get_X_y_data", false]], "impute_missing() (modeva.dataset method)": [[144, "modeva.DataSet.impute_missing", false]], "inputs (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.inputs", false]], "interaction_list_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.interaction_list_", false]], "interaction_list_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.interaction_list_", false]], "interaction_val_loss_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.interaction_val_loss_", false]], "interaction_val_loss_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.interaction_val_loss_", false]], "interpret_coef() (modeva.testsuite method)": [[246, "modeva.TestSuite.interpret_coef", false]], "interpret_effects() (modeva.testsuite method)": [[247, "modeva.TestSuite.interpret_effects", false]], "interpret_effects_moe_average() (modeva.testsuite method)": [[248, "modeva.TestSuite.interpret_effects_moe_average", false]], "interpret_fi() (modeva.testsuite method)": [[249, "modeva.TestSuite.interpret_fi", false]], "interpret_global_tree() (modeva.testsuite method)": [[250, "modeva.TestSuite.interpret_global_tree", false]], "interpret_llm_pc() (modeva.testsuite method)": [[251, "modeva.TestSuite.interpret_llm_pc", false]], "interpret_llm_profile() (modeva.testsuite method)": [[252, "modeva.TestSuite.interpret_llm_profile", false]], "interpret_llm_summary() (modeva.testsuite method)": [[253, "modeva.TestSuite.interpret_llm_summary", false]], "interpret_llm_violin() (modeva.testsuite method)": [[254, "modeva.TestSuite.interpret_llm_violin", false]], "interpret_local_fi() (modeva.testsuite method)": [[255, "modeva.TestSuite.interpret_local_fi", false]], "interpret_local_linear_fi() (modeva.testsuite method)": [[256, "modeva.TestSuite.interpret_local_linear_fi", false]], "interpret_local_moe_weights() (modeva.testsuite method)": [[257, "modeva.TestSuite.interpret_local_moe_weights", false]], "interpret_local_tree() (modeva.testsuite method)": [[258, "modeva.TestSuite.interpret_local_tree", false]], "interpret_moe_cluster_analysis() (modeva.testsuite method)": [[259, "modeva.TestSuite.interpret_moe_cluster_analysis", false]], "inverse_transform() (modeva.dataset method)": [[145, "modeva.DataSet.inverse_transform", false]], "is_splitted() (modeva.dataset method)": [[146, "modeva.DataSet.is_splitted", false]], "key (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.key", false]], "leaderboard() (modeva.modelzoo method)": [[199, "modeva.ModelZoo.leaderboard", false]], "leaf_estimators_ (modeva.models.moglmtreeclassifier attribute)": [[277, "modeva.models.MoGLMTreeClassifier.leaf_estimators_", false]], "list() (modeva.testsuite class method)": [[260, "modeva.TestSuite.list", false]], "list_model_names() (modeva.modelzoo method)": [[200, "modeva.ModelZoo.list_model_names", false]], "list_registered_data() (modeva.dataset method)": [[147, "modeva.DataSet.list_registered_data", false]], "list_registered_models() (modeva.modelzoo method)": [[201, "modeva.ModelZoo.list_registered_models", false]], "list_registered_tests() (modeva.testsuite method)": [[261, "modeva.TestSuite.list_registered_tests", false]], "load() (modeva.dataset method)": [[148, "modeva.DataSet.load", false]], "load() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.load", false]], "load() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.load", false]], "load() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.load", false]], "load() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.load", false]], "load() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.load", false]], "load() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.load", false]], "load() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.load", false]], "load() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.load", false]], "load() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.load", false]], "load() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.load", false]], "load() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.load", false]], "load() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.load", false]], "load() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.load", false]], "load() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.load", false]], "load() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.load", false]], "load() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.load", false]], "load() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.load", false]], "load() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.load", false]], "load() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.load", false]], "load() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.load", false]], "load() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.load", false]], "load() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.load", false]], "load() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.load", false]], "load() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.load", false]], "load() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.load", false]], "load() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.load", false]], "load() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.load", false]], "load() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.load", false]], "load() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.load", false]], "load() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.load", false]], "load() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.load", false]], "load() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.load", false]], "load_csv() (modeva.dataset method)": [[149, "modeva.DataSet.load_csv", false]], "load_dataframe() (modeva.dataset method)": [[150, "modeva.DataSet.load_dataframe", false]], "load_dataframe_train_test() (modeva.dataset method)": [[151, "modeva.DataSet.load_dataframe_train_test", false]], "load_preprocessing() (modeva.dataset method)": [[152, "modeva.DataSet.load_preprocessing", false]], "load_registered_data() (modeva.dataset method)": [[153, "modeva.DataSet.load_registered_data", false]], "load_registered_model() (modeva.modelzoo method)": [[202, "modeva.ModelZoo.load_registered_model", false]], "load_registered_test() (modeva.testsuite method)": [[262, "modeva.TestSuite.load_registered_test", false]], "load_spark() (modeva.dataset method)": [[154, "modeva.DataSet.load_spark", false]], "main_effect_val_loss_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.main_effect_val_loss_", false]], "main_effect_val_loss_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.main_effect_val_loss_", false]], "mocatboostclassifier (class in modeva.models)": [[267, "modeva.models.MoCatBoostClassifier", false]], "mocatboostregressor (class in modeva.models)": [[268, "modeva.models.MoCatBoostRegressor", false]], "moclassifier (class in modeva.models)": [[269, "modeva.models.MoClassifier", false]], "modecisiontreeclassifier (class in modeva.models)": [[270, "modeva.models.MoDecisionTreeClassifier", false]], "modecisiontreeregressor (class in modeva.models)": [[271, "modeva.models.MoDecisionTreeRegressor", false]], "model (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.model", false]], "models (modeva.modelzoo property)": [[203, "modeva.ModelZoo.models", false]], "modeltunegridsearch (class in modeva.models)": [[299, "modeva.models.ModelTuneGridSearch", false]], "modeltuneoptuna (class in modeva.models)": [[300, "modeva.models.ModelTuneOptuna", false]], "modeltunepso (class in modeva.models)": [[301, "modeva.models.ModelTunePSO", false]], "modeltunerandomsearch (class in modeva.models)": [[302, "modeva.models.ModelTuneRandomSearch", false]], "module": [[102, "module-notebook", false]], "moelasticnet (class in modeva.models)": [[272, "modeva.models.MoElasticNet", false]], "mogaminetclassifier (class in modeva.models)": [[273, "modeva.models.MoGAMINetClassifier", false]], "mogaminetregressor (class in modeva.models)": [[274, "modeva.models.MoGAMINetRegressor", false]], "moglmtreeboostclassifier (class in modeva.models)": [[275, "modeva.models.MoGLMTreeBoostClassifier", false]], "moglmtreeboostregressor (class in modeva.models)": [[276, "modeva.models.MoGLMTreeBoostRegressor", false]], "moglmtreeclassifier (class in modeva.models)": [[277, "modeva.models.MoGLMTreeClassifier", false]], "moglmtreeregressor (class in modeva.models)": [[278, "modeva.models.MoGLMTreeRegressor", false]], "mogradientboostingclassifier (class in modeva.models)": [[279, "modeva.models.MoGradientBoostingClassifier", false]], "mogradientboostingregressor (class in modeva.models)": [[280, "modeva.models.MoGradientBoostingRegressor", false]], "molgbmclassifier (class in modeva.models)": [[281, "modeva.models.MoLGBMClassifier", false]], "molgbmregressor (class in modeva.models)": [[282, "modeva.models.MoLGBMRegressor", false]], "mologisticregression (class in modeva.models)": [[283, "modeva.models.MoLogisticRegression", false]], "momoeclassifier (class in modeva.models)": [[284, "modeva.models.MoMoEClassifier", false]], "momoeregressor (class in modeva.models)": [[285, "modeva.models.MoMoERegressor", false]], "moneuraltreeclassifier (class in modeva.models)": [[286, "modeva.models.MoNeuralTreeClassifier", false]], "moneuraltreeregressor (class in modeva.models)": [[287, "modeva.models.MoNeuralTreeRegressor", false]], "morandomforestclassifier (class in modeva.models)": [[288, "modeva.models.MoRandomForestClassifier", false]], "morandomforestregressor (class in modeva.models)": [[289, "modeva.models.MoRandomForestRegressor", false]], "moregressor (class in modeva.models)": [[292, "modeva.models.MoRegressor", false]], "moreludnnclassifier (class in modeva.models)": [[290, "modeva.models.MoReLUDNNClassifier", false]], "moreludnnregressor (class in modeva.models)": [[291, "modeva.models.MoReLUDNNRegressor", false]], "moscoredclassifier (class in modeva.models)": [[295, "modeva.models.MoScoredClassifier", false]], "moscoredregressor (class in modeva.models)": [[296, "modeva.models.MoScoredRegressor", false]], "mosklearnclassifier (class in modeva.models)": [[293, "modeva.models.MoSKLearnClassifier", false]], "mosklearnregressor (class in modeva.models)": [[294, "modeva.models.MoSKLearnRegressor", false]], "moxgbclassifier (class in modeva.models)": [[297, "modeva.models.MoXGBClassifier", false]], "moxgbregressor (class in modeva.models)": [[298, "modeva.models.MoXGBRegressor", false]], "n_features (modeva.dataset property)": [[155, "modeva.DataSet.n_features", false]], "n_features_in_ (modeva.models.moglmtreeboostclassifier attribute)": [[275, "modeva.models.MoGLMTreeBoostClassifier.n_features_in_", false]], "n_features_in_ (modeva.models.moglmtreeboostregressor attribute)": [[276, "modeva.models.MoGLMTreeBoostRegressor.n_features_in_", false]], "n_interactions_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.n_interactions_", false]], "n_interactions_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.n_interactions_", false]], "name (modeva.dataset property)": [[156, "modeva.DataSet.name", false]], "net_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.net_", false]], "net_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.net_", false]], "net_ (modeva.models.moneuraltreeclassifier attribute)": [[286, "modeva.models.MoNeuralTreeClassifier.net_", false]], "net_ (modeva.models.moneuraltreeregressor attribute)": [[287, "modeva.models.MoNeuralTreeRegressor.net_", false]], "net_ (modeva.models.moreludnnclassifier attribute)": [[290, "modeva.models.MoReLUDNNClassifier.net_", false]], "net_ (modeva.models.moreludnnregressor attribute)": [[291, "modeva.models.MoReLUDNNRegressor.net_", false]], "notebook": [[102, "module-notebook", false]], "options (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.options", false]], "optipng() (in module sphinx_gallery.utils)": [[106, "sphinx_gallery.utils.optipng", false]], "pipeline (class in modeva.automation.pipeline)": [[266, "modeva.automation.pipeline.Pipeline", false]], "plot() (modeva.utils.results.validationresult method)": [[307, "modeva.utils.results.ValidationResult.plot", false]], "plot_save() (modeva.utils.results.validationresult method)": [[307, "modeva.utils.results.ValidationResult.plot_save", false]], "predict() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.predict", false]], "predict() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.predict", false]], "predict() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.predict", false]], "predict() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.predict", false]], "predict() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.predict", false]], "predict() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.predict", false]], "predict() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.predict", false]], "predict() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.predict", false]], "predict() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.predict", false]], "predict() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.predict", false]], "predict() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.predict", false]], "predict() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.predict", false]], "predict() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.predict", false]], "predict() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.predict", false]], "predict() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.predict", false]], "predict() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.predict", false]], "predict() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.predict", false]], "predict() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.predict", false]], "predict() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.predict", false]], "predict() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.predict", false]], "predict() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.predict", false]], "predict() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.predict", false]], "predict() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.predict", false]], "predict() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.predict", false]], "predict() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.predict", false]], "predict() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.predict", false]], "predict() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.predict", false]], "predict() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.predict", false]], "predict() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.predict", false]], "predict() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.predict", false]], "predict() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.predict", false]], "predict() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.predict", false]], "predict_interval() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.predict_interval", false]], "predict_interval() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.predict_interval", false]], "predict_interval() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.predict_interval", false]], "predict_interval() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.predict_interval", false]], "predict_interval() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.predict_interval", false]], "predict_interval() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.predict_interval", false]], "predict_interval() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.predict_interval", false]], "predict_interval() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.predict_interval", false]], "predict_interval() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.predict_interval", false]], "predict_interval() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.predict_interval", false]], "predict_interval() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.predict_interval", false]], "predict_interval() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.predict_interval", false]], "predict_interval() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.predict_interval", false]], "predict_interval() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.predict_interval", false]], "predict_interval() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.predict_interval", false]], "predict_interval() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.predict_interval", false]], "predict_interval() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.predict_interval", false]], "predict_interval() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.predict_interval", false]], "predict_interval() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.predict_interval", false]], "predict_interval() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.predict_interval", false]], "predict_interval() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.predict_interval", false]], "predict_interval() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.predict_interval", false]], "predict_interval() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.predict_interval", false]], "predict_interval() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.predict_interval", false]], "predict_interval() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.predict_interval", false]], "predict_proba() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.predict_proba", false]], "predict_proba() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.predict_proba", false]], "predict_proba() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.predict_proba", false]], "predict_proba() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.predict_proba", false]], "predict_proba() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.predict_proba", false]], "predict_proba() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.predict_proba", false]], "predict_proba() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.predict_proba", false]], "predict_proba() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.predict_proba", false]], "predict_proba() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.predict_proba", false]], "predict_proba() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.predict_proba", false]], "predict_proba() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.predict_proba", false]], "predict_proba() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.predict_proba", false]], "predict_proba() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.predict_proba", false]], "predict_proba() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.predict_proba", false]], "prediction (modeva.dataset property)": [[157, "modeva.DataSet.prediction", false]], "preprocess() (modeva.dataset method)": [[158, "modeva.DataSet.preprocess", false]], "raw_data (modeva.dataset property)": [[159, "modeva.DataSet.raw_data", false]], "register() (modeva.dataset method)": [[160, "modeva.DataSet.register", false]], "register() (modeva.modelzoo method)": [[204, "modeva.ModelZoo.register", false]], "register() (modeva.testsuite method)": [[263, "modeva.TestSuite.register", false]], "reset_preprocess() (modeva.dataset method)": [[161, "modeva.DataSet.reset_preprocess", false]], "run() (modeva.automation.pipeline.pipeline method)": [[266, "modeva.automation.pipeline.Pipeline.run", false]], "run() (modeva.models.modeltunegridsearch method)": [[299, "modeva.models.ModelTuneGridSearch.run", false]], "run() (modeva.models.modeltuneoptuna method)": [[300, "modeva.models.ModelTuneOptuna.run", false]], "run() (modeva.models.modeltunepso method)": [[301, "modeva.models.ModelTunePSO.run", false]], "run() (modeva.models.modeltunerandomsearch method)": [[302, "modeva.models.ModelTuneRandomSearch.run", false]], "sample_weight (modeva.dataset property)": [[162, "modeva.DataSet.sample_weight", false]], "save() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.save", false]], "save() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.save", false]], "save() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.save", false]], "save() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.save", false]], "save() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.save", false]], "save() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.save", false]], "save() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.save", false]], "save() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.save", false]], "save() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.save", false]], "save() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.save", false]], "save() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.save", false]], "save() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.save", false]], "save() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.save", false]], "save() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.save", false]], "save() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.save", false]], "save() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.save", false]], "save() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.save", false]], "save() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.save", false]], "save() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.save", false]], "save() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.save", false]], "save() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.save", false]], "save() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.save", false]], "save() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.save", false]], "save() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.save", false]], "save() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.save", false]], "save() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.save", false]], "save() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.save", false]], "save() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.save", false]], "save() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.save", false]], "save() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.save", false]], "save() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.save", false]], "save() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.save", false]], "save_preprocessing() (modeva.dataset method)": [[163, "modeva.DataSet.save_preprocessing", false]], "scale_numerical() (modeva.dataset method)": [[164, "modeva.DataSet.scale_numerical", false]], "set_active_features() (modeva.dataset method)": [[165, "modeva.DataSet.set_active_features", false]], "set_dataset() (modeva.testsuite method)": [[264, "modeva.TestSuite.set_dataset", false]], "set_feature_type() (modeva.dataset method)": [[166, "modeva.DataSet.set_feature_type", false]], "set_inactive_features() (modeva.dataset method)": [[167, "modeva.DataSet.set_inactive_features", false]], "set_mlflow_home() (in module modeva.utils.mlflow)": [[306, "modeva.utils.mlflow.set_mlflow_home", false]], "set_model() (modeva.testsuite method)": [[265, "modeva.TestSuite.set_model", false]], "set_params() (modeva.models.mocatboostclassifier method)": [[267, "modeva.models.MoCatBoostClassifier.set_params", false]], "set_params() (modeva.models.mocatboostregressor method)": [[268, "modeva.models.MoCatBoostRegressor.set_params", false]], "set_params() (modeva.models.moclassifier method)": [[269, "modeva.models.MoClassifier.set_params", false]], "set_params() (modeva.models.modecisiontreeclassifier method)": [[270, "modeva.models.MoDecisionTreeClassifier.set_params", false]], "set_params() (modeva.models.modecisiontreeregressor method)": [[271, "modeva.models.MoDecisionTreeRegressor.set_params", false]], "set_params() (modeva.models.moelasticnet method)": [[272, "modeva.models.MoElasticNet.set_params", false]], "set_params() (modeva.models.mogaminetclassifier method)": [[273, "modeva.models.MoGAMINetClassifier.set_params", false]], "set_params() (modeva.models.mogaminetregressor method)": [[274, "modeva.models.MoGAMINetRegressor.set_params", false]], "set_params() (modeva.models.moglmtreeboostclassifier method)": [[275, "modeva.models.MoGLMTreeBoostClassifier.set_params", false]], "set_params() (modeva.models.moglmtreeboostregressor method)": [[276, "modeva.models.MoGLMTreeBoostRegressor.set_params", false]], "set_params() (modeva.models.moglmtreeclassifier method)": [[277, "modeva.models.MoGLMTreeClassifier.set_params", false]], "set_params() (modeva.models.moglmtreeregressor method)": [[278, "modeva.models.MoGLMTreeRegressor.set_params", false]], "set_params() (modeva.models.mogradientboostingclassifier method)": [[279, "modeva.models.MoGradientBoostingClassifier.set_params", false]], "set_params() (modeva.models.mogradientboostingregressor method)": [[280, "modeva.models.MoGradientBoostingRegressor.set_params", false]], "set_params() (modeva.models.molgbmclassifier method)": [[281, "modeva.models.MoLGBMClassifier.set_params", false]], "set_params() (modeva.models.molgbmregressor method)": [[282, "modeva.models.MoLGBMRegressor.set_params", false]], "set_params() (modeva.models.mologisticregression method)": [[283, "modeva.models.MoLogisticRegression.set_params", false]], "set_params() (modeva.models.momoeclassifier method)": [[284, "modeva.models.MoMoEClassifier.set_params", false]], "set_params() (modeva.models.momoeregressor method)": [[285, "modeva.models.MoMoERegressor.set_params", false]], "set_params() (modeva.models.moneuraltreeclassifier method)": [[286, "modeva.models.MoNeuralTreeClassifier.set_params", false]], "set_params() (modeva.models.moneuraltreeregressor method)": [[287, "modeva.models.MoNeuralTreeRegressor.set_params", false]], "set_params() (modeva.models.morandomforestclassifier method)": [[288, "modeva.models.MoRandomForestClassifier.set_params", false]], "set_params() (modeva.models.morandomforestregressor method)": [[289, "modeva.models.MoRandomForestRegressor.set_params", false]], "set_params() (modeva.models.moregressor method)": [[292, "modeva.models.MoRegressor.set_params", false]], "set_params() (modeva.models.moreludnnclassifier method)": [[290, "modeva.models.MoReLUDNNClassifier.set_params", false]], "set_params() (modeva.models.moreludnnregressor method)": [[291, "modeva.models.MoReLUDNNRegressor.set_params", false]], "set_params() (modeva.models.moscoredclassifier method)": [[295, "modeva.models.MoScoredClassifier.set_params", false]], "set_params() (modeva.models.moscoredregressor method)": [[296, "modeva.models.MoScoredRegressor.set_params", false]], "set_params() (modeva.models.mosklearnclassifier method)": [[293, "modeva.models.MoSKLearnClassifier.set_params", false]], "set_params() (modeva.models.mosklearnregressor method)": [[294, "modeva.models.MoSKLearnRegressor.set_params", false]], "set_params() (modeva.models.moxgbclassifier method)": [[297, "modeva.models.MoXGBClassifier.set_params", false]], "set_params() (modeva.models.moxgbregressor method)": [[298, "modeva.models.MoXGBRegressor.set_params", false]], "set_prediction() (modeva.dataset method)": [[168, "modeva.DataSet.set_prediction", false]], "set_prediction_proba() (modeva.dataset method)": [[169, "modeva.DataSet.set_prediction_proba", false]], "set_protected_data() (modeva.dataset method)": [[170, "modeva.DataSet.set_protected_data", false]], "set_protected_extra_data() (modeva.dataset method)": [[171, "modeva.DataSet.set_protected_extra_data", false]], "set_random_split() (modeva.dataset method)": [[172, "modeva.DataSet.set_random_split", false]], "set_raw_extra_data() (modeva.dataset method)": [[173, "modeva.DataSet.set_raw_extra_data", false]], "set_sample_weight() (modeva.dataset method)": [[174, "modeva.DataSet.set_sample_weight", false]], "set_target() (modeva.dataset method)": [[175, "modeva.DataSet.set_target", false]], "set_task_type() (modeva.dataset method)": [[176, "modeva.DataSet.set_task_type", false]], "set_test_idx() (modeva.dataset method)": [[177, "modeva.DataSet.set_test_idx", false]], "set_train_idx() (modeva.dataset method)": [[178, "modeva.DataSet.set_train_idx", false]], "shape (modeva.dataset property)": [[179, "modeva.DataSet.shape", false]], "subsample_random() (modeva.dataset method)": [[180, "modeva.DataSet.subsample_random", false]], "summary() (modeva.dataset method)": [[181, "modeva.DataSet.summary", false]], "table (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.table", false]], "task_type (modeva.dataset property)": [[182, "modeva.DataSet.task_type", false]], "test_prediction (modeva.dataset property)": [[183, "modeva.DataSet.test_prediction", false]], "test_sample_weight (modeva.dataset property)": [[184, "modeva.DataSet.test_sample_weight", false]], "test_x (modeva.dataset property)": [[185, "modeva.DataSet.test_x", false]], "test_y (modeva.dataset property)": [[186, "modeva.DataSet.test_y", false]], "time_cost_ (modeva.models.mogaminetclassifier attribute)": [[273, "modeva.models.MoGAMINetClassifier.time_cost_", false]], "time_cost_ (modeva.models.mogaminetregressor attribute)": [[274, "modeva.models.MoGAMINetRegressor.time_cost_", false]], "to_df() (modeva.dataset method)": [[187, "modeva.DataSet.to_df", false]], "train() (modeva.modelzoo method)": [[205, "modeva.ModelZoo.train", false]], "train_all() (modeva.modelzoo method)": [[206, "modeva.ModelZoo.train_all", false]], "train_epoch_loss_ (modeva.models.moreludnnclassifier attribute)": [[290, "modeva.models.MoReLUDNNClassifier.train_epoch_loss_", false]], "train_epoch_loss_ (modeva.models.moreludnnregressor attribute)": [[291, "modeva.models.MoReLUDNNRegressor.train_epoch_loss_", false]], "train_prediction (modeva.dataset property)": [[188, "modeva.DataSet.train_prediction", false]], "train_sample_weight (modeva.dataset property)": [[189, "modeva.DataSet.train_sample_weight", false]], "train_x (modeva.dataset property)": [[190, "modeva.DataSet.train_x", false]], "train_y (modeva.dataset property)": [[191, "modeva.DataSet.train_y", false]], "transform() (modeva.dataset method)": [[192, "modeva.DataSet.transform", false]], "tree_ (modeva.models.moglmtreeclassifier attribute)": [[277, "modeva.models.MoGLMTreeClassifier.tree_", false]], "tree_ (modeva.models.moglmtreeregressor attribute)": [[278, "modeva.models.MoGLMTreeRegressor.tree_", false]], "validation_epoch_loss_ (modeva.models.moreludnnclassifier attribute)": [[290, "modeva.models.MoReLUDNNClassifier.validation_epoch_loss_", false]], "validation_epoch_loss_ (modeva.models.moreludnnregressor attribute)": [[291, "modeva.models.MoReLUDNNRegressor.validation_epoch_loss_", false]], "validationresult (class in modeva.utils.results)": [[307, "modeva.utils.results.ValidationResult", false]], "value (modeva.utils.results.validationresult attribute)": [[307, "modeva.utils.results.ValidationResult.value", false]], "x (modeva.dataset property)": [[193, "modeva.DataSet.x", false]], "y (modeva.dataset property)": [[194, "modeva.DataSet.y", false]]}, "objects": {"": [[102, 5, 0, "-", "notebook"]], "modeva.DataSet": [[110, 0, 1, "", "all_feature_names"], [111, 0, 1, "", "all_feature_types"], [112, 1, 1, "", "bin_numerical"], [113, 0, 1, "", "data"], [114, 1, 1, "", "data_drift_test"], [115, 1, 1, "", "delete_extra_data"], [116, 1, 1, "", "delete_registered_data"], [117, 1, 1, "", "detect_outlier_cblof"], [118, 1, 1, "", "detect_outlier_isolation_forest"], [119, 1, 1, "", "detect_outlier_pca"], [120, 1, 1, "", "eda_1d"], [121, 1, 1, "", "eda_2d"], [122, 1, 1, "", "eda_3d"], [123, 1, 1, "", "eda_correlation"], [124, 1, 1, "", "eda_pca"], [125, 1, 1, "", "eda_umap"], [126, 1, 1, "", "encode_categorical"], [127, 0, 1, "", "feature_names"], [128, 0, 1, "", "feature_names_categorical"], [129, 0, 1, "", "feature_names_mixed"], [130, 0, 1, "", "feature_names_numerical"], [131, 1, 1, "", "feature_select_corr"], [132, 1, 1, "", "feature_select_rcit"], [133, 1, 1, "", "feature_select_xgbpfi"], [134, 0, 1, "", "feature_types"], [135, 1, 1, "", "get_X_y_data"], [136, 1, 1, "", "get_data"], [137, 1, 1, "", "get_data_list"], [138, 1, 1, "", "get_extra_data_list"], [139, 1, 1, "", "get_prediction_data"], [140, 1, 1, "", "get_prediction_proba_data"], [141, 1, 1, "", "get_preprocessor"], [142, 1, 1, "", "get_protected_data"], [143, 1, 1, "", "get_raw_data"], [144, 1, 1, "", "impute_missing"], [145, 1, 1, "", "inverse_transform"], [146, 1, 1, "", "is_splitted"], [147, 1, 1, "", "list_registered_data"], [148, 1, 1, "", "load"], [149, 1, 1, "", "load_csv"], [150, 1, 1, "", "load_dataframe"], [151, 1, 1, "", "load_dataframe_train_test"], [152, 1, 1, "", "load_preprocessing"], [153, 1, 1, "", "load_registered_data"], [154, 1, 1, "", "load_spark"], [155, 0, 1, "", "n_features"], [156, 0, 1, "", "name"], [157, 0, 1, "", "prediction"], [158, 1, 1, "", "preprocess"], [159, 0, 1, "", "raw_data"], [160, 1, 1, "", "register"], [161, 1, 1, "", "reset_preprocess"], [162, 0, 1, "", "sample_weight"], [163, 1, 1, "", "save_preprocessing"], [164, 1, 1, "", "scale_numerical"], [165, 1, 1, "", "set_active_features"], [166, 1, 1, "", "set_feature_type"], [167, 1, 1, "", "set_inactive_features"], [168, 1, 1, "", "set_prediction"], [169, 1, 1, "", "set_prediction_proba"], [170, 1, 1, "", "set_protected_data"], [171, 1, 1, "", "set_protected_extra_data"], [172, 1, 1, "", "set_random_split"], [173, 1, 1, "", "set_raw_extra_data"], [174, 1, 1, "", "set_sample_weight"], [175, 1, 1, "", "set_target"], [176, 1, 1, "", "set_task_type"], [177, 1, 1, "", "set_test_idx"], [178, 1, 1, "", "set_train_idx"], [179, 0, 1, "", "shape"], [180, 1, 1, "", "subsample_random"], [181, 1, 1, "", "summary"], [182, 0, 1, "", "task_type"], [183, 0, 1, "", "test_prediction"], [184, 0, 1, "", "test_sample_weight"], [185, 0, 1, "", "test_x"], [186, 0, 1, "", "test_y"], [187, 1, 1, "", "to_df"], [188, 0, 1, "", "train_prediction"], [189, 0, 1, "", "train_sample_weight"], [190, 0, 1, "", "train_x"], [191, 0, 1, "", "train_y"], [192, 1, 1, "", "transform"], [193, 0, 1, "", "x"], [194, 0, 1, "", "y"]], "modeva.ModelZoo": [[195, 1, 1, "", "add_model"], [196, 0, 1, "", "dataset"], [197, 1, 1, "", "delete_registered_model"], [198, 1, 1, "", "get_model"], [199, 1, 1, "", "leaderboard"], [200, 1, 1, "", "list_model_names"], [201, 1, 1, "", "list_registered_models"], [202, 1, 1, "", "load_registered_model"], [203, 0, 1, "", "models"], [204, 1, 1, "", "register"], [205, 1, 1, "", "train"], [206, 1, 1, "", "train_all"]], "modeva.TestSuite": [[207, 1, 1, "", "compare_accuracy_table"], [208, 1, 1, "", "compare_fairness"], [209, 1, 1, "", "compare_reliability"], [210, 1, 1, "", "compare_residual_cluster"], [211, 1, 1, "", "compare_resilience"], [212, 1, 1, "", "compare_robustness"], [213, 1, 1, "", "compare_slicing_accuracy"], [214, 1, 1, "", "compare_slicing_fairness"], [215, 1, 1, "", "compare_slicing_overfit"], [216, 1, 1, "", "compare_slicing_reliability"], [217, 1, 1, "", "compare_slicing_robustness"], [218, 1, 1, "", "delete_registed_test"], [219, 1, 1, "", "diagnose_accuracy_table"], [220, 1, 1, "", "diagnose_fairness"], [221, 1, 1, "", "diagnose_mitigate_unfair_binning"], [222, 1, 1, "", "diagnose_mitigate_unfair_thresholding"], [223, 1, 1, "", "diagnose_reliability"], [224, 1, 1, "", "diagnose_residual_analysis"], [225, 1, 1, "", "diagnose_residual_cluster"], [226, 1, 1, "", "diagnose_residual_interpret"], [227, 1, 1, "", "diagnose_resilience"], [228, 1, 1, "", "diagnose_robustness"], [229, 1, 1, "", "diagnose_slicing_accuracy"], [230, 1, 1, "", "diagnose_slicing_fairness"], [231, 1, 1, "", "diagnose_slicing_overfit"], [232, 1, 1, "", "diagnose_slicing_reliability"], [233, 1, 1, "", "diagnose_slicing_robustness"], [234, 1, 1, "", "display_test_results"], [235, 1, 1, "", "explain_ale"], [236, 1, 1, "", "explain_hstatistic"], [237, 1, 1, "", "explain_lime"], [238, 1, 1, "", "explain_pdp"], [239, 1, 1, "", "explain_pfi"], [240, 1, 1, "", "explain_shap"], [241, 1, 1, "", "export_report"], [242, 1, 1, "", "get_dataset"], [243, 1, 1, "", "get_interactions"], [244, 1, 1, "", "get_main_effects"], [245, 1, 1, "", "get_model"], [246, 1, 1, "", "interpret_coef"], [247, 1, 1, "", "interpret_effects"], [248, 1, 1, "", "interpret_effects_moe_average"], [249, 1, 1, "", "interpret_fi"], [250, 1, 1, "", "interpret_global_tree"], [251, 1, 1, "", "interpret_llm_pc"], [252, 1, 1, "", "interpret_llm_profile"], [253, 1, 1, "", "interpret_llm_summary"], [254, 1, 1, "", "interpret_llm_violin"], [255, 1, 1, "", "interpret_local_fi"], [256, 1, 1, "", "interpret_local_linear_fi"], [257, 1, 1, "", "interpret_local_moe_weights"], [258, 1, 1, "", "interpret_local_tree"], [259, 1, 1, "", "interpret_moe_cluster_analysis"], [260, 1, 1, "", "list"], [261, 1, 1, "", "list_registered_tests"], [262, 1, 1, "", "load_registered_test"], [263, 1, 1, "", "register"], [264, 1, 1, "", "set_dataset"], [265, 1, 1, "", "set_model"]], "modeva.automation.pipeline": [[266, 2, 1, "", "Pipeline"]], "modeva.automation.pipeline.Pipeline": [[266, 1, 1, "", "add_step"], [266, 1, 1, "", "run"]], "modeva.models": [[267, 2, 1, "", "MoCatBoostClassifier"], [268, 2, 1, "", "MoCatBoostRegressor"], [269, 2, 1, "", "MoClassifier"], [270, 2, 1, "", "MoDecisionTreeClassifier"], [271, 2, 1, "", "MoDecisionTreeRegressor"], [272, 2, 1, "", "MoElasticNet"], [273, 2, 1, "", "MoGAMINetClassifier"], [274, 2, 1, "", "MoGAMINetRegressor"], [275, 2, 1, "", "MoGLMTreeBoostClassifier"], [276, 2, 1, "", "MoGLMTreeBoostRegressor"], [277, 2, 1, "", "MoGLMTreeClassifier"], [278, 2, 1, "", "MoGLMTreeRegressor"], [279, 2, 1, "", "MoGradientBoostingClassifier"], [280, 2, 1, "", "MoGradientBoostingRegressor"], [281, 2, 1, "", "MoLGBMClassifier"], [282, 2, 1, "", "MoLGBMRegressor"], [283, 2, 1, "", "MoLogisticRegression"], [284, 2, 1, "", "MoMoEClassifier"], [285, 2, 1, "", "MoMoERegressor"], [286, 2, 1, "", "MoNeuralTreeClassifier"], [287, 2, 1, "", "MoNeuralTreeRegressor"], [288, 2, 1, "", "MoRandomForestClassifier"], [289, 2, 1, "", "MoRandomForestRegressor"], [290, 2, 1, "", "MoReLUDNNClassifier"], [291, 2, 1, "", "MoReLUDNNRegressor"], [292, 2, 1, "", "MoRegressor"], [293, 2, 1, "", "MoSKLearnClassifier"], [294, 2, 1, "", "MoSKLearnRegressor"], [295, 2, 1, "", "MoScoredClassifier"], [296, 2, 1, "", "MoScoredRegressor"], [297, 2, 1, "", "MoXGBClassifier"], [298, 2, 1, "", "MoXGBRegressor"], [299, 2, 1, "", "ModelTuneGridSearch"], [300, 2, 1, "", "ModelTuneOptuna"], [301, 2, 1, "", "ModelTunePSO"], [302, 2, 1, "", "ModelTuneRandomSearch"]], "modeva.models.MoCatBoostClassifier": [[267, 1, 1, "", "calibrate_interval"], [267, 1, 1, "", "calibrate_proba"], [267, 1, 1, "", "decision_function"], [267, 1, 1, "", "fit"], [267, 1, 1, "", "get_params"], [267, 1, 1, "", "load"], [267, 1, 1, "", "predict"], [267, 1, 1, "", "predict_interval"], [267, 1, 1, "", "predict_proba"], [267, 1, 1, "", "save"], [267, 1, 1, "", "set_params"]], "modeva.models.MoCatBoostRegressor": [[268, 1, 1, "", "calibrate_interval"], [268, 1, 1, "", "fit"], [268, 1, 1, "", "get_params"], [268, 1, 1, "", "load"], [268, 1, 1, "", "predict"], [268, 1, 1, "", "predict_interval"], [268, 1, 1, "", "save"], [268, 1, 1, "", "set_params"]], "modeva.models.MoClassifier": [[269, 1, 1, "", "calibrate_interval"], [269, 1, 1, "", "calibrate_proba"], [269, 1, 1, "", "decision_function"], [269, 1, 1, "", "fit"], [269, 1, 1, "", "get_params"], [269, 1, 1, "", "load"], [269, 1, 1, "", "predict"], [269, 1, 1, "", "predict_interval"], [269, 1, 1, "", "predict_proba"], [269, 1, 1, "", "save"], [269, 1, 1, "", "set_params"]], "modeva.models.MoDecisionTreeClassifier": [[270, 1, 1, "", "calibrate_interval"], [270, 1, 1, "", "calibrate_proba"], [270, 1, 1, "", "decision_function"], [270, 1, 1, "", "fit"], [270, 1, 1, "", "get_params"], [270, 1, 1, "", "load"], [270, 1, 1, "", "predict"], [270, 1, 1, "", "predict_interval"], [270, 1, 1, "", "predict_proba"], [270, 1, 1, "", "save"], [270, 1, 1, "", "set_params"]], "modeva.models.MoDecisionTreeRegressor": [[271, 1, 1, "", "calibrate_interval"], [271, 1, 1, "", "fit"], [271, 1, 1, "", "get_params"], [271, 1, 1, "", "load"], [271, 1, 1, "", "predict"], [271, 1, 1, "", "predict_interval"], [271, 1, 1, "", "save"], [271, 1, 1, "", "set_params"]], "modeva.models.MoElasticNet": [[272, 1, 1, "", "calibrate_interval"], [272, 1, 1, "", "fit"], [272, 1, 1, "", "get_params"], [272, 1, 1, "", "load"], [272, 1, 1, "", "predict"], [272, 1, 1, "", "predict_interval"], [272, 1, 1, "", "save"], [272, 1, 1, "", "set_params"]], "modeva.models.MoGAMINetClassifier": [[273, 3, 1, "", "active_interaction_index_"], [273, 3, 1, "", "active_main_effect_index_"], [273, 1, 1, "", "calibrate_interval"], [273, 1, 1, "", "calibrate_proba"], [273, 1, 1, "", "decision_function"], [273, 1, 1, "", "fit"], [273, 1, 1, "", "get_params"], [273, 3, 1, "", "interaction_list_"], [273, 3, 1, "", "interaction_val_loss_"], [273, 1, 1, "", "load"], [273, 3, 1, "", "main_effect_val_loss_"], [273, 3, 1, "", "n_interactions_"], [273, 3, 1, "", "net_"], [273, 1, 1, "", "predict"], [273, 1, 1, "", "predict_interval"], [273, 1, 1, "", "predict_proba"], [273, 1, 1, "", "save"], [273, 1, 1, "", "set_params"], [273, 3, 1, "", "time_cost_"]], "modeva.models.MoGAMINetRegressor": [[274, 3, 1, "", "active_interaction_index_"], [274, 3, 1, "", "active_main_effect_index_"], [274, 1, 1, "", "calibrate_interval"], [274, 1, 1, "", "fit"], [274, 1, 1, "", "get_params"], [274, 3, 1, "", "interaction_list_"], [274, 3, 1, "", "interaction_val_loss_"], [274, 1, 1, "", "load"], [274, 3, 1, "", "main_effect_val_loss_"], [274, 3, 1, "", "n_interactions_"], [274, 3, 1, "", "net_"], [274, 1, 1, "", "predict"], [274, 1, 1, "", "predict_interval"], [274, 1, 1, "", "save"], [274, 1, 1, "", "set_params"], [274, 3, 1, "", "time_cost_"]], "modeva.models.MoGLMTreeBoostClassifier": [[275, 1, 1, "", "calibrate_interval"], [275, 1, 1, "", "calibrate_proba"], [275, 1, 1, "", "decision_function"], [275, 3, 1, "", "estimators_"], [275, 1, 1, "", "fit"], [275, 1, 1, "", "get_params"], [275, 1, 1, "", "load"], [275, 3, 1, "", "n_features_in_"], [275, 1, 1, "", "predict"], [275, 1, 1, "", "predict_interval"], [275, 1, 1, "", "predict_proba"], [275, 1, 1, "", "save"], [275, 1, 1, "", "set_params"]], "modeva.models.MoGLMTreeBoostRegressor": [[276, 1, 1, "", "calibrate_interval"], [276, 3, 1, "", "estimators_"], [276, 1, 1, "", "fit"], [276, 1, 1, "", "get_params"], [276, 1, 1, "", "load"], [276, 3, 1, "", "n_features_in_"], [276, 1, 1, "", "predict"], [276, 1, 1, "", "predict_interval"], [276, 1, 1, "", "save"], [276, 1, 1, "", "set_params"]], "modeva.models.MoGLMTreeClassifier": [[277, 1, 1, "", "calibrate_interval"], [277, 1, 1, "", "calibrate_proba"], [277, 1, 1, "", "decision_function"], [277, 1, 1, "", "get_params"], [277, 3, 1, "", "leaf_estimators_"], [277, 1, 1, "", "load"], [277, 1, 1, "", "predict"], [277, 1, 1, "", "predict_interval"], [277, 1, 1, "", "predict_proba"], [277, 1, 1, "", "save"], [277, 1, 1, "", "set_params"], [277, 3, 1, "", "tree_"]], "modeva.models.MoGLMTreeRegressor": [[278, 1, 1, "", "calibrate_interval"], [278, 1, 1, "", "get_params"], [278, 1, 1, "", "load"], [278, 1, 1, "", "predict"], [278, 1, 1, "", "predict_interval"], [278, 1, 1, "", "save"], [278, 1, 1, "", "set_params"], [278, 3, 1, "", "tree_"]], "modeva.models.MoGradientBoostingClassifier": [[279, 1, 1, "", "calibrate_interval"], [279, 1, 1, "", "calibrate_proba"], [279, 1, 1, "", "decision_function"], [279, 1, 1, "", "fit"], [279, 1, 1, "", "get_params"], [279, 1, 1, "", "load"], [279, 1, 1, "", "predict"], [279, 1, 1, "", "predict_interval"], [279, 1, 1, "", "predict_proba"], [279, 1, 1, "", "save"], [279, 1, 1, "", "set_params"]], "modeva.models.MoGradientBoostingRegressor": [[280, 1, 1, "", "calibrate_interval"], [280, 1, 1, "", "fit"], [280, 1, 1, "", "get_params"], [280, 1, 1, "", "load"], [280, 1, 1, "", "predict"], [280, 1, 1, "", "predict_interval"], [280, 1, 1, "", "save"], [280, 1, 1, "", "set_params"]], "modeva.models.MoLGBMClassifier": [[281, 1, 1, "", "calibrate_interval"], [281, 1, 1, "", "calibrate_proba"], [281, 1, 1, "", "decision_function"], [281, 1, 1, "", "fit"], [281, 1, 1, "", "get_params"], [281, 1, 1, "", "load"], [281, 1, 1, "", "predict"], [281, 1, 1, "", "predict_interval"], [281, 1, 1, "", "predict_proba"], [281, 1, 1, "", "save"], [281, 1, 1, "", "set_params"]], "modeva.models.MoLGBMRegressor": [[282, 1, 1, "", "calibrate_interval"], [282, 1, 1, "", "fit"], [282, 1, 1, "", "get_params"], [282, 1, 1, "", "load"], [282, 1, 1, "", "predict"], [282, 1, 1, "", "predict_interval"], [282, 1, 1, "", "save"], [282, 1, 1, "", "set_params"]], "modeva.models.MoLogisticRegression": [[283, 1, 1, "", "calibrate_interval"], [283, 1, 1, "", "calibrate_proba"], [283, 1, 1, "", "decision_function"], [283, 1, 1, "", "fit"], [283, 1, 1, "", "get_params"], [283, 1, 1, "", "load"], [283, 1, 1, "", "predict"], [283, 1, 1, "", "predict_interval"], [283, 1, 1, "", "predict_proba"], [283, 1, 1, "", "save"], [283, 1, 1, "", "set_params"]], "modeva.models.MoMoEClassifier": [[284, 1, 1, "", "calibrate_interval"], [284, 1, 1, "", "calibrate_proba"], [284, 1, 1, "", "decision_function"], [284, 1, 1, "", "fit"], [284, 1, 1, "", "get_params"], [284, 1, 1, "", "load"], [284, 1, 1, "", "predict"], [284, 1, 1, "", "predict_interval"], [284, 1, 1, "", "predict_proba"], [284, 1, 1, "", "save"], [284, 1, 1, "", "set_params"]], "modeva.models.MoMoERegressor": [[285, 1, 1, "", "calibrate_interval"], [285, 1, 1, "", "fit"], [285, 1, 1, "", "get_params"], [285, 1, 1, "", "load"], [285, 1, 1, "", "predict"], [285, 1, 1, "", "predict_interval"], [285, 1, 1, "", "save"], [285, 1, 1, "", "set_params"]], "modeva.models.MoNeuralTreeClassifier": [[286, 1, 1, "", "calibrate_interval"], [286, 1, 1, "", "calibrate_proba"], [286, 1, 1, "", "decision_function"], [286, 1, 1, "", "get_params"], [286, 1, 1, "", "load"], [286, 3, 1, "", "net_"], [286, 1, 1, "", "predict"], [286, 1, 1, "", "predict_interval"], [286, 1, 1, "", "predict_proba"], [286, 1, 1, "", "save"], [286, 1, 1, "", "set_params"]], "modeva.models.MoNeuralTreeRegressor": [[287, 1, 1, "", "calibrate_interval"], [287, 1, 1, "", "get_params"], [287, 1, 1, "", "load"], [287, 3, 1, "", "net_"], [287, 1, 1, "", "predict"], [287, 1, 1, "", "predict_interval"], [287, 1, 1, "", "save"], [287, 1, 1, "", "set_params"]], "modeva.models.MoRandomForestClassifier": [[288, 1, 1, "", "calibrate_interval"], [288, 1, 1, "", "calibrate_proba"], [288, 1, 1, "", "decision_function"], [288, 1, 1, "", "fit"], [288, 1, 1, "", "get_params"], [288, 1, 1, "", "load"], [288, 1, 1, "", "predict"], [288, 1, 1, "", "predict_interval"], [288, 1, 1, "", "predict_proba"], [288, 1, 1, "", "save"], [288, 1, 1, "", "set_params"]], "modeva.models.MoRandomForestRegressor": [[289, 1, 1, "", "calibrate_interval"], [289, 1, 1, "", "fit"], [289, 1, 1, "", "get_params"], [289, 1, 1, "", "load"], [289, 1, 1, "", "predict"], [289, 1, 1, "", "predict_interval"], [289, 1, 1, "", "save"], [289, 1, 1, "", "set_params"]], "modeva.models.MoReLUDNNClassifier": [[290, 1, 1, "", "calibrate_interval"], [290, 1, 1, "", "calibrate_proba"], [290, 1, 1, "", "decision_function"], [290, 1, 1, "", "fit"], [290, 1, 1, "", "get_params"], [290, 1, 1, "", "load"], [290, 3, 1, "", "net_"], [290, 1, 1, "", "predict"], [290, 1, 1, "", "predict_interval"], [290, 1, 1, "", "predict_proba"], [290, 1, 1, "", "save"], [290, 1, 1, "", "set_params"], [290, 3, 1, "", "train_epoch_loss_"], [290, 3, 1, "", "validation_epoch_loss_"]], "modeva.models.MoReLUDNNRegressor": [[291, 1, 1, "", "calibrate_interval"], [291, 1, 1, "", "fit"], [291, 1, 1, "", "get_params"], [291, 1, 1, "", "load"], [291, 3, 1, "", "net_"], [291, 1, 1, "", "predict"], [291, 1, 1, "", "predict_interval"], [291, 1, 1, "", "save"], [291, 1, 1, "", "set_params"], [291, 3, 1, "", "train_epoch_loss_"], [291, 3, 1, "", "validation_epoch_loss_"]], "modeva.models.MoRegressor": [[292, 1, 1, "", "calibrate_interval"], [292, 1, 1, "", "fit"], [292, 1, 1, "", "get_params"], [292, 1, 1, "", "load"], [292, 1, 1, "", "predict"], [292, 1, 1, "", "predict_interval"], [292, 1, 1, "", "save"], [292, 1, 1, "", "set_params"]], "modeva.models.MoSKLearnClassifier": [[293, 1, 1, "", "calibrate_interval"], [293, 1, 1, "", "calibrate_proba"], [293, 1, 1, "", "decision_function"], [293, 1, 1, "", "fit"], [293, 1, 1, "", "get_params"], [293, 1, 1, "", "load"], [293, 1, 1, "", "predict"], [293, 1, 1, "", "predict_interval"], [293, 1, 1, "", "predict_proba"], [293, 1, 1, "", "save"], [293, 1, 1, "", "set_params"]], "modeva.models.MoSKLearnRegressor": [[294, 1, 1, "", "calibrate_interval"], [294, 1, 1, "", "fit"], [294, 1, 1, "", "get_params"], [294, 1, 1, "", "load"], [294, 1, 1, "", "predict"], [294, 1, 1, "", "predict_interval"], [294, 1, 1, "", "save"], [294, 1, 1, "", "set_params"]], "modeva.models.MoScoredClassifier": [[295, 1, 1, "", "calibrate_interval"], [295, 1, 1, "", "calibrate_proba"], [295, 1, 1, "", "decision_function"], [295, 1, 1, "", "get_params"], [295, 1, 1, "", "load"], [295, 1, 1, "", "predict"], [295, 1, 1, "", "predict_interval"], [295, 1, 1, "", "predict_proba"], [295, 1, 1, "", "save"], [295, 1, 1, "", "set_params"]], "modeva.models.MoScoredRegressor": [[296, 1, 1, "", "calibrate_interval"], [296, 1, 1, "", "get_params"], [296, 1, 1, "", "load"], [296, 1, 1, "", "predict"], [296, 1, 1, "", "predict_interval"], [296, 1, 1, "", "save"], [296, 1, 1, "", "set_params"]], "modeva.models.MoXGBClassifier": [[297, 1, 1, "", "calibrate_interval"], [297, 1, 1, "", "calibrate_proba"], [297, 1, 1, "", "decision_function"], [297, 1, 1, "", "fit"], [297, 1, 1, "", "get_params"], [297, 1, 1, "", "load"], [297, 1, 1, "", "predict"], [297, 1, 1, "", "predict_interval"], [297, 1, 1, "", "predict_proba"], [297, 1, 1, "", "save"], [297, 1, 1, "", "set_params"]], "modeva.models.MoXGBRegressor": [[298, 1, 1, "", "calibrate_interval"], [298, 1, 1, "", "fit"], [298, 1, 1, "", "get_params"], [298, 1, 1, "", "load"], [298, 1, 1, "", "predict"], [298, 1, 1, "", "predict_interval"], [298, 1, 1, "", "save"], [298, 1, 1, "", "set_params"]], "modeva.models.ModelTuneGridSearch": [[299, 1, 1, "", "run"]], "modeva.models.ModelTuneOptuna": [[300, 1, 1, "", "run"]], "modeva.models.ModelTunePSO": [[301, 1, 1, "", "run"]], "modeva.models.ModelTuneRandomSearch": [[302, 1, 1, "", "run"]], "modeva.testsuite.utils.slicing_utils": [[303, 4, 1, "", "get_data_info"]], "modeva.utils.mlflow": [[304, 4, 1, "", "clear_mlflow_home"], [305, 4, 1, "", "get_mlflow_home"], [306, 4, 1, "", "set_mlflow_home"]], "modeva.utils.results": [[307, 2, 1, "", "ValidationResult"]], "modeva.utils.results.ValidationResult": [[307, 3, 1, "", "data"], [307, 3, 1, "", "func"], [307, 1, 1, "", "get_figure_names"], [307, 3, 1, "", "inputs"], [307, 3, 1, "", "key"], [307, 3, 1, "", "model"], [307, 3, 1, "", "options"], [307, 1, 1, "", "plot"], [307, 1, 1, "", "plot_save"], [307, 3, 1, "", "table"], [307, 3, 1, "", "value"]], "sphinx_gallery.utils": [[106, 4, 1, "", "optipng"]]}, "objnames": {"0": ["py", "property", "Python property"], "1": ["py", "method", "Python method"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "module", "Python module"]}, "objtypes": {"0": "py:property", "1": "py:method", "2": "py:class", "3": "py:attribute", "4": "py:function", "5": "py:module"}, "terms": {"": [5, 49, 112, 123, 131, 135, 136, 139, 140, 142, 143, 207, 213, 214, 215, 216, 217, 219, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 246, 247, 249, 250, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 318, 322, 323, 324, 326, 327, 328, 329, 330, 332, 333, 335, 337, 338, 339, 343, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 88, 107, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 131, 132, 133, 144, 164, 172, 180, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 248, 255, 256, 257, 258, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 318, 319, 320, 323, 324, 326, 327, 332, 333, 334, 336, 337, 339, 342, 344, 345, 347, 349, 351, 352, 355, 356, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 379], "00": [8, 9, 10, 11, 21, 22, 25, 27, 35, 47, 49, 59, 63, 64, 67, 68, 71, 72, 79, 80, 83, 379], "000": [36, 72, 318, 353, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 379], "0000": [8, 9, 10, 17, 23, 24, 52, 67, 71, 79, 83], "000000": [2, 3, 5], "00000000e": 22, "00000002e": 25, "000028": 5, "000043": [2, 5], "0001": [14, 23, 24, 44, 273, 274, 286, 287], "0002": [20, 23, 24, 52, 67, 361], "00021112504082323335": 52, "0003": [24, 68, 86], "0004": [23, 43], "000434": [2, 3, 5], "0004342": 2, "000488": 323, "0005": 86, "0006": [], "000611": 57, "00065090e": 25, "0007": [23, 24, 46, 52], "0007069232358482019": 52, "0008": 23, "000806": 15, "0008e": 23, "0009": [20, 44], "000e": 10, "001": [23, 24, 25, 26, 43, 45, 46, 49, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 286, 287, 290, 291, 361, 374], "0010": [23, 24, 86], "0012": 23, "0013": [19, 44], "001398e": 334, "0014": 34, "00162004": 40, "0017": [18, 43], "00178131": 25, "0019": [18, 23, 43, 46], "0020": [52, 68], "002041522022738862": 52, "0021": 68, "00214606": 25, "0022": [23, 35], "0023": 25, "0024": 24, "0025": [18, 24], "0025790630388779416": 52, "00259": 24, "0026": [20, 23, 24, 52], "00260": 24, "00262": 24, "00263": 24, "00267": 24, "00268": 24, "0027": 20, "00272": 24, "00278": 24, "0028": 34, "00286": 24, "00287": 24, "00289": 24, "0029": [20, 86], "00291": 24, "00292": 24, "00293": 24, "00295": 24, "00297": 24, "0030": [23, 26], "00302": 24, "00307": 24, "0031": [18, 86], "003126e": 334, "00315": 24, "0033": 18, "0033984293947358856": 52, "0034": [23, 52], "00340": 24, "003448": 15, "00347": 24, "00354": 24, "00354041": 25, "0036": [24, 86], "00369": 24, "0037": [18, 46], "00371": 24, "003728": 15, "0038": 24, "00380": 24, "00382": 324, "00387936": 25, "00388": 24, "0039": [19, 24, 25, 38], "0040": 24, "0041": 18, "0042": [18, 23, 24, 43], "00420": 24, "0043": [18, 24], "0044": [18, 24], "00441816": 25, "00444": 24, "0045": [18, 24], "0046": 18, "0047": [18, 24], "00471474": 25, "0048": [18, 24], "0049": [18, 24, 34], "00490": 24, "004945": 13, "00499824": 8, "0050": [18, 24, 34, 46], "005082": 58, "0051": [18, 24, 67], "00511972": 8, "0052": [18, 24, 86], "0053": [18, 24], "0054": 18, "0055": [18, 24], "0056": 18, "00568": 24, "0057": [18, 26, 38], "0058": 18, "0059": 18, "00594566e": 22, "0060": 18, "006083": 15, "0061": [18, 34, 35], "0062": [18, 35], "006292": 13, "0063": 18, "0065": [18, 46, 366], "0066": 18, "0067": [24, 35], "00676261": 25, "0069": 18, "0070": 18, "0071": 23, "0072": 18, "0073": 43, "0075": 18, "0076": 18, "007705": 14, "0078": 34, "0079": [18, 23], "0080": [18, 80], "0081": 18, "00813082": 25, "00817011": 25, "0082": [23, 68], "00823353": 8, "008289": 15, "0083": 86, "00835": 24, "0084": [26, 67], "0085": [18, 23, 25], "0086": 23, "0087": 23, "0088": 18, "00881300e": 25, "00889805": 25, "0090": [18, 19], "0091": 19, "0093": 25, "00935902": 25, "0094": 18, "0095": [18, 19, 25], "009701": 9, "009832": 14, "0099": 18, "00996485": 25, "01": [2, 4, 10, 14, 21, 22, 23, 25, 27, 34, 36, 41, 43, 45, 46, 47, 49, 83, 273, 274, 301, 358, 370, 379], "010": [39, 41], "0100": 18, "0101": 23, "01028866": 8, "0105": 18, "01055193": 25, "01075141": 25, "0110": 18, "0113": 22, "01136341": 25, "0115": [18, 44], "0116": 86, "01185624": 25, "0120": 18, "01217": 24, "0124": [18, 67], "0125": 18, "0126": 23, "012624": 14, "01265278": 25, "0128": 18, "01286074": 25, "0129": 18, "0130": 68, "0134": 18, "0135": 18, "01355191": 25, "01358633": 25, "0137": 18, "01371426": 25, "013826": 13, "01398571": 25, "0140": 18, "0142": 18, "01428879": 8, "0143": 18, "0145": 18, "0146": 18, "0148": 18, "0149": 23, "0150": 18, "0151": 18, "0152": 18, "0154": [18, 34], "0155": 18, "0156": 18, "0157": 18, "0158": 18, "0160": 18, "0161": 18, "0162": 18, "0163": 18, "0164": [18, 23, 68], "01641528": 25, "0165": 18, "01658904": 25, "0166": [18, 34], "0168": 18, "0169": [18, 68], "017": [25, 27], "0170": 18, "01700743": 25, "017097": 14, "0171": 18, "0172": 18, "0173": [18, 24], "0174": 68, "0175": 18, "017541e": 334, "0176": 67, "0177": [18, 68], "0178": 68, "0180": 18, "0181": [18, 67], "01815329": 25, "0182": 18, "0183": 18, "01830676": 40, "0184": 18, "01845475": 8, "0185": 18, "01853939": 8, "0188": 67, "01883298": 25, "0189": 18, "01901355": 25, "0191": [18, 68], "019206": 13, "0194": 18, "0197": [18, 68], "0198": 80, "0198504": 25, "02": [10, 27, 34, 36, 41, 43, 49, 63, 65, 68, 72, 83, 334, 370], "0201": 18, "0202": 68, "0204": 68, "020537e": 334, "0206": [18, 68], "02073921": 25, "0211": 18, "0212": 46, "021241": 16, "021339": 16, "0214": [21, 44], "0216": 44, "0218": 18, "02180920e": 25, "0219": 22, "02204623": 25, "0221": 18, "02214641": 25, "0222": [45, 68], "022405e": 334, "0225": 18, "02270906": 25, "02299061": 25, "0233": 18, "0235": [46, 62], "023606": 3, "0237": [22, 68], "0238": 18, "02398097": 8, "02418091": 25, "0244": [18, 68], "0247": 18, "02474484": 25, "0248": [18, 68], "0250": [23, 34], "0251": 67, "0252": 18, "0254": [35, 45, 46], "02541088": 25, "0255": [18, 68], "0257": 80, "0258": 18, "0261": 18, "0262": 68, "0263": 18, "0264": 80, "02643381": 25, "0265": 18, "0268": [18, 68], "0269": [21, 34], "026928": 14, "0271": [18, 67], "0278": 18, "0284": 18, "0287": 67, "0287415": 25, "028757": 5, "02922558": 25, "029384": [2, 5], "02953576": 25, "0296": 23, "03": [2, 11, 24, 27, 36, 43, 49, 63, 77, 79, 334], "0300": 18, "03026423": 25, "0303": 8, "0305032": 8, "03081845": 25, "0311": [35, 43], "03114211": 25, "0312": [18, 83], "0317": 67, "0318": 23, "0319": 67, "0320": 43, "0321": 43, "0324": [34, 68], "0325": 67, "03263528": 17, "03267184": 25, "0328": 34, "03286639": 25, "0334": 24, "0336": [67, 68], "0337": 67, "03414900e": 25, "0343": 18, "0345": 43, "034555e": 334, "0345931": 25, "0347": 44, "0349187": 25, "035233": 3, "0353": [46, 71], "0354": 46, "0355": [31, 44], "03566952": 25, "03576016": 25, "0358": 24, "0367": 20, "0368": 24, "036867": 3, "0369": 68, "0370": 44, "037003": 58, "0371": 35, "0372": 18, "0376": [20, 68], "0377": 23, "0381": 68, "0387": [23, 68], "03888": [332, 339], "03891696": 8, "03964159": 25, "0397": 68, "0398": [68, 71], "04": [8, 11, 27, 43, 49, 55, 72, 88, 334, 339], "04027566": 25, "04028322": 25, "04034364": 25, "04067592": 8, "0408": 68, "04087": 49, "0411": [43, 68], "0414": 18, "0417": 68, "041787": [2, 5], "04199568": 25, "0421": 35, "0423": 62, "0423956": 25, "0425": 34, "04257239": 25, "04270729": 25, "0430": 68, "04318783": 25, "04341139": 25, "04367255e": 25, "043822": 49, "0439": 35, "04395604e": 21, "0441": 46, "04415915e": 25, "0443": 68, "0444": [24, 46], "0448": 86, "04500528": 25, "0451": 24, "0452": 68, "0454": 68, "045872": 57, "0459": [], "045e": 10, "0466": 68, "0467": [34, 80], "04677684": 25, "0468": 46, "04687064": 25, "0471": [18, 31], "0474": 68, "047750": 16, "0478": 17, "04787676": 25, "0479": 62, "04795205e": 21, "048790": 58, "0488": 46, "04895105e": 21, "04900599": 25, "04949369": 25, "0497": 43, "04975605": 25, "0498": 68, "05": [11, 21, 23, 24, 27, 34, 43, 63, 65, 290, 291, 344, 345], "0505": 68, "0506": [], "050628": 58, "05087281": 25, "0516": 67, "05168332976549405": 52, "0517": 52, "0519": [34, 68], "052": [67, 69], "0520": 68, "05251747": 8, "05253822": 25, "052885": 9, "0530": 18, "0532": 23, "0534514": 25, "0536": 68, "0537": 71, "0538": 80, "0540": 52, "05400321268524999": 52, "05408157": 25, "05424298": 25, "0543": 83, "0544": 34, "0546": 24, "0547": 24, "0549": 68, "05490845": 25, "055148": 9, "05536766": 25, "0563": 35, "056328": 3, "05644409": 25, "05759116": 8, "0577": 43, "0578455": 25, "05801912": 25, "05822533": 25, "0583": 43, "0584": 43, "0586": [31, 44], "0588013": 25, "0590748": 25, "0591": [23, 68], "0595": 43, "0599": [62, 68], "06": [11, 63, 73, 77, 132, 334], "06005889": 8, "0601": 23, "0602": 68, "06129566246677624": 52, "0613": [52, 80], "061519": 3, "0619": 68, "062": [31, 36], "0623": 68, "0626": 67, "062784e": 334, "063": [5, 11, 26, 27], "0633": 18, "0636": 18, "0639": 68, "0644": 80, "0647": [21, 35], "0650": [], "065002": 58, "06531028": 25, "06555223": 25, "0656": 68, "0657": 44, "0659": 80, "0660": [45, 68], "0661": 68, "0667": [18, 44, 80], "0669": 68, "067656": 9, "06786967": 25, "0681": 46, "06810255500960018": 46, "0682": 68, "068376": 57, "0684": 61, "0689": 34, "069200": 3, "0695": 68, "0697": [35, 68], "07": [11, 34, 55, 63, 334, 339], "07045835": 25, "0707": 34, "07084209": 25, "07145943": 25, "071514": [2, 5], "072": [80, 81], "0720": 44, "0722": 68, "072233": 49, "07236131": 8, "07256868277920407": 52, "0726": 52, "0727": 68, "0728663": 25, "0730": [], "073011": 58, "0737": 35, "073938": [2, 5], "07412234": 25, "0743": 45, "0744": 45, "07455473": 8, "07458042": 25, "0746": 18, "074631": 3, "07463474": 25, "0748": 80, "0749": 18, "07496113": 25, "07552771": 18, "07558263": 25, "0758": 68, "07592173": 8, "0762": 35, "07630248": 8, "0764496": 25, "0765": 67, "07686822": 25, "0770": 68, "0772": 18, "0774": 68, "0776": 45, "07869662": 17, "0788": 68, "0789": 44, "0790": 18, "0790521": 25, "0792": 44, "0793": 23, "079543": [2, 5], "08": [49, 65, 68, 81, 334], "0801": 68, "080281": 9, "0803": 45, "0805": [46, 68], "08114306": 25, "0812": 68, "08127522": 25, "0816": 44, "082": [16, 27], "0820": [34, 80], "0826": 45, "08304836": 8, "083151": 9, "0833": [23, 45], "0836": 68, "0844": 43, "0849": 35, "0852": 68, "08544422": 8, "0856": 71, "08572601": 25, "0860": 68, "0862": 68, "0863": 45, "086518": 9, "0872": [], "087219": 58, "0873": [], "087324": 57, "0875": 45, "0877": [], "087737": 58, "0879": 17, "0880": 67, "0884": [17, 68], "0886037": 17, "08875921": 25, "08920078": 25, "0894": 45, "0895": 43, "0896": [8, 10, 45], "0897": 67, "0898": 45, "09": [49, 65, 69, 71, 88, 334], "090": [7, 11], "0900": 68, "0902": [62, 68], "0905": 68, "0906": 45, "0909": 45, "09141124": 17, "0915": 21, "0919": 68, "0920": 67, "0925": 45, "0926": 68, "0930": 68, "093091": 9, "0931": 80, "0932": 23, "0934e": 34, "0938": 45, "0942": [43, 68], "0944": 80, "0949": 45, "095": 379, "09508197e": 22, "0962": 80, "0963": 45, "0971": 46, "0972": 68, "09737877": 25, "097382": 9, "0977724": 25, "09817635": 25, "0982": 67, "09821501": 25, "0985": 35, "0988": 43, "0989": 18, "09906073": 25, "0991": 68, "09918538": 25, "099335": 3, "0995": 45, "0_model": 379, "0_residu": 379, "1": [2, 3, 4, 5, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107, 112, 117, 118, 119, 123, 125, 133, 164, 180, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 238, 240, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 319, 323, 324, 326, 327, 329, 331, 332, 365], "10": [3, 5, 9, 10, 17, 18, 21, 22, 23, 24, 25, 26, 34, 35, 43, 44, 45, 46, 49, 52, 57, 58, 59, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 107, 112, 114, 117, 120, 133, 180, 210, 211, 212, 213, 214, 215, 216, 217, 221, 225, 227, 228, 229, 230, 231, 232, 233, 236, 239, 273, 274, 277, 278, 284, 285, 286, 287, 290, 291, 300, 301, 302, 318, 320, 322, 323, 324, 328, 329, 333, 334, 335, 336, 337, 342, 353, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370, 371, 374, 379], "100": [9, 10, 17, 18, 23, 24, 25, 26, 43, 45, 46, 49, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 118, 125, 210, 225, 226, 227, 248, 273, 274, 275, 276, 301, 327, 333, 335, 337, 339, 351, 355, 356, 357, 359, 360, 365, 366, 367, 368, 369, 370, 371, 374], "1000": [3, 6, 7, 10, 14, 23, 24, 44, 52, 79, 122, 164, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 273, 274, 286, 287, 290, 291, 329, 374], "10000": [3, 5, 34, 35, 52, 273, 274, 323], "100000": 2, "1000000": [3, 5, 63, 371], "10004": 6, "1002": 45, "10020": 6, "10027": 6, "1003": 35, "10034": 6, "10039": 6, "1004": 80, "10054": 6, "1006": 45, "10063": 6, "10074": 6, "10080": 6, "10086455e": 22, "10087": 6, "10091232": 25, "100e": 10, "101": 67, "1010": 68, "1011": 35, "1013": 6, "10134": 6, "101399": 57, "1015": 35, "1016": 35, "10160": 6, "1018": 6, "1019": [35, 45], "10202": 6, "1021": 45, "10218": 6, "1022": 45, "1023": 45, "1024": 68, "1026": 46, "10279": 6, "10284346": 25, "10287": 6, "10294": 6, "10295": 6, "103": [6, 9], "1031": [], "10310": 6, "103147": 57, "1032": 45, "10323": 6, "10331": 6, "10344": 6, "10344295": 8, "10369": 6, "10388": 6, "104": [63, 67, 71], "1043": 21, "10444": 6, "10448": 6, "1044807": 8, "1045": 10, "10452": 6, "10459": 6, "1046": 45, "10469937": 17, "10471": 6, "10481": 6, "10487": 6, "1049": 35, "105": 68, "1051": [22, 80], "1053": 45, "105361": 5, "10544": 6, "10549": 6, "105570": 361, "10561": 6, "10564": 6, "1057": 6, "10571": 6, "10572": 6, "10585": 3, "1059": 331, "10594": 6, "1060883": 8, "106133": 3, "10623": 6, "10639": 6, "1064": 45, "10659": 6, "1066": 68, "10666": 6, "10667": 6, "10674": 6, "10685": 6, "1071": 17, "10711": 6, "1072": 68, "10722": 6, "10723": 6, "1073": 68, "10743": [6, 9], "10759": 6, "1076": 68, "10769": 6, "1077": 68, "1078": [6, 68], "1079": 68, "108": 71, "1080": 45, "1081": 68, "10818": 6, "10820": 6, "10829": 6, "10849": 6, "10855": 6, "1086": [6, 331], "10861737": 25, "10862531": 8, "10869": 6, "1087": 80, "10870": 6, "10875": 6, "10876": 6, "10880": 6, "109": 57, "1090": 34, "10941": 6, "10947": 6, "10954": 6, "10977": 6, "1098": 68, "10989": 6, "1099": 68, "11": [3, 5, 9, 17, 18, 23, 24, 25, 34, 43, 44, 45, 47, 49, 63, 64, 67, 68, 71, 72, 79, 80, 83, 107, 334, 336], "110": [10, 57, 68], "1100": [45, 68], "110027e": 334, "11003": 6, "11008": 6, "1101": 68, "11018": 6, "1102": 34, "1103": [6, 44, 68], "1104": 68, "11058": 6, "1107": 64, "1108": 45, "11086": 6, "1109": [324, 328], "110928": 49, "1110": [9, 68], "11109": 6, "11113": 6, "111206": 9, "11126": 6, "11153": 6, "11159": 6, "11185": 6, "11192": 6, "112": [9, 68], "1120": 21, "11229": 6, "1123": 68, "1124": 6, "11243": 6, "1125": [63, 67, 68, 71, 79], "11257": 6, "1128": [], "112845": 58, "113": [18, 58, 72, 73], "11304": 6, "1131": 68, "1132": 68, "11339": 6, "1134": 71, "11345341": 8, "11356": 6, "113597": 49, "1137": 34, "113943": [2, 5], "1139433": 2, "11398": 6, "11399": 6, "1141": 68, "11413": 6, "11415": 6, "1143": 6, "114493": 58, "1145": 6, "11454": 6, "1146": 68, "11469": 6, "11473": 6, "11476": 6, "1149": 68, "11493": 6, "11499": 6, "115": [8, 9], "115045": 58, "115057": 58, "1151": 45, "11510": 6, "11541": 6, "11559": 6, "1156": 23, "11563613": 25, "1157": 45, "11570": 6, "11573": 6, "115869": 57, "11588": 6, "11589": 6, "116": [123, 326], "1160": 9, "1161": 68, "1162": 68, "1163": 18, "1164": [17, 68], "11644": 6, "1165": 68, "1166": [9, 68], "11673": 6, "1168": 9, "11689": 6, "11690": 6, "117": 58, "1170": 68, "11704": 6, "1171": [9, 68], "1172": 6, "11725": 6, "1173": 68, "1175": [9, 68], "11754": 6, "1176": 46, "11765": 6, "11769": 6, "1178": 68, "1181": 64, "1182": [6, 68], "11835": 6, "118367": 3, "118388": 57, "1184": [], "1186": 68, "11862": 6, "1187": 6, "11877264": 8, "11879": 6, "1188": [67, 71, 79], "11885": 6, "11888": 3, "1189": 331, "119": [9, 10], "1191": [67, 79], "1193": 68, "1194": 6, "11944": 6, "1195": 6, "11952": 6, "1196": 34, "11962": 6, "1197": 63, "11972": 6, "1199": [35, 43, 68], "11997": 6, "119971": 49, "12": [5, 6, 8, 9, 10, 17, 18, 22, 23, 24, 25, 27, 43, 44, 45, 49, 52, 63, 64, 67, 68, 71, 72, 79, 80, 83, 107, 334], "120": [10, 58, 68], "1200": 79, "120000": 2, "12004": 6, "1201": 68, "1202": [8, 327], "12023": 6, "12043": 6, "12047": 6, "12051": 6, "12052": 6, "12056": 6, "12060": 6, "1207": 68, "12071": 6, "12080": 6, "12087": 6, "1209": 80, "121": 68, "12105": 6, "12119": 6, "1212": 68, "12122": 6, "1213": [45, 80], "12135": 6, "1214": 67, "12141": 6, "1218": [], "121813": 57, "122": 68, "1220": 68, "12200": 6, "1222": 23, "12237": 6, "12240358": 8, "12244993": 25, "12252": 6, "12260411": 25, "1229": 68, "12302": 6, "1232": 331, "12325": 6, "12330": 6, "12338": 6, "1234": [29, 30], "1235": 8, "12390": 6, "12392": 6, "124": [6, 10], "12409": 6, "1241": 68, "1242532": 25, "12434": 6, "12467": 6, "12470": 6, "12490": 6, "12493": 6, "1250": 67, "125000": 25, "1252": 64, "125214": 9, "1255": 68, "12559": 6, "12567": 6, "1257": 24, "1258": 68, "12587": 6, "12592": 6, "126": [63, 67], "1262": 45, "12622": 6, "12624014": 25, "1263": [64, 68], "12634": 9, "12640": 6, "12658": 6, "126704": 49, "12674": 6, "1268": 68, "12692": 6, "12693": 6, "127": 6, "1270": 34, "12716": 6, "12718679": 25, "12735": 6, "12754": 6, "12759": 6, "1276295": 25, "12788": 6, "128": 71, "1280": 68, "12805": 6, "12806": 6, "12815": 6, "12817": 6, "1282": [64, 67, 68], "12846": 6, "12863": 6, "1287": [68, 80], "12870": 6, "1288": 22, "12881": 6, "1289": 45, "12899": 6, "129": 80, "1290": [6, 68], "12910663e": 22, "12914": 6, "12920": 6, "12925": 6, "12929": 6, "1295": 45, "12971": 6, "129740": 5, "129745": 3, "1298": 6, "12982": 6, "12983": 6, "12989": 6, "12994237": 8, "13": [5, 8, 9, 10, 17, 18, 23, 24, 25, 43, 44, 45, 49, 63, 64, 67, 68, 71, 79, 80, 324, 334], "1301": 80, "13013": 6, "13021": 6, "1303": [6, 34, 68], "13032": 6, "130323": 49, "13036": 6, "13044491": 18, "1305": [57, 68], "13050": 6, "13055": 6, "13066686": 8, "13068": 6, "130687": 49, "1307": 23, "13071": 6, "13073": 6, "13080": 6, "1309": 68, "130937": 49, "130939": 49, "130998": 49, "131": 71, "1310": 6, "131044": 49, "1311": [19, 25], "131115": 49, "13112096": 25, "1313": 68, "13132": 6, "1314": 68, "13199": 6, "132": 63, "13214": 6, "1322": 80, "13221": 6, "132260": [2, 5], "1326": [23, 68], "13269": 6, "1327": 64, "13273": 6, "1328": 6, "13281": 6, "13283": 6, "13296": 6, "133016": 49, "13323": 6, "13324": 6, "133381": 49, "1334": [6, 21, 25], "1336e": 34, "13407": 6, "13425": 6, "1343": [8, 9, 10, 67], "13436": 6, "13451": 6, "13464": 6, "13465": 6, "13471": 6, "13481": 6, "1349": 68, "13496": 6, "13497": 6, "135": [67, 68], "13504": 6, "1351": 19, "135229": 15, "13531": 6, "13538": 6, "1354": [52, 68], "13541995570654827": 52, "13559": 6, "13564104": 25, "1358": 6, "13586": 6, "13587": 6, "136": [86, 88], "13606": 6, "13619": 6, "1362": 6, "1363": 34, "13638": 6, "13658": 6, "13659": 3, "13663": 6, "13664": 6, "13670": 6, "13673": 6, "13682": 6, "136851": 58, "1369": [], "137": [9, 63], "13709": 6, "137371": 49, "13739": 6, "1374": 57, "13745": 6, "13759": 6, "1377": 8, "13771": 6, "13774": 6, "13780": 6, "13782": 6, "1379": 45, "13792": 6, "13796": 6, "138": [63, 68], "13805": 6, "13810": 6, "13818": 6, "13827": 6, "1383343": 2, "13835849": 25, "138395": 57, "1384": [], "138412": 9, "13850": 6, "13863": 6, "13875": 6, "13877": 6, "13889": 323, "138957": 15, "1389656": 2, "139": 63, "1391": 80, "1392": 6, "13931": 6, "13934": 6, "1394": 9, "13940": 6, "13954": 6, "13965": 6, "139691e": 334, "13973": 6, "13975": 67, "13976": 6, "1398": 49, "1399": [64, 68], "14": [2, 3, 4, 5, 9, 10, 11, 17, 18, 23, 24, 25, 43, 44, 45, 49, 63, 64, 67, 68, 69, 71, 79, 80, 81, 83, 334], "140": [52, 63], "140000": [3, 5], "14030": 3, "14035251191539191": 52, "1404": 52, "14045": 6, "14055": 6, "14069": 6, "14071": 6, "14077": 6, "14088": 6, "141": 63, "14107": 6, "14108088": 8, "14125": 6, "14139967": 25, "1414": 45, "14149": 6, "14162": 6, "14183": 6, "14198544": 8, "142": [6, 63], "142199": 58, "14232": 6, "14237": 6, "14243": 6, "14257": 6, "14260": 6, "1427": 6, "14280": 6, "14303": 6, "14317": 49, "14333": 6, "14357": 6, "1436": 80, "1437": 68, "1438": [62, 68], "1442": 9, "14427": 6, "14429": 6, "1443": [68, 324], "14430": 6, "14454": 6, "14464": 6, "14481": 6, "14499": 6, "145": [8, 68], "145000": 25, "14514": 6, "14519": 6, "14520": 6, "1454": 9, "1456": [9, 18, 45], "14562": 6, "14566": 6, "145671": 57, "1457": 9, "1458": 9, "14582492": 8, "14583421": 8, "14599": 6, "146": 10, "1460": 6, "14615": 6, "14617": 6, "14664": 6, "1468": 64, "146835": 58, "146874": 58, "1469": 6, "14695": 6, "146996": [2, 5], "147": [8, 58], "1471": 324, "14716": 6, "14724": 6, "14726": 6, "1474": 68, "14747": 6, "14756": 6, "14772": 6, "1478": 68, "14787": 6, "14794": 6, "148": 8, "1480": [6, 18], "14818567": 25, "14829": 6, "14833": 6, "1484": 34, "1485": 34, "14855": 6, "14858": 6, "14873": 6, "14875539": 8, "14877": 6, "1488": 44, "14892": 6, "149": 8, "1490": 68, "14901": 6, "1491": 67, "14919": 6, "1493": 68, "14935775": 25, "1495": 6, "1497": 68, "14972": 6, "14973": 6, "15": [2, 5, 8, 9, 13, 14, 17, 18, 23, 24, 25, 43, 44, 45, 49, 52, 63, 67, 68, 71, 79, 80, 125, 332, 334, 339, 358], "150": [8, 58], "150000": [2, 5], "1501": 68, "15015": 6, "15028": 6, "15038": 6, "1504": 68, "15050": 6, "15060264": 8, "1507": 68, "15075029": 25, "1508": [64, 68], "15091": 6, "15094": 6, "15100": 6, "151090": 3, "1511": 80, "15121": 6, "1514": 68, "1515": [10, 34], "1517": 68, "15192": 6, "15198": 6, "15203": 6, "1521": 57, "15210": 6, "15220": 6, "15228": 6, "15231": 6, "15244": 6, "15257": 6, "15260": 9, "15280": 6, "15282": 6, "15297": 6, "153": 8, "153066": 58, "1531": 68, "1532": [34, 68], "15322": 6, "15324403": 8, "15333": 6, "15366": 6, "15388": 6, "154": 6, "15417": 6, "1543": 6, "15462": 6, "15470": 6, "15472": 6, "15479": 6, "155": [8, 58, 71], "155000": 25, "15501": 6, "1551": [35, 80], "15510": 6, "15517": 6, "1552055": 8, "15524": 6, "15532": 6, "15538": 6, "15545": 6, "1555": 68, "15556": 67, "155640": [2, 5], "15565": 6, "15579": 6, "1558": 71, "15585": 6, "15587": 6, "156": 6, "15615": 6, "1562": 31, "156307": [2, 5], "15647769": 25, "1565": 64, "15668": 6, "15670": 6, "156719": 5, "15673": 6, "1569": 68, "157": 8, "1571": 83, "15718208": 8, "15725": 6, "15729": 6, "1573": 68, "15738": 6, "15745": 6, "1576": 68, "15767": 6, "15772": 6, "15781": 6, "15793": 6, "15796": 6, "1581": 68, "15812": 6, "1582": 68, "15827": 6, "1583": [6, 68], "1585": 68, "15857": 67, "1586": [6, 68], "158681e": 334, "1587": [64, 68], "15873": 6, "1588": 67, "15888": 6, "1589": 72, "15894": 6, "159": [6, 8], "15904": 6, "15908": 6, "15910": 6, "15930": 6, "15945": 6, "1595": 35, "15953": 6, "15964": 3, "15966": 6, "1596886": 8, "1597": 68, "15984": 6, "1599": 34, "15991107": 25, "15998": 6, "16": [3, 5, 6, 8, 9, 10, 17, 18, 22, 23, 24, 25, 27, 34, 44, 45, 49, 63, 64, 67, 68, 71, 79, 80, 334, 353], "160": 8, "1603": [6, 68], "1604": 34, "16042": 6, "16055990e": 22, "16085": 6, "161": [8, 18], "1612": 64, "16144": 6, "16158": 6, "16160": 6, "1619": 46, "16196": 6, "16199": 6, "1621": 46, "16220": 6, "1623": 68, "1624": 6, "1626": 8, "16272": 6, "16275": 6, "16285": 6, "16294": 6, "163": 8, "16313": 6, "1632": [64, 68], "16325": 6, "1635372": 25, "16367": 6, "1637": 57, "16373902": 8, "1638": 68, "164": 8, "1640": [46, 80], "1641": [324, 328], "1642": [8, 9, 10], "16425": 6, "1645": 6, "16452": 6, "1646": 68, "1647": 6, "16474": 6, "16478": 6, "16491": 6, "165": 8, "1650": [43, 324, 328], "16508": 6, "16518": 6, "16524": 6, "16532": 6, "1655": [], "165517": 57, "16556": 6, "1658": [43, 61, 68], "16584": 6, "166": [8, 10, 68], "16600": 6, "16621": 6, "166214e": 334, "16642": 6, "16665": 6, "1667": 10, "167": 8, "1670": 45, "1672": 34, "167233": 3, "1672709": 17, "167295": 5, "16733": 6, "1674": 43, "167484": 3, "167502": 5, "16767": 6, "16770": 6, "168": 83, "1680": 68, "16819": 6, "1684": [64, 68], "16842": 6, "1686": 43, "16890": 6, "16892": 6, "169": 8, "1690": 44, "16901": 6, "16902": 6, "16904": 6, "16906": 6, "16948": 6, "16960": 6, "16997403": 25, "17": [3, 5, 8, 9, 10, 17, 18, 22, 23, 24, 25, 44, 45, 46, 49, 63, 67, 68, 71, 72, 73, 79, 80, 320, 324, 328, 333, 334, 335, 336, 337, 338, 339], "1700": 68, "1702": 68, "17033": 6, "17035": 6, "1704": [34, 43], "17041": 8, "17042": 8, "17043": 8, "17044": 6, "170817": [13, 49], "17085": 6, "171": 8, "17105": 6, "1710586": 18, "17125": 6, "17127": 6, "17162": 6, "17167": 6, "172": [8, 57, 59, 379], "17204": 6, "17205": 8, "17211": 6, "17226": 6, "17247": 6, "1725": 68, "1725592": 8, "1727": [6, 68], "17285": 6, "17287": 6, "173": 10, "17305": 6, "17319": 8, "1732": [68, 71], "17320": [6, 8], "17339": 6, "17347": 6, "1735": 43, "17353": 6, "1736": 9, "17367": 6, "1737": [9, 34, 68], "17374": [8, 9, 10], "17375": [8, 9, 10], "17376": [8, 9, 10], "17377": [8, 9, 10], "17378": [8, 9, 10], "17379": [6, 9, 10], "174": 8, "1742": [68, 71], "1743": 9, "174612": [2, 5], "1747": 68, "1747162": 8, "17478107": 18, "1752667": 25, "1755": [64, 68], "175762": [13, 49], "1758": 43, "1759": 6, "176": 58, "17617815": 25, "17623590e": 25, "176381": [2, 3, 5], "1765252": 25, "1768": 80, "177": 18, "1771": 68, "1772": 80, "177261": 9, "17742966": 8, "1776": 46, "177892": 9, "178": [8, 19, 27], "1780": 68, "1781": 6, "1785": [6, 68], "178571": 57, "1786": [], "179": [8, 35, 58], "17904737": 25, "1793": 43, "1794": 43, "1795": [43, 61], "17becf": 52, "18": [5, 6, 8, 9, 10, 17, 18, 23, 24, 25, 34, 44, 45, 49, 63, 64, 67, 68, 71, 79, 80, 334, 335], "180": [34, 83], "180000": 5, "1802": [332, 339], "18033722": 18, "1805": [35, 44], "180590": 58, "1806": [], "180851": 57, "1809": [], "1811": 68, "18112": 3, "1814": 68, "181558": [2, 5], "1818": 10, "182": 8, "1821": 34, "18238135": 25, "182791": 58, "1828": [], "183": 6, "18335122e": 21, "1835": 6, "184": 8, "1843": 43, "1845": 6, "18458366509258792": 52, "1846": 52, "1847": 6, "185089": [2, 5], "1854": 6, "18544136": 8, "18554294": 25, "1858": 23, "186": 83, "1861": 6, "1868": 23, "187": [8, 67, 80], "1871": 46, "18726286": 18, "1876": 68, "187721e": 334, "188": [8, 58], "188002": 58, "188366": 2, "18843615e": 25, "1884769": 8, "188550": 58, "1886": [], "1887635938666557": 52, "1888": 52, "1889": 6, "189": [9, 35], "19": [5, 8, 9, 10, 17, 18, 23, 24, 25, 27, 44, 45, 63, 64, 67, 68, 71, 79, 80, 83, 324, 334], "190408": 49, "191": 67, "1911": 34, "19129001": 25, "19129730e": 25, "1913": 34, "1915": 6, "1916": 6, "191731": [2, 5], "19179": 9, "1918": 68, "192": 8, "1920": 43, "1921": 43, "1926": [64, 68], "19284549": 8, "1933": 6, "1939": 43, "1940": 10, "194163": 49, "1948": [], "194833": 57, "195": [8, 83], "19509665e": 25, "1953": 34, "195578": 58, "1956": [], "1957": 71, "1959": 43, "196": [8, 35], "1966": 68, "196632": 3, "19668267": 8, "1970": [8, 10], "1972": 6, "197313": 9, "198": 35, "198068": 57, "1980e": 24, "1981": 80, "1985": 6, "1986": 68, "199": 63, "1990": [64, 68], "19940979": 8, "1995": [9, 34, 35, 64, 68], "1996": [9, 34, 35], "1997": [9, 34, 35], "1998": [9, 34, 35, 68], "1999": [9, 34, 35], "19it": 49, "1_extmodel": 379, "1_perform": 379, "1d": [63, 64, 71, 72, 79, 80, 83, 229, 230, 231, 232, 233, 235, 238, 247, 248, 292, 301, 321, 323, 329, 333, 335, 337, 340, 344, 355], "1e": [132, 273, 274, 290, 291, 361, 369], "1f77b4": 52, "1f968b": 52, "2": [2, 3, 4, 5, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 54, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 107, 125, 131, 132, 172, 180, 210, 211, 212, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 238, 243, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 322, 323, 324, 327, 328, 331, 332, 365, 375], "20": [2, 3, 5, 8, 9, 10, 17, 18, 23, 24, 25, 26, 35, 43, 44, 45, 46, 49, 52, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 222, 235, 238, 273, 274, 275, 276, 277, 278, 290, 291, 327, 334, 339, 342, 353, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 374, 376], "200": [8, 43, 87, 247, 286, 287, 301], "2000": [7, 9, 34, 35, 52, 57, 58, 86, 210, 224, 225, 324, 327, 333, 334, 335, 337, 367, 368, 370], "20000": [2, 5], "200000": [5, 23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "200060": 58, "2001": [324, 331, 338], "2002": 324, "2003": [324, 328], "2005": [34, 318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "200671": 5, "2007": [6, 68], "2008": [324, 328, 331, 334], "2009": [123, 326], "200e": 10, "201": [6, 18, 35, 83], "2011": 35, "2012": [324, 327], "20135065": 25, "2015": 335, "2016": [331, 332], "201691": 57, "2017": 332, "2018": [332, 339], "2019": 327, "202": [8, 83], "2020": [327, 331], "2021": [123, 324, 326], "2022": [123, 326], "2024": [35, 87], "2025": [2, 49], "2029": 6, "203": [8, 35], "2030": 68, "2031": 68, "2036": [44, 68], "203604": [2, 5], "2037": [62, 64], "203739e": 334, "204": [8, 71, 79, 83], "2040": 6, "2043": 68, "2045": 67, "20452690e": 25, "204581": 58, "2046": [], "205": [10, 34, 71, 79, 83], "2050": 68, "2053": 71, "2059": 68, "206": [71, 79, 83], "20604": 3, "2062": 80, "2068": 80, "207": [8, 57, 71, 79, 83], "2071": 6, "2076": [64, 68], "207632": 5, "207947": 58, "208": [8, 71, 79, 83], "2080": 43, "2082": 23, "2084": 6, "2089": 34, "209": [35, 71, 79], "20a386": 52, "21": [2, 3, 8, 9, 10, 17, 18, 24, 25, 45, 46, 47, 49, 63, 64, 68, 71, 79, 80, 83, 107, 334], "210": 8, "2100": [63, 71], "21010": 3, "2102": 64, "210778": 57, "2108": 6, "211": 8, "2111": 18, "2112": 68, "2114": 68, "21189790e": 22, "212": [6, 8], "21208736": 8, "2121": 10, "2135": 17, "214": 8, "2148": 31, "2149762": 25, "215": 327, "21508346": 8, "2152": 34, "2154": 67, "21548": 3, "2158": 6, "216167": 49, "216430": [2, 5], "2165": 9, "2169": 23, "217": 8, "2174": 34, "217750": 3, "218": 8, "2181": [9, 68], "2183": 6, "2184": 9, "2188": 9, "219": 8, "219010": 3, "219618": 49, "21968930e": 25, "2197": 68, "21974921": 8, "2198": 68, "22": [8, 9, 10, 17, 18, 21, 24, 25, 27, 45, 63, 68, 71, 79, 80, 334], "2200": 6, "220000": [2, 5], "220098": 3, "2201": [6, 324], "22026": 3, "2209": 68, "221": 6, "221177": 3, "22122524": 8, "2215": 68, "222": 8, "2223": 6, "222458": 49, "223": [6, 34], "22346": 3, "2237": 68, "2239": 10, "2240": 44, "2241": 6, "22424265": 8, "224594e": 334, "224693": 9, "225": 8, "2250": 79, "2259": 22, "226342": [2, 5], "226409": 3, "2265": [], "226538": 58, "2268": 80, "227": [8, 35, 58], "22723": 3, "2273724": 2, "2277": 68, "2279": 67, "227978": 9, "228": 8, "2295": 68, "22nd": 332, "23": [5, 8, 9, 10, 17, 18, 24, 34, 45, 49, 63, 64, 67, 68, 71, 79, 80, 324, 334], "230": [58, 71, 73, 327], "230452": 3, "2308": 68, "231": 8, "232285": 3, "2324": [], "232430": 57, "2325": 80, "23254459": 25, "23268937": 8, "2328": 68, "2329": 64, "233": 8, "2330": 6, "23364": 3, "2351": [64, 68], "2356": 34, "23565667": 8, "2361": 6, "2362": 80, "23693366": 25, "237": [9, 58], "237041": [2, 5], "2371": 6, "2373e": 34, "237566": 3, "238": 8, "2385": 68, "2389": [], "238911": 57, "238a8d": 52, "2393": 68, "239484": 5, "2395": 68, "2398": 34, "24": [2, 3, 5, 8, 9, 10, 17, 18, 24, 34, 45, 49, 63, 68, 71, 79, 324, 328, 334, 335], "240": [8, 58], "2400": 6, "24000": 49, "240000": [3, 5], "2401": 80, "2405e": 24, "24081257": 25, "241270": 58, "2413": [], "2414": 83, "242": 58, "242304": 49, "2424": 8, "2429": 6, "2434": [64, 68], "24355615": 25, "244024": 3, "244266": 58, "2443": [], "245": 80, "2450": 6, "2453e": 24, "2457": 6, "246": [8, 62, 65], "246499": 3, "2467": 68, "2468": 68, "2469": 68, "2474": 6, "2476": [6, 68], "2477": 34, "2478": 22, "248": [8, 68, 83], "24835294": 25, "249": 8, "2491": 6, "2493": 68, "25": [3, 5, 9, 10, 17, 18, 24, 45, 49, 63, 67, 68, 71, 79, 132, 180, 334, 365], "2500": 63, "25000": 25, "250000": 5, "250372": 3, "250825": 57, "251": 8, "2511": 34, "2513": 24, "251380": 3, "2517": 6, "252": [6, 8], "2525": 6, "2528": 67, "253": 67, "2531": [], "253104": 58, "2535": 6, "2537": [8, 10], "254": [8, 76, 77], "255514": [2, 3, 5], "2558": 44, "256": 68, "256477": [2, 5], "256837e": 334, "2569": [6, 68], "25754": 9, "2576": [8, 9, 10, 68], "2578": 68, "257811": 3, "25827247": 17, "2585": 6, "2592": 68, "25th": 322, "26": [2, 8, 9, 10, 17, 18, 24, 27, 45, 67, 68, 71, 79, 107, 334], "2600": 6, "260000": 5, "261": [6, 8], "2617427": 17, "2618": 6, "2619": 6, "262214": [2, 5], "2623": 34, "26273726e": 21, "2631": [], "263139": 58, "2636": [], "263630": 57, "2639": 6, "2641": 6, "264345": [2, 5], "26452012": 8, "2646": 68, "266": 8, "266068e": 334, "26611415e": 25, "26635944": 8, "266649": 9, "266958": 5, "267": [9, 57, 64, 68, 80], "2673": 68, "2674": 23, "268": 8, "26802368": 40, "2685": 67, "26863568": 25, "2688": 23, "269": 18, "2692": [64, 68], "27": [17, 18, 24, 34, 45, 67, 68, 71, 79, 334], "270": [8, 71], "2702": [6, 80], "2706": [64, 68], "27079123": 25, "2709": 6, "27130596": 8, "271688e": 334, "272": [43, 47], "2723": 31, "2727": [8, 9, 10], "273": [8, 9, 11], "2734": 80, "27368400e": 25, "2739": 61, "2742": 6, "275": 6, "27521925e": 25, "2755": 68, "2759": 6, "275949": 57, "276": [68, 327], "2760": 52, "27604510845035524": 52, "276345": [2, 5], "277": [58, 68], "2783": 6, "2786": 26, "2788": [], "278830": 58, "2789": [], "278928": 58, "279": 68, "279756": 9, "279964": 3, "28": [3, 5, 17, 18, 24, 45, 46, 63, 68, 71, 79, 107, 334], "280": [8, 17, 64, 68], "2800": 23, "2804": 46, "2805": 6, "2808": 68, "2809": [63, 71], "281": 8, "2813": 6, "281760": [2, 5], "282": [10, 68], "282101": [2, 5], "283": [38, 41, 64, 68, 80], "2831581": 8, "2834": 17, "283544": 57, "2839": 6, "284": [9, 64, 68, 80], "2841": 6, "2842": 17, "2848818": 2, "284882": [2, 5], "285": [8, 9, 64, 68, 80], "285000": 25, "285143": [2, 5], "286": 68, "2861982": 25, "286861": [2, 5], "2869": 6, "287": [8, 64, 68], "2870": 26, "2871": [], "287129": 57, "287682": 5, "2878": 80, "2879": [8, 9, 10], "287d8e": 52, "2880562": 25, "288299": 58, "2883": [], "2883102": 8, "2884": 23, "288854": 58, "2889": 79, "289": [68, 71], "2890": 23, "289794": 5, "289872e": 334, "29": [5, 10, 17, 18, 24, 34, 45, 49, 68, 71, 72, 79, 324, 331, 334], "290": [9, 64, 80], "2903": [64, 68], "291": [9, 64, 68, 80], "2919": 6, "292": [6, 8], "2926": 64, "2936": 67, "29381192": 17, "294": [9, 64, 68, 80], "2941": [], "294118": 57, "2948": 6, "294803": 57, "295": [6, 64, 68, 80], "2950": [], "295050": 57, "295459": 58, "2955": [], "2956": 6, "2958": 34, "296": [64, 68, 80], "297": 68, "2971": 68, "2972": 6, "297246": 25, "2976": 6, "2977": 68, "297860": 58, "2979": [], "298": [34, 68], "2980": 6, "298096": 9, "2984": 6, "2985": [10, 34, 68], "299010": 57, "2995": 10, "299512": 58, "2996": 10, "29962235": 8, "2997": 10, "2998": 10, "299878": 49, "2999": 10, "29991030e": 25, "29995": [2, 5], "29996": [2, 5], "29997": [2, 5], "29998": [2, 5], "29999": [2, 5], "29af7f": 52, "2_calibr": 379, "2_overfit": 379, "2ca02c": 52, "2d": [52, 64, 71, 72, 122, 229, 230, 231, 232, 233, 235, 238, 247, 248, 269, 292, 316, 321, 324, 333, 337, 340, 341, 345, 355], "2d718e": 52, "3": [2, 3, 5, 8, 9, 10, 15, 16, 17, 18, 21, 22, 23, 24, 25, 31, 34, 35, 40, 43, 44, 45, 46, 49, 52, 54, 57, 58, 63, 64, 67, 68, 71, 72, 76, 79, 80, 83, 107, 125, 210, 211, 221, 225, 227, 273, 274, 277, 278, 284, 285, 320, 325, 333, 334, 335, 339, 356, 359, 361, 365, 368, 369, 370], "30": [5, 9, 10, 17, 18, 24, 35, 45, 49, 52, 63, 64, 67, 68, 71, 79, 80, 83, 252, 318, 332, 334, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "300": 52, "3000": [10, 52, 63, 67], "30000": [2, 3, 5], "30000000000000004": 44, "3002": [], "300208": 58, "300305": 58, "300e": 10, "301": 68, "301052": [2, 5], "301247": [2, 5], "3012471": 2, "30135555": 25, "301387": 5, "3019": 6, "302": [8, 68], "302009": 49, "302398e": 334, "3025": 6, "3028": 6, "302969": 3, "303": 57, "3030": [6, 8], "303196": 3, "303456": 58, "3035": 6, "30378332": 8, "3040": [], "304003": 57, "305": 68, "305000": 25, "305270": 58, "3053": [], "305351": [2, 5], "3055": 6, "3056": 71, "3058": 83, "30592314": 25, "306": 68, "3062105": 2, "306258": 9, "3074": 68, "3075": 6, "3078": [6, 31], "3079": 67, "308": 6, "3080": [], "308019": 57, "308076": 58, "3081": [], "3085": 46, "308986": 5, "309": [67, 68], "3098": 17, "31": [5, 17, 18, 23, 24, 25, 26, 34, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 334], "310": 8, "310554": 9, "310739e": 334, "311": 8, "311355": 57, "3120": 6, "31249470e": 25, "3125": 6, "3126": 6, "3131": 6, "313509": [2, 5], "314": 327, "3148": 6, "315": 67, "3153": 6, "3158": 6, "3161": 6, "31663391": 8, "317": 8, "3171": 6, "31771278": 8, "317854": [2, 5], "3179": 67, "3181": [6, 34], "3182": 10, "318827": [2, 5], "319710": [2, 5], "32": [9, 10, 17, 18, 24, 45, 63, 67, 68, 71, 331, 334, 338], "320": 8, "320000": 5, "3202": 23, "3204": 68, "320997": [2, 5], "3211": 17, "322": 8, "322426": 3, "322667": 3, "32294844": 8, "323": [8, 34], "3234": [64, 68], "32395616": 25, "324": 57, "3240": 6, "324067": 9, "3245": 79, "3257": [6, 68], "326357": 3, "3265": 6, "327": 71, "3270": [], "327047": 58, "32731152": 8, "3277": 6, "3278": [], "327839": 57, "3279": [64, 68], "3284": 8, "329": 68, "329380": 58, "3294": [], "329773": 58, "3298": [], "33": [17, 18, 24, 43, 45, 47, 49, 54, 67, 68, 71, 334], "3304": 80, "331": [40, 41], "3311": [64, 68], "3313": [23, 68], "332": 8, "333": 52, "3333": 10, "3335": 6, "3336": 6, "33365986": 40, "334": 8, "3341": 6, "33446600e": 25, "3346861": 8, "33472527": 25, "335": 6, "3358": 68, "3359": 6, "336": 57, "33638d": 52, "3375": 6, "337599": 3, "33798283": 17, "3387": [], "338729": 58, "33972852": 8, "33973635": 25, "34": [2, 3, 5, 10, 11, 17, 18, 24, 45, 49, 68, 71, 79, 334], "340": 8, "3405": 68, "3411": 6, "341274": 9, "3419": 68, "34190655": 8, "342": 68, "3423": [], "342345": 58, "342442": [2, 5], "3426": 68, "3430": 44, "3432": 6, "3439": 6, "34549761": 8, "3455": [], "345541": 58, "3456": 80, "34597341": 8, "34619687": 8, "346930": 9, "346985": 9, "3476": 323, "3479": 6, "3480": 6, "3485": 10, "34879130e": 25, "3488": [6, 23], "348849": 57, "3489307": 25, "349": 58, "3492": 6, "3494": 6, "34941552": 8, "349909": 3, "35": [2, 3, 5, 17, 18, 24, 25, 45, 52, 63, 67, 68, 71, 334], "350": [58, 68], "3502": 68, "3505": 6, "351": 8, "352": 8, "3521": [63, 67, 71, 79], "353": [8, 57], "35396525e": 25, "354": 8, "3542": 68, "35430714": 8, "354665e": 334, "355": 57, "355216e": 334, "355448": 9, "355489": 49, "356": 17, "357": 8, "35708636": 8, "3572": 6, "3578e": 23, "358": 8, "3582e": 23, "358358": 5, "3584": 68, "3585": 6, "358546": 49, "3586": 6, "35866153": 18, "359": 8, "3590": 6, "35911069": 8, "36": [9, 10, 17, 18, 24, 45, 63, 68, 71, 327, 334], "3600": 6, "360000": 5, "3601": 6, "3622": 21, "3629": 6, "363": [8, 58], "3636": 10, "3638": 68, "3639": 68, "363952": 49, "364": [67, 83], "3658": 68, "3667": 68, "3668836": 8, "3669": 68, "366936": 3, "367038e": 334, "367725": 5, "368296": 9, "369609": 9, "3697": 45, "37": [2, 5, 10, 17, 18, 24, 34, 45, 68, 71, 334], "370": [6, 11], "3701": 6, "371": [8, 34], "3713": [], "371348": 57, "3715": 34, "371893": 58, "3719": 6, "372": 8, "3725": 6, "373": 8, "3732": 80, "37398868": 8, "374": [8, 17, 27], "3750": 79, "375577": 58, "376": [34, 67], "3766": 18, "3769": 23, "377": [3, 8], "3770237": 8, "3775": 327, "378": 17, "3788": [], "378812": 57, "379": 6, "3797": 35, "38": [9, 10, 17, 18, 24, 34, 45, 68, 71, 79, 334], "380": 6, "3807": 6, "38169601": 8, "381888": 57, "3819": [], "382": 10, "382035e": 334, "3822": [6, 35], "3825739": 8, "38260215e": 25, "383": [8, 68], "384": 8, "385": 8, "3850": 64, "3856": 18, "3858271": 18, "385873": 9, "387": 8, "3873": [], "387318": 58, "38810125e": 25, "38877612": 8, "38886216": 25, "389": [320, 333, 334, 335, 336, 337, 338, 339], "3890": 44, "3893": 23, "3893073": 40, "3896": 45, "3899": 6, "39": [2, 5, 9, 17, 18, 24, 25, 45, 58, 59, 68, 71, 80, 83, 107, 334, 379], "3900": [64, 68], "390088": 25, "3904e": 34, "39070830e": 25, "3908": 6, "390801": 9, "391": 8, "391002": 9, "3914": 6, "3919": 6, "392": [8, 68, 69], "3921": 6, "39269155": 18, "393": 8, "3939": 10, "394": 8, "3940": 68, "394160": 57, "3942": [], "395": 57, "3951375": 17, "39558c": 52, "3956": [67, 71, 79], "3959": 6, "396": 17, "3965": 6, "396690": 57, "3967": [], "397": 57, "3970": 6, "3980": 6, "39820050e": 25, "3994": [], "399424": 58, "3995": 79, "39957": 9, "3996": 67, "399835": 9, "3_hpo": 379, "3_reliabl": 379, "3d": [122, 316, 340, 341, 346], "3dbc74": 52, "4": [2, 3, 5, 8, 9, 10, 17, 18, 23, 24, 25, 34, 35, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 63, 64, 67, 68, 71, 72, 79, 80, 83, 87, 107, 273, 274, 320, 331, 333, 334, 335, 353, 359, 361, 365, 366, 368, 369, 370], "40": [9, 10, 17, 18, 24, 35, 45, 49, 52, 63, 64, 67, 71, 72, 79, 80, 83, 290, 291, 320, 334, 361, 370], "400": [38, 40, 52, 58, 370], "4000": 67, "40019150e": 25, "4002": 64, "400673": 58, "4007": [], "40079126": 8, "400e": 10, "401": 58, "4011": 83, "4012": 6, "40173483": 8, "4019": 6, "40198600e": 25, "402": [57, 58], "4036": 6, "403976": 3, "4043": 26, "404688": 52, "405": 8, "405027e": 334, "4063": 6, "407": [87, 88], "4074": 17, "408": 68, "4082": 18, "4083": 18, "4084": 18, "4085": 18, "408532": 49, "4086": 18, "4087": 18, "409": 35, "4096": 64, "41": [2, 3, 5, 8, 9, 10, 17, 18, 24, 46, 68, 334], "410": [18, 27], "4100": 26, "4106": 6, "411566": 3, "4117694": 8, "412": [8, 64, 68], "4123": 6, "4125": 6, "41267808": 8, "413": [324, 328], "41498684": 8, "415": [64, 65, 68], "415164": 5, "4156": 44, "4157": [], "415748": 57, "4158": 38, "415875": 57, "4159": [], "416": [53, 55, 64], "4162": 23, "416251": 49, "4165": 38, "416518": 49, "4166": 44, "4167": 63, "4172": 18, "4175": 44, "417972": 49, "417998": 49, "418": 8, "418748e": 334, "4189": 68, "4198": 23, "42": [2, 8, 17, 18, 24, 31, 32, 33, 34, 35, 63, 79, 334, 348, 376], "420": 83, "420104": 49, "4202": 6, "420393": 49, "4204": 38, "4208": 19, "4209": [], "420928": 58, "421141": 49, "4213": 44, "421357": 9, "4216": [25, 38], "421604": 49, "422": [8, 324, 328], "42231476": 8, "4226": 6, "4232": 23, "4236": 6, "423921": 3, "424": [8, 34], "4242": 8, "424638": 49, "4251": [], "425116": 57, "4255": [6, 25], "425528": 49, "4259185": 8, "425949": 49, "426064": 3, "4266": 17, "4269": [17, 21], "427": [68, 324], "4270": 17, "4271": 17, "4272": 17, "4274": 17, "4275": 17, "4277": 17, "428": [9, 64, 68, 80], "4280": 17, "4281": 17, "4285": 17, "42861287e": 22, "428621": [2, 5], "4287": 17, "4288": 17, "4289": 17, "4290": 17, "4292": 83, "4293": 17, "429303": 58, "4294": 17, "4295": 17, "4296": 17, "4298": 19, "4299": 17, "43": [2, 5, 10, 17, 18, 24, 49, 72, 334], "430": 71, "4300": 17, "4301": 17, "4302": 17, "4304": 17, "4305": 17, "4309": 6, "431": 68, "4311": 17, "4312": 17, "4313": [6, 17], "4316": 17, "4317": 17, "432": 8, "4322": [17, 83], "4323": 17, "432403": 49, "4326": 17, "433": [9, 64, 68], "4330": [6, 17], "43309994": 8, "4333": 17, "4334": 17, "4334417": 25, "4336": [17, 67], "4339": 17, "4340": 17, "43404303": 8, "4342": 23, "4348": 17, "4349": 17, "4352": 17, "4357": 35, "4358": 83, "436": 57, "43600182": 8, "4362": 17, "43645358": 8, "436493": 15, "4366": 17, "4367": [17, 45], "4368": 45, "437": 68, "4374": 17, "4377": 17, "437721": 3, "4378": 17, "438": [8, 324], "4382": 17, "4383": 17, "4384": [17, 23], "4386": 17, "4387": 17, "4388": 17, "4389": [6, 17], "4390": 17, "4391": 17, "4392": [6, 17], "4393": 17, "4394": [17, 23], "4395": 17, "4396": 17, "4397": [17, 61], "4398": 17, "4399": 17, "44": [6, 17, 18, 24, 34, 49, 64, 67, 68, 71, 334, 335], "440": [8, 58, 68], "4400": 17, "4401": [17, 45], "440154": 52, "4402": [6, 17], "4403": 17, "4404": 17, "4405": [17, 44], "4406": 17, "4407": [17, 45], "440752": [2, 5], "4408": 17, "4409": 17, "441": [64, 68], "4410": 17, "4411": 17, "4412": 17, "4414": 17, "4415": 17, "4416": 17, "4417": [17, 35], "441707": 3, "441833": 5, "4419": 35, "442": 8, "4421": 17, "4423": 17, "4425": 17, "4426": 17, "4428": 17, "4429": 17, "443": [8, 68], "4430": 17, "4431": 6, "4433": 17, "4434": [6, 17], "4436": 6, "4438": 17, "4439": 17, "4440": 17, "4441": 45, "4444": 17, "444782": 15, "4448": 17, "445": [9, 64, 80], "4451": 17, "4454": 17, "4457": 17, "4458": 17, "4460": 17, "4462": 17, "4463": 17, "4464": 17, "4465": 17, "44654": 49, "4466": 17, "4467": 6, "447": [9, 64, 68, 80], "4470": 17, "4472": 17, "44725275e": 21, "4475": 17, "4476": 23, "4477": 17, "4479": 45, "4481": 17, "4484": 17, "4485": 17, "44855145e": 21, "4486": [17, 64], "4487": 17, "4490": 17, "4491": 17, "4494": 45, "4496842": 25, "4497": [17, 45], "45": [6, 8, 10, 17, 18, 24, 25, 67, 80, 83, 331, 338], "4500": 67, "45000": 25, "4501": 17, "4504": 45, "4506": 17, "451": 57, "4510": 45, "451197": 49, "4512": 17, "4513": 35, "451952": 5, "4520": 44, "452016": [2, 5], "45206945": 8, "45209790e": 21, "4521": 17, "4522": 17, "4523": 6, "45238": 23, "4525": 17, "4528": 44, "45290": 23, "4530": 17, "4531": [17, 44], "45338": 23, "453781": 52, "4539": 44, "45391": 23, "45396535": 8, "4540": 44, "4541": 17, "45425": 23, "454411": 49, "45458": 23, "45465": 23, "454741": 3, "4552": [23, 35], "45525": 23, "4553": 17, "45535": 23, "4554": 17, "45545": 23, "4558": 6, "456": [64, 68, 80], "4561": [21, 67], "456563": 49, "4568": [17, 44], "45725397": 25, "458": [61, 65, 68], "458053": 57, "4581": [], "45813": 23, "4582": 17, "4585": 6, "4587": 19, "4589": 23, "4594": 17, "4597": 17, "46": [2, 5, 10, 17, 18, 24, 49, 67, 83], "460": 8, "4602": 6, "4606": [], "460619": 58, "461": 6, "4615": 79, "461799": [2, 5], "462006": 49, "4627": 6, "46286": 23, "4631": 6, "4633": 45, "4634": 45, "4635": 6, "4636": 6, "4637": [6, 17], "464659": 57, "4647": [], "4648": 17, "4654": 17, "46568324": 8, "4659": 6, "465977": [2, 5], "4662439": 17, "4667": 71, "4676": 45, "4682": 19, "4683": 6, "4694": 23, "4696": 6, "47": [9, 17, 18, 24, 67], "4704": 6, "4705": 80, "470528": [2, 5], "4713": 35, "4721": 6, "4726": 25, "472634": 49, "472756": 3, "4728": 83, "473737": 15, "4738": 83, "4739": 17, "47391497": 8, "474": [8, 11], "4741": 6, "474354": 58, "474359": 57, "4744": [], "474543": 15, "4747": [6, 67], "475053": 3, "475099": 3, "4758": 45, "476388": 49, "4769": 6, "477": 67, "47719370e": 25, "4775": 23, "477859": 25, "478": 8, "4784": 17, "478440": 58, "479": 8, "47997744": 40, "48": [6, 9, 17, 18, 24, 52, 63, 83], "4800": 6, "4803": [], "480339": 58, "480644": 49, "48065574e": 22, "4808": 6, "480872": 58, "4809": [], "481": 34, "48118": 49, "4812": 25, "481467": 52, "482576": 52, "483111": 49, "4834": 6, "484015": [2, 5], "484224": 3, "4846": 23, "484c": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "485500": 3, "4858": 23, "486": [4, 8, 11], "4862": 67, "486322": 49, "48640678": 40, "486594": 49, "487094": 58, "4871": [], "487169": 5, "487297": 49, "487756": 49, "4878481": 8, "488": 6, "488310": 14, "488876e": 334, "4889": 45, "489": 6, "4895": 63, "4896": 46, "49": [5, 9, 10, 17, 18, 24, 34, 63, 67, 68, 79, 80], "4907": 35, "49080441": 8, "491": 80, "4911": 46, "4913": 46, "4915": 45, "4915018": 2, "491502": [2, 5], "4917": 3, "491782": [2, 5], "4918": 46, "492": 63, "4939": 17, "4943": 6, "494683": [2, 5], "4952176": 8, "495683": 3, "4963": 18, "4965": 6, "4975": 79, "4977": 67, "4978": 46, "4983": 43, "498575": 57, "4986": [], "499": 6, "499088": 3, "4994": 44, "499614": 58, "499676e": 334, "4997": 46, "4999": 17, "4_resili": 379, "4th": 337, "5": [2, 3, 5, 7, 8, 9, 14, 17, 18, 22, 23, 24, 25, 34, 35, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 107, 112, 132, 209, 210, 213, 214, 215, 216, 217, 221, 223, 225, 229, 230, 231, 232, 233, 268, 271, 272, 273, 274, 275, 276, 278, 280, 282, 285, 287, 289, 290, 291, 292, 294, 296, 298, 300, 301, 302, 318, 322, 325, 327, 331, 334, 338, 344, 345, 352, 358, 359, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375], "50": [2, 9, 17, 18, 19, 20, 23, 24, 27, 34, 35, 43, 49, 52, 63, 64, 67, 68, 71, 79, 80, 83, 223, 268, 271, 272, 274, 275, 276, 277, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 368, 379], "500": [38, 40, 240, 290, 291, 332, 339], "5000": [63, 67, 71, 83, 235, 236, 238, 239, 248, 273, 274], "50000": [2, 3, 5, 63, 371], "500000": [2, 57], "50000000e": 25, "5002": 6, "5003": 6, "500934": 14, "500983": 57, "500e": 10, "5010": 43, "502296": 57, "5023": 6, "503": 6, "5034": 46, "5036": 6, "503607": 58, "505": 57, "5054": 35, "5056": 6, "506": 58, "5061": 43, "5063": 6, "506395": 9, "506675": 57, "5067": [], "507501": 3, "5081": [], "508102": 57, "5082": 6, "5083": 46, "5093": 6, "5096": 35, "50986901": 8, "5099": 43, "51": [5, 6, 9, 17, 18, 24, 72, 83], "5100": [], "510015": 57, "510080e": 334, "5101": 6, "51036978": 8, "5107": 6, "510933": [2, 5], "51097": 49, "5111": [], "511111": 57, "51115655e": 25, "5115": [], "511516": 57, "5118": 6, "5123": 35, "513": [67, 71, 79], "5134": 63, "513484": [2, 5], "5138": 17, "5141": 6, "5148": 6, "514946": [2, 5], "515154": 9, "51526166": 8, "5153": 361, "5155": 43, "5161": 67, "5169": 17, "51749181": 8, "518": 57, "5193": 46, "5196": 46, "52": [17, 18, 24, 68, 327], "520": 8, "5211e": 34, "5218": 6, "5227": [], "522729": 57, "523": 8, "5232": 6, "5234": 35, "52340825": 8, "5236": [], "523619": 57, "5238": 83, "523983": [13, 49], "52420093": 8, "5243": 6, "5244": 43, "5256": 67, "5259": 35, "525951": [2, 5], "526": 71, "5260": 6, "5262": 23, "5265": 6, "5271": 6, "5276": 6, "5283": 6, "528675": 49, "5288": 17, "529": 8, "5297": 6, "53": [2, 17, 18, 24, 63, 68, 71, 327], "5309": 43, "530973": 3, "5314": 35, "5321": 35, "532105": 58, "532205": 3, "5327": 67, "532754": [2, 5], "5336": 45, "5337": [17, 35], "5344": 6, "5347": 46, "5348": 35, "536": [6, 123, 326], "537809": [13, 49], "53846154e": 21, "538574": [2, 5], "54": [17, 18, 46, 49, 79], "5401": 43, "5404": 43, "540491": 57, "5405": 34, "54057249": 8, "5406": 43, "5411": 17, "542": 68, "5426": 80, "5427": 35, "5428": 6, "5429": 83, "5430": 35, "5439": 6, "5440": 6, "5444": 79, "544440": [2, 5], "5449": 6, "5450": 68, "54575816": 8, "546": [15, 17, 27, 57], "5466": 6, "547011": 3, "547405": [2, 5], "5476": 6, "548": 6, "5483": 68, "5490": 6, "5494": 45, "5495846": 17, "549641": 9, "55": [8, 9, 17, 18, 49, 67], "5500": 6, "5501": 6, "550138": 49, "55101803e": 21, "551419": 3, "552": [75, 77], "552181": [2, 5], "5523": 6, "5525": 43, "5528": 6, "55287443": 8, "55334894": 8, "553405e": 334, "553617": 49, "5538": [], "553846": 57, "5539": 45, "554319": [2, 5], "5554": [6, 35], "5557": 6, "555878": 16, "556": [6, 83], "556351": 57, "5564": [], "5565": [], "556518": 58, "5569": 46, "5570": 35, "5574": 35, "5578": [], "557807": 57, "5583": 6, "5587": 6, "5588": 67, "558922": 9, "559": 80, "56": [3, 8, 9, 10, 17, 18, 57, 63, 71, 79], "560": [2, 11], "5601": 6, "5604": 21, "5607": 6, "5609": 6, "561": [23, 27], "5610": 45, "56143856e": 21, "5619": 6, "562": [35, 36], "5621": 67, "5623": 67, "562721": [2, 5], "5629": 34, "56381725": 8, "5639": 6, "5644": 6, "56443556e": 21, "564453": [2, 5], "564856": 57, "5649": [], "5651": 6, "565182": 57, "5652": [], "568": [34, 36], "5684": 68, "5685": 67, "5686": 35, "56906283": 8, "5691": 35, "5694": 68, "5699": 18, "56c667": 52, "57": [2, 9, 17, 18, 34, 46, 49, 79], "5701": 17, "570193": 57, "5702": 6, "5713": 43, "5714": 67, "5715": 43, "572": 57, "5727": 6, "5730": 17, "5733": 8, "5741": 23, "5742": 18, "57501659": 8, "5756": 67, "5759": 6, "576": [3, 8, 11], "576596": 3, "577": [6, 71, 80], "5770": [6, 35], "5771": 43, "577269": 57, "5773": 79, "5774": 23, "577433": 57, "5776": 35, "578": [6, 63], "5790": 23, "579652": 16, "5797": 63, "5798e": 34, "58": [17, 18, 46, 68, 379], "580": 57, "5804": 6, "58060728": 8, "5813": 43, "581320": 9, "582": [8, 68], "5822": 6, "5825": 6, "5831": 6, "5833": 6, "5836": 23, "583668": 58, "584": [45, 47, 64, 68, 80], "5840": [], "584032": 57, "5843": 67, "584311": 57, "584421": 361, "5846": 83, "585": 8, "5852": 6, "5854": 8, "586385": 57, "5864": [], "58744649": 8, "58798145": 8, "588": 83, "588372": 9, "5889": 6, "5891": 6, "59": [8, 9, 17, 18, 58, 63, 68, 71, 80, 83, 324], "5908": 67, "591": 68, "5917": 35, "592177": 3, "5922": 8, "592378": 58, "5924": 6, "5925": [6, 67], "592621": [2, 5], "5929": 35, "5933": 6, "5942": 67, "5945": 35, "5948": 6, "5963": 63, "5966": 6, "597": 63, "597476": 58, "5979": 35, "598": 8, "59815633": 17, "598259": 57, "5983": [], "599": 80, "599323": 3, "5_robust": 379, "6": [2, 3, 5, 8, 9, 10, 17, 18, 22, 23, 24, 25, 34, 35, 43, 44, 45, 46, 49, 54, 57, 58, 63, 64, 67, 68, 71, 72, 75, 79, 80, 83, 132, 307, 318, 320, 333, 334, 335, 365, 369, 371], "60": [6, 8, 9, 10, 17, 18, 34, 35, 49, 63, 64, 67, 71, 79, 80, 83, 365], "600": [52, 63], "6000": 79, "60000000e": 22, "600567": 58, "6006": [], "600893": 16, "601": 63, "601572": 58, "6016": [], "6017": 6, "602": [8, 63, 67], "6021686": 2, "602169": 3, "6023": 6, "6025": 17, "603": 63, "603604": 3, "603628": 16, "60372308": 8, "6044": 83, "6048": 6, "605": 8, "60513461": 40, "605292": 58, "6053": [], "605574": 3, "606": 8, "6060": 6, "6061": 10, "6064909": 17, "6069": 43, "6074": 17, "6075": 6, "6076": 34, "6078": 6, "6080": 17, "6088": 6, "609": 8, "6097": [], "609726": 57, "6097598": 25, "60986068": 8, "61": [9, 10, 17, 18, 63], "610": 6, "6104": 63, "611": 8, "6114": 67, "6124": 9, "613": 68, "61302157": 8, "61372": 49, "613720": 13, "6138": 79, "61438626": 25, "6146": 63, "6147": 35, "6148": 71, "615382e": 334, "6158": 35, "6161": 67, "6163": [], "616325": 57, "6165": 23, "6165768": 18, "6167": 6, "6168": 35, "618": [54, 55], "619": 8, "6190": [], "619006": 58, "6193": 6, "619748": 3, "62": [10, 17, 18, 34, 57, 67, 68, 71], "6201": 6, "6208": 35, "62129865": 8, "622": 6, "6224": 6, "6227": 67, "6228": 71, "6232": 44, "623232": 57, "6233528": 2, "623353": [2, 5], "6238": 67, "623963": 57, "624": 6, "6240": [], "624382": 9, "6249": 6, "6257": 79, "6258": 6, "6260": 71, "6261": 63, "626765": 57, "6277": 17, "62774804e": 22, "6279": 6, "6282": 67, "6285": 17, "629466": 9, "6298": 6, "629950": 3, "63": [17, 18, 58, 63, 324], "630000": 5, "6304": 83, "631071": 57, "6311": [], "631123": 57, "6315": 6, "631849": 49, "6319": 6, "632": 6, "63209229": 8, "6321": 6, "6326": 79, "632617": 9, "632926": [13, 49], "6343": 6, "6351": 6, "6352": [], "635214": 57, "636069": 57, "636641": 9, "637231": 3, "6377": 6, "638": [33, 36], "6381": [6, 67], "6386": [], "638638": 57, "639": 68, "639519": 3, "6398": 6, "64": [10, 17, 18, 67, 79, 83], "640": [8, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "640444": 9, "6409": 6, "6411": 67, "64117468": 8, "64293911": 8, "6439": 6, "6444": 17, "646": [14, 27, 64], "6460": 63, "6467": 67, "6472": [6, 79], "64728517": 8, "6473": 6, "648": 58, "6481": 6, "6487": [], "648743": 58, "6488": 6, "6492": 6, "6494": 45, "6499": 6, "65": [8, 9, 10, 17, 18, 46, 63, 67, 335, 371], "6507": [], "650738": 57, "6509": 63, "6524": 23, "6529": 83, "6531": 63, "65313364": 8, "65340550e": 25, "653791": 3, "6538": 17, "6539": [63, 79], "654": 6, "6542": 6, "654506": 3, "6548": 67, "6556": 6, "6557": 9, "6558": 67, "6560": 67, "656616": 9, "65801040e": 25, "6584": 67, "65910128e": 22, "6595109": 8, "6599": 67, "66": [10, 17, 18, 67, 68], "66048595e": 25, "6615": 67, "6618": 83, "6619": 6, "662183": 49, "663": 6, "66311172": 8, "6636": 3, "6639": 6, "664": [22, 27], "6641": 83, "66410094": 17, "664760": 9, "6648": 67, "6649": 17, "6650": 17, "6651": 17, "6652": 17, "6653": 17, "6654": 17, "6655": 23, "6666": 45, "6667": 67, "6672": [], "667222": 58, "6673": 6, "667824": 9, "667965": 58, "6680": [], "6682": 44, "66824562": 8, "6688": 23, "6692": 6, "66937524": 18, "67": [17, 18, 64, 68], "6700": 6, "670062": 3, "6713": 6, "6718": 6, "67196976": 8, "672015": [2, 5], "6736": 35, "6744": 67, "6747": 6, "6750": 34, "67514110e": 25, "6752": 6, "6753": 6, "6755": 6, "677068": 57, "6771": [], "6773": 67, "6774": 6, "6775": 67, "6780": 67, "678666": 3, "6790": 35, "68": [5, 9, 17, 18, 57, 63, 64, 68, 72, 80], "6800": 79, "6803": 35, "680607": [2, 5], "6814": 79, "6818": 10, "6823": 34, "6829": 67, "683353": [2, 5], "6837": 6, "684187": 49, "685": 8, "68506386": 8, "6856": 6, "6866": 67, "6873": 6, "687531": 9, "6877": 67, "6878": 6, "6886": 6, "689033e": 334, "6891": 6, "689362": [2, 5], "6895": 6, "6897": 3, "689708": [2, 5], "69": [17, 18, 49, 63, 64, 67, 68, 71, 79, 80], "6904": 35, "69050610e": 25, "6908": 17, "6910": 6, "6912": [6, 35], "6919": 6, "691958": 3, "6920": 67, "6923": 6, "6926": 6, "6927": 83, "692776": [2, 5], "6937": 3, "6939": 3, "69402145": 25, "6944": 71, "6954": 6, "6961": [], "696101": 58, "696166": 9, "696219": 9, "696812": 3, "696924": [2, 5], "6975": 6, "6977": 6, "698437": 9, "6986": 67, "69896608": 8, "699": [], "6990569": 2, "699057": [2, 3, 5], "6991": 35, "69910025": 25, "699317": [2, 5], "699578": 3, "6_fair": 379, "6th": 324, "7": [5, 8, 9, 10, 17, 18, 22, 23, 24, 25, 34, 35, 43, 44, 45, 46, 49, 54, 57, 58, 63, 64, 67, 68, 71, 79, 80, 83, 107, 221, 303, 318, 324, 327, 334, 365, 370], "70": [3, 9, 17, 18, 35, 49, 63, 64, 67, 68, 71, 79, 80], "70000": 5, "7005": 6, "7005e": 34, "7006": 6, "700630": 3, "700e": 10, "70141498": 8, "701555": 9, "701683": 16, "7017": 6, "7024171": 18, "7034": 67, "703447": 9, "703580e": 334, "70426": 49, "7049": 35, "7052": 6, "70522849e": 22, "7058": 67, "7062": [], "706218": 57, "70624983": 17, "7069": [63, 67], "7077": 79, "7081": 79, "70876671": 8, "709229": 49, "71": [17, 18, 63, 64, 68, 71, 83], "7109": 6, "7111": 67, "7113": 63, "7115": 6, "7118": 6, "712": 64, "712698": 57, "7127": [], "713": [79, 81], "7131": 67, "71343716": 8, "7136": 6, "7145": 6, "715107": 8, "715251": [2, 5], "715383": 57, "7154": [], "7157": 79, "717": 58, "7170": [17, 63], "7175": 6, "7177": 43, "718": [45, 49], "7180374727086953": 45, "7196138": 8, "7198": 6, "72": [9, 10, 17, 18, 64, 79], "7208288": 25, "721": 64, "7222": 6, "722428": [2, 5], "723": 6, "723022": 16, "7231485": 8, "723182": 3, "7238": 6, "723989": [2, 5], "7256": 45, "726041": 9, "7273": 10, "7274": 6, "727856": 9, "7279": 6, "7281": 6, "7284": 83, "7285": 9, "728754": 3, "7289": 17, "7297": 67, "73": [17, 18, 57, 68, 83], "730": 63, "7302": 6, "7305": 63, "7308": 67, "7312": 6, "7314": 6, "7317": 6, "73172633": 8, "7324": 46, "73282696": 40, "733311": 15, "733875": 3, "7340": 6, "7341": 67, "7344": [43, 71], "7345": 43, "7347": 67, "7349": 79, "7350": 6, "735054": 361, "7352": 17, "7355": 83, "73576964": 8, "736452": 3, "736758": 15, "7369": 63, "737": 6, "7372": 63, "7374": 35, "7378": 43, "7381": 67, "739": 8, "7393": 79, "73937898": 8, "739384": 3, "7398": 6, "73it": 49, "74": [6, 10, 17, 18, 67, 68, 83], "740": [67, 79], "7403": 35, "7405": 79, "7406": [43, 79], "7407": 43, "74075924e": 21, "7408": 43, "74094000e": 25, "7411": 79, "7412": 79, "7414": 79, "7417": 79, "7418": [43, 79], "7419": 6, "7420": 79, "7421": 79, "7424": [10, 79], "7427": 79, "7428": 79, "7432": 46, "7433": [45, 79], "743313": 58, "7434": 79, "7435": [6, 79], "7437": 79, "7438": 79, "7439": 79, "7443": 79, "7444": 79, "7445": 79, "7446": 79, "7448": 79, "7450": 79, "7453": 6, "7454": [43, 79], "7455": 79, "7456": [6, 79], "7460": 79, "7464": [45, 46, 67, 79], "7465": 63, "746540": 9, "7466": 79, "747": 35, "7471": 6, "7474": 6, "747475": 52, "7476": 6, "748347": 57, "7492": [43, 46], "749674": 49, "75": [3, 5, 8, 9, 10, 17, 18, 63, 67, 68, 83, 371], "750": 72, "7500": [43, 71], "75000": 25, "7502": 6, "7503": 6, "7505": 24, "7509": 18, "7512": [45, 67], "751288": 9, "7514": 67, "7518": 3, "752": [63, 67, 71, 79], "7525315": 25, "75308490e": 25, "7532": 6, "7535": 46, "753660": [2, 5], "7538": [6, 46], "753876": 9, "7539": [43, 46], "7540": 43, "75513729": 8, "7552": 43, "7554": 63, "755482": 9, "7556": 83, "7557": 45, "7559": 45, "7560": 24, "756332": 9, "7566": [43, 46], "7569": 6, "7570": 46, "7575": 63, "757503e": 334, "7576": [10, 18], "7577": 6, "7578": 63, "7580": [6, 46], "75817946e": 21, "7582": 23, "7584": 6, "7589": 63, "759": 80, "7593": 43, "75945": 49, "7598": 43, "75d054": 52, "75th": 322, "76": [10, 17, 18, 63, 67, 68, 83], "760": 6, "7611": 46, "76191292": 8, "7624": 6, "762511": 3, "763": 6, "7632": 45, "7633": 45, "764056": 57, "7641": [35, 45], "7645": 6, "7646": 45, "7648": 46, "764923": 2, "7655": 45, "7658": 63, "76589893": 8, "7662": [61, 79], "7664": 6, "766402": 3, "7667": 6, "7669": 63, "7671": 34, "7675": 6, "7676": 71, "768": 6, "7681": 6, "7683": 6, "768742": 49, "7690": [6, 63], "769194e": 334, "7695": 23, "7696": 45, "77": [17, 18, 67, 68, 72, 80, 83], "7701": 6, "7705": 6, "7706": 45, "7708": 34, "77098477": 17, "771": 34, "77103605": 25, "77109665": 17, "7711": 6, "7714": 63, "772": 6, "772886e": 334, "773": [71, 79], "773221": 49, "77373500e": 25, "7742": 23, "7748": 45, "77488155e": 25, "775": [6, 63, 65], "7751": 45, "775229": 49, "7754": 67, "7757": 6, "776": 67, "7765": [6, 21], "777542": [13, 49], "7778": 71, "7779": 23, "7782731": 8, "7793": 23, "779349": 3, "77944850e": 25, "77957888": 8, "7798899449724863": 5, "78": [17, 18, 63, 67, 71, 80, 83], "780": 35, "7800": 6, "780283": 49, "7803": 25, "78091513": 8, "781": [46, 47], "7814": 35, "781533": 49, "78185": 49, "7819": 19, "782492": 3, "7826": 6, "7829": 6, "7832": 19, "783313": 49, "783833": [13, 49], "7840": [6, 23], "784044": 49, "7842": 45, "7854": 63, "7857": 18, "786645": 49, "787": [6, 35], "7870": 6, "7872": 23, "7873": [], "787302": 57, "7882": 83, "78831236": 8, "7887": 71, "789": 35, "7896": [25, 63], "789608": 49, "7899": 3, "79": [3, 17, 18, 63, 68, 72, 79, 80], "790": 8, "7902": 6, "791": 6, "7910": 68, "7911": 6, "791414": 49, "7918": 63, "7919": 6, "7925": [23, 43], "7926": 6, "793092": 3, "7943": [3, 6], "7945": 6, "7952": 46, "795420": 3, "7955": 67, "7956": 63, "7959": 46, "7964": 23, "796614": 49, "796958": 49, "7973": 6, "7974": 6, "7980": 6, "7980e": 34, "798615": 14, "798646e": 334, "7993": 43, "7994": 6, "7996": 63, "799742": 49, "7_explain": 379, "7f7f7f": 52, "8": [3, 5, 6, 9, 10, 17, 18, 23, 24, 25, 29, 30, 34, 35, 43, 44, 45, 46, 49, 52, 57, 58, 63, 64, 67, 68, 71, 79, 80, 83, 107, 318, 319, 334, 335, 339, 365, 370], "80": [8, 9, 10, 17, 18, 35, 49, 63, 64, 67, 68, 71, 72, 79, 80, 365], "800": [35, 52], "80000": [2, 5], "8001": 6, "800262": 9, "8006": [6, 44], "8010": 43, "801333": 49, "802": 35, "802168": 49, "8022": 6, "803167": 49, "8032": 43, "803478": 9, "8035": [35, 43], "8038": 6, "8040": 6, "804507e": 334, "80464866": 8, "80485797e": 22, "805": 35, "8050": 63, "8051": 6, "8057": 46, "806077": 58, "8061": [], "806229": 3, "806320": 14, "8069": 63, "80710694": 40, "8085": [23, 35], "809333": 49, "81": [3, 5, 8, 9, 10, 17, 18, 46, 72, 80], "8101": 43, "8102": 35, "81036737": 8, "8111": 34, "812": [6, 35, 52, 55], "813179": 9, "8136": [24, 67], "81561248": 8, "8157": [6, 35], "8158": [45, 67], "816": 57, "8162": 46, "81639344e": 22, "8164": 6, "8167": 35, "8168": 43, "81689633": 8, "8169": [6, 43], "8170": [43, 67], "81719511": 8, "817664": 3, "8179": [6, 19], "8183": 9, "8185": 24, "8187": 6, "8195": 21, "8196": 6, "819798": 5, "8199": 23, "82": [10, 17, 18, 72, 80, 83, 331], "8201": 35, "8202": [6, 61], "820250": 15, "8203": 63, "8205": 25, "820542": 49, "8207": 23, "82073219e": 21, "820e": 10, "8210": [6, 43], "821208": 49, "8217": 23, "8222": 46, "82275": 49, "823": [49, 64, 68, 80], "823417": 49, "8237": 43, "824": [21, 27], "82406478": 8, "8251": 6, "8255": 18, "8257": 46, "826333": 15, "826671": 3, "826716e": 334, "8270": 19, "8275": 6, "8276": 43, "827667": 49, "8277": [43, 63], "827833": 49, "828": 57, "8286": 63, "829": 6, "829167": 49, "8294": 18, "8296": 43, "8297": 6, "8298": 23, "83": [10, 17, 18, 49, 67, 68, 72, 80], "830": 35, "8300": 25, "8305": 46, "8307": 6, "831": 49, "8312": 63, "8315": 43, "8317": 6, "8321": 6, "8325": 46, "8325088": 2, "832509": [2, 5], "83255660e": 25, "8327": 6, "832833": 49, "8330": 6, "833031": 3, "8332428": 25, "8339": 43, "834": [10, 11], "8343": 45, "8346": 46, "8350": [23, 43], "83535468e": 21, "8360": 31, "83600735e": 25, "836042": 49, "8363": 43, "8366": 6, "8372": 46, "8374": 10, "8375": 10, "8376": 10, "8377": 10, "8378": 10, "837806": 9, "8379": 10, "8381": 46, "8383": [6, 46], "8384": 68, "8387": 46, "83874189e": 21, "838849": [2, 5], "8394": 6, "839678": 9, "84": [17, 18, 72], "841": 6, "8412": 45, "84176620e": 25, "8422": 46, "8425": 6, "842721e": 334, "8430": 6, "84309127": 8, "843542": 49, "8436": 43, "843718": 3, "8441": 6, "845": 6, "84516": 2, "84522210e": 25, "8458": 63, "8460": 34, "8464": 21, "8469": 6, "8479": [6, 34], "848": 35, "8488": 6, "8496": 6, "8499": 6, "85": [17, 18, 34, 68, 72, 83], "850124": 3, "85092333": 8, "852405": 9, "853476": 9, "8540": 83, "8542": 6, "854855": 5, "8555": 45, "855556": 9, "85635531": 8, "8571": 67, "8577": 18, "858": 8, "8582": 26, "8588": 34, "8589": 6, "85911047": 8, "86": [10, 17, 18, 68], "8612": 26, "86173277": 8, "86308480e": 25, "8645": 71, "864547": 3, "8652": 34, "86580032": 8, "866": 63, "86689458": 8, "867": [64, 68, 80], "8677": 83, "867905": 3, "8680": 21, "8693": 71, "87": [10, 17, 18, 80], "8710": 35, "8713": [6, 45], "8716": 83, "8719": 6, "8724": 6, "8728": 6, "8731": 44, "8734": 23, "874": [64, 68, 80], "874094": 25, "874692": 9, "8757": 24, "8760": 34, "8763": 6, "87638926": 8, "87680055": 8, "879374": 3, "87964097e": 22, "88": [17, 18, 64, 67, 68, 83], "880594": 49, "881": 6, "8825": 24, "882553": [2, 5], "8831": 31, "88344987": 8, "885018e": 334, "8855": 71, "885958": 3, "8863": 44, "8869": 6, "8875": 6, "8876": 44, "888": 144, "88811712": 8, "8883": 6, "8885": 61, "8888": 6, "89": [9, 10, 17, 18, 71, 80], "890075": 58, "8901": [], "8902": 35, "8907": [71, 72], "89070025": 25, "89082292": 8, "8910": 34, "891201e": 334, "8918": 71, "8924": 72, "8929": 45, "893123": 9, "8936": 6, "89376030e": 25, "8938": 6, "894205": [2, 5], "8965": 71, "8978": 34, "8979": 71, "8981": 6, "89852583": 8, "8987": 71, "8991": 6, "8992": 6, "8996": 6, "8c564b": 52, "8e93": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "9": [3, 5, 8, 9, 10, 17, 18, 21, 22, 23, 24, 25, 34, 35, 43, 44, 45, 46, 49, 57, 58, 63, 64, 67, 68, 71, 79, 80, 83, 86, 107, 112, 119, 211, 213, 214, 215, 216, 217, 221, 227, 229, 230, 231, 232, 233, 324, 328, 334, 335, 347, 349, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "90": [9, 10, 17, 18, 35, 46, 49, 52, 64, 71, 80, 210, 223, 225, 320, 347, 349], "90000": 2, "9001": 6, "901": 8, "9010": 6, "901036": 9, "902": [32, 36], "9025": 71, "90398368": 8, "90417395e": 25, "9042": 72, "9049": 6, "90490433": 8, "906131": 3, "9062": 71, "9063": 6, "9068": 35, "908": 35, "9080": 6, "9091": 6, "91": [17, 18, 63, 80, 83], "910277": 3, "910548e": 334, "911598": 3, "912": [8, 64, 68, 80], "9122": 6, "9131": 6, "9133": 6, "9134": 6, "9135": 6, "916": [331, 334], "9164": 6, "9171": 6, "918": 34, "918397": 5, "92": [17, 18, 34, 46, 67, 83], "920": 58, "921166": 3, "9219": 6, "92212328": 8, "9228": 6, "924": [58, 59, 379], "9257": 6, "926": 35, "9263": 45, "9267": 34, "92769672e": 21, "9277": 6, "928": [20, 27], "928576": 54, "9286": 71, "9291": 34, "929470": [2, 5], "9295": 34, "93": [8, 9, 17, 18, 63], "9303": 9, "93043925e": 25, "9311": 6, "931103": 9, "931307": 3, "931323": 5, "9319": 6, "9324": 6, "9327": 71, "9333": 6, "93370274": 8, "93374030e": 25, "933998": [2, 5], "9340": 6, "9341": 6, "935406": [2, 5], "9355069": 25, "9357": 23, "9363": 22, "9365": 44, "93651168": 8, "9368": 23, "939141e": 334, "94": [8, 17, 18, 57], "940": [44, 47], "9407": 71, "940e": 10, "941289": 3, "9426": 6, "9430": 6, "94301852": 8, "9431": 6, "9432": 6, "9440": 34, "9442": 6, "94448235e": 25, "944507": [2, 5], "9447": 6, "9449": [20, 34], "9453": [6, 34], "945496": 9, "9457": [23, 34, 61], "94615745e": 25, "9467bd": 52, "9470": 6, "9472": 6, "947248": 57, "9475": 20, "9476": 22, "9479": 6, "95": [10, 17, 18, 63, 67, 68, 79], "95000": 25, "950164": 3, "95042713": 8, "9508": 71, "950861": 3, "951874": 9, "952": 6, "95213115e": 22, "952328": 3, "9524": 6, "953276": [2, 5], "954": [331, 334], "954194": [2, 5], "9542909": 2, "954291": [2, 5], "9544": 6, "9554": 62, "95640850e": 25, "9574": [23, 34], "957594": 9, "9576e": 34, "9584": 44, "95855359": 8, "9589": [], "958904": 57, "9590": 6, "9599828": 25, "95d840": 52, "96": [17, 18, 34, 63, 64, 67, 79], "96001879": 8, "96020776": 8, "960e": 10, "961": 72, "962": [13, 27], "962809": 9, "964": 34, "9648": 6, "965827": 3, "966": [8, 24, 27], "9660": 6, "9662": [6, 34], "967160": 3, "9679": 6, "9689": [6, 44], "9698": 44, "97": [10, 17, 18, 63, 67, 79], "9710": 71, "9725": 6, "972620": 9, "9728": 34, "974": 6, "9741": 6, "976": 35, "9769": 35, "9772": 6, "9777": 6, "9788": 34, "9789": 62, "97900371e": 22, "9791": 35, "98": [17, 18, 58, 63, 64, 67, 79, 80], "980": 6, "9803": 72, "9808": 6, "981730": 3, "98238435": 25, "9830": 6, "98300947": 8, "983024": 3, "9836": 6, "983871": 57, "9839": 23, "984308": 3, "9851": 6, "9852": 6, "9858": 6, "9861": 6, "987": [63, 71], "9881": 52, "9881131988260086": 52, "9882": 6, "989": [6, 35], "98914508": 8, "989873e": 334, "99": [9, 17, 18, 63, 67, 68, 79, 80, 83, 117, 118, 119], "9902": 6, "9910": 6, "9923": 6, "992965": 3, "993234": 5, "99470963": 8, "99496903": 8, "995": [3, 10], "99578865": 25, "996": [3, 10, 35], "996155": 9, "99629270e": 25, "997": [3, 10], "9971": 6, "9977": 6, "998": [3, 10], "999": [3, 10, 144], "A": [52, 90, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 160, 164, 180, 181, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 223, 224, 226, 227, 232, 233, 237, 239, 240, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258, 260, 267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 323, 324, 326, 328, 331, 332, 333, 337, 350, 351, 359, 361, 362, 365, 367, 370, 377], "And": [226, 273, 274, 324], "As": [53, 71, 72, 226, 273, 274, 318, 324, 325, 327, 333, 338, 339, 361, 373], "At": 356, "But": [324, 328], "By": [83, 318, 320, 324, 325, 328, 331, 335, 336, 338, 342, 359, 361, 365, 366, 367, 369, 370, 371], "For": [19, 20, 25, 26, 112, 135, 136, 139, 140, 142, 144, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 238, 240, 247, 273, 274, 301, 318, 322, 323, 324, 325, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 376], "If": [106, 107, 112, 114, 116, 121, 122, 123, 124, 125, 126, 144, 147, 153, 160, 164, 165, 167, 180, 187, 199, 204, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 238, 239, 240, 246, 248, 256, 263, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 305, 306, 307, 324, 328, 331, 333, 334, 335, 336, 337, 338, 339, 353, 369, 370], "In": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 301, 318, 319, 320, 323, 324, 325, 327, 328, 331, 332, 333, 335, 336, 337, 338, 339, 351, 355, 359, 360, 361, 365, 368, 369, 370, 373, 376], "It": [117, 118, 119, 120, 122, 123, 125, 126, 132, 135, 136, 139, 140, 142, 143, 144, 181, 209, 211, 212, 213, 215, 216, 217, 220, 222, 227, 228, 229, 230, 232, 233, 236, 237, 247, 252, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 336, 339, 340, 346, 352, 353, 355, 360, 362, 365, 371, 374, 375], "Its": [123, 326, 331, 333], "No": [21, 22, 378], "Not": 223, "On": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 318, 320, 331, 333], "One": [248, 322, 329, 355, 356, 357, 358, 359, 360, 369], "Such": 361, "That": [331, 333], "The": [5, 106, 112, 115, 118, 121, 122, 123, 126, 133, 135, 136, 139, 140, 142, 143, 144, 145, 149, 150, 151, 152, 153, 154, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 180, 187, 192, 195, 197, 198, 199, 201, 202, 204, 205, 207, 208, 209, 210, 211, 213, 214, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 241, 243, 244, 246, 248, 249, 251, 252, 253, 254, 255, 257, 258, 259, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375], "Then": [318, 320, 323, 327, 329, 361, 369, 370], "There": [322, 353, 365, 367, 368, 369], "These": [320, 355, 356, 367, 369, 371], "To": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 229, 230, 231, 232, 233, 307, 320, 323, 327, 332, 333, 334, 335, 336, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 353, 358, 359, 361, 365, 366, 367, 368, 369, 370, 371], "Will": 307, "_": [322, 323, 327, 329, 331, 333, 335, 337, 359, 366, 368, 369, 371], "__": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "__doc__": 52, "_f": 327, "_i": [367, 368], "_j": [355, 356, 360], "_predict": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "_x": [355, 360], "a0": 322, "abil": [323, 324, 328, 356, 365, 366, 367, 368, 369, 370, 371], "abl": 373, "about": [208, 213, 215, 216, 217, 225, 227, 228, 247, 324, 333, 343, 355, 360, 368], "abov": [67, 68, 71, 72, 117, 119, 131, 133, 302, 318, 320, 324, 327, 331, 333, 334, 337, 338, 339, 361, 366, 370, 375], "abs_residu": [57, 58, 210, 225, 367], "abs_residual_perturb": [57, 58, 210, 225, 370], "absolut": [131, 180, 210, 225, 226, 323, 329, 339, 361, 367, 369], "absorb": 356, "acc": [13, 15, 19, 21, 23, 25, 34, 43, 45, 46, 49, 61, 75, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 318, 350, 351, 352, 365, 374], "acc_rank": [43, 46], "accept": [208, 220, 332, 339, 349, 366], "access": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 225, 356, 358, 362, 376], "accommod": 359, "accomplish": 337, "accord": [273, 274, 355, 356, 357, 359, 360, 368, 369], "accordingli": 376, "account": [230, 235, 324, 328, 332, 339, 355, 356, 357, 358, 359, 360, 365, 366], "accumul": [235, 327, 330, 340], "accur": [210, 225, 331, 333, 355, 360, 369, 370], "accuraci": [9, 13, 23, 24, 29, 30, 31, 34, 35, 229, 235, 240, 317, 327, 332, 339, 349, 355, 356, 359, 360, 362, 365, 367, 369, 370], "accuracy_plot": 320, "accuracy_result": 53, "achiev": [273, 274, 324, 331, 338, 355, 359, 360, 361, 365, 367, 368], "acm": [324, 327, 332], "across": [63, 64, 67, 68, 144, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 225, 227, 230, 233, 235, 236, 248, 251, 252, 255, 322, 324, 331, 333, 335, 339, 347, 348, 349, 352, 358, 359, 362, 365, 366, 367, 369, 370, 371], "act": 236, "action": [340, 349, 359, 367], "activ": [4, 135, 139, 140, 142, 165, 167, 172, 183, 184, 186, 188, 189, 190, 273, 274, 286, 287, 290, 291, 322, 329, 361, 366, 368, 369, 376], "activation_func": [273, 274], "active_interaction_index_": [273, 274], "active_main_effect_index_": [273, 274], "active_sample_index": 136, "active_samples_index": 6, "actual": [40, 214, 223, 224, 273, 274, 318, 324, 347, 349, 365, 367], "ad": [273, 274, 318, 320, 322, 327, 356, 369, 370, 375], "adam": [273, 274, 335], "adapt": [324, 357, 359, 369], "add": [5, 30, 144, 173, 195, 210, 225, 228, 266, 322, 344, 345, 346, 351, 356, 366, 368, 370], "add_ind": [5, 144, 322], "add_model": [49, 375], "add_step": [54, 266], "addit": [210, 225, 240, 273, 274, 286, 287, 318, 319, 320, 323, 324, 325, 328, 330, 331, 333, 336, 337, 340, 348, 352, 355, 356, 360, 367, 368, 369, 375], "addition": [325, 333, 334, 337, 340, 367], "address": [359, 364, 365, 366, 371], "adjust": [83, 122, 222, 325, 333, 346, 350, 366, 367, 368, 369, 370], "adopt": [324, 328, 365], "advanc": [324, 332, 340, 349, 350, 356, 359, 364], "advantag": [324, 356, 368, 371], "advers": [83, 208, 220, 221, 222, 319], "adversari": [366, 369, 370], "affect": [136, 222, 247, 332, 339, 366, 369], "after": [210, 217, 221, 222, 225, 228, 233, 239, 275, 276, 277, 290, 291, 324, 327, 333, 342, 343, 349, 350, 352, 353, 356, 361, 370, 373], "ag": [2, 3, 5, 25, 63, 83, 365, 371], "against": [71, 210, 212, 214, 221, 222, 224, 225, 229, 230, 231, 232, 233, 299, 300, 301, 302, 318, 319, 320, 324, 336, 340, 349, 359, 365, 366, 367, 370], "age_missing_nan": 5, "aggreg": [209, 226, 324, 359, 365], "aggress": 366, "agnost": [237, 238, 330, 331, 333, 337, 340, 348, 368], "aim": [210, 223, 225, 320, 324, 327, 331, 333, 357, 365], "air": [83, 208, 220, 221, 222, 230, 319], "al": [235, 330, 339, 340], "aletheia": 361, "alex": 335, "alex2015": 335, "alexand": 324, "algorithm": [117, 118, 123, 125, 132, 210, 225, 237, 300, 301, 318, 320, 324, 328, 331, 332, 350, 351, 356, 357, 361, 362, 367, 368, 369, 374], "align": [52, 323, 324, 325, 329, 331, 332, 333, 334, 335, 337, 339, 340, 355, 356, 360, 361, 365, 367], "alignwithlabel": 52, "all": [4, 21, 22, 29, 52, 63, 64, 67, 68, 71, 72, 79, 80, 83, 110, 111, 112, 114, 120, 121, 122, 123, 124, 125, 126, 135, 136, 137, 139, 140, 142, 143, 144, 147, 153, 161, 164, 165, 167, 199, 201, 202, 206, 207, 208, 209, 210, 212, 214, 217, 219, 220, 221, 222, 225, 226, 228, 229, 230, 231, 232, 233, 236, 238, 240, 246, 248, 250, 255, 260, 261, 273, 274, 290, 291, 299, 300, 301, 302, 304, 307, 318, 320, 322, 324, 327, 328, 331, 332, 333, 334, 335, 338, 339, 343, 353, 355, 356, 358, 359, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 379], "all_bias_weight": 254, "allow": [114, 180, 208, 211, 212, 213, 214, 215, 217, 220, 233, 247, 300, 324, 325, 329, 331, 332, 337, 339, 350, 351, 352, 355, 357, 358, 360, 363, 366, 367, 369, 370, 371, 374], "alon": 226, "along": [144, 219, 356, 358], "alongsid": [256, 365], "alpha": [14, 39, 40, 44, 71, 72, 119, 209, 210, 211, 216, 223, 225, 227, 232, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 320, 324, 358, 366, 368, 374], "alpha_1": 357, "alpha_2": 357, "alpha_i": 360, "alpha_l": 357, "alreadi": [146, 305, 338, 373], "also": [115, 135, 136, 139, 140, 142, 143, 180, 207, 209, 211, 212, 214, 219, 220, 221, 222, 230, 259, 273, 274, 301, 318, 319, 322, 323, 324, 325, 327, 328, 331, 332, 333, 335, 336, 337, 338, 339, 350, 355, 359, 363, 373, 374, 376], "alter": 323, "altern": [210, 225, 299, 305, 331, 333, 337, 339, 366, 368, 370], "although": [318, 324, 333], "alwai": [120, 326], "am": 336, "amazonaw": 29, "amer": [123, 326], "among": [125, 230, 324, 327, 328, 332, 339, 367, 369], "amount": 322, "an": [5, 30, 117, 118, 122, 133, 180, 220, 231, 236, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 287, 288, 290, 293, 295, 297, 299, 300, 301, 302, 305, 307, 318, 320, 322, 324, 325, 326, 327, 328, 331, 332, 333, 335, 336, 337, 339, 343, 350, 351, 352, 353, 355, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 375, 376], "analogi": [332, 339], "analys": 49, "analysi": [1, 9, 11, 23, 24, 29, 34, 35, 49, 53, 56, 59, 60, 66, 69, 73, 77, 81, 84, 93, 114, 120, 121, 122, 123, 124, 125, 131, 133, 181, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 247, 248, 254, 255, 256, 257, 259, 286, 287, 316, 321, 327, 328, 331, 333, 334, 335, 337, 338, 343, 344, 345, 348, 349, 352, 358, 364, 365, 371, 379], "analyt": 340, "analyz": [63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 117, 118, 119, 120, 131, 133, 181, 210, 211, 214, 217, 221, 222, 224, 225, 226, 227, 229, 231, 232, 233, 235, 238, 247, 248, 252, 255, 256, 257, 259, 324, 346, 348, 352, 366, 367, 368, 369, 370, 371], "andrea": 324, "angiulli": 324, "angiulli2002": 324, "ani": [52, 123, 160, 204, 263, 266, 284, 285, 286, 287, 307, 319, 326, 332, 335, 338, 339, 368, 376], "anim": 52, "animationdur": 52, "animationdurationupd": 52, "animationeas": 52, "animationeasingupd": 52, "animationthreshold": 52, "annal": [327, 331, 334], "annot": 326, "anomal": [227, 369], "anomali": [117, 324, 328], "anoth": [4, 19, 20, 71, 72, 323, 325, 331, 333, 365, 369], "anova": [226, 354, 357], "anyon": [25, 26], "apart": 335, "api": [29, 30, 49, 318, 320, 324, 333, 334, 335, 336, 337, 338, 339, 340, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "aplei": 331, "apley2016": [331, 333], "appear": [338, 350, 353], "appli": [4, 8, 121, 125, 126, 164, 180, 210, 212, 217, 221, 222, 225, 228, 275, 276, 290, 291, 318, 320, 323, 331, 332, 334, 339, 342, 344, 345, 355, 360, 361, 365, 366, 368, 369, 370], "applic": [114, 209, 229, 327, 355, 356, 359, 360, 370], "appnam": 30, "approach": [119, 324, 327, 328, 332, 339, 340, 359, 360, 367, 374], "appropri": [125, 144, 319, 324, 359, 365], "approv": [365, 370], "approx": [301, 366], "approxim": [125, 256, 327, 331, 332, 337, 339, 346, 368, 371], "april": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "ar": [4, 52, 114, 116, 117, 119, 124, 125, 131, 132, 133, 135, 136, 139, 140, 142, 164, 207, 208, 209, 210, 212, 214, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 235, 236, 237, 240, 247, 248, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 319, 320, 322, 323, 324, 325, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 350, 352, 353, 355, 356, 358, 359, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 376], "arang": [7, 31, 32, 33, 34, 35, 40, 376], "arbitrari": [28, 36, 48, 267, 268, 269, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 292, 297, 298, 363, 373, 379], "arbmodel": 376, "architectur": [273, 274, 290, 291, 340, 354, 355, 368, 369, 370], "area": [366, 367, 368, 369, 371], "arg": [106, 149, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298], "argsort": 40, "argument": [52, 106, 149, 210, 225, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298, 300, 307, 318, 320, 323, 327, 333, 334, 335, 336, 337, 339, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "aris": 368, "around": [333, 335, 356, 358, 362, 367], "arrai": [2, 6, 8, 9, 10, 17, 18, 21, 22, 25, 30, 32, 33, 39, 235, 238, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 376], "array_of_bin_edg": [112, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233], "articl": 373, "arxiv": [324, 327, 332, 339], "as_data_fram": 29, "ascend": [199, 324, 375], "asfactor": 29, "ask": 0, "aspect": [324, 358, 368, 369], "assembl": 30, "assess": [114, 123, 215, 220, 223, 227, 228, 230, 319, 320, 323, 326, 329, 331, 338, 349, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 369, 370, 371, 374], "assign": [259, 324, 332, 336, 356, 359, 371], "assoc": [123, 326], "associ": [52, 123, 254, 307, 319, 326, 353], "assum": [235, 273, 274, 331, 332, 337, 338, 339, 361, 367, 370], "assumpt": [323, 331, 337, 367, 368], "astyp": [63, 71, 72, 75, 83], "asymmetr": [323, 329], "asymptot": 327, "atemp": [4, 8, 9, 10, 20, 24, 52, 64, 68, 80, 86, 333, 336, 338, 339, 366, 368, 370], "attempt": [221, 222, 235], "attract": [332, 339], "attribut": [51, 55, 224, 269, 292, 319, 327, 332, 336, 339, 342, 365, 379], "auc": [13, 15, 17, 19, 21, 23, 25, 34, 43, 45, 46, 49, 54, 57, 61, 63, 67, 75, 79, 83, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 253, 299, 300, 301, 302, 303, 331, 338, 347, 349, 350, 351, 352, 361, 365, 367, 371, 374], "auc_rank": [43, 45, 46], "augment": [355, 360, 367, 368, 369], "august": 324, "authent": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "author": 324, "auto": [52, 63, 64, 67, 68, 79, 80, 83, 86, 112, 213, 214, 215, 216, 217, 221, 226, 229, 230, 231, 232, 233, 235, 236, 238, 273, 274, 303, 350, 352, 353, 365, 366, 370, 371], "auto_s": 52, "autom": [0, 54, 340, 366], "automat": [54, 126, 175, 213, 215, 216, 217, 305, 307, 325, 342, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 370], "avail": [9, 34, 35, 63, 64, 114, 121, 124, 135, 136, 137, 139, 140, 142, 143, 148, 207, 208, 209, 210, 214, 219, 220, 221, 222, 225, 226, 229, 230, 231, 232, 233, 235, 236, 238, 243, 244, 272, 273, 274, 283, 290, 291, 299, 300, 301, 302, 307, 322, 325, 331, 332, 335, 337, 339, 344, 351, 358, 362, 367, 374], "averag": [209, 216, 223, 232, 238, 248, 320, 324, 328, 331, 333, 335, 336, 337, 338, 339, 355, 356, 357, 358, 360, 361, 362, 367, 368, 370], "avg": [9, 34, 35, 71, 72], "avoid": [273, 274, 327, 351, 361, 369, 370], "awar": [365, 369], "ax": 345, "axi": [31, 32, 33, 83, 117, 118, 119, 121, 122, 207, 208, 211, 213, 215, 216, 217, 223, 224, 227, 228, 235, 236, 237, 238, 239, 240, 246, 249, 251, 255, 256, 257, 301, 318, 319, 320, 336, 339, 344, 349, 361, 376], "axis_nam": [38, 40], "axislabel": 52, "axislin": 52, "axispoint": 52, "axistick": 52, "b": [323, 327, 329, 331, 360, 361, 365, 370], "b140": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "b_i": 360, "back": 370, "backend": 48, "background": [240, 332, 339], "backgroundcolor": 52, "backpropag": 360, "backslash": [332, 339], "backward": [132, 327], "bad": 303, "bade28": 52, "bag": 370, "balanc": [222, 319, 322, 343, 344, 345, 355, 356, 360, 365, 366, 368, 369, 370], "bandwidth": 335, "bank": [368, 369, 370], "bar": [114, 120, 121, 131, 133, 206, 207, 208, 209, 210, 212, 220, 221, 225, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 255, 256, 257, 299, 300, 301, 302, 307, 318, 319, 320, 326, 332, 333, 336, 337, 339, 343, 344, 347, 348, 349, 350, 351, 358, 361, 367], "basak": 327, "base": [117, 118, 119, 121, 123, 131, 132, 133, 158, 164, 180, 181, 208, 210, 212, 213, 215, 216, 217, 220, 221, 225, 228, 229, 231, 232, 233, 247, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 318, 319, 321, 322, 323, 325, 326, 327, 329, 331, 332, 333, 334, 336, 337, 338, 339, 340, 342, 344, 345, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375], "base_scor": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "baselin": [222, 240, 369, 370], "baseline_dataset": [87, 240], "baseline_sample_index": [87, 240], "baseline_sample_s": [87, 240], "basi": [324, 370], "basic": [1, 11, 13, 23, 24, 29, 52, 107, 316, 321, 325, 342, 343, 357, 379], "batch": [63, 64, 71, 72, 79, 80, 83, 229, 230, 231, 232, 233, 273, 274, 286, 287, 290, 291, 374, 375], "batch_siz": [273, 274, 290, 291], "batch_size_infer": [273, 274], "bcbd22": 52, "becaus": [106, 236, 331, 333, 336, 355, 356, 357, 360], "becom": [332, 336, 339, 369], "been": [152, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 361], "befor": [125, 160, 172, 180, 226, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 370, 371], "begin": [323, 324, 328, 329, 331, 332, 333, 334, 335, 337, 339, 350, 355, 357, 361, 365, 366, 368, 369], "behav": 369, "behavior": [227, 233, 324, 349, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 369, 371, 374], "behind": 324, "being": [118, 207, 209, 211, 212, 213, 215, 216, 217, 225, 252, 331, 332, 333, 338, 339], "belong": [324, 328], "below": [132, 318, 319, 320, 322, 324, 332, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 376], "benchmark": [57, 58, 340, 365, 370], "benefici": 327, "benefit": [332, 339, 358, 359, 362], "benign": 370, "bernhard": [324, 327], "best": [15, 16, 273, 274, 300, 318, 347, 350, 359, 367], "beta": [366, 368], "beta_1": 357, "beta_2": 357, "beta_l": 357, "better": [5, 118, 222, 318, 320, 324, 331, 335, 338, 355, 356, 357, 358, 360, 361, 366, 367, 368, 374], "between": [3, 7, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 114, 117, 118, 119, 121, 122, 123, 125, 131, 180, 208, 209, 215, 216, 219, 220, 221, 222, 223, 224, 229, 230, 231, 232, 233, 236, 251, 300, 318, 320, 323, 324, 326, 327, 328, 329, 331, 332, 333, 334, 335, 337, 338, 339, 343, 344, 345, 346, 348, 349, 352, 355, 357, 358, 359, 360, 366, 367, 368, 369, 370, 371], "beyond": [331, 333], "bi_featur": [333, 337], "bia": [251, 254, 278, 319, 340, 357, 361, 365, 366, 367, 371], "bias": [331, 333, 360, 361, 365, 371], "bigl": 359, "bigr": 359, "bike": 320, "bikeshar": [4, 6, 8, 9, 10, 14, 16, 18, 20, 22, 24, 26, 40, 44, 52, 57, 58, 61, 62, 64, 68, 72, 76, 80, 86, 148, 322, 333, 334, 335, 336, 337, 338, 339, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370], "bill_amt1": [2, 3, 5, 25, 63, 71, 79, 83, 365, 371], "bill_amt2": [2, 3, 5, 25, 63, 79, 83], "bill_amt3": [2, 3, 5, 25, 63, 79, 83], "bill_amt4": [2, 3, 5, 25, 63, 71, 79, 83], "bill_amt5": [2, 3, 5, 25, 63, 71], "bill_amt6": [2, 3, 5, 25, 63], "bin": [5, 63, 64, 67, 68, 83, 112, 114, 120, 126, 213, 214, 215, 216, 217, 221, 222, 226, 229, 230, 231, 232, 233, 318, 323, 324, 329, 331, 333, 342, 343, 352, 353, 366, 367, 368, 369, 370], "bin_numer": [5, 322], "binari": [29, 37, 41, 48, 53, 61, 63, 124, 125, 126, 176, 219, 235, 236, 238, 268, 271, 272, 274, 276, 277, 278, 280, 282, 285, 287, 289, 290, 291, 292, 294, 296, 298, 318, 324, 331, 332, 333, 334, 335, 336, 337, 338, 339, 361, 368, 379], "binaryclassifi": 29, "bind": 353, "binning_featur": 221, "binning_method": [83, 221, 365], "bird": 374, "bit": [332, 339], "bivari": [79, 80, 83, 121, 321, 365, 368, 370], "black": [331, 348, 356, 361], "blank": 52, "bleich": 335, "block": [273, 274], "blue": 339, "blursiz": 52, "bogdan": [331, 334], "bolder": 52, "bonu": [332, 339], "bool": [117, 119, 144, 160, 172, 180, 187, 195, 199, 201, 206, 208, 214, 220, 221, 222, 224, 230, 237, 255, 256, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307], "boolean": [146, 214, 215, 216, 217, 229, 230, 231, 232, 233], "boost": [216, 223, 268, 271, 272, 274, 275, 276, 278, 280, 282, 285, 286, 287, 289, 291, 292, 294, 296, 298, 316, 331, 354, 359, 360, 367, 370, 373], "booster": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "boosting_typ": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "borboudaki": 327, "borboudakis2019": 327, "bordercolor": 52, "bordertyp": 52, "borderwidth": 52, "both": [112, 118, 122, 123, 124, 125, 144, 207, 219, 222, 229, 231, 237, 246, 247, 273, 274, 275, 276, 319, 320, 324, 326, 328, 332, 333, 335, 339, 340, 344, 355, 356, 358, 359, 360, 361, 362, 365, 366, 368, 369, 370, 376], "botta": 324, "bottom": [52, 336], "bound": [208, 214, 220, 221, 222, 230, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 370], "boundari": [112, 126, 327, 347, 349, 366], "boundary_clip": [273, 274], "box": [79, 121, 228, 320, 326, 331, 342, 344, 348, 356, 361, 362], "boxplot": 320, "break": [5, 9, 10, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 54, 83, 332, 339], "breiman": [331, 338], "bridg": [348, 360], "brief": 324, "briefli": [324, 361], "brier": [13, 15, 19, 21, 23, 25, 34, 43, 45, 46, 49, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 318, 351, 367, 374], "brier_rank": 43, "broader": 365, "broken": [331, 338], "bruce": 327, "brush": 52, "brute": [331, 337, 374], "build": [12, 48, 340, 355, 356, 357, 365, 366, 369, 371, 373, 376], "builder": 30, "built": [93, 148, 265, 332, 339, 375], "bundl": [355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "burden": [324, 327, 368], "busi": [340, 356, 367], "button": [342, 343, 344, 345, 347, 348, 349, 350, 351, 352], "by_weight": [208, 214, 220, 221, 222, 230], "c": [324, 331, 335, 337, 361, 365, 370], "c1": 346, "c2": 346, "c3": 346, "c_": 368, "c_1": 359, "c_2": 359, "c_j": 359, "c_k": 359, "cach": [107, 304], "cal": 368, "calcul": [52, 71, 72, 83, 114, 117, 118, 119, 123, 131, 207, 208, 210, 219, 220, 221, 223, 224, 225, 226, 230, 231, 232, 235, 236, 237, 238, 239, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 299, 300, 301, 302, 318, 320, 323, 324, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 356, 359, 361, 367, 368, 369, 370], "calhous": 353, "calibr": [41, 71, 72, 93, 209, 210, 216, 223, 225, 232, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 349, 359, 365, 368, 379], "calibrate_interv": [39, 40, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "calibrate_proba": [38, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297], "california": [31, 32, 33, 373, 375], "californiah": [148, 322, 375], "call": [112, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 320, 325, 331, 333, 335, 337, 361], "callabl": [117, 118, 119, 266, 269, 292], "callback": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "can": [53, 71, 93, 107, 112, 121, 123, 126, 135, 136, 139, 140, 142, 143, 144, 164, 173, 209, 210, 211, 212, 219, 220, 221, 222, 223, 224, 225, 227, 228, 235, 236, 238, 246, 284, 285, 299, 301, 303, 305, 307, 318, 319, 320, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 342, 350, 351, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376], "candid": [278, 327, 355, 359, 367, 368, 374, 375], "cannot": [112, 180, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 319], "capabl": [324, 326, 327, 340, 356, 358, 362, 366], "capac": [366, 368], "capit": [320, 333, 334, 335, 336, 337, 338, 339], "capsul": 29, "captur": [123, 275, 276, 324, 326, 336, 355, 356, 357, 359, 366, 367, 368, 369, 371], "card": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "care": 324, "carefulli": 365, "carlo": [300, 332], "cartesian2d": 52, "cascad": 356, "case": [212, 228, 322, 325, 331, 332, 336, 338, 349, 357, 366, 367, 368, 369, 370], "catboost": [107, 267, 268, 350, 356, 367, 369, 370], "catboost2": 49, "catboostclassifi": 267, "catboostregressor": 268, "categor": [2, 3, 5, 19, 20, 23, 25, 26, 63, 64, 111, 112, 120, 121, 122, 123, 124, 125, 126, 128, 131, 144, 166, 181, 208, 213, 214, 215, 216, 217, 220, 221, 222, 229, 230, 231, 232, 233, 235, 247, 248, 272, 273, 274, 283, 301, 318, 320, 326, 327, 333, 337, 342, 344, 345, 351, 353, 356, 357, 358, 359, 360, 365, 366, 367, 368, 369, 371], "categori": [3, 5, 52, 122, 124, 125, 126, 208, 214, 220, 221, 222, 230, 301, 324, 325, 328, 333, 343, 344, 355, 356, 357, 358, 359, 360, 370], "categorical_encod": [124, 125], "caus": [328, 365, 370], "causal": [327, 340], "caution": 327, "cblof": [117, 321, 340], "cboost_model": 356, "ccc": 52, "ccp_alpha": [15, 16], "cdf": [324, 327, 369, 370], "cdot": [355, 356, 360, 366, 367], "cell": [3, 5, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 343], "center": [13, 14, 17, 18, 19, 20, 23, 24, 25, 26, 52, 87, 117, 164, 237, 255, 256, 259, 284, 285, 328, 331, 333, 336, 355, 356, 357, 358, 359, 360, 361, 369], "central": [353, 363, 375], "centroid": [21, 22, 259, 284, 285, 301, 324, 328, 359], "certain": [23, 320, 323, 324, 325, 331, 332, 337, 339, 355, 356, 357, 360, 365], "cezar": 324, "chain": 340, "challeng": [211, 227, 332, 339, 347, 349, 359, 365, 369], "chang": [15, 16, 79, 80, 136, 228, 238, 320, 323, 324, 327, 328, 329, 335, 336, 347, 349, 356, 358, 362, 365, 366, 367, 368, 369, 370, 371], "changed_name_kei": 52, "charact": 327, "character": [368, 371], "characterist": [212, 259, 324, 328, 359, 370], "chart": [120, 316, 318, 320, 326, 337, 341, 343, 345, 347], "chart_id": 52, "chatterje": [123, 326], "chatterjee2021": 326, "chebyshev": 125, "check": [5, 83, 135, 136, 139, 140, 142, 143, 153, 320, 342, 353, 355, 359, 360, 366, 367, 368, 369, 370, 371], "checkbox": 342, "chen": [324, 328], "chi": 361, "child": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 324], "ching": [324, 328], "choic": [324, 356, 361, 362], "choos": [209, 300, 324, 328, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 366, 370], "chosen": [119, 216, 224, 318, 369, 370], "circl": [320, 324], "circumst": 369, "clara": 324, "clariti": [224, 273, 274, 355], "class": [0, 49, 52, 180, 208, 214, 220, 221, 222, 224, 230, 235, 236, 238, 240, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 322, 326, 363, 365, 367, 368, 376], "class_weight": [15, 23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "classif": [0, 12, 27, 29, 30, 48, 54, 56, 59, 60, 65, 66, 69, 70, 73, 74, 77, 78, 81, 82, 84, 89, 118, 119, 176, 182, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 299, 300, 301, 302, 317, 322, 324, 325, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 374, 376, 379], "classifi": [28, 36, 37, 41, 48, 223, 258, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 324, 328, 332, 356, 362, 367, 379], "classmethod": 260, "clean": [107, 322, 366], "cleaner": 356, "clear": [333, 353, 355, 356, 359], "clear_mlflow_hom": [0, 107], "clearer": 356, "clearli": 324, "click": [52, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353], "client": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "clip": [52, 273, 274, 275, 276, 277, 278], "clip_predict": [23, 24, 275, 276, 277, 278], "close": [123, 320, 326, 336, 361, 365], "closer": 236, "cluster": [75, 76, 117, 210, 211, 212, 225, 227, 248, 259, 284, 285, 328, 340, 346, 347, 359, 364, 366, 367], "cluster_i": 225, "cluster_id": [367, 368, 369, 370], "cluster_label": 225, "cluster_method": [57, 58, 210, 225, 367, 368, 369, 370], "cluster_no": 359, "cluster_perform": [57, 58, 210, 225, 367], "cluster_pred_func": 225, "cluster_qr": 369, "cluster_residu": [57, 58, 210, 225, 367], "cluster_sample_weight": 225, "cluster_threshold": 117, "cluster_x": 225, "cma": [46, 300], "cmaessampl": 300, "cnt": [9, 10, 14, 16, 18, 20, 22, 24, 26, 40, 44, 58, 62, 64, 68, 72, 76, 80, 86, 320, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370], "coalit": [332, 339], "coarser": 365, "code": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 107, 121, 316, 318, 319, 320, 323, 324, 325, 333, 334, 335, 336, 337, 338, 339, 340, 344, 345, 353, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "coef": 339, "coeffcient": [358, 361], "coeffici": [123, 226, 237, 246, 251, 254, 256, 321, 326, 332, 336, 339, 355, 357, 358, 360, 361, 367], "coefici": [358, 361], "col_nam": [29, 52], "colab": 93, "collect": [30, 366, 368, 369, 371], "color": [3, 52, 121, 122, 326, 344, 345, 346, 351], "colorbi": 52, "colsample_bylevel": [9, 38, 39, 40, 53, 61, 62, 63], "colsample_bynod": [9, 38, 39, 40, 53, 61, 62, 63], "colsample_bytre": [9, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "colsiz": 52, "column": [2, 3, 5, 8, 9, 10, 17, 18, 29, 30, 31, 32, 33, 34, 35, 52, 63, 64, 67, 68, 71, 72, 79, 80, 83, 110, 111, 124, 125, 126, 144, 157, 168, 169, 174, 208, 214, 220, 221, 222, 230, 247, 322, 342, 343, 350, 351, 353, 376], "com": 29, "combin": [9, 132, 236, 240, 277, 278, 284, 285, 286, 287, 307, 324, 327, 328, 332, 339, 343, 344, 345, 347, 351, 357, 358, 359, 366, 367, 369, 371, 374], "come": [236, 332, 339, 365], "command": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 106, 107], "commiss": 365, "common": [332, 339, 343, 368, 369, 371, 374], "commonli": [323, 324, 331, 337, 365], "compar": [64, 75, 76, 79, 80, 83, 114, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 222, 236, 317, 318, 319, 320, 323, 324, 333, 336, 347, 349, 351, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "compare_accuraci": 53, "compare_accuracy_t": [38, 54, 61, 62, 367], "compare_fair": [83, 365], "compare_reli": [71, 72, 368], "compare_residual_clust": [57, 58], "compare_resili": [75, 76, 369], "compare_resilience_clust": 369, "compare_robust": [54, 79, 80, 370], "compare_slicing_accuraci": [63, 64, 371], "compare_slicing_fair": [83, 365], "compare_slicing_overfit": [67, 68, 366], "compare_slicing_reli": [71, 72, 368], "compare_slicing_robust": [79, 80, 370], "comparison": [0, 114, 207, 213, 214, 215, 216, 220, 259, 316, 341, 352, 355, 356, 357, 358, 360, 361, 364], "compat": [144, 269, 292, 340, 358, 362], "compet": 365, "competit": 355, "complement": [180, 324, 331, 335, 337], "complementari": 367, "complet": [124, 181, 250, 274, 290, 291, 343, 350, 362], "complex": [275, 276, 277, 324, 331, 337, 345, 346, 348, 359, 361, 367], "compliant": 365, "complic": [361, 371], "compon": [112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 232, 233, 247, 249, 251, 252, 253, 254, 255, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 326, 328, 355, 356, 357, 358, 359, 360, 361, 365], "composit": 367, "comprehens": [123, 181, 208, 211, 212, 324, 326, 328, 340, 345, 347, 356, 365, 374, 377], "compris": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "comput": [107, 117, 118, 119, 123, 124, 133, 164, 181, 213, 214, 215, 216, 220, 221, 229, 230, 231, 232, 233, 235, 239, 240, 247, 249, 252, 255, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 323, 324, 327, 328, 331, 332, 333, 334, 335, 337, 338, 339, 356, 357, 359, 365, 366, 367, 368, 369, 371, 378], "computation": [368, 374], "concat": [31, 32, 33, 376], "concaten": [34, 35], "concept": [332, 339, 357, 367], "conceptu": [355, 360], "concern": 365, "conclus": [320, 365], "concord": [123, 326], "conda": 93, "condit": [132, 209, 227, 233, 321, 324, 332, 339, 340, 349, 365, 367, 368, 369, 370, 371], "conduct": [4, 217, 327, 340, 369], "confer": [324, 328, 332], "confid": [210, 223, 225, 347, 349, 367, 368, 369, 371], "config": [83, 218, 262], "configur": [5, 52, 53, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 126, 131, 132, 133, 144, 164, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 299, 300, 301, 302, 307, 322, 335, 343, 347, 348, 349, 353, 365, 369], "confin": 52, "conflict": [107, 365], "conform": [71, 72, 210, 223, 225, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 340, 364], "confus": [61, 219, 223], "confusion_matrix": [53, 61, 219], "consecut": 369, "consequ": 319, "consid": [117, 119, 131, 228, 239, 275, 276, 277, 318, 319, 324, 328, 331, 332, 334, 337, 338, 339, 355, 356, 360, 361, 365, 366, 367], "consider": [144, 320, 368], "consist": [123, 164, 210, 225, 320, 326, 332, 333, 334, 335, 336, 337, 338, 339, 340, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "const": 342, "constant": [144, 322, 335, 356, 357, 366, 369, 370], "constrain": [356, 367], "constrainst": 366, "constraint": [273, 274, 286, 287, 354, 365, 367, 368, 369, 370], "construct": [278, 307, 324, 328, 356, 368], "consum": 339, "contain": [0, 48, 93, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 152, 160, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 316, 324, 328, 338, 357, 368, 371], "containlabel": 52, "content": [234, 304, 343], "context": [299, 300, 301, 302, 324, 331, 332, 337, 339, 365], "contextu": 365, "continu": [52, 112, 123, 320, 324, 326, 333, 334, 335, 336, 337, 338, 339, 340, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 370, 371, 375], "contrast": [324, 328, 336], "contribut": [226, 237, 240, 256, 275, 276, 324, 328, 332, 335, 336, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 370], "control": [112, 119, 172, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 236, 238, 240, 247, 266, 277, 300, 324, 325, 337, 340, 355, 356, 358, 360, 361, 365, 370], "conveni": [320, 376], "converg": [356, 359], "convers": [319, 324], "convert": [29, 30, 124, 125, 126, 145, 192, 286, 287, 360, 370], "coordin": [251, 259, 345, 346, 351], "coordinatesystem": 52, "copi": 38, "copy_x": [14, 44], "coral": [324, 328], "core": [240, 273, 274, 290, 291], "correct": 356, "correctli": 367, "correl": [52, 123, 131, 321, 324, 328, 331, 332, 333, 337, 339, 340, 344, 366], "correspond": [211, 235, 238, 239, 246, 249, 300, 324, 328, 332, 339, 355, 359, 360, 361, 371, 374], "corrratio": 327, "corrupt": 328, "cosin": 125, "cost": [273, 274, 355, 360, 365, 366, 367, 368, 369], "could": [273, 274, 332, 339, 367], "count": [3, 17, 18, 253, 254, 320, 325, 333, 334, 335, 336, 337, 338, 339, 343, 361, 367], "count_llm": 254, "covari": [324, 327, 328, 340, 368], "cover": 363, "coverag": [9, 34, 35, 71, 72, 209, 210, 216, 223, 225, 232, 347, 349, 368], "cp": 368, "cpu": [17, 18, 19, 20, 23, 24, 273, 274, 286, 287, 290, 291], "creat": [5, 53, 112, 120, 121, 122, 124, 125, 126, 144, 152, 210, 216, 224, 225, 236, 238, 246, 247, 248, 249, 250, 251, 258, 284, 285, 286, 287, 305, 307, 322, 324, 332, 333, 336, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "createdatafram": 30, "credit": [5, 365], "criteria": 365, "criterion": [15, 16, 362, 365, 369], "critic": [359, 361, 365, 366, 367], "cross": [284, 285, 299, 300, 301, 302, 327, 367, 374], "crowd": 320, "crqr": 368, "crucial": [328, 336, 374], "csur": 327, "csv": [29, 149, 153, 353], "cubicout": 52, "cuda": [286, 287, 290, 291], "cultur": 365, "cumul": [119, 220, 323, 329, 369, 370], "cumulative_variance_threshold": 119, "cup": [332, 339], "current": [121, 122, 204, 263, 356], "cursor": 52, "curv": [3, 61, 121, 219, 331, 333, 347, 367, 369], "custer": 369, "custom": [63, 64, 114, 208, 214, 220, 222, 230, 275, 276, 277, 278, 284, 285, 286, 287, 325, 340, 342, 343, 350, 369, 370], "custom_tooltip": 52, "customiz": [120, 344], "customm": 371, "cutoff": 222, "cv": [43, 44, 45, 46, 284, 285, 299, 300, 301, 302, 374], "cyclic": [14, 44], "d": [2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 145, 152, 192, 208, 209, 211, 212, 220, 223, 225, 227, 228, 301, 322, 323, 327, 329, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376], "d1": 3, "d2": 3, "d62728": 52, "d_": [323, 329, 331, 334, 368], "d_j": [331, 334], "d_k": [331, 334], "dag": 266, "dai": [333, 335, 337], "daniel": 331, "darker": 333, "dashboard": [107, 340, 353], "data": [0, 1, 4, 6, 8, 11, 52, 53, 54, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 158, 159, 160, 162, 164, 170, 171, 172, 173, 179, 180, 181, 187, 192, 193, 194, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 307, 316, 318, 320, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 349, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 371, 379], "data_drift": 114, "data_drift_test": [7, 21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 208, 209, 211, 212, 220, 223, 225, 227, 228, 329, 359, 366, 367, 368, 369, 370, 371], "data_eda_1d": 120, "data_eda_2d": 121, "data_eda_3d": 122, "data_eda_correl": [52, 123], "data_eda_pca": 124, "data_eda_umap": 125, "data_fs_corr": 131, "data_fs_rcit": 132, "data_fs_xgbpfi": 133, "data_info": [21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 208, 209, 211, 212, 220, 223, 225, 227, 228, 259, 303, 359, 366, 367, 368, 369, 370, 371], "data_load": 353, "data_outlier_cblof": 117, "data_outlier_isolationforest": 118, "data_outlier_pca": 119, "data_path": [149, 154], "data_preprocess_bin": 112, "data_preprocess_encod": 126, "data_preprocess_imput": 144, "data_preprocess_sc": 164, "data_process": 342, "data_qu": 324, "data_result": [21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 208, 209, 211, 212, 220, 223, 225, 227, 228, 359, 366, 367, 368, 369, 370, 371], "data_summari": [181, 325, 343], "databas": [260, 266, 322], "datafram": [5, 9, 10, 30, 31, 32, 33, 34, 35, 52, 113, 114, 117, 118, 119, 123, 124, 125, 131, 132, 133, 144, 145, 147, 150, 151, 159, 170, 171, 173, 181, 187, 192, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 231, 232, 233, 235, 236, 237, 238, 239, 246, 247, 249, 253, 255, 256, 260, 307, 322, 334, 373, 376], "dataset": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 197, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 242, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 264, 273, 274, 275, 276, 290, 291, 295, 296, 299, 300, 301, 302, 303, 318, 319, 320, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 335, 336, 337, 338, 340, 341, 342, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376, 379], "dataset1": [7, 114, 303], "dataset2": [7, 114, 303], "datazoom": 52, "dateutil": 107, "daytim": 337, "dde318": 52, "de": 361, "deactiv": [355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "deal": [1, 11, 273, 274, 370, 379], "debias": 365, "debug": [348, 367], "decid": [324, 370], "decis": [12, 27, 48, 235, 236, 238, 250, 258, 267, 269, 270, 273, 275, 277, 278, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 316, 332, 336, 339, 352, 354, 357, 359, 365, 366, 367, 370, 379], "decision_funct": [235, 236, 238, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 333, 334, 335, 337], "decisiontre": 375, "decisiontreeclassifi": [270, 362], "decisiontreeregressor": [271, 362], "declin": 369, "decompos": [332, 339, 355, 356, 357, 359, 360, 366], "decomposit": 361, "decreas": [23, 24, 123, 273, 274, 275, 276, 277, 278, 286, 287, 326, 355, 356, 360, 365], "dedegr": 340, "dedic": 319, "deep": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 340, 361, 376], "deepcopi": 38, "deeper": 359, "def": [29, 30, 32, 33, 54, 376], "default": [4, 52, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 147, 153, 160, 164, 165, 167, 172, 180, 181, 187, 199, 201, 202, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 305, 306, 307, 318, 320, 323, 324, 328, 332, 333, 334, 335, 336, 337, 338, 339, 342, 344, 345, 346, 352, 361, 365, 374], "defin": [29, 208, 213, 214, 216, 217, 220, 222, 230, 233, 284, 285, 299, 300, 322, 323, 324, 327, 329, 331, 332, 334, 335, 337, 339, 349, 351, 356, 359, 361, 365, 366, 370, 371, 374, 376], "definit": [208, 213, 214, 215, 216, 217, 220, 229, 230, 231, 232, 233, 331, 333, 364], "degrad": [320, 331, 338, 340, 347, 349, 369, 370, 371], "delet": [115, 116, 197, 304, 322, 327, 353], "delete_extra_data": 10, "delete_registered_data": 322, "delinqu": 322, "deliv": 359, "delta": [366, 369, 370], "demo": [2, 9, 34, 35, 322, 324, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353], "demograph": [170, 171, 208, 319, 365], "demonstr": [49, 52, 53, 54, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 318, 319, 320, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 373, 376], "deng": [324, 328], "dengel": 324, "denomin": 236, "denot": [331, 332, 335, 338, 339, 359, 361, 365], "densiti": [3, 7, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 117, 118, 119, 120, 208, 209, 211, 212, 220, 223, 225, 227, 228, 323, 324, 326, 333, 343, 344, 345, 366, 367, 368, 369, 370, 371], "depend": [107, 120, 123, 235, 236, 238, 324, 326, 327, 330, 332, 334, 335, 340, 342, 348, 365, 367], "depict": 319, "deploi": [340, 355, 360, 371], "deploy": [347, 350, 369], "dept": [324, 328], "depth": [209, 210, 216, 223, 225, 226, 229, 230, 232, 233, 268, 271, 272, 274, 275, 276, 277, 278, 280, 282, 285, 286, 287, 289, 291, 292, 294, 296, 298, 324, 352, 359, 367, 368, 370], "depth2": [374, 375], "depth5": 375, "deriv": [320, 324], "descend": [327, 361], "descent": [23, 24, 361], "describ": [160, 318, 324, 327, 331, 333, 337], "descript": [160, 181, 204, 263, 322, 342, 366, 371], "design": [136, 303, 324, 332, 339, 340, 355, 365, 370, 375], "desir": [323, 324, 328, 329, 355, 360, 368, 370, 371], "despit": [361, 369], "detail": [25, 52, 123, 181, 207, 208, 209, 212, 213, 214, 215, 216, 223, 225, 227, 228, 247, 255, 260, 301, 302, 307, 318, 320, 324, 326, 327, 328, 331, 332, 340, 344, 351, 353, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "detect": [0, 1, 11, 93, 117, 118, 119, 123, 211, 227, 229, 231, 316, 318, 320, 321, 326, 340, 342, 346, 364, 365, 367, 368, 379], "detect_outlier_cblof": [8, 328], "detect_outlier_isolation_forest": [8, 328], "detect_outlier_pca": [8, 328], "determin": [117, 223, 228, 247, 278, 285, 300, 301, 302, 323, 324, 325, 328, 329, 331, 332, 337, 339, 359, 367, 368, 369, 370, 371, 374], "dev": 107, "develop": [93, 107, 254, 320, 322, 323, 333, 334, 335, 336, 337, 338, 339, 340, 359, 361, 367, 368, 369, 377], "deviat": [210, 225, 228, 251, 253, 322, 324, 325, 328, 366, 369, 370], "devic": [9, 17, 18, 19, 20, 23, 24, 38, 39, 40, 53, 61, 62, 63, 273, 274, 286, 287, 290, 291], "df": [30, 322], "di": 365, "diagnos": 366, "diagnose_accuracy_residual_fi": 371, "diagnose_accuracy_t": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 34, 35, 43, 44, 45, 46, 53, 61, 62, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 371, 376], "diagnose_fair": [83, 365], "diagnose_mitigate_unfair_bin": [83, 365], "diagnose_mitigate_unfair_threshold": [83, 365], "diagnose_reli": [9, 34, 35, 71, 72, 368], "diagnose_residu": 224, "diagnose_residual_analysi": [9, 34, 35, 57, 58, 367], "diagnose_residual_clust": [57, 58, 367, 368, 370], "diagnose_residual_fi": 371, "diagnose_residual_interpret": [57, 58, 367], "diagnose_resili": [9, 34, 35, 75, 76, 369], "diagnose_resilience_clust": [225, 369], "diagnose_robust": [79, 80, 370], "diagnose_slicing_accuraci": [9, 34, 35, 63, 64, 371], "diagnose_slicing_fair": [83, 365], "diagnose_slicing_overfit": [9, 34, 35, 67, 68, 366], "diagnose_slicing_reli": [71, 72, 368], "diagnose_slicing_robust": [79, 80, 303, 370], "diagnost": [0, 316, 317, 340, 347, 349, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 369, 370, 371], "diagram": [250, 258, 362], "dict": [52, 112, 160, 204, 208, 210, 213, 214, 215, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 247, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307], "dictionari": [112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 160, 164, 180, 181, 195, 203, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 277, 299, 300, 301, 302, 303, 374], "differ": [7, 48, 49, 53, 63, 64, 67, 68, 114, 131, 181, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 224, 225, 227, 228, 230, 233, 251, 252, 284, 285, 317, 318, 319, 320, 322, 323, 327, 328, 329, 331, 332, 333, 336, 337, 338, 339, 344, 352, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 374], "differenti": [359, 360], "difficult": [211, 227, 236, 369], "diistribut": 340, "dill": 107, "dimens": [52, 125, 324, 347, 349, 356], "dimension": [119, 125, 323, 324, 326, 328, 346, 366, 367], "direct": [123, 326, 340, 347, 355, 356, 357, 358, 360, 361, 362, 367, 369, 376], "directli": [284, 285, 318, 319, 332, 338, 339, 358, 361, 362, 365, 366], "directori": [305, 306, 307], "disabl": [2, 322], "disadvantag": [327, 371], "discontinu": 357, "discord": [123, 326], "discov": [324, 328], "discoveri": [324, 327, 332, 346], "discrep": [323, 324, 369], "discret": [112, 323, 329], "discrimin": [319, 365], "diseas": 365, "disentangl": [355, 361], "displai": [38, 40, 114, 201, 207, 208, 209, 210, 214, 219, 220, 221, 222, 225, 226, 229, 230, 231, 232, 233, 234, 246, 299, 300, 301, 302, 307, 318, 319, 320, 323, 324, 339, 342, 343, 344, 346, 349, 350, 352, 355, 356, 357, 358, 359, 360, 361, 362, 368, 369, 371], "display_plot": 234, "display_t": 234, "disproportion": [369, 370], "dissimilar": [323, 324, 328], "distanc": [114, 117, 119, 125, 208, 210, 220, 225, 324, 328, 329, 333, 340, 359, 367, 368, 370], "distance_metr": [7, 21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 323, 359, 366, 367, 368, 369, 370, 371], "distance_scor": 114, "distinct": [122, 319, 324, 356, 359], "distinguish": [117, 355, 367], "distribut": [63, 64, 83, 114, 120, 209, 211, 220, 223, 225, 227, 228, 252, 300, 302, 303, 318, 320, 321, 326, 327, 328, 332, 339, 340, 343, 344, 347, 349, 358, 359, 364, 365, 366, 367, 368, 371, 374], "divers": [340, 359, 363, 365], "divid": [235, 324, 328, 331, 333, 362, 366, 371], "divis": 362, "dnn": 354, "do": [9, 325, 331, 332, 333, 338, 339, 376], "document": [331, 335, 338, 344, 345], "doe": [23, 123, 305, 324, 326, 328, 332, 333, 334, 335, 336, 337, 338, 365, 366], "doesn": [116, 275, 276], "doi": [324, 328], "domain": [355, 356, 360, 366, 368, 369, 370], "dominik": 327, "done": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 318, 333, 336, 366, 370], "dot": [320, 324], "down": [331, 332, 333, 339, 344, 345], "download": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 344, 345], "downsampl": [332, 339], "downstream": 173, "draw": [71, 333, 339], "drawn": [121, 240, 370], "drift": [0, 1, 11, 57, 58, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 303, 316, 321, 340, 359, 364, 367, 368, 370, 371, 379], "drill": 349, "drive": [367, 371], "driven": [340, 359, 365, 367, 371], "driver": 359, "drop": [83, 132, 227, 327, 331, 338, 370], "dropdown": [342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352], "drug": 345, "ds_new": 49, "dsload": 2, "dt": 49, "dtype": [17, 18, 39, 144], "dual": 247, "due": [107, 229, 230, 232, 233, 322, 359, 361, 366, 369, 370], "duplic": [3, 5, 322, 343, 351], "durat": [49, 350, 351], "dure": [206, 210, 225, 228, 286, 287, 290, 291, 323, 333, 335, 336, 337, 369, 374], "dx": [323, 329, 367, 369], "dx_": [331, 337], "dx_k": [355, 356, 360], "dynam": [340, 359], "e": [25, 46, 115, 144, 145, 164, 170, 171, 173, 192, 209, 211, 212, 213, 214, 215, 216, 217, 220, 223, 225, 227, 228, 229, 230, 231, 232, 233, 234, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 300, 307, 323, 324, 327, 328, 329, 331, 332, 333, 334, 335, 337, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 374], "e377c2": 52, "e_": 366, "eaaa4301": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "each": [30, 57, 58, 71, 72, 112, 114, 124, 125, 126, 144, 164, 181, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 237, 238, 239, 249, 255, 256, 259, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 303, 307, 318, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 335, 336, 337, 338, 339, 342, 353, 356, 357, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 375], "earli": [23, 132, 273, 274, 275, 276, 286, 287, 290, 291, 327, 366, 370], "early_stop_thr": [273, 274], "early_stopping_round": [9, 38, 39, 40, 53, 61, 62, 63], "eas": [340, 356], "easi": [362, 365, 371], "easier": [322, 324, 328, 346, 356], "easili": [324, 328, 373], "ebm": 319, "ecod": 324, "econom": 369, "eda": [316, 326, 341, 343], "eda_1d": [3, 326], "eda_2d": [3, 326, 344], "eda_3d": [3, 326, 345], "eda_correl": [3, 52, 326], "eda_multivari": 346, "eda_pca": [3, 326], "eda_umap": 3, "edg": [213, 215, 216, 217, 221, 229, 230, 232, 233, 367, 369], "edit": 353, "educ": [2, 3, 5, 7, 13, 19, 23, 25, 63, 67, 71, 79, 83, 303, 371], "education_1": 5, "education_2": 5, "education_3": 5, "education_missing_nan": 5, "eeoc": 365, "effect": [23, 24, 49, 57, 58, 222, 226, 235, 236, 237, 238, 240, 244, 246, 247, 248, 255, 273, 274, 286, 287, 324, 328, 330, 335, 336, 337, 339, 340, 348, 357, 358, 361, 365, 366, 367, 368, 369, 370, 371], "effect_import": [57, 58, 226, 367], "effici": [248, 324, 328, 340, 342, 350, 353, 356, 365, 368, 374], "effort": [340, 350], "eigenvalu": [324, 328], "eight": 324, "eighth": [324, 328], "either": [53, 120, 126, 144, 240, 246, 331, 338, 375], "elabor": 324, "elasticnet": [272, 358, 375], "electr": [324, 328], "eleg": 361, "element": [214, 229, 230, 231, 232, 233, 333, 336], "elimin": [132, 324, 327], "ell": 359, "ellipsi": 52, "embed": 225, "emerg": 361, "emil": 335, "emphas": [324, 328], "empir": [209, 220, 323, 364, 368, 369, 370], "emploi": [320, 323, 355, 359, 369], "employ": [365, 369], "empti": [307, 327, 368, 371], "enabl": [322, 325, 340, 342, 344, 345, 346, 347, 349, 350, 353, 356, 359, 360, 363, 367], "enable_categor": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "encapsul": [211, 212, 247, 254], "encod": [5, 121, 124, 125, 126, 226, 272, 283, 342, 353, 355, 356, 357, 358, 359, 360, 365, 371], "encode_categor": [5, 54, 322, 365, 371], "encount": [107, 307], "end": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 106, 323, 324, 329, 331, 332, 333, 334, 335, 337, 339, 355, 357, 360, 361, 365, 366, 368, 369], "end_tim": 49, "enforc": [355, 360, 365], "engin": [1, 11, 112, 126, 144, 164, 322, 324, 328, 367, 368, 369, 370, 379], "enhanc": [121, 324, 327, 340, 357, 358, 359, 361, 362, 366, 367, 368, 369, 370, 371], "enough": [355, 361], "ensembl": [12, 27, 48, 118, 247, 249, 255, 279, 280, 284, 285, 288, 289, 324, 328, 331, 332, 334, 339, 357, 360, 366, 367, 368, 369, 370, 379], "ensur": [124, 125, 132, 180, 212, 300, 322, 325, 340, 351, 355, 356, 358, 359, 360, 362, 365, 366, 367, 368, 369, 370, 371], "enter": [52, 325, 348, 350, 351], "enterpris": 340, "entir": [123, 235, 239, 300, 319, 320, 332, 337, 339, 355, 359, 360], "entropi": [367, 369], "envelop": [331, 333, 337], "environ": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 305, 306, 369], "epoch": [17, 18, 23, 24, 273, 274, 286, 287, 290, 291], "epsilon": 369, "equal": [112, 124, 209, 213, 215, 216, 217, 221, 229, 230, 231, 232, 233, 236, 238, 273, 274, 323, 329, 332, 339, 361, 365, 369, 371], "equat": [359, 361], "equit": 365, "equiv": 361, "equival": [286, 287, 327, 356, 361, 370], "eric": 327, "erion": [332, 339], "errat": 366, "error": [119, 211, 226, 227, 239, 324, 328, 347, 349, 356, 359, 364, 365, 367, 369, 370], "especi": [320, 365, 370], "essenti": [336, 356, 365, 367, 370], "establish": [358, 365, 369], "estim": [23, 24, 29, 31, 32, 33, 49, 213, 214, 217, 229, 230, 231, 232, 233, 239, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 320, 323, 324, 331, 332, 333, 337, 339, 367, 368, 376], "estimators_": [275, 276], "eta": [54, 301, 360, 361], "eta_k": 356, "etc": [136, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 286, 287, 290, 291, 333, 352], "ethic": 365, "ethnic": 365, "euclidean": [125, 324, 328, 359], "european": 324, "eval_metr": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "evalu": [8, 54, 57, 58, 61, 62, 71, 72, 114, 133, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 219, 220, 222, 223, 225, 227, 228, 230, 232, 233, 248, 277, 299, 300, 301, 302, 318, 319, 323, 327, 329, 331, 332, 336, 338, 339, 340, 347, 351, 352, 355, 359, 360, 364, 366, 368, 369, 370, 371, 374], "even": [324, 355, 359, 360, 361], "event": 52, "evolv": [340, 369], "exact": 301, "exactli": [332, 339], "examin": [226, 335, 367, 368, 369, 371], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 152, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 299, 300, 301, 302, 303, 317, 321, 330, 345, 354, 363, 364, 379], "exce": 236, "exceed": 133, "excel": 356, "except": [29, 339], "exchang": 368, "exclud": [210, 225, 333], "execut": [54, 106, 266, 299, 322, 340, 351, 365, 371, 379], "exhaust": 351, "exhibit": [229, 324, 361, 369], "exist": [107, 116, 135, 136, 139, 140, 142, 143, 153, 158, 165, 167, 305, 335, 353, 355, 356, 358, 362, 365], "exp": [49, 54, 319, 325, 335, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359], "expand": 305, "expect": [232, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 320, 324, 328, 332, 339, 347, 349, 366, 368], "expens": [368, 374], "experi": [49, 260, 322, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 369, 374], "experiment": [42, 47, 48, 300, 350, 379], "experiment_id": 49, "experiment_nam": 49, "expert": [12, 27, 48, 247, 248, 249, 255, 257, 259, 284, 285, 316, 340, 354, 366, 368, 369, 379], "expert_id": 259, "expert_nam": 359, "expert_no": 359, "expertis": 359, "explain": [88, 93, 119, 124, 226, 235, 236, 237, 238, 239, 240, 252, 316, 324, 326, 328, 333, 335, 336, 337, 338, 339, 340, 341, 355, 356, 361, 366, 367, 379], "explain_al": 86, "explain_hstatist": 86, "explain_lim": [32, 33, 87], "explain_pdp": [31, 86], "explain_pfi": [32, 33, 53, 86], "explain_shap": [31, 87], "explainableboostingclassifi": 319, "explan": [0, 32, 33, 235, 236, 237, 239, 240, 249, 251, 252, 253, 254, 255, 258, 317, 324, 330, 331, 333, 334, 335, 337, 338, 340, 356, 360, 373], "explicit": [213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 305], "explicitli": [325, 332, 339, 355, 360, 367], "explor": [0, 122, 299, 320, 340, 343, 344, 345, 352, 353, 374], "exploratori": [1, 11, 120, 121, 122, 123, 124, 125, 181, 316, 321, 340, 343, 344, 345, 346, 371, 379], "exponenti": 351, "export": 241, "expos": [369, 370], "express": [273, 274, 361, 367], "extend": [357, 358, 368], "extens": [340, 350], "extent": [323, 329, 365, 369], "extern": [93, 265, 340, 367, 369, 375], "extra": [0, 1, 11, 106, 107, 135, 138, 139, 140, 142, 158, 171, 320, 353, 379], "extract": [25, 30, 198, 246, 303, 361, 367, 369, 371, 373], "extrapol": [331, 333, 337, 356], "extrem": [236, 238, 361, 369], "f": [49, 323, 329, 331, 333, 334, 335, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "f1": [13, 15, 19, 21, 23, 25, 34, 43, 45, 46, 49, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 351, 367, 369, 374], "f9f633c8bacb": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "f_": [355, 356, 357, 359, 360, 366, 368, 369], "f_0": 356, "f_i": 360, "f_j": [324, 355, 356, 357, 359, 360], "f_k": [356, 359, 366], "f_m": [356, 357], "f_n": 369, "fabrizio": 324, "face": [227, 359, 370], "facilit": 359, "factor": [29, 117, 328, 332, 339, 355, 359, 360, 365, 368, 369], "fail": [106, 367, 370], "fair": [84, 93, 208, 213, 214, 216, 217, 220, 221, 222, 230, 316, 317, 340, 364, 371, 379], "fairli": [332, 339, 365], "fall": [320, 324, 357, 359, 368], "fals": [9, 14, 21, 22, 23, 24, 34, 35, 38, 39, 40, 44, 49, 52, 53, 54, 61, 62, 63, 64, 67, 68, 71, 72, 79, 80, 83, 87, 117, 119, 146, 160, 180, 187, 195, 199, 201, 206, 224, 234, 266, 273, 274, 275, 276, 277, 278, 286, 287, 290, 291, 307, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 360, 361, 365, 367], "familiar": [358, 362], "fanova": [243, 244, 340], "fanovaar": 367, "far": [324, 328, 331, 337, 369], "fast": [324, 327, 355], "faster": [210, 225, 331, 333, 337], "favor": 365, "favorable_label": [83, 208, 214, 220, 221, 222, 230, 365], "fbedk": 132, "fde725": 52, "feasibl": 366, "featur": [0, 1, 2, 3, 9, 10, 11, 16, 23, 24, 29, 30, 31, 32, 33, 34, 35, 40, 44, 49, 52, 54, 62, 63, 64, 71, 72, 75, 76, 79, 80, 83, 112, 114, 115, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 142, 144, 155, 164, 165, 166, 167, 168, 169, 170, 171, 174, 175, 180, 181, 193, 194, 208, 210, 212, 213, 214, 215, 216, 217, 220, 221, 222, 224, 225, 226, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 251, 252, 254, 255, 256, 257, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 303, 316, 318, 320, 321, 322, 323, 324, 326, 328, 330, 332, 333, 334, 335, 336, 337, 346, 347, 348, 349, 353, 356, 357, 358, 362, 367, 368, 369, 370, 371, 373, 376, 379], "feature1": [63, 67, 68, 71, 79, 80, 221], "feature2": [63, 67, 68, 71, 79, 80, 221], "feature_color": [3, 121, 122], "feature_exclud": 325, "feature_i": [3, 121, 122], "feature_import": [57, 58, 210, 225, 226, 252, 254, 367], "feature_nam": [2, 4, 13, 14, 23, 24, 30, 31, 32, 33, 49, 112, 114, 164, 213, 214, 215, 216, 217, 221, 229, 230, 231, 232, 233, 236, 252, 254, 272, 273, 274, 283, 286, 287, 303, 322, 355, 358, 361, 365, 376], "feature_name1": [273, 274], "feature_name2": [273, 274], "feature_names_categor": [5, 322], "feature_names_mix": [5, 322], "feature_names_numer": [5, 322, 356, 357, 359, 360, 366, 367, 368, 369, 370], "feature_names_out": [112, 126, 144, 164], "feature_select_corr": [4, 327], "feature_select_rcit": [4, 327], "feature_select_xgbpfi": [4, 327], "feature_typ": [2, 9, 13, 14, 21, 22, 38, 39, 40, 49, 53, 61, 62, 63, 166, 272, 273, 274, 283, 325, 356, 357, 358, 359, 360, 366, 367, 368, 369, 370], "feature_x": [3, 121, 122], "feature_z": [3, 122], "features_nam": 365, "featurescol": 30, "feedforward": [355, 361], "fei": [324, 328], "femal": 83, "fetch": [307, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "fetch_california_h": [31, 33, 376], "few": [331, 337], "fewer": [117, 118, 229, 230, 232, 233, 273, 274, 324, 365], "ff7f0e": 52, "fidx": [25, 112, 126, 144, 164], "field": [350, 351], "fig": [307, 318], "fignam": 52, "figsiz": [3, 38, 40, 43, 44, 45, 46, 52, 54, 63, 64, 68, 79, 80, 83, 307], "figur": [52, 63, 64, 307, 319, 361, 371], "file": [53, 149, 152, 153, 154, 163, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 353, 379], "file_nam": [53, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307], "filenam": [106, 307, 353], "fill": 353, "fill_valu": 144, "filter": [147, 153, 201, 202, 213, 214, 215, 216, 217, 218, 230, 246, 261, 262, 307], "final": [210, 225, 226, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 324, 327, 328, 331, 332, 333, 335, 338, 339, 342, 353, 356, 359, 361], "financ": 359, "find": [361, 368, 369, 374], "fine": [23, 24, 273, 274, 275, 276, 278, 286, 287, 340, 350, 355, 365], "finer": 235, "finit": [327, 368], "finland": 324, "first": [7, 114, 117, 119, 132, 212, 226, 273, 274, 286, 287, 300, 301, 302, 318, 320, 325, 327, 328, 331, 333, 334, 335, 336, 337, 338, 339, 343, 353, 356, 361, 368, 370, 373], "fit": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 118, 126, 144, 223, 226, 229, 230, 232, 233, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 324, 327, 328, 331, 332, 333, 334, 335, 336, 337, 339, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "fit_conform": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "fit_funct": [269, 292], "fit_intercept": [14, 44], "five": [332, 339], "fix": [323, 329, 331, 332, 333, 339, 351], "fl": [324, 328], "flag": [366, 368], "flagdefault": [2, 3, 5, 13, 15, 17, 19, 21, 23, 25, 57, 63, 83, 318, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "flat": 201, "flatten": [29, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "flexibl": [217, 277, 278, 325, 338, 340, 355, 356, 357, 360, 376], "float": [63, 71, 72, 75, 83, 117, 118, 119, 131, 132, 133, 144, 172, 180, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 225, 227, 228, 229, 230, 231, 232, 233, 236, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 307, 361], "float32": [17, 18], "fluctuat": [356, 370], "fn": 367, "fn_": 365, "fname": 106, "focu": [335, 359], "focus": [123, 319, 326, 365, 367, 369, 371], "fold": [284, 285, 299, 300, 301, 302, 367, 374], "folder": [305, 307], "follow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 224, 225, 226, 229, 230, 231, 232, 233, 247, 249, 251, 252, 253, 254, 255, 256, 299, 300, 301, 302, 303, 318, 319, 320, 322, 323, 324, 325, 327, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 344, 355, 356, 357, 359, 361, 365, 366, 367, 368, 369, 370, 371, 373, 376], "fontfamili": 52, "fontsiz": 52, "fontstyl": 52, "fontweight": 52, "footag": 356, "foral": 365, "forc": 374, "forest": [118, 210, 225, 321, 331, 338, 340, 356, 364, 367, 369, 374], "form": [135, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 355, 360, 361], "formal": 365, "format": [53, 112, 126, 136, 142, 143, 173, 201, 208, 213, 214, 215, 216, 217, 220, 222, 229, 230, 231, 232, 233, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 325, 373, 376], "former": [319, 332, 339], "formul": [354, 355, 357, 360, 368], "formula": [323, 324, 328, 331, 332, 333, 339, 365], "forward": [112, 132, 327], "found": [106, 318, 319, 320, 323, 324, 325, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 378], "foundat": 340, "four": [322, 326, 333, 347, 349, 353, 375], "fourier": [132, 327], "fourth": [122, 326], "fp": 367, "fp_": 365, "fpr": [365, 367], "frac": [323, 329, 331, 332, 333, 334, 337, 339, 355, 356, 359, 360, 365, 366, 367, 369], "fraction": [211, 227, 370], "frame": [29, 201], "framework": [226, 322, 340, 356, 357, 358, 359, 362, 367, 368, 371, 376], "free": 368, "frequenc": [213, 215, 216, 217, 221, 229, 230, 231, 232, 233, 322, 323, 324, 325, 344, 370], "frequent": [0, 144, 342], "friedman": [8, 330], "friedman2001": [331, 337], "friedman2008": [331, 334], "friendli": 340, "from": [3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 107, 114, 116, 123, 125, 149, 150, 151, 152, 154, 175, 209, 221, 227, 236, 246, 247, 255, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 303, 307, 318, 319, 320, 322, 323, 324, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 368, 369, 370, 371, 374, 375, 376, 379], "from_cod": 322, "fsc": 368, "full": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 119, 124, 133, 319, 323, 324, 325, 333, 334, 335, 336, 337, 339, 340, 344, 345, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 369, 370, 371], "fulli": [331, 338, 366], "func": [8, 52, 54, 117, 118, 119, 266, 307], "func_input": [54, 266], "function": [30, 52, 106, 112, 114, 117, 118, 119, 120, 122, 124, 125, 126, 133, 135, 136, 139, 140, 142, 143, 144, 164, 175, 180, 181, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 225, 226, 230, 232, 233, 235, 236, 238, 246, 249, 251, 252, 254, 255, 256, 266, 267, 269, 270, 273, 274, 275, 277, 279, 281, 283, 284, 286, 288, 290, 291, 292, 293, 295, 297, 307, 318, 319, 320, 322, 323, 324, 325, 326, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 354, 357, 358, 361, 366, 368, 369, 370], "further": [57, 58, 209, 211, 220, 223, 225, 227, 228, 303, 324, 327, 365, 368, 369, 371, 373], "furthermor": [320, 359], "futur": [338, 343, 344, 345, 346, 351, 373], "g": [25, 46, 115, 144, 145, 164, 170, 171, 173, 192, 209, 211, 212, 213, 214, 215, 216, 217, 220, 223, 225, 227, 228, 229, 230, 231, 232, 233, 234, 300, 307, 323, 324, 327, 329, 332, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 358, 359, 360, 365, 366, 367, 368, 369, 370, 374], "g_": 359, "g_n": 369, "gabl": [324, 328], "gabriel": [332, 339], "gain": [367, 369], "galleri": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 89, 379], "galleries_data": 379, "galleries_dev": 379, "galleries_util": 379, "galleries_v": 379, "gam": [273, 274, 355, 356], "gam_sample_s": [273, 274], "game": [332, 339], "gami": [273, 274, 316, 340, 354, 356, 357, 359, 360], "gaminet": [12, 27, 48, 247, 249, 255, 274, 355, 379], "gaminetclassifi": 273, "gamma": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63, 327, 355, 360], "gamma_m": 356, "gap": [9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 31, 34, 35, 38, 43, 44, 45, 46, 61, 62, 67, 68, 207, 215, 216, 219, 231, 318, 320, 348, 352, 364], "gate": [284, 285], "gaussian": [117, 210, 212, 225, 228, 300, 324, 327, 328, 347, 349], "gbdt": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 354, 367, 370], "gbdt2": 49, "gblt": 354, "gbm": [209, 232], "gender": [54, 83, 208, 220, 319, 322, 329, 343, 353, 365], "gener": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 89, 93, 112, 118, 120, 121, 122, 125, 126, 132, 180, 181, 210, 212, 219, 223, 225, 235, 237, 238, 240, 247, 250, 251, 252, 253, 254, 258, 273, 274, 278, 284, 285, 290, 291, 299, 300, 301, 302, 307, 316, 318, 320, 323, 326, 331, 333, 334, 335, 336, 337, 338, 339, 340, 344, 354, 355, 356, 359, 361, 362, 364, 365, 367, 368, 369, 370], "georg": 324, "geq": 368, "get": [2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 110, 111, 127, 128, 129, 130, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 153, 155, 157, 162, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 232, 233, 234, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 322, 333, 334, 336, 339, 367, 371], "get_data": 10, "get_data_info": [0, 63, 64, 67, 68, 71, 72, 79, 80, 83, 366, 370, 371], "get_data_list": [10, 135, 136, 139, 140, 142, 143], "get_figure_nam": [53, 63, 64, 307, 371], "get_mlflow_hom": [0, 49], "get_model": [49, 374, 375], "get_param": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "get_x_y_data": 136, "getorcr": 30, "gg": 366, "gini": 15, "giorgo": 327, "github": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "give": [133, 235, 239, 273, 274, 305, 324, 328, 338], "given": [135, 136, 139, 140, 142, 143, 151, 252, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 302, 307, 324, 327, 328, 329, 332, 336, 339, 356, 359, 361, 367, 368, 374], "glm": [13, 14, 44, 286, 287, 319, 320, 336, 340, 354, 361], "glmclassifi": 319, "glmt": 357, "glmtree": [275, 276, 286, 287], "global": [17, 18, 85, 88, 89, 125, 235, 236, 238, 239, 249, 250, 253, 316, 330, 337, 354, 361, 366, 368, 369, 379], "global_fi": 361, "global_ic": 335, "glossari": [301, 302], "gmm": 117, "go": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "goal": [324, 327, 332, 339, 365, 370, 374], "goldstein": [324, 335], "goldstein2012": 324, "good": [303, 356, 361, 367, 368], "googl": 93, "gp": 300, "gpsampler": 300, "gradient": [23, 24, 122, 216, 223, 268, 271, 272, 274, 275, 276, 278, 280, 282, 285, 287, 289, 290, 291, 292, 294, 296, 298, 316, 331, 344, 345, 354, 355, 359, 360, 361, 367, 370, 373], "gradientboostingclassifi": 279, "gradientboostingregressor": 280, "gradual": [355, 360, 366, 369], "grain": [275, 276, 278, 365], "grant": 365, "granular": [112, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 235, 365], "graphic": [52, 246, 335, 340], "greater": [236, 273, 274, 318, 324, 325, 327, 335], "greatest": [339, 369], "greatli": [332, 336, 339], "greedi": 331, "grid": [42, 46, 47, 48, 52, 222, 235, 236, 238, 247, 248, 275, 276, 277, 299, 300, 333, 334, 335, 337, 351, 379], "grid_resolut": [86, 235, 236, 238], "grid_siz": [247, 248, 333, 334, 335, 337], "gridsampl": 300, "gridsearchcv": 374, "ground": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 376], "group": [79, 80, 83, 115, 173, 208, 211, 214, 220, 221, 222, 227, 228, 230, 252, 259, 319, 336, 361, 364, 367, 369], "group_config": [83, 208, 214, 220, 221, 222, 230, 365], "group_nam": [208, 214, 220, 221, 222, 230], "grow": 366, "grow_polici": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "gt": [357, 360, 368], "guarante": [332, 339, 356, 365, 368], "guestrin": 332, "guid": [342, 361, 366, 371], "guidelin": 365, "guo": 327, "h": [236, 324, 330, 333, 340, 366], "h2o": [28, 36, 48, 376, 379], "h2o_model": 29, "h2ofram": 29, "h2ogradientboostingestim": 29, "h_": [331, 334, 355], "h_j": 355, "h_m": [356, 357], "ha": [5, 226, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 318, 320, 323, 324, 327, 328, 329, 333, 336, 339, 355, 357, 360, 361, 370], "had": 339, "hand": [331, 333], "handl": [52, 122, 124, 125, 144, 274, 307, 324, 327, 328, 355, 356, 357, 366, 368, 369, 371], "hao": 327, "happen": 376, "hard": [75, 76, 211, 227, 347, 349, 360, 361, 369], "harder": 236, "hardest": 369, "hardwar": [273, 274], "harmon": 367, "hat": [318, 327, 331, 333, 334, 335, 337, 355, 359, 360, 365, 366, 367, 368], "have": [46, 107, 123, 152, 170, 171, 173, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 320, 324, 325, 326, 328, 331, 332, 333, 334, 335, 337, 338, 339, 355, 356, 357, 358, 360, 361, 365, 366, 369, 370, 373, 376], "hbo": 324, "he": [324, 328], "he2003": [324, 328], "head": [5, 322], "header": 342, "healthcar": [359, 365], "heatmap": [52, 123, 132, 235, 238, 247, 248, 321, 333, 337, 346, 355], "heavi": 333, "heavili": 366, "height": [38, 40, 52, 307], "help": [219, 221, 222, 224, 227, 228, 231, 327, 331, 332, 337, 339, 346, 347, 358, 361, 365, 366, 367, 369, 370, 371], "helsinki": 324, "henc": [318, 361], "here": [5, 318, 320, 323, 324, 327, 329, 331, 333, 335, 337, 338, 359, 373], "here_": 331, "hered": [273, 274, 355], "heterogen": [359, 368, 369, 371], "heteroscedast": [224, 367, 368], "hidden": [273, 274, 290, 291, 361, 374], "hidden_layer_s": [290, 291, 361, 376], "hidedelai": 52, "hierarch": [362, 367], "high": [236, 318, 320, 323, 324, 327, 328, 331, 333, 334, 335, 336, 337, 338, 339, 340, 343, 346, 347, 353, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "higher": [117, 118, 133, 208, 220, 221, 222, 226, 235, 239, 247, 319, 320, 323, 324, 328, 337, 355, 356, 357, 358, 359, 360, 366, 368], "highest": [325, 333, 339, 356], "highli": [331, 333, 337, 339, 356], "highlight": [258, 324, 346, 347, 359, 362, 366, 367, 369, 371], "hire": 365, "hist": 301, "histogram": [3, 117, 118, 119, 120, 326, 343, 367, 368, 369], "histori": [290, 291, 299, 300, 301, 302], "hoc": [0, 85, 89, 327, 338, 340, 348], "hold": [295, 296, 323, 355, 360, 367], "holder": [355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "holdout": 366, "holidai": [4, 8, 9, 10, 52, 64, 86, 338], "home": [304, 305, 306, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "homogen": [324, 359], "homoscedast": 367, "honest": 368, "horizont": [52, 114, 131, 133, 236, 237, 239, 240, 246, 249, 255, 256], "hot": [126, 226, 272, 283, 322, 355, 356, 357, 358, 359, 360], "hour": 333, "hourli": [320, 333, 334, 335, 336, 337, 338, 339], "hous": [31, 32, 33, 373, 375], "hover": [344, 345, 351], "hoverlink": 52, "how": [49, 53, 54, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 210, 217, 222, 225, 226, 227, 228, 235, 236, 238, 247, 318, 320, 323, 324, 325, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 347, 348, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 373], "howev": [319, 320, 324, 328, 331, 332, 335, 336, 337, 338, 339, 361, 365], "hpo": [43, 44, 45, 374], "hr": [4, 8, 9, 10, 14, 18, 20, 22, 24, 26, 52, 58, 64, 68, 72, 76, 80, 86, 320, 333, 335, 336, 337, 338, 339, 355, 356, 357, 359, 360, 366, 367, 368, 369, 370], "hstack": 40, "hstat": 330, "html": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 241, 307], "htmlstr": [38, 40], "http": 29, "httpx": 107, "hu": 324, "hua": [324, 328], "hub": [316, 341], "hum": [4, 8, 9, 10, 24, 52, 64, 68, 72, 80, 86, 336, 339, 359, 370], "hyperparamet": [0, 93, 226, 269, 292, 299, 300, 301, 302, 340, 350, 351, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 374], "hypothesi": 327, "i": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 106, 107, 112, 117, 118, 119, 120, 121, 122, 123, 124, 126, 136, 139, 140, 142, 144, 146, 153, 160, 164, 180, 199, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 248, 249, 251, 255, 256, 257, 259, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 305, 306, 307, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 373, 374, 375, 376], "i_1": [355, 356, 360], "i_j": 339, "i_t": [355, 356, 360], "i_u": [355, 356, 360], "icdm": [324, 328], "icon": 350, "id": [29, 49, 52, 163, 204, 218, 225, 257, 262, 263, 277, 303, 362, 367, 368, 369, 370], "id_": 52, "idea": [324, 368, 369], "ideal": [344, 345, 370], "ident": [323, 361], "identif": [215, 340, 364, 367], "identifi": [114, 117, 118, 119, 132, 211, 215, 219, 222, 224, 227, 228, 229, 231, 232, 233, 267, 268, 270, 271, 272, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 297, 298, 324, 327, 328, 335, 339, 340, 346, 347, 349, 355, 356, 357, 358, 359, 360, 361, 364, 365, 367, 368, 369, 370, 371], "idx": [40, 329], "ieee": [324, 328], "ignor": [52, 224, 227, 332, 339], "ij": 359, "ik": 359, "ikj": 359, "illustr": [238, 252, 318, 320, 332, 333, 335, 337, 339, 370, 373], "iloc": [5, 10, 83], "im": 356, "imag": [53, 307, 344, 345], "imbal": 367, "imbalanc": 367, "imlbook": 339, "impact": [83, 208, 220, 221, 222, 319, 323, 324, 328, 331, 333, 339, 355, 356, 357, 358, 359, 360, 364, 366, 367, 369, 374], "implement": [118, 119, 132, 265, 290, 291, 300, 324, 327, 328, 332, 335, 336, 356, 358, 361, 362, 370, 374], "impli": [319, 361, 366], "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16, 23, 24, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 87, 107, 131, 132, 133, 210, 225, 226, 237, 238, 239, 247, 249, 251, 252, 254, 255, 256, 273, 274, 318, 319, 320, 321, 322, 324, 330, 334, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 362, 365, 366, 367, 368, 369, 370, 374, 375, 376], "import_fil": 29, "importance_typ": [9, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "impos": [273, 274], "improv": [224, 239, 275, 276, 286, 287, 290, 291, 324, 340, 352, 356, 357, 359, 365, 366, 367, 368, 369, 370, 371], "impur": [275, 276, 277, 278], "imput": [5, 144, 322, 342, 353], "impute_miss": [5, 54, 322], "inaccur": [331, 337], "inact": [165, 167, 365, 371], "inactive_featur": 54, "inch": 307, "includ": [25, 26, 111, 120, 121, 123, 124, 125, 133, 136, 144, 148, 176, 180, 182, 208, 209, 210, 223, 225, 227, 228, 229, 230, 231, 237, 251, 253, 254, 272, 273, 274, 283, 300, 301, 318, 320, 322, 323, 324, 325, 327, 331, 337, 342, 343, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 362, 365, 366, 370, 374], "include_interaction_list": [273, 274], "incom": [355, 356, 360, 365, 369, 370], "inconsist": [331, 337, 369], "incorpor": [355, 368, 369, 370], "incorrect": [367, 371], "increas": [118, 123, 133, 235, 239, 247, 273, 274, 286, 287, 320, 323, 324, 326, 327, 331, 332, 335, 338, 339, 347, 355, 356, 360, 361, 365, 369, 370], "increasingli": 227, "increment": 370, "independ": [132, 235, 236, 321, 324, 328, 331, 332, 337, 339, 340, 356, 366], "index": [8, 30, 112, 114, 126, 136, 144, 164, 237, 240, 255, 256, 257, 258, 273, 274, 323, 329, 331, 333, 336, 339, 340, 348, 356, 360, 361, 367, 369], "indic": [5, 114, 123, 144, 146, 177, 178, 180, 208, 209, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 239, 247, 252, 259, 277, 284, 285, 299, 300, 301, 302, 318, 319, 322, 323, 324, 326, 328, 329, 331, 332, 333, 335, 337, 338, 339, 350, 351, 355, 356, 357, 358, 359, 360, 361, 365, 367, 368, 369, 370, 376], "indicatorimput": 144, "indicators": 52, "individu": [235, 236, 273, 274, 324, 331, 332, 333, 336, 338, 339, 344, 348, 358, 370, 375], "inf": [3, 5, 25, 322], "infer": [175, 273, 274, 327], "infinit": [3, 5, 322, 343], "influenc": [235, 247, 319, 331, 338, 355, 356, 357, 358, 359, 360], "info": 153, "inform": [25, 132, 164, 208, 213, 215, 216, 217, 220, 225, 227, 228, 230, 240, 303, 318, 324, 325, 332, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "infrastructur": 340, "infti": 369, "inher": [0, 211, 227, 340, 348, 355, 356, 357, 359, 360, 361, 365, 368, 370, 373], "init": [29, 273, 274], "initi": [15, 23, 24, 29, 30, 273, 274, 275, 276, 277, 278, 286, 287, 322, 327, 341, 350, 356, 357, 359, 360], "inject": 370, "innat": [123, 326], "input": [29, 52, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 266, 267, 269, 270, 273, 274, 275, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 292, 293, 295, 297, 299, 300, 301, 302, 307, 318, 320, 331, 332, 333, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 371, 376], "inputcol": 30, "inquiri": 322, "insight": [209, 233, 256, 324, 338, 340, 343, 348, 349, 352, 357, 359, 366, 367, 369, 371], "insignific": 327, "inspect": 353, "inspir": [332, 339, 374], "instal": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "instanc": [53, 144, 222, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 322, 324, 325, 328, 332, 335, 336, 339, 368, 369, 370], "instead": [119, 136, 318, 320, 325, 331, 332, 333, 334, 335, 337, 339, 367], "institut": 327, "insuffici": [365, 367], "insur": 365, "int": [30, 45, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 131, 132, 133, 144, 153, 164, 172, 177, 178, 180, 202, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 247, 248, 252, 255, 256, 257, 258, 268, 271, 272, 273, 274, 275, 276, 277, 278, 280, 282, 284, 285, 286, 287, 289, 290, 291, 292, 294, 296, 298, 299, 300, 301, 302, 307, 323, 329, 331, 337, 355, 356, 360, 369], "int_": [367, 369], "integ": [124, 125, 126, 144, 290, 291, 299, 300, 301, 302], "integr": [324, 331, 336, 337, 340, 342, 359, 361, 363, 374, 376], "intend": 367, "interact": [64, 71, 72, 122, 229, 230, 231, 232, 233, 235, 236, 238, 243, 247, 248, 273, 274, 324, 326, 331, 332, 333, 334, 335, 337, 339, 340, 344, 345, 346, 352, 355, 357, 359, 360, 366, 367, 368, 369, 370, 371], "interact_num": [273, 274], "interaction_constraint": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "interaction_list_": [273, 274], "interaction_val_loss_": [273, 274], "intercept": [336, 355, 356, 360, 361], "interest": [246, 318, 320, 324, 331, 333, 335, 336, 337, 349], "interfac": [340, 343, 356, 358, 362], "intern": [112, 158, 278, 286, 287, 324, 328, 332], "interpret": [0, 93, 236, 237, 275, 276, 277, 278, 286, 287, 316, 324, 327, 330, 331, 333, 340, 348, 365, 368, 370, 371, 373, 375], "interpret_cluster_analysi": 259, "interpret_coef": [13, 14, 358], "interpret_effect": [13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 49, 57, 58, 355, 356, 357, 359, 360, 367], "interpret_ei": [21, 22, 25, 26, 249, 355, 356, 357, 359, 360], "interpret_fi": [13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 49, 355, 356, 357, 358, 359, 360, 361], "interpret_fi_loc": 255, "interpret_glm_coef": 246, "interpret_global_tre": [15, 16, 362], "interpret_llm_pc": [17, 18, 361], "interpret_llm_profil": [17, 18, 361], "interpret_llm_summari": [17, 18, 361], "interpret_local_ei": [19, 20, 21, 22, 25, 26, 355, 356, 357, 359, 360], "interpret_local_fi": [13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 57, 58, 355, 356, 357, 358, 359, 360, 367], "interpret_local_linear_fi": [13, 14, 17, 18, 358], "interpret_local_moe_weight": [21, 22, 359], "interpret_local_tre": [15, 16, 362], "interpret_moe_cluster_analysi": [21, 22, 359], "interpret_tree_glob": 250, "interpret_tree_loc": 258, "interv": [37, 41, 48, 52, 209, 210, 211, 216, 223, 225, 232, 235, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 320, 331, 333, 347, 349, 352, 356, 368, 370, 371, 379], "interven": [332, 339], "intervent": [332, 339, 367], "intric": 319, "introduc": [322, 324, 332, 339, 357, 361, 365, 368, 369, 370, 375], "introduct": [316, 364], "intuit": [340, 343], "invalid": [307, 351], "invers": [52, 112, 358, 370], "investig": [365, 367, 368, 369, 370], "involv": [131, 318, 320, 322, 324, 325, 331, 338, 365, 368, 369, 374], "ioanni": 327, "ionescu": 324, "ipynb": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "ipython": [38, 40, 107], "ipyvuetifi": 107, "ipywidget": 107, "iri": 322, "irisdata": 322, "irreduc": 366, "isol": [118, 321, 340, 371], "isolationforest": [324, 328], "isoton": [38, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297], "issu": [107, 116, 219, 227, 273, 274, 320, 352, 355, 356, 357, 358, 360, 361, 364, 366, 367, 369], "itali": [324, 328], "item": [52, 164, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 225, 227, 228, 230, 259], "itemgap": 52, "itemheight": 52, "items": 52, "itemwidth": 52, "iter": [23, 24, 132, 133, 273, 274, 275, 276, 284, 285, 299, 300, 301, 302, 324, 331, 338, 351, 356, 357, 359, 361, 366, 374], "its": [107, 181, 195, 217, 222, 225, 227, 233, 238, 239, 273, 274, 320, 324, 328, 332, 333, 334, 335, 336, 337, 338, 339, 343, 348, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 375], "itself": [295, 296, 336], "j": [123, 323, 324, 326, 327, 331, 332, 333, 334, 339, 355, 356, 357, 359, 360, 366], "j_1": [355, 356, 360], "j_i": 360, "j_v": [355, 356, 360], "janz": 327, "jerom": [331, 334], "jingyu": 331, "jiuyong": 327, "jk": [331, 334, 355, 356, 357, 360], "job": [299, 300, 301, 302], "joblib": [299, 300, 301, 302], "john": 324, "joint": [236, 337], "jona": 327, "journal": [327, 331, 335], "jpg": 307, "jsd": 369, "jth": 324, "judgment": 336, "jupyt": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 340], "just": [331, 332, 333, 339], "justin": 335, "k": [75, 76, 114, 117, 208, 220, 284, 285, 323, 327, 328, 329, 331, 333, 334, 338, 355, 356, 357, 359, 360, 366, 367, 369, 370], "k_": [331, 333], "kai": [324, 328], "kanoksri": [324, 328], "kapeln": 335, "keep": [331, 333, 338, 361], "kei": [0, 49, 52, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 299, 300, 301, 302, 307, 316, 322, 324, 331, 337, 347, 349, 350, 351, 358, 359, 365, 366, 367, 368, 369, 370, 374], "kendal": [3, 123, 326], "kept": 370, "kernel": [240, 324, 327, 332, 339, 374], "keyword": [149, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298, 318, 320, 324, 333, 334, 336, 337, 339, 361], "kfold": [300, 301, 302], "ki": 324, "kj": [331, 334], "kl": [323, 329], "kmean": [8, 117, 369], "kmedoid": [210, 225], "knn": 324, "know": [316, 332, 339], "knowledg": [324, 332, 355, 356, 358, 360, 362, 366, 368, 369, 370], "known": [324, 356, 361, 367], "kolmogorov": [114, 323, 329], "ks_2samp": [323, 329], "kui": 327, "kullback": [323, 329], "kun": 327, "kwarg": [149, 267, 268, 269, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 292, 297, 298], "kyuseok": 324, "l": [323, 329, 331, 338, 355, 356, 357, 359, 360, 361, 366], "l1": [275, 276, 277, 278, 290, 291, 358, 361, 366, 370], "l1_ratio": [14, 44, 358, 375], "l1_reg": [290, 291, 361], "l2": [226, 358, 366, 370], "l2001": [331, 338], "l_": [355, 356, 360, 366, 368, 369, 370], "lab": 367, "label": [30, 40, 52, 114, 208, 214, 220, 221, 222, 224, 225, 230, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 303, 318, 344, 345, 366, 367], "labelcol": 30, "lack": [361, 368, 371], "lambda": [355, 366, 368, 369, 370], "lambda_": [324, 328], "lambda_1": [366, 370], "lambda_2": [366, 370], "lambda_i": 327, "land": 367, "larg": [79, 80, 117, 120, 122, 123, 125, 228, 273, 274, 324, 327, 328, 332, 336, 339, 346, 355, 356, 360, 361, 366, 367], "larger": [122, 125, 208, 214, 220, 221, 222, 224, 227, 230, 239, 273, 274, 320, 324, 328, 331, 333, 334, 335, 337, 338, 339, 355, 360, 361, 366], "largest": [223, 318, 320, 324, 336, 361, 365, 370], "lasso": [332, 336, 366, 370], "last": [273, 274, 318, 323, 327, 331, 333, 342, 373], "latent": 369, "later": 375, "latest": [2, 49, 153], "latter": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 332, 339], "layer": [273, 274, 290, 291, 359, 361, 374], "ldot": [332, 339, 361], "lead": [236, 320, 323, 331, 333, 336, 355, 356, 359, 360, 365, 368, 369, 370], "leaderboard": [316, 350, 351, 352, 363], "leaf": [275, 276, 277, 278, 332, 339, 355, 356, 357, 360, 367], "leaf_estimators_": 277, "learn": [107, 126, 238, 269, 273, 274, 286, 287, 292, 293, 294, 317, 319, 320, 323, 324, 327, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 348, 350, 351, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 369, 371, 373, 374, 376], "learner": [356, 357], "learning_r": [9, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 275, 276, 290, 291, 350, 361, 374], "least": [355, 361, 368, 369], "leav": [277, 278, 324, 357], "lee": [332, 339], "left": [52, 319, 324, 327, 331, 332, 334, 339, 356, 359, 360, 365, 367], "legal": 365, "legend": [52, 318], "legendhoverlink": 52, "legitim": 365, "leibler": [323, 329], "len": [34, 35, 366], "length": [52, 170, 171, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298, 324, 328, 361], "leq": [355, 356, 357, 360, 366], "less": [208, 220, 221, 320, 325, 331, 332, 333, 335, 337, 339, 359, 366, 368, 369, 370], "let": [331, 333, 335, 361, 370], "letter": [324, 328], "level": [79, 208, 210, 212, 216, 220, 223, 225, 228, 230, 233, 278, 319, 324, 327, 339, 343, 347, 349, 355, 356, 357, 358, 359, 360, 365, 366, 368, 369, 370], "leverag": [322, 324, 340, 358, 362, 365, 367, 369], "lgbm": [31, 32, 33, 43, 45, 46, 49, 54, 57, 58, 63, 86, 87, 273, 274], "lgbm2": 49, "lgbm_model": [356, 365, 366, 367, 368, 369, 370, 371], "lgbmclassifi": [32, 49, 281], "lgbmclassifierlgbmclassifi": 32, "lgbmregressor": [31, 33, 209, 282], "lgbmregressorlgbmregressor": [31, 33], "lgmb": [49, 54], "li": [324, 327], "li2021": 324, "librari": [52, 122, 300, 307, 340, 356], "licenc": [5, 9, 10, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 54, 83], "lie": 369, "lifecycl": 340, "light": 333, "lighter": 333, "lightgbm": [31, 32, 33, 49, 107, 281, 282, 350, 351, 356, 365, 366, 367, 368, 369, 370, 371], "lightweight": [267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 288, 289, 297, 298], "like": [122, 173, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 319, 324, 328, 333, 340, 351, 353, 361, 365, 367, 368, 369, 370], "lime": [32, 33, 107, 237, 330, 340, 348], "limit": [164, 320, 331, 333, 337, 361, 365, 368], "limit_b": [2, 3, 5, 25, 63, 371], "limit_bal_special_sv1": 5, "limits_": 355, "lin": 327, "lindsai": 327, "lindsayl2000": 327, "line": [106, 107, 121, 133, 211, 213, 214, 215, 216, 217, 221, 222, 223, 227, 235, 238, 247, 248, 320, 324, 333, 335, 337, 344, 351, 355, 361], "linear": [12, 27, 48, 123, 226, 246, 247, 249, 251, 255, 256, 275, 276, 278, 316, 326, 327, 331, 332, 336, 337, 339, 351, 354, 359, 360, 367, 370, 374, 379], "linear_model": [272, 283, 358], "linear_tre": [23, 24, 54], "linearshap": 339, "lineartre": 370, "lineplot": 40, "ling": [324, 327, 328], "link": [52, 319, 323, 324, 325, 349, 353, 358, 360, 365, 371], "link_id": 52, "linspac": 374, "lipschitz": 366, "list": [5, 49, 63, 64, 110, 111, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 137, 138, 144, 147, 164, 165, 167, 200, 201, 202, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 243, 244, 246, 248, 249, 252, 254, 255, 256, 261, 267, 268, 270, 271, 272, 273, 274, 275, 276, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 297, 298, 299, 300, 301, 302, 303, 307, 320, 322, 325, 334, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374], "list_registered_data": [2, 322], "list_registered_model": 49, "liu": [324, 327, 328], "liu2008": [324, 328], "liwu": [324, 328], "ll": 339, "llm": [251, 252, 253, 254, 354], "llm_pc": 251, "llm_profil": 252, "llm_summari": 253, "llm_violin": 254, "ln": [323, 329], "load": [0, 3, 4, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 124, 149, 150, 151, 152, 153, 154, 218, 262, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 321, 325, 326, 342, 347, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "load_breast_canc": [30, 32], "load_builtin_data": [5, 10, 83], "load_csv": 322, "load_data": 54, "load_datafram": [5, 9, 10, 29, 30, 31, 32, 33, 34, 35, 83, 322, 376], "load_iri": 322, "load_registered_data": [2, 9, 34, 35], "load_registered_model": 49, "load_spark": 322, "loaded_model": 49, "loan": [365, 370], "local": [23, 24, 32, 33, 57, 58, 85, 88, 89, 117, 125, 235, 237, 240, 251, 252, 253, 255, 256, 258, 316, 328, 330, 337, 339, 340, 354, 367, 368, 369, 370, 371, 379], "local_fi": 361, "local_linear_fi": 361, "local_model_zoo": 49, "localdataset": 264, "localgap": 366, "localmodelzoo": 49, "locat": [349, 353, 371], "lock": [342, 351], "log": [273, 274, 324, 331, 333, 334, 335, 337, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "log1p": [5, 14, 16, 18, 20, 22, 24, 26, 40, 44, 58, 62, 64, 68, 72, 76, 80, 86, 164, 322, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370], "logarithm": [164, 351], "logbas": 52, "logic": [348, 355, 356, 360], "logist": [12, 27, 38, 39, 48, 53, 61, 63, 246, 247, 249, 255, 256, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 358, 379], "logisticregress": [30, 283, 358], "logit": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297], "logit_predict": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297], "logloss": [13, 15, 19, 21, 23, 25, 34, 38, 43, 45, 46, 49, 54, 61, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 318, 351, 374], "logloss_rank": [43, 45, 46], "long": [346, 361], "longer": [323, 324, 328], "look": 367, "lose": 365, "loss": [17, 18, 23, 24, 232, 273, 274, 275, 276, 290, 291, 331, 338, 356, 359, 365, 366, 367, 368, 369, 370], "loss_threshold": [273, 274], "lot": [332, 339], "low": [40, 93, 229, 316, 339, 340, 365, 366, 368, 369], "lower": [83, 208, 214, 220, 221, 222, 230, 236, 238, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 319, 320, 324, 335, 356, 365, 367, 368, 369], "lower_inclus": [83, 208, 214, 220, 221, 222, 230, 365], "lowest": [320, 359], "lpb": 327, "lr": [30, 49], "lr_model": 30, "lt": [355, 356, 357, 360], "lundberg": [332, 339], "lundberg2017": [332, 339], "lundberg2018": [332, 339], "m": [323, 332, 339, 355, 356, 357, 360, 367, 369], "machin": [107, 126, 238, 317, 319, 320, 323, 324, 327, 331, 332, 333, 334, 335, 336, 337, 338, 339, 342, 348, 350, 351, 362, 364, 365, 366, 367, 371, 373, 374, 376], "made": [323, 356], "mae": [9, 14, 16, 20, 22, 24, 26, 31, 35, 44, 58, 62, 64, 68, 80, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 320, 350, 351, 352, 366, 367, 368, 369, 370, 374], "magnitud": [210, 212, 217, 225, 228, 355, 356, 357, 358, 360, 361, 366, 369, 370], "mahalanobi": [119, 324, 328, 369], "mai": [25, 26, 107, 175, 215, 229, 230, 232, 233, 235, 301, 322, 323, 324, 327, 329, 331, 332, 333, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 376], "main": [3, 6, 8, 9, 10, 23, 24, 34, 35, 52, 57, 58, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 244, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 273, 274, 299, 300, 301, 302, 329, 333, 340, 343, 344, 345, 346, 353, 355, 357, 359, 360, 368, 370], "main_effect_val_loss_": [273, 274], "mainli": 336, "maintain": [227, 275, 276, 340, 355, 356, 358, 359, 360, 362, 366, 369, 371], "major": 324, "make": [238, 250, 273, 274, 292, 322, 324, 328, 332, 335, 336, 338, 346, 348, 352, 355, 356, 359, 360, 361, 362, 365, 367, 368, 370, 371], "make_classif": 34, "make_friedman1": [8, 35], "male": 83, "manag": [0, 49, 322, 340, 363], "manhattan": 125, "mani": [125, 324, 331, 333, 346, 355, 356, 359, 360, 365, 369], "manifest": 323, "manifold": 346, "manner": [180, 363], "manual": [5, 112, 135, 136, 139, 140, 142, 143, 175, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 325], "map": [54, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 367, 370], "map_rang": 52, "marco": 332, "margin": [52, 238, 273, 274, 329, 332, 336, 339, 352, 355, 356, 357, 358, 359, 360, 361, 368, 369], "mark": [223, 320, 324, 361], "market": 359, "markov": 327, "marku": 324, "marriag": [2, 3, 5, 25, 63, 83, 365, 371], "marriage_1": 2, "marriage_2": 2, "match": 347, "math": 356, "mathbb": [331, 337, 355, 359, 360, 361, 368, 369], "mathbf": [355, 356, 360], "mathcal": [359, 370], "mathemat": [327, 354, 368], "mathrm": [323, 327, 331, 335, 337, 357, 360], "matplotlib": 39, "matric": [123, 367], "matrix": [61, 123, 210, 219, 225, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 324, 328, 333, 356, 361, 367, 369], "max": [3, 5, 52, 164, 273, 274, 278, 301, 324, 325, 351, 352, 355, 360, 361, 365, 367, 368, 370], "max_": [52, 369], "max_bin": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63, 112, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233], "max_cat_threshold": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "max_cat_to_onehot": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "max_delta_step": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "max_depth": [9, 15, 16, 21, 22, 23, 24, 25, 26, 34, 35, 38, 39, 40, 43, 45, 46, 49, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 209, 216, 223, 226, 232, 268, 271, 272, 274, 275, 276, 277, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 301, 350, 353, 356, 357, 359, 362, 365, 366, 367, 368, 369, 370, 371, 375], "max_epoch": [17, 18, 23, 24, 273, 274, 290, 291, 355], "max_featur": [15, 16], "max_it": [14, 44], "max_iter_per_epoch": [273, 274], "max_leaf_nod": [15, 16], "max_leav": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "maxim": 374, "maximum": [107, 112, 121, 122, 209, 210, 213, 214, 215, 216, 217, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 239, 248, 268, 271, 272, 274, 275, 276, 277, 278, 280, 282, 285, 286, 287, 289, 290, 291, 292, 294, 296, 298, 322, 323, 324, 325, 328, 329, 343, 356, 359, 369, 370, 371], "maxopac": 52, "mb": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90, 379], "mbox": 361, "mc": [38, 40], "md": [324, 328], "mean": [3, 5, 17, 18, 75, 76, 117, 126, 144, 164, 208, 214, 220, 221, 222, 230, 236, 237, 253, 255, 256, 273, 274, 300, 301, 302, 322, 324, 325, 328, 331, 332, 333, 336, 338, 339, 342, 343, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370], "mean_fit_tim": [45, 46], "meaning": [324, 367, 371], "measur": [123, 181, 217, 228, 235, 236, 237, 239, 240, 323, 324, 326, 327, 328, 329, 331, 334, 338, 364, 365, 368, 370, 371], "mechan": 367, "medhousev": [355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 376], "median": [3, 5, 144, 322, 324, 325, 342, 343, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "medic": [355, 360], "medinc": [31, 209, 211, 212, 220, 223, 225, 227, 228], "medium": 365, "medoid": 369, "meet": [340, 348, 367], "mei": [324, 328], "mem": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90, 379], "member": [332, 339], "membership": [208, 214, 220, 221, 222, 223, 230, 359, 367], "memori": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "mention": 324, "menu": 340, "mere": [332, 339], "met": 324, "meta": [153, 325], "metadata": 353, "metaheurist": 374, "metamodel": [211, 227], "method": [3, 5, 8, 14, 16, 17, 18, 19, 20, 22, 24, 26, 38, 40, 44, 52, 54, 58, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 112, 114, 117, 118, 119, 121, 122, 123, 124, 125, 126, 132, 144, 152, 164, 210, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 240, 247, 250, 253, 258, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 317, 318, 320, 321, 322, 323, 326, 327, 329, 331, 332, 333, 337, 338, 339, 340, 342, 344, 346, 347, 348, 349, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 368, 369, 370, 371, 374, 375], "methodologi": 331, "metric": [9, 34, 35, 38, 43, 44, 45, 46, 54, 57, 58, 60, 63, 64, 65, 67, 68, 71, 72, 75, 76, 79, 80, 83, 89, 114, 125, 131, 181, 199, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 227, 228, 229, 230, 231, 232, 233, 299, 300, 301, 302, 303, 317, 318, 320, 323, 324, 329, 331, 338, 340, 343, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 364, 366, 368, 369, 370, 371, 374, 379], "metric_nam": [207, 219], "mi": 367, "miami": [324, 328], "mid": 327, "might": [324, 331, 333, 366, 367, 369], "mild": 366, "mimic": 369, "min": [3, 5, 52, 125, 164, 273, 274, 301, 325, 351], "min_": 52, "min_child_sampl": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "min_child_weight": [9, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "min_impurity_decreas": [15, 16, 23, 24, 275, 276, 277, 278], "min_samples_leaf": [15, 16, 23, 24, 275, 276, 277, 278], "min_samples_split": [15, 16], "min_split_gain": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "min_weight_fraction_leaf": [15, 16], "mind": 333, "mine": [324, 328, 332], "ming": [324, 328], "minim": [340, 350, 356, 359, 365, 366, 368], "minimum": [107, 131, 133, 275, 276, 277, 278, 322, 324, 325, 328, 343, 371], "minkowski": 125, "minmax": [5, 17, 18, 19, 20, 24, 54, 71, 75, 164, 322, 342, 361], "minmax_rang": 164, "minor": [365, 370], "minu": [124, 126], "minut": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "miscellan": 107, "misclassif": 367, "miscoverag": [209, 210, 223, 225, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 368], "misdiagnos": 365, "mislead": [365, 367], "misleadingli": 236, "mismatch": 323, "mispredict": 369, "miss": [3, 5, 9, 21, 22, 38, 39, 40, 53, 61, 62, 63, 144, 325, 332, 339, 340, 342, 343, 367], "missing": [332, 339], "missing_valu": 144, "misspecif": 367, "misspecifi": 368, "mitig": [221, 222, 324, 327, 340, 364, 367, 369, 371], "mix": [3, 5, 129, 181, 322, 327, 343], "mixtur": [12, 27, 48, 117, 247, 248, 249, 255, 257, 259, 284, 285, 316, 324, 327, 328, 340, 354, 366, 368, 369, 379], "mj": [355, 356, 360], "mk": [355, 356, 360], "ml": [30, 353], "mlflow": [0, 107, 116, 147, 160, 163, 204, 263, 322, 340, 343], "mlflow_hom": [49, 305, 306], "mlflowexcept": 116, "mlop": 340, "mlp_sample_s": [273, 274], "mlpregressor": 376, "mnth": [4, 8, 9, 10, 64, 68, 325, 356, 357, 359, 360, 366, 367, 368, 369, 370], "mocatboostclassifi": [25, 49, 356], "mocatboostregressor": [26, 356], "mochart": [38, 40, 52, 107, 122, 307], "mocharts_plot": [38, 40], "moclassifi": [0, 32, 376], "mode": [63, 64, 71, 72, 79, 80, 83, 229, 230, 231, 232, 233, 273, 274, 318], "modecisiontreeclassifi": [15, 49, 362], "modecisiontreeclassifiermodecisiontreeclassifi": 15, "modecisiontreeregressor": [16, 362, 375], "modecisiontreeregressormodecisiontreeregressor": 16, "model": [0, 1, 2, 11, 27, 36, 42, 52, 53, 54, 66, 70, 74, 75, 76, 78, 79, 82, 84, 86, 87, 93, 117, 118, 126, 133, 136, 139, 140, 195, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 265, 266, 307, 316, 318, 319, 320, 322, 323, 324, 327, 328, 331, 333, 334, 335, 337, 338, 340, 341, 342, 353, 355, 357, 362, 364, 365, 371, 377, 379], "model1": [61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 371], "model2": [61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 371], "model_calibr": 38, "model_compar": [318, 320, 347], "model_dtre": 362, "model_explain": [333, 334, 335, 336, 337, 338, 339], "model_fairness_compar": 319, "model_gami": 355, "model_gbdt": 356, "model_gblt": 357, "model_glm": 358, "model_glmt": 357, "model_lgbm": [365, 366, 367, 368, 369, 370, 371], "model_mo": 359, "model_nam": [207, 208, 209, 211, 212, 213, 214, 215, 216, 217], "model_neut": 360, "model_relunet": 361, "model_select": [31, 32, 33, 34, 35, 376], "model_test": 349, "model_train": 350, "model_tun": [43, 44, 45, 46, 54, 351], "model_tune_grid_search": 299, "model_tune_optuna": 300, "model_tune_pso": 301, "model_tune_random_search": 302, "model_xgb": [365, 366, 367, 368, 369, 370, 371], "modelbas": 265, "modelnn": [23, 24], "modeltun": 363, "modeltunegridsearch": [0, 43, 374], "modeltuneoptuna": [0, 46], "modeltunepso": [0, 45, 374], "modeltunerandomsearch": [0, 44, 374], "modelzoo": [48, 50, 363, 375, 379], "modern": 359, "modeva": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 85, 86, 87, 89, 107, 322, 326, 327, 328, 329, 331, 332, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 363, 364, 374, 375], "modeva_arbitrary_classifi": [29, 30], "modeva_arbitrary_regressor": 376, "modeva_mlflow": [49, 305, 306], "modeva_sklearn_classifi": 49, "modeva_sklearn_regressor": 376, "modif": [368, 369, 370], "modifi": [175, 325, 350, 365], "modul": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 290, 291, 316, 324, 325, 376], "moe": [12, 27, 48, 247, 248, 249, 255, 257, 259, 284, 285, 316, 340, 354, 366, 379], "moe_classif": 359, "moe_regress": 359, "moelasticnet": [14, 44, 358, 375], "moelasticnetmoelasticnet": [14, 44], "mogaminetclassifi": [19, 49, 355], "mogaminetclassifiermogaminetclassifi": 19, "mogaminetregressor": [20, 355], "mogaminetregressormogaminetregressor": 20, "moglmtreeboost": [23, 24], "moglmtreeboostclassifi": [23, 49, 286, 357], "moglmtreeboostclassifiermoglmtreeboostclassifi": 23, "moglmtreeboostregressor": [24, 286, 287, 357], "moglmtreeboostregressormoglmtreeboostregressor": 24, "moglmtreeclassifi": 357, "moglmtreeregressor": 357, "mogradientboostingclassifi": [25, 49], "mogradientboostingregressor": 26, "molgbmclassifi": [23, 25, 43, 45, 46, 49, 54, 57, 61, 63, 67, 71, 75, 79, 83, 87, 208, 356, 365, 371], "molgbmclassifiermolgbmclassifi": [23, 25, 43, 45, 46, 57, 61, 63, 67, 71, 75, 79, 83, 87], "molgbmregressor": [24, 26, 58, 62, 64, 68, 72, 76, 80, 86, 211, 212, 356, 366, 367, 368, 369, 370], "molgbmregressormolgbmregressor": [24, 26, 58, 62, 64, 68, 72, 76, 80, 86], "mologisticregress": [13, 49, 358], "moment": [327, 332, 339], "momentchi2": 107, "momoeclassifi": [21, 359], "momoeclassifiermomoeclassifi": 21, "momoeregressor": [22, 359], "momoeregressormomoeregressor": 22, "moneuraltre": [23, 24], "moneuraltreeclassifi": [23, 49, 360], "moneuraltreeclassifiermoneuraltreeclassifi": 23, "moneuraltreeregressor": [24, 360], "moneuraltreeregressormoneuraltreeregressor": 24, "monitor": [340, 350, 353, 365, 366, 370], "mono_decreasing_list": [24, 273, 274, 286, 287, 355, 360], "mono_increasing_list": [23, 24, 273, 274, 286, 287, 355, 360], "mono_sample_s": [23, 24, 273, 274, 286, 287, 355, 360], "monoton": [123, 273, 274, 286, 287, 326, 331, 337, 354, 361, 366, 370], "monotone_constraint": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "monotonically_increasing_id": 30, "mont": 300, "morandomforestclassifi": [25, 49], "morandomforestregressor": [26, 375], "more": [123, 125, 133, 144, 210, 225, 239, 301, 302, 318, 319, 320, 323, 324, 326, 329, 331, 335, 337, 338, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 374], "moregressor": [0, 33, 376], "moreludnn": [12, 27, 48, 251, 252, 253, 254, 256, 361, 379], "moreludnnclassifi": [17, 49, 355, 361], "moreludnnclassifiermoreludnnclassifi": 17, "moreludnnregressor": [18, 361], "moreludnnregressormoreludnnregressor": 18, "moreov": [327, 331, 332, 333, 339], "mortgag": [322, 343, 344, 345, 347, 349], "moscoredclassifi": [0, 34, 376], "moscoredregressor": [0, 9, 35, 376], "mosklearnclassifi": [0, 376], "mosklearnregressor": [0, 31, 376], "most": [144, 222, 227, 229, 230, 231, 232, 233, 273, 274, 275, 276, 327, 332, 335, 336, 338, 339, 342, 343, 346, 349, 361, 362, 367, 369, 370], "most_frequ": [5, 144, 322], "motiv": 359, "mous": 345, "mousemov": 52, "move": [331, 333], "moxgbclassifi": [25, 34, 38, 39, 49, 53, 61, 63, 67, 71, 75, 79, 83, 356, 365, 371], "moxgbclassifiermoxgbclassifi": [38, 39, 53, 61, 63], "moxgbregressor": [9, 22, 26, 35, 40, 62, 64, 68, 72, 76, 80, 356, 366, 367, 368, 369, 370, 375], "moxgbregressormoxgbregressor": [9, 40, 62], "mse": [9, 14, 16, 18, 20, 22, 24, 26, 31, 35, 44, 58, 62, 76, 80, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 253, 299, 300, 301, 302, 320, 331, 338, 347, 349, 350, 351, 352, 367, 369, 370, 374, 375], "mse_rank": 44, "mu": [355, 356, 357, 358, 360], "mu_": 366, "mu_j": 359, "much": [226, 236, 320, 332, 333, 335, 339], "mulit": [211, 213, 215, 216, 217], "multi": [290, 291], "multi_strategi": [9, 21, 22, 38, 39, 40, 53, 61, 62, 63], "multidimension": 345, "multipl": [49, 53, 71, 72, 75, 76, 79, 80, 83, 93, 144, 207, 208, 209, 211, 212, 213, 215, 216, 229, 230, 231, 232, 233, 246, 284, 285, 299, 307, 317, 322, 324, 326, 328, 339, 346, 347, 351, 356, 359, 367, 368, 370, 375], "multipli": [210, 225, 228, 324, 328, 332, 370], "multivari": [316, 324, 326, 331, 337, 340, 341], "must": [114, 119, 144, 209, 216, 219, 223, 236, 238, 247, 300, 302, 325, 333, 336, 356], "mutual": [324, 328, 356], "mz": [49, 374, 375], "mz_new": 49, "n": [90, 323, 327, 331, 333, 334, 337, 339, 359, 366, 367, 368, 369, 370], "n_": [331, 333, 361, 365], "n_bar": [25, 26, 53, 86, 307, 359], "n_cluster": [57, 58, 75, 76, 117, 210, 211, 225, 227, 284, 285, 301, 359, 367, 368, 369, 370], "n_compon": [3, 124, 125, 346], "n_epoch_no_chang": [23, 24, 275, 276, 290, 291], "n_estim": [9, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 118, 213, 214, 215, 216, 217, 226, 229, 230, 231, 232, 233, 275, 276, 301, 351, 353, 356, 357, 359, 360, 365, 366, 367, 368, 369, 370, 371, 374], "n_featur": [34, 35, 125, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "n_feature_search": [23, 24, 275, 276, 277, 278], "n_features_in_": [275, 276], "n_forward": 132, "n_forward_phas": 327, "n_fourier": 132, "n_fourier2": 132, "n_i": 369, "n_interactions_": [273, 274], "n_iter": [44, 45, 300, 301, 302, 374], "n_j": 369, "n_job": [9, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 290, 291, 299, 300, 301, 302], "n_l": 361, "n_miss": 325, "n_neighbor": [125, 346], "n_other": 325, "n_output": [267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 293, 294, 297, 298], "n_particl": [45, 301], "n_quantil": 164, "n_redund": 34, "n_repeat": [86, 133, 210, 212, 217, 225, 228, 233, 239, 338], "n_sampl": [34, 35, 125, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "n_screen_grid": [23, 24, 275, 276, 277, 278], "n_split_grid": [23, 24, 275, 276, 277, 278], "n_uniqu": 325, "na": [5, 144], "nabla": 366, "name": [2, 3, 5, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 147, 148, 153, 160, 164, 165, 166, 167, 168, 169, 171, 173, 174, 175, 180, 181, 195, 197, 198, 200, 201, 202, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 307, 318, 320, 322, 323, 324, 325, 327, 328, 333, 335, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376], "name1": [7, 114, 303], "name2": [7, 114, 303], "name_": 52, "name_list": 307, "namegap": 52, "nameloc": 52, "nametextstyl": 52, "nan": [3, 5, 9, 17, 18, 21, 22, 34, 38, 39, 40, 53, 61, 62, 63, 67, 68, 71, 72, 79, 80, 83, 86, 144, 365], "natur": [164, 355, 359, 360, 367], "nbviewer": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "ndarrai": [114, 135, 136, 139, 140, 142, 143, 150, 151, 170, 171, 173, 177, 178, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "ne": [355, 356, 360], "nearest": 328, "necessari": [252, 346, 359], "need": [5, 46, 316, 320, 324, 325, 327, 332, 333, 335, 337, 339, 340, 359, 367, 369, 373, 376], "neg": [123, 326, 331, 333, 338, 355, 356, 358, 359, 360, 365, 366, 367], "neglig": [336, 366], "neighbor": [125, 328, 346], "neighborhood": 366, "neither": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "nest": [207, 208, 215, 216, 217, 220, 221, 222, 225, 227, 228, 230, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "net": [273, 274, 316, 340, 354, 357, 359, 360], "net_": [273, 274, 286, 287, 290, 291], "network": [273, 274, 284, 285, 286, 287, 290, 291, 316, 340, 354, 355, 360, 370, 374], "neural": [286, 287, 290, 291, 316, 324, 332, 340, 354, 355, 370, 374], "neural_network": 376, "neuraltre": [49, 360], "neuron": [290, 291, 361], "new": [117, 118, 119, 123, 126, 164, 173, 195, 286, 287, 323, 324, 326, 328, 343, 353, 356, 366, 368, 369, 370, 376], "new_d": [9, 376], "next": [9, 331, 338, 342, 351], "nich": 369, "nicola": 324, "nighttim": 337, "nllm": 252, "nm": 323, "nn": [290, 291], "nn_batch_siz": [23, 24, 286, 287], "nn_epoch_no_chang": [286, 287], "nn_lr": [23, 24, 286, 287], "nn_max_epoch": [23, 24, 49, 286, 287], "nn_n_epoch_no_chang": [23, 24, 286, 287], "nn_temperatur": [23, 24, 49, 286, 287], "nnede": [355, 360], "no_progress": 29, "node": [250, 258, 275, 276, 277, 278, 324, 328, 332, 339, 355, 356, 359, 360, 361, 362, 370], "noic": 340, "nois": [35, 79, 210, 212, 225, 228, 318, 320, 332, 336, 340, 347, 349, 356, 366, 371], "noise_level": [54, 79, 80, 210, 212, 217, 225, 228, 233, 303, 370], "noisi": [366, 367, 368, 370, 371], "nomin": 368, "non": [8, 71, 72, 117, 118, 119, 123, 132, 217, 228, 233, 275, 276, 324, 326, 327, 337, 343, 357, 359, 367, 370, 376], "nonconform": 223, "none": [3, 4, 6, 9, 14, 15, 16, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 44, 45, 46, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 112, 114, 120, 121, 122, 123, 124, 125, 126, 135, 139, 140, 142, 144, 147, 153, 160, 164, 165, 167, 180, 195, 199, 201, 202, 204, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 246, 248, 252, 254, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 306, 307, 366, 370], "nonlinear": [123, 326, 346, 361, 366, 367, 368, 369], "noplot_3_h2o": [29, 36, 379], "noplot_4_spark": [30, 36, 379], "nor": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "norm": 365, "normal": [52, 117, 118, 119, 133, 210, 212, 217, 225, 226, 228, 233, 273, 274, 318, 320, 324, 327, 328, 332, 339, 342, 347, 349, 355, 356, 357, 358, 359, 360, 361, 367], "notabl": 319, "note": [5, 9, 34, 35, 52, 53, 112, 210, 213, 214, 215, 216, 217, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 237, 238, 240, 272, 273, 274, 283, 300, 301, 307, 318, 319, 320, 323, 324, 327, 328, 329, 331, 332, 333, 336, 337, 338, 339], "notebook": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107, 340], "notic": 324, "notin": 368, "novel": [324, 328, 360], "now": [336, 373], "np": [7, 9, 30, 31, 32, 33, 34, 35, 39, 40, 114, 135, 136, 139, 140, 142, 143, 144, 170, 171, 173, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 374, 376], "nu": 357, "nuanc": [357, 359, 365], "null": 327, "nullabl": 144, "num": 352, "num_leav": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "num_parallel_tre": [9, 38, 39, 40, 53, 61, 62, 63], "number": [112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 132, 133, 155, 164, 180, 210, 211, 212, 213, 214, 215, 216, 217, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 238, 239, 240, 248, 252, 259, 273, 274, 275, 276, 277, 278, 284, 285, 286, 287, 290, 291, 299, 300, 301, 302, 307, 318, 320, 322, 323, 324, 325, 327, 328, 329, 331, 332, 333, 334, 335, 337, 338, 339, 342, 343, 346, 356, 359, 361, 366, 367, 368, 369, 370, 371, 374], "numer": [2, 3, 5, 19, 20, 23, 25, 26, 63, 64, 111, 112, 120, 121, 122, 123, 124, 125, 126, 130, 131, 144, 164, 166, 181, 208, 210, 213, 214, 215, 216, 217, 220, 221, 222, 225, 228, 229, 230, 231, 232, 233, 240, 247, 248, 272, 273, 274, 283, 301, 318, 320, 326, 327, 331, 333, 337, 342, 344, 345, 346, 351, 353, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370, 371], "numpi": [7, 9, 30, 31, 32, 33, 34, 35, 39, 40, 107, 150, 151, 177, 178, 269, 292, 373, 376], "o7": 106, "object": [9, 23, 24, 25, 26, 34, 35, 38, 39, 40, 43, 45, 46, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 195, 196, 198, 205, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 223, 224, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 239, 240, 242, 245, 246, 247, 249, 250, 251, 252, 253, 254, 255, 256, 258, 263, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 350, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "observ": [319, 323, 324, 328, 335, 337, 367, 369], "obtain": [71, 210, 225, 320, 324, 325, 327, 328, 331, 332, 337, 339, 359, 361], "occur": [144, 236, 365, 367, 370], "occurr": 144, "ocsvm": 324, "od_marginal_outlier_distribut": 324, "od_score_distribut": 324, "od_tsne_comparison": 324, "odd": [331, 333, 334, 335, 337, 365], "off": [240, 300, 301, 302, 332, 339, 361], "offer": [319, 320, 325, 326, 331, 332, 333, 339, 340, 343, 350, 355, 356, 367, 368, 369, 371], "often": [355, 356, 359, 360, 361, 365, 367, 371, 374, 376], "old": [107, 195], "omega": [355, 359], "onc": [112, 333, 350, 361], "one": [68, 71, 72, 114, 123, 124, 126, 144, 164, 207, 208, 209, 210, 214, 219, 220, 221, 222, 225, 226, 229, 230, 231, 232, 233, 235, 238, 247, 272, 283, 299, 300, 301, 302, 307, 320, 322, 323, 324, 325, 326, 327, 328, 331, 333, 335, 337, 338, 344, 350, 355, 359, 361, 365, 369], "oneclasssvm": 324, "onehot": [5, 124, 125, 126, 322, 342], "ones": [132, 327, 331, 337, 355, 356], "ongo": 340, "onli": [52, 112, 114, 119, 121, 122, 127, 128, 129, 130, 134, 135, 139, 140, 142, 144, 155, 193, 194, 209, 210, 212, 213, 214, 215, 216, 217, 223, 225, 229, 230, 231, 232, 233, 243, 244, 246, 268, 271, 272, 273, 274, 276, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 300, 301, 307, 320, 324, 328, 331, 336, 338, 339, 342, 343, 344, 347, 348, 353, 355, 356, 359, 361, 365, 367, 368, 373, 374, 376], "ood": 369, "oot": [83, 115, 173], "op": 107, "open": [322, 342, 350], "oper": [1, 11, 124, 286, 287, 316, 321, 340, 342, 343, 355, 360, 361, 362, 365, 367, 379], "operatio": 322, "opportun": 365, "optim": [42, 47, 48, 106, 273, 274, 286, 287, 290, 291, 299, 300, 301, 302, 324, 340, 346, 350, 351, 356, 359, 362, 363, 366, 371, 379], "optimisticbia": 366, "option": [9, 34, 35, 38, 40, 52, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 180, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 246, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 266, 269, 272, 283, 290, 291, 292, 293, 294, 299, 300, 301, 302, 307, 318, 323, 324, 325, 326, 328, 329, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 344, 345, 346, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 374], "optuna": [42, 47, 48, 300, 379], "order": [52, 121, 123, 199, 324, 326, 327, 333, 344, 356, 361], "order_bi": [49, 199, 375], "ordin": [54, 123, 124, 125, 126, 322, 326, 342, 365, 371], "org": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "orient": 52, "origin": [9, 223, 255, 256, 273, 274, 324, 328, 329, 331, 332, 333, 336, 337, 338, 339, 342, 366, 368, 369, 370], "original_scal": 337, "orthogon": [355, 356, 360], "other": [123, 125, 135, 136, 139, 140, 142, 143, 220, 226, 227, 230, 238, 319, 323, 324, 325, 326, 328, 331, 332, 333, 335, 337, 339, 340, 343, 344, 350, 357, 363, 365, 368, 369, 375], "otherwis": [146, 187, 235, 236, 238, 240, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 318, 320, 324, 325, 332, 333, 334, 335, 336, 337, 338, 339, 353, 366, 368, 369], "our": [332, 335, 336, 338, 368], "out": [115, 173, 221, 238, 259, 273, 274, 368, 369], "outcom": [214, 238, 324, 347, 365, 367, 370], "outer": [75, 76, 211, 227, 347, 349, 369], "outlier": [0, 1, 11, 117, 118, 119, 123, 211, 227, 316, 320, 321, 326, 340, 344, 366, 367, 371, 379], "outlier_detect": 324, "outliers_sample_index": 8, "outlin": [324, 370], "outpupt": 375, "output": [32, 33, 54, 112, 114, 126, 144, 164, 225, 235, 236, 238, 247, 269, 273, 274, 284, 292, 324, 331, 332, 333, 335, 336, 337, 339, 340, 343, 347, 349, 355, 356, 357, 358, 359, 360, 361, 362, 368, 376], "outputcol": 30, "outsid": [225, 227, 278, 320, 331, 333, 337, 368], "over": [229, 230, 231, 232, 233, 238, 323, 325, 331, 333, 339, 344, 345, 351, 359, 368, 369], "overal": [181, 319, 322, 324, 327, 328, 333, 355, 356, 357, 358, 359, 360, 365, 366, 367, 368, 369, 370], "overcom": [331, 333], "overconfid": 368, "overfit": [9, 34, 35, 69, 93, 215, 219, 231, 316, 317, 327, 340, 352, 356, 358, 361, 364, 365, 367, 370, 379], "overflow": [52, 324], "overli": [365, 370, 371], "overrid": [2, 9, 34, 35, 160, 322, 353], "overridden": [165, 167], "overview": [324, 325], "overwrit": 112, "own": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93], "p": [40, 54, 132, 318, 323, 324, 329, 331, 332, 334, 337, 339, 365, 366, 367, 368, 369, 370], "p_": 359, "p_i": [323, 329, 367, 369], "p_j": 359, "p_k": 359, "p_valu": 327, "packag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107, 300, 331, 332, 333, 335, 336, 337, 339, 361], "pad": 52, "page": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 324], "pair": [71, 131, 164, 208, 211, 212, 213, 214, 215, 216, 217, 220, 221, 222, 230, 236, 259, 273, 274, 326, 327, 366], "pairwis": [243, 273, 274, 326, 333, 355, 357, 359, 360, 367], "pam": [57, 58, 210, 225, 367, 368, 370], "panda": [5, 10, 30, 31, 32, 33, 34, 35, 107, 123, 144, 150, 151, 187, 207, 213, 246, 322, 376], "panel": [325, 340, 341, 350], "paper": [123, 326, 331, 333], "paragraph": [332, 339], "parallel": [43, 44, 45, 46, 251, 273, 274, 290, 291, 299, 300, 301, 302, 351, 356], "parallel_backend": [299, 300, 301, 302], "parallelaxi": 52, "param": [43, 44, 45, 46, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "param_bound": [45, 301], "param_distribut": [44, 46, 300, 302, 374], "param_grid": [43, 44, 299], "param_spac": 374, "param_typ": [45, 301], "paramet": [106, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 180, 181, 187, 192, 195, 197, 198, 199, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 320, 324, 325, 327, 329, 333, 335, 336, 337, 338, 339, 353, 355, 358, 359, 360, 362, 366, 374], "parametr": [132, 324, 327], "parent": [54, 266, 353, 355, 356], "pariti": 365, "parsimoni": 355, "part": [323, 359, 366], "partial": [235, 236, 238, 275, 276, 278, 327, 330, 334, 340, 348, 355, 356, 360, 366], "partial_depend": [331, 337], "particl": [42, 47, 48, 301, 359, 379], "particular": [323, 332, 336, 339, 361], "particularli": [123, 323, 324, 326, 332, 339, 355, 356, 360, 368, 369], "partit": [112, 117, 118, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 181, 211, 212, 214, 221, 222, 247, 256, 277, 278, 324, 328, 331, 335, 337, 359], "partitionto": 224, "parzen": 300, "pass": [29, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 297, 298, 300, 358, 362], "past": 322, "path": [149, 152, 154, 163, 241, 258, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 305, 306, 307, 324, 328, 332, 339, 356, 357, 362], "path_or_buf": [152, 163], "patienc": [286, 287], "pattern": [123, 224, 323, 324, 326, 328, 335, 344, 346, 355, 356, 357, 359, 361, 367, 368, 369, 370, 371], "pay_1": [2, 3, 5, 7, 13, 17, 19, 21, 23, 25, 49, 57, 63, 67, 71, 75, 79, 83, 208, 303, 318, 361, 365, 371], "pay_1_special_sv2": 5, "pay_2": [2, 3, 5, 13, 19, 25, 63, 67, 71, 79], "pay_3": [2, 3, 5, 13, 25, 63, 67, 71, 79, 361], "pay_4": [2, 3, 5, 25, 63, 79, 83], "pay_5": [2, 3, 5, 25, 63, 67, 71], "pay_6": [2, 3, 5, 25, 63, 67, 71, 79, 83], "pay_amt1": [2, 3, 5, 25, 63, 83, 361, 371], "pay_amt2": [2, 3, 5, 25, 63, 71], "pay_amt3": [2, 3, 5, 25, 63], "pay_amt4": [2, 3, 5, 25, 63], "pay_amt5": [2, 3, 5, 25, 63], "pay_amt6": [2, 3, 5, 25, 63], "pc1": 346, "pc2": 346, "pc3": 346, "pca": [119, 124, 211, 227, 321, 324], "pd": [5, 30, 31, 32, 33, 34, 35, 52, 113, 144, 145, 147, 149, 159, 170, 171, 173, 192, 228, 229, 231, 238, 260, 307, 322, 331, 337, 376], "pd_": [331, 334], "pdf": 339, "pdp": [31, 238, 330, 333, 334, 335, 339, 340, 348], "peak": 333, "pearson": [3, 52, 123, 131, 326, 327], "penal": [355, 360, 361, 367], "penalti": [355, 360, 361, 366, 370], "per": [122, 133, 216, 225, 273, 274, 275, 276, 286, 287, 331, 333, 339, 348, 355, 356, 357, 358, 359, 360, 361], "percent": [368, 369, 370], "percentag": [172, 232, 259, 322, 343], "percentil": [86, 236, 238, 322], "perfect": [123, 323, 326, 365, 367], "perforamnc": [221, 222], "perform": [49, 54, 57, 58, 65, 75, 76, 79, 80, 83, 93, 112, 117, 118, 119, 124, 125, 132, 144, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 222, 225, 226, 227, 228, 229, 231, 232, 233, 273, 274, 299, 300, 301, 302, 316, 319, 323, 324, 327, 328, 329, 331, 338, 340, 343, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 364, 366, 368, 369, 370, 371, 374, 375, 379], "performance_metr": [83, 221, 222, 365], "period": 335, "peripheri": 369, "perman": [327, 353], "permiss": 116, "permut": [32, 33, 133, 239, 327, 330, 340, 348], "permutation_import": [331, 338], "perorm": 369, "perp": 327, "perspect": 319, "perturb": [210, 212, 217, 225, 228, 233, 237, 318, 320, 332, 336, 340, 347, 349, 352, 364, 366, 371], "perturb_featur": [79, 80, 210, 212, 217, 225, 228, 233, 303, 318, 320, 370], "perturb_method": [54, 79, 80, 210, 212, 217, 225, 228, 233, 318, 320, 370], "perturb_s": [318, 320, 370], "perturbaion": 370, "peter": 327, "pfi": [53, 239, 330, 340, 348], "pfi_result": 53, "phase": [327, 342, 370], "phenomenon": [323, 324], "phi_": [332, 339], "phi_0": [332, 339], "phi_j": [332, 339], "pi": 40, "pi_i": 368, "pi_width": [57, 58, 210, 225, 368], "pick": [347, 348, 349, 352], "pilla": 327, "piml": [318, 320, 323, 324, 325, 333, 334, 335, 336, 337, 338, 339, 373], "pinpoint": [324, 340, 367, 368, 369, 371], "pip": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107], "pipelin": [0, 51, 55, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 340, 376, 379], "pipeline1": [2, 54], "pisa": [324, 328], "pitkin": 335, "pizzuti": 324, "pkdd": 324, "pkl": 152, "place": [106, 339], "placehold": 144, "plai": [332, 339], "platt": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 324], "player": [332, 339], "pleas": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 324, 331, 333, 335, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362], "plot": [3, 4, 7, 8, 15, 16, 19, 20, 21, 22, 23, 24, 31, 32, 33, 43, 44, 45, 46, 48, 49, 52, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 87, 114, 117, 118, 119, 120, 121, 122, 123, 124, 131, 132, 133, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 299, 300, 301, 302, 307, 318, 319, 320, 321, 323, 324, 330, 333, 334, 335, 336, 338, 340, 343, 344, 345, 346, 347, 348, 349, 351, 352, 357, 358, 362, 365, 366, 367, 368, 369, 370, 371], "plot_0_accuracy_table_cl": [61, 65, 379], "plot_0_accuracy_table_reg": [62, 65, 379], "plot_0_calibrate_proba": [38, 41, 379], "plot_0_data_oper": [2, 11, 379], "plot_0_fairness_cl": [83, 84, 379], "plot_0_glm_cl": [13, 27, 379], "plot_0_glm_reg": [14, 27, 379], "plot_0_global_explain": [86, 88, 379], "plot_0_grid": [43, 47, 379], "plot_0_modelzoo": [49, 50, 379], "plot_0_pred_interval_cl": [39, 41, 379], "plot_0_pred_interval_reg": [40, 41, 379], "plot_0_reliability_cl": [71, 73, 379], "plot_0_resilience_cl": [75, 77, 379], "plot_0_robustness_cl": [79, 81, 379], "plot_0_sklearn": [31, 36, 379], "plot_0_slice_overfit_cl": [67, 69, 379], "plot_0_valres_attribut": [52, 55, 379], "plot_1_arbitrary_cl": [32, 36, 379], "plot_1_arbitrary_reg": [33, 36, 379], "plot_1_dt_cl": [15, 27, 379], "plot_1_dt_reg": [16, 27, 379], "plot_1_eda": [3, 11, 379], "plot_1_local_explain": [87, 88, 379], "plot_1_random": [44, 47, 379], "plot_1_reliability_reg": [72, 73, 379], "plot_1_residual_cl": [57, 59, 379], "plot_1_residual_reg": [58, 59, 379], "plot_1_resilience_reg": [76, 77, 379], "plot_1_robustness_reg": [80, 81, 379], "plot_1_slice_accuracy_cl": [63, 65, 379], "plot_1_slice_accuracy_reg": [64, 65, 379], "plot_1_slice_overfit_reg": [68, 69, 379], "plot_1_valres_sav": [53, 55, 379], "plot_2_feature_select": [4, 11, 379], "plot_2_pipelin": [54, 55, 379], "plot_2_pso": [45, 47, 379], "plot_2_reludnn_cl": [17, 27, 379], "plot_2_reludnn_reg": [18, 27, 379], "plot_2_scored_cl": [34, 36, 379], "plot_2_scored_reg": [35, 36, 379], "plot_3_feature_engin": [5, 11, 379], "plot_3_gaminet_cl": [19, 27, 379], "plot_3_gaminet_reg": [20, 27, 379], "plot_3_optuna": [46, 47, 379], "plot_4_moe_cl": [21, 27, 379], "plot_4_moe_reg": [22, 27, 379], "plot_4_subsampl": [6, 11, 379], "plot_5_drift_test": [7, 11, 379], "plot_5_lineartree_cl": [23, 27, 379], "plot_5_lineartree_reg": [24, 27, 379], "plot_6_const_tree_cl": [25, 27, 379], "plot_6_const_tree_reg": [26, 27, 379], "plot_6_outlier_detect": [8, 11, 379], "plot_7_data_with_predict": [9, 11, 379], "plot_8_extra_data": [10, 11, 379], "plot_sav": [53, 307], "plot_typ": [3, 120], "plt": 39, "plu": [164, 376], "png": [53, 106, 307], "point": [25, 117, 122, 125, 180, 210, 222, 224, 225, 236, 238, 240, 247, 248, 273, 274, 275, 276, 277, 278, 323, 324, 328, 331, 333, 334, 335, 336, 337, 339, 344, 345, 346, 357, 359, 361, 366, 367, 368, 370, 371], "pointer": 52, "pointsiz": 52, "polynomi": [121, 324, 344], "poor": [361, 368, 369, 371], "poorest": 369, "poorli": [367, 368, 371], "popescu": [331, 334], "popul": [114, 229, 230, 231, 232, 233, 253, 323, 329, 336, 340, 355, 356, 357, 358, 360, 361, 369, 374], "popular": [362, 371, 376], "popup": [52, 307], "posit": [14, 44, 52, 123, 149, 224, 235, 236, 238, 240, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 326, 355, 358, 359, 360, 361, 365, 367], "possess": [332, 339], "possibl": [236, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 301, 302, 319, 332, 339, 367, 374], "post": [0, 85, 89, 327, 338, 340, 348], "poster": 324, "potenti": [132, 215, 219, 227, 231, 324, 327, 328, 352, 365, 367, 369], "power": [122, 340, 352, 355, 356, 357, 360, 361, 365], "pp": [324, 327, 328], "pr": [208, 220, 221, 222, 230], "practic": [319, 332, 339, 361, 365, 367], "practition": [355, 360, 365, 366, 367, 371], "prasanta": 327, "pre": [213, 215, 216, 217, 221, 229, 230, 232, 233, 284, 285, 286, 287, 327, 332, 339, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "prebin": 221, "precis": [52, 61, 208, 219, 220, 221, 222, 324, 328, 365, 367, 370], "precision_recal": [53, 61, 219], "precomput": [14, 44, 63, 64, 112, 213, 214, 215, 216, 217, 221, 226, 229, 230, 231, 232, 233, 322, 371], "pred": [366, 370], "pred_proba": 34, "predecessor": 356, "predefin": [114, 219, 231, 327, 351, 374], "predict": [1, 11, 29, 30, 33, 37, 41, 48, 49, 60, 79, 80, 83, 89, 136, 139, 140, 168, 169, 183, 188, 207, 208, 209, 210, 211, 214, 216, 217, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 232, 235, 236, 237, 238, 239, 240, 247, 249, 251, 256, 258, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 320, 324, 327, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 347, 348, 349, 352, 358, 362, 363, 364, 365, 366, 367, 369, 370, 371, 375, 376, 379], "predict_func": [29, 30, 33, 376], "predict_funct": [29, 30, 33, 292, 376], "predict_interv": [39, 40, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "predict_last_hidden_lay": [17, 18], "predict_proba": [32, 34, 38, 49, 235, 236, 238, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 332, 333, 334, 335, 336, 337, 376], "predict_proba_func": [29, 30, 32, 376], "predict_proba_funct": [29, 30, 32, 269, 376], "prediction_proba": 136, "predictor": [226, 319, 331, 335, 336, 337, 338, 358, 359, 368, 369], "prefer": [114, 120, 207, 208, 209, 210, 214, 219, 220, 221, 222, 225, 226, 229, 230, 231, 232, 233, 299, 300, 301, 302], "prefix": 307, "prepar": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 52, 53, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 321, 324, 338, 342], "preprint": [327, 332, 339], "preprocess": [0, 16, 17, 18, 19, 20, 22, 24, 26, 40, 44, 54, 58, 62, 64, 68, 71, 72, 75, 76, 80, 86, 110, 111, 112, 113, 118, 124, 125, 135, 136, 139, 140, 142, 145, 152, 161, 162, 163, 183, 184, 186, 187, 188, 189, 190, 192, 193, 194, 272, 274, 283, 318, 321, 328, 342, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "preprocessor": 141, "presenc": 324, "present": [318, 319, 320, 325, 332, 339, 359, 369], "preserv": [346, 355, 356, 358, 360, 362, 370], "preval": 324, "prevent": [324, 358, 365], "preview": 353, "previou": [54, 112, 161, 320, 333, 335, 356, 376], "price": [355, 360, 365], "prime": [332, 339], "princip": [119, 124, 326, 328], "principl": 324, "print": [40, 49, 52, 275, 276, 286, 287, 290, 291, 365], "priorit": [366, 369], "privileg": 365, "proba": [34, 83, 140], "proba_cutoff": [83, 222, 365], "probabilist": [208, 214, 220, 221, 222, 230, 359], "probabl": [29, 30, 140, 169, 208, 214, 220, 221, 222, 224, 230, 235, 236, 238, 240, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 323, 331, 333, 334, 335, 337, 339, 358, 359, 361, 365, 367, 368, 369, 370], "problem": [63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 318, 320, 332, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "problemat": [211, 227, 332, 339], "proceed": [324, 332], "process": [1, 11, 54, 112, 125, 126, 132, 144, 164, 237, 239, 254, 290, 291, 300, 307, 316, 320, 322, 324, 327, 328, 332, 336, 337, 341, 347, 348, 349, 350, 351, 352, 353, 355, 357, 361, 365, 366, 371, 374, 375, 379], "processor": [299, 300, 301, 302], "prod_j": 356, "produc": [125, 335, 359, 367, 368], "product": [340, 355, 360, 371], "profil": 252, "program": [5, 9, 10, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 54, 83], "programmat": 305, "progress": [52, 206, 275, 276, 286, 287, 290, 291, 350, 351, 369], "progressivethreshold": 52, "project": [346, 353], "promot": [366, 370], "proper": [340, 366, 367, 368], "properti": [0, 110, 111, 113, 127, 128, 129, 130, 134, 155, 156, 157, 159, 162, 179, 182, 183, 184, 185, 186, 188, 189, 190, 191, 193, 194, 196, 203, 323, 332, 339, 356, 366, 370], "proport": [71, 72, 117, 180, 209, 216, 223, 228, 259, 275, 276, 286, 287, 290, 291, 318, 320, 323, 329, 342, 344, 345, 346, 349, 367, 369], "propos": [324, 328], "propto": 366, "prostat": 29, "protect": [0, 83, 115, 142, 170, 171, 208, 214, 220, 221, 222, 230, 319, 353, 365], "protected_data": 83, "prototyp": 350, "provid": [52, 118, 120, 122, 123, 153, 180, 181, 208, 209, 217, 220, 232, 237, 240, 247, 248, 250, 256, 267, 268, 269, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 319, 322, 323, 324, 325, 326, 328, 329, 331, 332, 335, 337, 338, 339, 340, 343, 346, 348, 349, 350, 352, 353, 355, 356, 357, 358, 359, 360, 362, 363, 365, 366, 367, 368, 369, 370, 371, 373, 376], "proxim": [210, 225, 332, 336, 367, 368, 369, 370], "prune": [273, 274, 355], "pseudo": [356, 376], "psi": [7, 21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 323, 329, 340, 349, 359, 366, 367, 368, 370, 371], "psi_bin": [21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 359, 366, 367, 368, 369, 370, 371], "psi_bucket": 323, "psi_method": [21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 359, 366, 367, 368, 369, 370, 371], "pso": [300, 301, 359, 374], "public": [29, 324], "purifi": 356, "purpos": [216, 232, 322, 324, 333, 337, 339, 353, 373], "put": [332, 339], "py": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 88, 318, 319, 320, 323, 324, 325, 333, 334, 335, 336, 337, 338, 339, 373, 376, 379], "pyal": [331, 333], "pylab": 39, "pyspark": [28, 36, 48, 376, 379], "pyswarm": 107, "python": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 107, 300, 331, 332, 333, 339, 361, 376], "pytorch": [286, 287], "q": [323, 329, 367, 368, 369, 370], "q1": [325, 343], "q2": 343, "q3": [325, 343], "q_": [366, 368, 369, 370], "q_1": 368, "q_i": [323, 329, 369], "q_k": 366, "q_l": 366, "qmc": [46, 300], "qmcsampler": 300, "qr": 368, "quad": 365, "qualiti": [300, 301, 302, 340, 343, 367, 370], "quantif": [340, 368], "quantifi": [236, 318, 323, 324, 328, 332, 339, 365, 367, 368, 369, 370], "quantil": [5, 54, 63, 64, 67, 68, 79, 80, 112, 114, 117, 118, 119, 164, 209, 210, 212, 213, 214, 215, 216, 217, 221, 223, 225, 226, 228, 229, 230, 231, 232, 233, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 322, 323, 324, 329, 331, 333, 340, 342, 347, 349, 352, 365, 366, 367, 368], "quantiti": [355, 360], "quartil": [325, 342, 343], "quasi": 300, "queri": 367, "question": 0, "quicker": [331, 333], "quit": 333, "r": [359, 360, 361, 365, 366, 367, 368, 369, 370], "r2": [9, 14, 16, 20, 22, 24, 26, 31, 35, 44, 62, 207, 210, 211, 212, 213, 214, 215, 217, 219, 221, 222, 225, 227, 228, 229, 231, 233, 299, 300, 301, 302, 320, 351, 367, 374], "r_": [356, 366, 368, 369], "r_1": 359, "r_2": 359, "r_i": 368, "r_j": 366, "race": [54, 319, 322, 343, 365], "radar": 52, "radial": 324, "radio": [343, 344, 345], "rain": 333, "rais": [116, 235, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 365], "rajeev": 324, "ramani": 327, "ramaswami": 324, "ramaswamy2000": 324, "randint": [46, 374], "random": [42, 46, 47, 48, 117, 119, 120, 121, 122, 123, 124, 125, 131, 132, 133, 172, 180, 209, 210, 211, 212, 216, 217, 223, 224, 225, 227, 228, 232, 233, 235, 236, 237, 238, 239, 240, 248, 273, 274, 275, 276, 277, 278, 286, 287, 290, 291, 300, 301, 302, 324, 327, 328, 329, 331, 336, 338, 340, 342, 344, 345, 347, 351, 352, 356, 364, 367, 369, 379], "random_st": [14, 15, 16, 19, 20, 23, 24, 25, 26, 31, 32, 33, 34, 35, 43, 44, 45, 46, 49, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 117, 119, 120, 121, 122, 123, 124, 125, 131, 132, 133, 172, 180, 209, 210, 211, 212, 216, 217, 223, 224, 225, 227, 228, 232, 233, 235, 236, 237, 238, 239, 240, 248, 273, 274, 275, 276, 277, 278, 286, 287, 290, 291, 300, 301, 302, 353, 368, 376], "randomforestclassifi": 288, "randomforestregressor": 289, "randomizedsearchcv": 374, "randomli": [122, 125, 180, 240, 320, 323, 324, 328, 329, 331, 332, 336, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374], "randomsampl": 300, "randomsplit": 30, "rang": [34, 35, 43, 44, 52, 123, 125, 164, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 235, 238, 247, 275, 276, 277, 324, 326, 328, 331, 333, 336, 339, 340, 342, 351, 361, 368, 370, 371, 374], "range_": 52, "rank": [123, 211, 227, 318, 320, 326, 331, 338, 351, 366, 367, 368, 369, 370], "rapid": 350, "rare": 324, "rastogi": 324, "rate": [209, 210, 216, 223, 225, 273, 274, 275, 276, 286, 287, 355, 356, 357, 360, 361, 365, 367, 368, 369, 374], "rather": [235, 336], "ratio": [29, 83, 123, 131, 208, 211, 220, 221, 222, 227, 273, 274, 319, 320, 327, 342, 349, 366], "rational": [324, 369], "ravel": [19, 20, 23, 24, 25, 26, 40, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 301, 355, 361], "raw": [38, 139, 140, 142, 143, 145, 150, 151, 158, 159, 170, 173, 181, 187, 192, 267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 318, 320, 322, 340, 342, 355, 356, 357, 358, 360, 361], "raw_data": [187, 192, 365], "raw_extra_data": 10, "rbf": 374, "rcit": 132, "re": [322, 359, 376], "reach": [17, 18, 23, 24, 324, 333, 359], "read": 153, "read_csv": 149, "readi": [322, 376], "real": [349, 356, 359, 367, 369, 370], "realist": 370, "realtim": 52, "reason": 328, "recal": [61, 208, 219, 220, 221, 222, 365, 367, 370], "receiv": [225, 359], "reclassifi": [343, 344, 345], "recogn": [332, 339, 362], "recognit": [324, 328], "recommend": [327, 361], "recomput": 359, "reconst_error": [8, 119], "reconstruct": [119, 324, 328], "record": [318, 320, 324, 331, 335, 338, 343, 353], "recur": 371, "recurs": [277, 278, 324, 328, 331, 337, 356, 361, 362], "red": [324, 339], "reduc": [123, 125, 221, 222, 235, 324, 327, 328, 332, 333, 339, 344, 345, 346, 351, 355, 356, 357, 359, 360, 361, 365, 368, 369, 370], "reduct": [119, 125, 324, 326, 328, 332, 339, 346, 366, 367, 368], "redund": [132, 327], "refer": [83, 124, 126, 208, 214, 220, 221, 222, 230, 240, 275, 276, 319, 321, 323, 330, 333, 337, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 365, 366, 367, 368, 369, 370, 371], "refin": [359, 367, 368, 369, 370, 371], "refit": 368, "reflect": [343, 369, 370], "reg": [9, 40, 62], "reg_alpha": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "reg_clar": [273, 274], "reg_lambda": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 275, 276, 277, 278], "reg_mono": [23, 24, 273, 274, 286, 287, 355, 360], "regard": 325, "regardless": 371, "region": [215, 216, 217, 229, 231, 232, 233, 284, 285, 318, 320, 355, 356, 357, 359, 360, 361, 367, 368, 369, 370, 371], "regist": [9, 34, 35, 116, 135, 136, 139, 140, 142, 143, 147, 153, 197, 201, 202, 218, 234, 261, 262, 266, 322, 343, 347, 348, 349, 352, 353, 363], "register_nam": [204, 263], "registered_model": 49, "registr": [321, 350, 353], "registri": [0, 316, 340, 341], "registry_hub": 353, "regress": [0, 12, 21, 27, 48, 56, 59, 60, 65, 66, 69, 70, 73, 74, 77, 78, 81, 89, 176, 182, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 237, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 317, 322, 324, 331, 333, 334, 335, 336, 337, 338, 339, 340, 342, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 374, 376, 379], "regressor": [28, 36, 37, 41, 48, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 356, 379], "regular": [226, 273, 274, 275, 276, 277, 278, 286, 287, 290, 291, 324, 355, 358, 360, 361, 366, 370], "regulatori": [340, 348, 365, 369], "rel": [320, 324, 327, 328, 355, 356, 357, 358, 360, 361], "relat": [136, 209, 211, 223, 230, 318, 320, 323, 327, 329, 335, 352], "relationship": [121, 122, 123, 131, 224, 226, 238, 251, 275, 276, 286, 287, 323, 324, 326, 327, 331, 333, 335, 337, 338, 339, 344, 345, 346, 355, 356, 357, 358, 360, 361, 366, 367, 369, 371], "releas": 338, "relev": [220, 327, 333, 334, 335, 337, 359, 374], "reli": [239, 324, 325, 328, 366, 371], "reliability_coverag": 320, "reliability_perf": 318, "reliabl": [9, 34, 35, 73, 93, 209, 210, 211, 216, 223, 225, 232, 239, 316, 317, 324, 331, 333, 340, 352, 355, 356, 360, 364, 366, 367, 369, 370, 371, 379], "relianc": [331, 338], "reload": 9, "reload_d": [9, 34, 35], "relu": [273, 274, 290, 291, 316, 340, 354], "relu_net": 361, "reludnn": [49, 290, 291, 333], "remain": [75, 76, 212, 228, 318, 320, 327, 332, 335, 336, 339, 359, 368, 370], "remark": [356, 361], "remedi": [364, 365, 369], "remov": [8, 132, 161, 324, 327, 331, 332, 338, 339, 353, 356, 361, 366, 370], "remove_outli": 324, "render": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 346], "rendermod": 52, "rental": [320, 333, 334, 335, 336, 337, 338, 339], "repai": 365, "repaid": 365, "repeat": [79, 210, 212, 217, 225, 228, 239, 301, 324, 327, 328, 331, 336, 338, 356, 359], "repetit": [233, 338], "replac": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 126, 144, 195, 222, 332, 339, 353, 357, 376], "report": [210, 225, 241, 340, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "repositori": [318, 320, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371, 375], "repres": [122, 180, 222, 290, 291, 318, 319, 320, 323, 324, 326, 328, 331, 333, 334, 335, 336, 337, 339, 351, 353, 355, 356, 359, 360, 361, 362, 367, 369, 374], "represent": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 114, 237, 246, 248, 324, 328, 354, 356, 357, 361, 365, 371], "reproduc": [117, 119, 120, 121, 123, 124, 125, 131, 132, 133, 180, 209, 210, 211, 212, 216, 217, 223, 224, 225, 227, 228, 232, 233, 235, 237, 238, 239, 240, 248, 275, 276, 277, 286, 287, 290, 291, 300, 301, 302, 340, 342, 347], "requir": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 126, 131, 275, 276, 277, 318, 324, 325, 328, 331, 332, 333, 337, 339, 340, 348, 353, 361, 365, 368], "rerun": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "res_valu": [63, 64, 67, 68, 71, 72, 79, 80, 83, 303, 366, 370, 371], "research": 327, "resect": [323, 329], "resembl": 369, "reset": 353, "reset_calibrate_interv": [39, 40], "reset_calibrate_proba": 38, "reset_preprocess": [5, 54, 322], "reshap": [34, 35, 301], "reshuffl": [273, 274], "residu": [9, 34, 35, 59, 61, 62, 63, 64, 93, 210, 223, 224, 225, 226, 229, 230, 232, 233, 268, 271, 272, 274, 275, 276, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 316, 340, 349, 352, 356, 357, 364, 366, 368, 369, 370, 371, 379], "resili": [9, 34, 35, 77, 79, 80, 93, 211, 227, 316, 317, 340, 359, 364, 371, 379], "resilience_dist": [318, 320], "resilience_perf": [318, 320], "resilreli": 368, "resiz": [307, 344, 345], "resolut": 247, "respect": [133, 230, 273, 274, 323, 327, 329, 331, 334, 336, 339, 355, 356, 359, 360, 361, 365, 368, 370], "respons": [17, 18, 210, 223, 225, 226, 253, 273, 290, 291, 318, 320, 323, 327, 331, 332, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "response_kwarg": [210, 225], "response_method": [86, 235, 236, 238, 333, 334, 335, 337], "response_typ": [57, 58, 210, 225, 367, 368, 370], "rest": [63, 64, 236, 324, 328, 331, 333, 335, 338, 359, 368, 370, 371], "restrict": 359, "result": [0, 3, 4, 5, 6, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 43, 44, 45, 46, 49, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 114, 117, 118, 119, 120, 121, 122, 123, 124, 131, 132, 133, 180, 181, 199, 201, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 266, 278, 299, 300, 301, 302, 303, 317, 318, 319, 320, 324, 327, 328, 331, 332, 333, 336, 337, 338, 339, 350, 351, 353, 355, 357, 358, 359, 360, 361, 362, 365, 366, 368, 369, 370, 371, 374], "result1": 54, "result2": 54, "retain": 132, "retrain": [355, 359], "retriev": [246, 252, 307, 366, 370, 371, 375], "return": [29, 30, 32, 33, 54, 106, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 153, 156, 159, 164, 173, 179, 180, 181, 187, 192, 196, 198, 200, 201, 202, 203, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 307, 322, 329, 332, 334, 339, 376], "return_data": [334, 336], "return_html": [38, 40], "reus": 322, "reveal": [318, 320, 324, 331, 338, 369, 371], "revert": 4, "reweight": 369, "rewritten": 356, "rf": [367, 375], "rf2": 49, "rf_max_depth": [57, 58, 210, 225, 367, 368, 369, 370], "rf_n_estim": [57, 58, 210, 225, 367, 368, 369, 370], "rgba": 52, "ribeiro": 332, "ribeiro2016": [332, 336], "rich": 340, "ridg": [226, 366, 370], "right": [52, 319, 324, 327, 331, 332, 334, 336, 339, 356, 359, 360, 365, 366, 367], "right_inclus": 25, "rightarrow": 366, "rigor": 340, "risk": [355, 356, 360, 364, 365, 368, 371], "robsut": 370, "robust": [9, 34, 35, 75, 81, 83, 93, 123, 164, 210, 212, 217, 225, 228, 233, 316, 317, 326, 340, 351, 352, 356, 358, 359, 362, 364, 367, 369, 371, 379], "robustness_perf": [318, 320], "robustness_perf_worst": [318, 320], "roc": [61, 219, 367], "roc_auc": [53, 61, 219], "role": [332, 339], "root": 318, "rotat": [52, 345], "rough": [273, 274, 278], "roughli": 361, "round": [4, 275, 276], "row": [2, 3, 5, 8, 9, 17, 18, 30, 34, 35, 63, 64, 67, 68, 71, 72, 79, 80, 83, 247, 343, 350, 351, 352, 353, 361], "row_nam": 52, "royal": 331, "rr": [208, 220, 221, 222, 230], "rule": [331, 334, 362, 365], "run": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 49, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 106, 114, 117, 118, 119, 120, 121, 122, 123, 124, 131, 132, 133, 163, 204, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 262, 263, 266, 299, 300, 301, 302, 322, 326, 327, 342, 374], "run_id": [163, 204, 218, 234, 262, 263], "runtim": [300, 301, 302], "rush": 333, "rv": 302, "s3": 29, "s_1": 355, "s_2": 355, "s_i": 368, "s_l": 324, "s_m": [355, 356, 360], "s_r": 324, "said": 361, "same": [170, 171, 173, 195, 204, 237, 263, 320, 324, 328, 353, 361, 365, 367, 370, 371], "sameer": 332, "samesign": 52, "sampl": [0, 2, 3, 5, 7, 8, 19, 20, 29, 40, 63, 64, 67, 68, 71, 72, 75, 76, 112, 114, 117, 118, 119, 120, 121, 122, 123, 125, 131, 135, 136, 139, 140, 142, 162, 164, 168, 169, 172, 174, 177, 178, 180, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 220, 223, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 248, 252, 255, 256, 257, 258, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 300, 302, 303, 322, 323, 324, 325, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 344, 345, 346, 347, 348, 349, 351, 353, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371, 376], "sample_dataset": [213, 214, 215, 216, 217, 229, 230, 231, 232, 233], "sample_id": [213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 336, 339], "sample_idx": [6, 8, 180, 329], "sample_idx1": [7, 114, 303], "sample_idx2": [7, 114, 303], "sample_idx_by_llm": 252, "sample_index": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 57, 58, 87, 237, 240, 255, 256, 257, 258, 355, 356, 357, 358, 359, 360, 362, 367], "sample_method": [121, 122], "sample_s": [3, 6, 52, 57, 58, 86, 120, 121, 122, 123, 124, 125, 180, 210, 224, 225, 235, 236, 238, 239, 248, 273, 274, 329, 333, 334, 335, 337, 339, 367, 368, 370], "sample_weight": [135, 136, 184, 189, 225, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298], "sampler": [46, 300], "sampler_arg": 300, "san": 52, "sarinnapakorn": [324, 328], "satisfi": [356, 365], "save": [52, 152, 163, 260, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 350], "save_data": [54, 266], "save_img": 52, "save_model": [54, 266], "save_preprocess": 152, "save_testsuit": [54, 266], "saveasimag": 52, "scalabl": [273, 274], "scale": [5, 125, 164, 210, 225, 228, 320, 337, 340, 342, 351, 353, 355, 356, 357, 358, 359, 360, 362, 370], "scale_numer": [5, 14, 16, 17, 18, 19, 20, 22, 24, 26, 40, 44, 54, 58, 62, 64, 68, 71, 72, 75, 76, 80, 86, 322, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370], "scaler": 164, "scatter": [121, 122, 224, 316, 339, 341, 344, 346, 367], "scatterplot": 38, "scenario": [227, 318, 320, 324, 340, 367, 369, 370], "schema": 30, "scheme": [323, 324, 328, 329], "schoelkopf": 327, "sch\u00f6lkopf": 324, "sch\u00f6lkopf2001": 324, "scientist": 340, "scikit": [107, 269, 292, 293, 294, 324, 331, 335, 337, 338, 340, 358, 362, 374, 376], "scikitlearn": 376, "scipi": [46, 107, 300, 302, 323, 329, 374], "score": [2, 8, 9, 28, 36, 48, 71, 72, 114, 117, 118, 119, 131, 133, 210, 211, 212, 220, 221, 222, 223, 225, 226, 227, 228, 233, 251, 252, 254, 255, 256, 295, 296, 300, 328, 331, 332, 333, 338, 339, 355, 356, 360, 363, 365, 367, 369, 370, 379], "scoredmodel_californiah": 376, "scott": [332, 339], "screen": [273, 274, 275, 276, 277, 278, 344, 345], "script": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 373], "scroll": [344, 345], "seamless": [340, 363], "search": [42, 47, 48, 275, 276, 278, 299, 300, 301, 302, 379], "season": [4, 8, 9, 10, 14, 26, 52, 64, 68, 72, 80, 86, 337, 339, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "seciton": 363, "second": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 114, 273, 274, 318, 325, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "section": [0, 48, 93, 316, 318, 319, 320, 322, 323, 324, 325, 332, 333, 335, 339, 351, 361, 365, 366, 369, 370, 371], "see": [123, 301, 302, 319, 320, 324, 326, 327, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 344, 345, 351, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "seed": [29, 30, 117, 119, 120, 121, 122, 123, 124, 125, 131, 132, 133, 172, 180, 209, 210, 211, 212, 216, 217, 223, 224, 225, 227, 228, 232, 233, 235, 236, 237, 238, 239, 240, 248, 273, 274, 275, 276, 277, 286, 287, 290, 291, 300, 301, 302, 347], "seem": [338, 339], "segment": [9, 34, 35, 63, 64, 67, 68, 71, 72, 79, 80, 83, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 317, 340, 359, 368, 369, 371], "segment1": [63, 67, 68, 71, 79, 80], "segment2": [63, 67, 68, 71, 79, 80], "segment_info": [213, 214, 215, 216, 217, 229, 230, 231, 232, 233], "select": [0, 1, 11, 14, 30, 44, 114, 119, 126, 127, 128, 129, 130, 131, 132, 133, 134, 155, 162, 164, 166, 193, 194, 213, 215, 216, 217, 224, 227, 229, 230, 231, 232, 233, 235, 237, 238, 240, 253, 255, 256, 257, 258, 273, 274, 278, 316, 318, 320, 321, 324, 328, 331, 333, 340, 353, 355, 358, 359, 365, 366, 367, 368, 369, 370, 374, 379], "self": [175, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307], "sens": 336, "sensit": [123, 228, 320, 324, 325, 326, 339, 346, 365, 367, 370, 371], "separ": [228, 229, 230, 231, 232, 233, 324, 325, 328, 355, 356, 367], "septemb": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "sequenc": [266, 356], "sequenti": [273, 274, 327, 356, 357], "seri": [52, 331], "seriesasc": 52, "serieslayoutbi": 52, "serif": 52, "serv": [307, 318, 324, 328, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371, 375], "session": 30, "set": [1, 2, 4, 7, 11, 19, 20, 29, 30, 63, 64, 67, 68, 71, 72, 79, 80, 83, 112, 114, 119, 122, 125, 132, 144, 151, 158, 165, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 180, 209, 210, 211, 213, 214, 215, 216, 217, 219, 223, 225, 229, 230, 231, 232, 233, 237, 239, 249, 251, 252, 253, 254, 255, 258, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 305, 306, 318, 320, 322, 323, 324, 325, 327, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 376, 379], "set_active_featur": [4, 322], "set_active_sampl": 329, "set_feature_typ": [356, 357, 359, 360, 366, 367, 368, 369, 370], "set_inactive_featur": [2, 10, 54, 63, 322, 355, 356, 357, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "set_inactive_sampl": 8, "set_legend": 40, "set_mlflow_hom": [0, 49], "set_param": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "set_predict": [9, 35, 376], "set_prediction_proba": 34, "set_protected_data": [83, 365], "set_protected_extra_data": 83, "set_random_split": [2, 4, 5, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 44, 45, 46, 49, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 322, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "set_raw_extra_data": [10, 83], "set_sample_weight": [2, 322], "set_target": [2, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 54, 57, 58, 62, 63, 64, 83, 322, 358, 362, 365, 371, 376], "set_task_typ": [29, 54, 175], "set_test_idx": [9, 29, 30, 31, 32, 33, 34, 35, 376], "set_train_idx": [9, 29, 30, 31, 32, 33, 34, 35, 376], "set_xaxi": [38, 40], "set_yaxi": [38, 40], "setup": [355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "sever": [48, 329, 332, 339, 356, 365, 366, 367, 368, 369, 370, 371, 374], "sex": [2, 3, 5, 13, 25, 63, 83, 365, 371], "sex_2": [2, 5], "shade": 333, "shadowcolor": 52, "shallow": 359, "shap": [107, 240, 330, 340, 348, 356], "shap_": 339, "shap_fi": 339, "shap_scatt": 339, "shap_summari": 339, "shap_waterfal": 339, "shapblog": 339, "shape": [6, 8, 31, 32, 33, 34, 35, 40, 49, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 343, 355, 356, 376], "shaplei": [31, 240, 330, 340, 348], "share": [344, 345], "shaw": 324, "shengchun": [324, 328], "shift": [209, 210, 211, 225, 228, 318, 320, 323, 340, 349, 359, 368, 369, 370, 371], "shim": 324, "short": 359, "shorter": [324, 328], "should": [32, 33, 125, 152, 170, 171, 173, 180, 222, 229, 230, 231, 232, 233, 246, 273, 274, 286, 287, 331, 332, 333, 334, 337, 338, 355, 356, 360, 365, 370, 376], "show": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 51, 52, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 114, 117, 118, 119, 120, 121, 122, 123, 124, 131, 132, 133, 199, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 260, 299, 300, 301, 302, 307, 318, 320, 324, 326, 333, 334, 335, 336, 337, 338, 339, 347, 356, 358, 361, 362, 366, 367, 368, 369, 370, 373], "show_featur": 323, "showcas": 375, "showcont": 52, "showminlabel": 52, "shown": [246, 301, 318, 323, 333, 334, 339, 361, 365, 367], "showtitl": 52, "shrink": 361, "shrinkag": [275, 276], "shu": [324, 328], "shuffl": [172, 180, 329, 331, 338], "shutdown": 29, "shyam": 327, "shyu": [324, 328], "shyu2003": [324, 328], "side": [326, 366, 369], "sigkdd": 332, "sigma": [327, 360, 361, 366, 370], "sigma_": [327, 366], "sigmod": 324, "sigmoid": [267, 269, 270, 273, 274, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 360, 361], "signifi": 319, "signific": [123, 132, 320, 326, 327, 331, 332, 338, 339, 349, 355, 356, 365, 368, 369], "significantli": [320, 323, 324, 328, 333, 336, 365, 366, 369], "silent": [38, 40, 49, 206], "similar": [213, 214, 215, 216, 217, 222, 229, 230, 231, 232, 233, 273, 274, 318, 323, 324, 331, 333, 335, 336, 339, 359, 365, 366, 367, 369, 370, 374], "similarli": [320, 324], "simpl": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 324, 333, 365, 367, 371], "simpler": 361, "simplest": 366, "simpli": 357, "simplif": 365, "simplifi": [23, 24, 275, 276, 278, 340, 342, 353, 356, 361, 365, 375], "simucredit": [43, 46, 54, 148, 319, 322, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353], "simucredit_md": [342, 347, 348, 349, 350, 351, 352], "simul": [8, 332, 336, 339, 367, 369, 370], "simultan": [346, 355], "sinc": [319, 320], "singh": 332, "singl": [52, 53, 67, 68, 71, 72, 75, 76, 79, 80, 83, 120, 210, 212, 225, 228, 229, 230, 231, 232, 233, 235, 237, 238, 246, 247, 255, 258, 307, 318, 320, 331, 333, 337, 339, 355, 356, 357, 360, 361, 362, 366, 374], "site": 338, "size": [9, 34, 35, 57, 58, 63, 64, 67, 68, 71, 72, 79, 80, 83, 117, 120, 124, 164, 180, 210, 213, 214, 215, 216, 217, 224, 225, 229, 230, 231, 232, 233, 239, 259, 273, 274, 275, 276, 290, 291, 307, 318, 320, 323, 324, 328, 337, 347, 351, 353, 355, 356, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371, 374], "skew": [324, 366, 367, 371], "skip": [284, 285], "sklearn": [8, 28, 30, 32, 33, 34, 35, 36, 48, 270, 271, 272, 279, 280, 283, 288, 289, 322, 324, 328, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 373, 379], "skmlp": 376, "slice": [9, 34, 35, 60, 65, 89, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 303, 318, 320, 333, 337, 340, 352, 364, 368, 370, 379], "slice_featur": [318, 320], "sliced_lin": [333, 337], "slicing_util": [0, 63, 64, 67, 68, 71, 72, 79, 80, 83, 366, 370, 371], "slight": [320, 370], "slightli": [318, 327, 355, 360], "slow": [346, 351], "slower": [332, 339], "small": [79, 80, 117, 228, 324, 328, 331, 332, 333, 339, 355, 357, 360, 361, 366, 369, 370], "smalldata": 29, "smaller": [124, 208, 214, 220, 221, 222, 230, 235, 273, 274, 355, 360, 361, 362, 371], "smallest": [144, 320], "smd": [208, 220, 221, 222, 230, 365], "smirnov": [114, 323, 329], "smola": 324, "smooth": [3, 121, 221, 286, 287, 355, 365, 366], "smoother": [247, 356], "smoother_ord": [3, 121], "sne": 324, "snippet": 335, "so": [5, 210, 225, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 320, 325, 327, 331, 332, 336, 338, 339], "soccer": [332, 339], "social": [365, 374], "societ": 365, "societi": 331, "soft": 359, "softmax": 359, "sole": [325, 332, 339], "solid": [52, 340], "solut": [300, 301, 302, 368, 369], "some": [273, 274, 318, 322, 324, 331, 337, 338, 355, 356, 357, 359, 360, 361, 365, 366, 367, 368, 369, 370], "sometim": 376, "sort": [324, 327, 369], "sound": [355, 360], "sourc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 187, 322], "space": [119, 125, 210, 225, 228, 236, 238, 273, 274, 277, 278, 284, 285, 324, 328, 351, 359, 366, 367, 368, 369, 370, 371, 374], "spap": 339, "spark": [30, 154], "spark_df": 30, "sparksess": 30, "spars": [119, 355, 356, 360, 368, 371], "sparse_pca": 119, "sparsiti": [119, 355, 358, 370], "spearman": [3, 123, 326], "speci": 322, "special": [5, 144, 284, 285, 316, 322, 359, 361, 366, 368, 369], "special_valu": [5, 144, 322], "specif": [57, 58, 79, 112, 164, 212, 213, 214, 215, 216, 217, 227, 229, 230, 231, 232, 233, 237, 240, 246, 252, 255, 256, 257, 258, 318, 319, 320, 323, 324, 325, 328, 329, 331, 332, 333, 335, 337, 338, 346, 347, 348, 349, 351, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "specifi": [52, 112, 114, 115, 117, 118, 120, 121, 122, 123, 124, 125, 126, 131, 133, 164, 180, 181, 207, 209, 211, 213, 214, 215, 216, 217, 219, 220, 221, 224, 229, 230, 231, 232, 233, 235, 238, 240, 247, 254, 255, 256, 275, 276, 290, 291, 299, 300, 301, 302, 307, 318, 320, 325, 327, 329, 332, 333, 337, 338, 339, 351, 355, 360, 361, 367, 368, 370, 374], "spectral": 367, "speed": [235, 236, 238, 239, 240, 323, 333, 334, 335, 337, 339, 356], "speedup": [210, 225], "sphinx": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 89], "sphx_glr__source_auto_galleries_dev_1_extmodels_plot_1_arbitrari": 376, "sphx_glr__source_auto_galleries_dev_1_extmodels_plot_2_scor": 376, "sphx_glr_auto_examples_0_data_plot_1_data_summari": 325, "sphx_glr_auto_examples_0_data_plot_4_data_qu": [323, 324], "sphx_glr_auto_examples_1_train_plot_2_register_1_h2o": 373, "sphx_glr_auto_examples_2_explain_plot_0_pfi": 338, "sphx_glr_auto_examples_2_explain_plot_1_pdp": 337, "sphx_glr_auto_examples_2_explain_plot_1_pdp_hstat": 334, "sphx_glr_auto_examples_2_explain_plot_2_ic": 335, "sphx_glr_auto_examples_2_explain_plot_3_al": 333, "sphx_glr_auto_examples_2_explain_plot_4_lim": 336, "sphx_glr_auto_examples_2_explain_plot_5_shap": 339, "sphx_glr_auto_examples_2_explain_plot_6_data_dependent_explain": [333, 334, 335, 336, 337, 338, 339], "sphx_glr_auto_examples_5_compare_plot_0_compare_classif": 318, "sphx_glr_auto_examples_5_compare_plot_0_compare_regress": 320, "sphx_glr_auto_examples_5_compare_plot_1_compare_fair": 319, "split": [0, 2, 23, 24, 25, 26, 29, 30, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 133, 135, 136, 137, 138, 139, 140, 142, 143, 146, 171, 172, 173, 180, 209, 210, 219, 223, 225, 232, 250, 268, 271, 272, 274, 275, 276, 277, 278, 280, 282, 284, 285, 287, 289, 291, 292, 294, 296, 298, 299, 300, 301, 302, 322, 324, 328, 331, 333, 340, 343, 344, 345, 346, 347, 348, 349, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 369, 370, 371], "split_custom": [23, 24, 275, 276, 277, 278], "split_fram": 29, "splitarea": 52, "splitlin": 52, "splitnumb": 52, "splitter": [15, 16, 299, 300, 301, 302], "sport": [332, 339], "sq_residu": [210, 225], "sq_residual_perturb": [210, 225], "sql": 30, "squar": [5, 164, 210, 225, 318, 322, 324, 328, 356, 359, 361, 367, 369, 370], "squared_error": 16, "squarederror": [9, 40, 62], "sridhar": 324, "stabil": [114, 118, 217, 228, 323, 329, 340, 347, 349, 358, 359, 366, 369, 370], "stabl": [133, 355, 356, 357, 358, 360, 361, 366, 370], "stack": [121, 326], "stackstrategi": 52, "stage": [23, 24, 132, 273, 274, 327], "stake": [365, 368], "stand": [115, 173], "standalon": 353, "standard": [119, 124, 164, 208, 210, 220, 221, 222, 225, 228, 251, 253, 322, 325, 327, 331, 333, 342, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370], "start": [350, 351, 355, 356, 360, 361, 366], "start_tim": 49, "stat": [46, 300, 302, 323, 329, 374], "state": [332, 339, 342, 347, 352, 361], "static": 361, "statist": [123, 181, 211, 213, 216, 227, 236, 251, 253, 254, 286, 287, 290, 291, 322, 323, 326, 327, 329, 330, 335, 340, 343, 361, 365, 367, 368, 370, 371], "statu": [54, 131, 132, 133, 322, 344, 345, 350, 351, 353, 365], "std": [3, 5, 17, 18, 164, 253, 325, 366], "std_dev": 251, "steep": [227, 360], "stem": [237, 255, 256, 336, 358, 361], "step": [112, 132, 136, 152, 161, 163, 266, 284, 285, 290, 291, 322, 324, 327, 328, 331, 332, 338, 339, 353, 356, 361, 368, 369, 370, 374, 376], "step_log": 132, "still": [324, 333, 335, 355, 360, 376], "stop": [23, 24, 273, 274, 275, 276, 286, 287, 290, 291, 327, 366, 370], "store": [52, 112, 269, 292, 307, 343, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "str": [34, 35, 52, 106, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 147, 148, 149, 152, 153, 154, 160, 163, 164, 165, 166, 167, 168, 169, 171, 173, 174, 175, 176, 180, 181, 195, 197, 198, 199, 201, 202, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307], "straightforward": [332, 336, 337, 370], "strategi": [112, 114, 144, 211, 227, 284, 285, 299, 300, 301, 302, 327, 328, 340, 364], "stratif": [180, 329], "stratifi": [180, 300, 301, 302, 329, 366], "streamlin": [340, 346, 350, 351], "strength": [123, 131, 236, 273, 274, 275, 276, 277, 278, 286, 287, 290, 291, 326, 327, 331, 334, 347, 349, 355, 357, 358, 360, 361, 365], "stress": 227, "strict": [355, 360], "strike": 366, "string": [53, 144, 273, 274, 284, 285, 286, 287, 290, 291, 318, 320, 325, 374], "strobl": 327, "strobl2019": 327, "strong": [123, 326], "stronger": [226, 236, 331, 334, 355, 356, 357, 358, 359, 360, 370], "strongli": [331, 333, 355, 360], "structur": [125, 181, 213, 247, 250, 255, 277, 278, 299, 300, 301, 302, 303, 324, 328, 332, 339, 343, 346, 353, 355, 356, 357, 360, 361, 362, 367, 369, 370], "struggl": [367, 369, 371], "style": [28, 36, 48, 52, 363, 373, 376, 379], "su": [332, 339], "sub": [273, 274, 368, 370], "sub_item": 208, "subgroup": [346, 359, 365, 369], "subitem": 207, "subject": [212, 273, 274, 327, 366, 371], "sublink": 52, "submodul": 324, "subnet_size_interact": [273, 274], "subnet_size_main_effect": [273, 274], "subnetwork": [273, 274, 355], "subobject": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298], "suboptim": 359, "subpopul": [359, 369], "subsampl": [1, 11, 23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 122, 124, 125, 135, 139, 140, 142, 180, 224, 236, 238, 316, 321, 324, 332, 333, 334, 335, 337, 339, 379], "subsample_for_bin": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "subsample_freq": [23, 24, 25, 26, 43, 45, 46, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "subsample_random": [6, 329], "subscript": 365, "subsect": [324, 373], "subsequ": [112, 324, 356], "subset": [210, 225, 227, 239, 300, 319, 324, 327, 331, 333, 334, 335, 337, 339, 346, 362, 366, 367, 369, 371], "subseteq": [332, 339], "substanti": 337, "subtarget": 52, "subtext": 52, "subtract": [237, 255, 256, 333, 336, 356], "success": [332, 339], "successfulli": [2, 57], "sudjianto2020": 361, "suffer": 320, "suffici": 369, "suffix": 342, "suggest": [236, 320, 323, 324, 331, 333, 337, 339, 365, 367], "suit": [0, 264, 265, 316, 325, 326, 340, 347, 349, 353], "suitabl": [324, 328, 340, 367, 370], "sum": [236, 285, 323, 324, 327, 328, 329, 355, 356, 357, 358, 359, 360, 361], "sum_": [323, 324, 327, 329, 331, 332, 333, 334, 337, 339, 355, 356, 357, 359, 360, 361, 366, 367, 369, 370], "sum_i": [359, 360], "sum_j": [356, 357, 369], "sum_k": [355, 356, 360], "sum_m": 356, "summar": [229, 231, 233, 259, 320, 325, 344, 365, 367, 370, 371], "summari": [7, 21, 22, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 114, 208, 209, 211, 212, 220, 223, 225, 227, 228, 240, 253, 316, 321, 340, 341, 344, 349, 359, 366, 367, 368, 369, 370, 371], "sup_": 369, "sup_x": [323, 329], "supabas": 107, "superior": 319, "supervis": [331, 364], "supplement": 353, "support": [120, 121, 122, 125, 126, 176, 208, 214, 220, 222, 229, 230, 231, 232, 233, 235, 237, 286, 287, 290, 291, 307, 320, 322, 324, 326, 329, 332, 333, 339, 340, 351, 352, 356, 359, 365, 370, 374], "suppos": [331, 332, 337, 339, 376], "surpris": 338, "surrog": [332, 336, 339], "survei": 327, "sv1": [5, 322], "sv2": [5, 322], "svg": 307, "swarm": [42, 47, 48, 301, 359, 379], "switch": [343, 348], "symbol": 305, "symmetr": [123, 331, 334], "system": [267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 320, 332, 333, 334, 335, 336, 337, 338, 339, 340, 365], "systemat": [365, 367, 370, 371], "t": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 43, 44, 45, 46, 49, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 116, 275, 276, 303, 324, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "t_k": 356, "tab": [343, 346, 348, 353], "tabl": [3, 5, 8, 9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 34, 35, 38, 43, 44, 45, 46, 52, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 79, 80, 83, 86, 114, 117, 118, 119, 123, 124, 125, 131, 132, 133, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 253, 255, 256, 260, 299, 300, 301, 302, 307, 322, 323, 342, 343, 349, 355, 356, 357, 358, 359, 360, 362, 365, 366, 367, 368, 370, 371, 374, 376], "tabular": [240, 246, 248, 299, 300, 301, 302], "tag": [160, 204, 263, 331, 332, 333, 334, 337, 339, 355, 361], "tailor": [359, 368, 369], "taiwancredit": [2, 3, 5, 7, 13, 15, 17, 19, 21, 23, 25, 38, 39, 45, 49, 53, 57, 61, 63, 67, 71, 75, 79, 83, 87, 148, 318, 322, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371], "taiwancreditdata": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "take": [230, 269, 292, 324, 328, 332, 339, 346], "taken": 320, "tanh": [273, 274, 376], "target": [2, 5, 29, 30, 31, 32, 33, 52, 126, 131, 164, 175, 194, 209, 210, 216, 223, 224, 225, 236, 238, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 322, 323, 327, 329, 331, 333, 337, 338, 342, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376], "target_featur": 54, "target_nam": [31, 32, 33, 322, 376], "task": [175, 176, 182, 208, 209, 216, 220, 221, 223, 224, 232, 235, 236, 237, 238, 240, 268, 271, 272, 274, 276, 278, 280, 282, 284, 285, 287, 289, 290, 291, 292, 294, 296, 298, 318, 322, 324, 328, 331, 333, 334, 335, 337, 338, 339, 340, 342, 347, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374, 376], "task_typ": [54, 176, 223, 268, 271, 272, 274, 276, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 373], "tau": [123, 326, 359, 368], "tau_1": 368, "tau_2": 368, "taylor": 324, "teacher": [273, 274], "team": [332, 339], "technic": 333, "techniqu": [324, 328, 340, 346, 365, 366, 368, 369, 370, 371, 374], "tell": 333, "temp": [4, 8, 9, 10, 52, 64, 68, 72, 80, 325, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "temperatur": 359, "templat": [293, 294], "tempor": 367, "temporari": 327, "temporarili": 327, "tend": [337, 361, 366], "tendenc": [355, 360], "term": [251, 254, 319, 332, 336, 339, 355, 356, 357, 359, 360, 361, 366, 368, 369, 371], "termin": [17, 18, 23, 24, 359, 360, 370], "test": [0, 1, 2, 9, 10, 11, 13, 14, 15, 16, 19, 20, 23, 24, 25, 26, 38, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 66, 67, 68, 71, 72, 83, 86, 87, 89, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 151, 164, 172, 173, 177, 180, 181, 183, 184, 185, 186, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 265, 284, 285, 299, 300, 301, 302, 303, 316, 318, 320, 322, 324, 329, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 353, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 367, 368, 369, 371, 375, 376, 379], "test1": 234, "test2": 234, "test_dataset": [9, 34, 35, 38, 54, 61, 62, 67, 68, 71, 72, 207, 209, 215, 216, 219, 223, 231, 232, 365, 366, 367, 368, 371], "test_explain": 348, "test_i": [2, 38, 39, 40], "test_idx": [9, 31, 32, 33, 34, 35, 177, 376], "test_indic": [30, 34, 35], "test_list": 234, "test_model": 54, "test_ratio": [54, 172], "test_result": 263, "test_sample_s": [336, 339], "test_sample_weight": 2, "test_scor": [207, 219], "test_siz": [31, 32, 33, 34, 35, 71, 72, 209, 216, 223, 232, 368, 376], "test_weak": 352, "test_x": [2, 38, 39, 40], "testsuit": [0, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 43, 44, 45, 46, 49, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "testsuite_nam": 234, "text": [52, 357, 359, 365, 366, 367, 368, 369, 370], "textalign": 52, "textbf": [331, 333, 355, 361], "textbordertyp": 52, "textgap": 52, "textshadowcolor": 52, "textstyl": 52, "textverticalalign": 52, "th": [225, 324, 328, 331, 332, 333, 334, 337, 339, 356, 361], "than": [123, 144, 226, 235, 236, 273, 274, 318, 319, 320, 324, 325, 326, 327, 331, 332, 333, 334, 335, 336, 337, 339, 357, 361, 366, 374], "thei": [238, 322, 324, 328, 331, 332, 337, 339, 356, 361, 365], "theil": [123, 131, 327], "theilsu": 327, "them": [49, 114, 123, 219, 322, 326, 327, 357, 363, 365, 366, 369, 376], "theoret": 369, "theori": 327, "therebi": [324, 359], "therefor": [331, 332, 333, 336, 339, 361], "theta": [355, 359, 360], "theta_i": 360, "thi": [0, 5, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 48, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 156, 160, 166, 173, 179, 180, 181, 199, 204, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 307, 316, 318, 319, 320, 322, 323, 324, 325, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 373, 374, 376], "third": [121, 273, 274, 325, 343, 344, 345, 361], "thorough": 370, "those": [302, 319, 320, 365, 370], "three": [122, 208, 214, 220, 222, 230, 273, 274, 318, 320, 323, 325, 326, 327, 328, 345, 355, 359, 360, 370, 371], "threre": 365, "threshold": [4, 8, 9, 34, 35, 63, 64, 67, 68, 71, 72, 79, 80, 83, 117, 118, 119, 131, 132, 133, 208, 213, 214, 215, 216, 217, 220, 222, 223, 228, 229, 230, 231, 232, 233, 273, 274, 303, 324, 327, 328, 349, 356, 357, 360, 366, 367, 368, 370, 371], "through": [121, 124, 133, 221, 247, 258, 286, 287, 290, 291, 320, 326, 344, 351, 354, 355, 357, 358, 359, 360, 361, 362, 364, 366, 368, 371, 374], "throuput": 340, "ti": [229, 230, 232, 233], "tild": 361, "time": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 115, 118, 123, 133, 173, 210, 212, 217, 225, 228, 235, 239, 247, 273, 274, 323, 327, 332, 338, 339, 350, 351, 353, 361, 368, 369], "time_cost_": [273, 274], "ting": [324, 328], "titl": [52, 266], "tn": 367, "to_df": [5, 9], "toarrai": 30, "togeth": [195, 355, 360, 365], "token": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "tol": [14, 44], "toler": [273, 274], "tolist": 30, "toni": [324, 328], "too": [320, 331, 332, 333, 339, 346, 361, 366], "tool": [238, 326, 331, 332, 336, 337, 339, 340, 343, 352, 367, 373, 377], "toolbox": 52, "tooltip": [52, 122], "top": [52, 252, 253, 273, 274, 277, 307, 318, 320, 322, 324, 325, 327, 334, 336, 355, 359, 361, 368], "top1": [3, 325], "top2": [3, 325], "top3": [3, 325], "torch": [107, 273, 274, 290, 291], "total": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 259, 343, 355, 356, 360, 361, 366, 370, 379], "toward": [361, 365, 369], "tp": 367, "tp_": 365, "tpe": [46, 300], "tpesampl": 300, "tpr": [365, 367], "tqdm": 107, "track": [144, 324, 340, 369, 370], "trade": [240, 300, 301, 302, 368], "tradeoff": [222, 366], "tradit": [324, 355, 357, 358, 359, 360, 367], "train": [0, 2, 5, 7, 9, 10, 23, 24, 29, 30, 31, 34, 35, 38, 43, 44, 45, 46, 53, 54, 57, 58, 61, 62, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 151, 164, 172, 173, 178, 180, 181, 188, 189, 190, 191, 197, 199, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 297, 298, 299, 300, 301, 302, 316, 318, 320, 322, 323, 324, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342, 343, 344, 345, 346, 349, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 367, 368, 369, 370, 371, 374, 376], "train_al": [49, 375], "train_dataset": [9, 34, 35, 38, 54, 61, 62, 67, 68, 71, 72, 207, 209, 215, 216, 219, 223, 231, 232, 365, 366, 367, 368, 371], "train_epoch_loss_": [290, 291], "train_i": [2, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 44, 45, 46, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "train_idx": [9, 31, 32, 33, 34, 35, 178, 376], "train_indic": [30, 34, 35], "train_model": 54, "train_sample_s": [336, 339], "train_sample_weight": 2, "train_scor": [207, 219], "train_siz": 180, "train_test_split": [31, 32, 33, 34, 35, 376], "train_x": [2, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 44, 45, 46, 49, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 301, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "training_fram": 29, "transfom": [355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "transform": [30, 112, 119, 124, 126, 164, 226, 322, 324, 327, 328, 332, 339, 353, 361, 366, 367, 368, 369, 370, 373], "transitiondur": 52, "translat": 367, "transpar": [52, 356, 361], "travers": [258, 362], "treat": [144, 173, 301, 327], "treatment": [222, 340], "tree": [12, 27, 48, 118, 209, 210, 215, 216, 223, 225, 226, 247, 249, 250, 255, 258, 268, 270, 271, 272, 274, 275, 276, 277, 278, 280, 282, 285, 286, 287, 289, 291, 292, 294, 296, 298, 300, 316, 318, 324, 328, 331, 332, 336, 337, 339, 340, 354, 355, 359, 367, 368, 369, 370, 374, 379], "tree_": [277, 278], "tree_method": 301, "treeclassifi": 339, "treeregressor": 339, "treeshap": 339, "trend": [121, 344, 357, 366, 367], "trial": [5, 9, 10, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 54, 83], "trigger": [52, 337], "triggeron": 52, "trivial": [355, 361], "troubleshoot": 341, "true": [2, 5, 9, 13, 14, 17, 18, 19, 20, 23, 24, 25, 26, 29, 34, 35, 38, 40, 44, 49, 52, 54, 57, 58, 63, 64, 67, 68, 71, 72, 79, 80, 83, 119, 144, 146, 172, 180, 187, 208, 214, 220, 221, 222, 224, 230, 234, 237, 255, 256, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307, 322, 324, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 375], "truncat": [331, 338], "trust": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 332], "trustworthi": [355, 360, 365, 368, 371], "truth": [267, 269, 270, 273, 275, 277, 279, 281, 283, 284, 286, 288, 290, 293, 295, 297, 376], "try": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 299, 300, 302], "ts_residu": [57, 58, 367], "tsamardino": 327, "tsc": [38, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 365, 366, 367, 369, 370, 371], "tset_task_typ": 322, "tulio": 332, "tune": [0, 23, 24, 47, 49, 54, 93, 269, 273, 274, 286, 287, 292, 299, 300, 301, 302, 316, 324, 340, 341, 347, 350, 353, 355, 360, 363, 379], "tupl": [53, 106, 112, 114, 123, 124, 125, 126, 144, 164, 165, 167, 207, 210, 211, 212, 217, 219, 221, 222, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 238, 246, 247, 248, 273, 274, 286, 287, 290, 291, 299, 300, 301, 302, 307, 358, 361, 365], "tutori": 376, "tw": 5, "twcredit": 353, "twice": 327, "two": [3, 114, 119, 121, 123, 132, 231, 232, 233, 235, 236, 238, 247, 248, 319, 323, 324, 325, 326, 327, 328, 329, 331, 332, 334, 335, 336, 339, 344, 353, 356, 357, 361, 365, 366, 367, 368, 369, 370], "tx": 360, "type": [2, 52, 111, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 164, 166, 175, 176, 180, 181, 182, 187, 192, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 307, 322, 324, 326, 327, 328, 342, 350, 351, 352, 353, 357, 358, 365, 367, 368, 370, 373], "type_": 52, "typic": [123, 125, 324, 326, 331, 338, 356, 367, 368, 369, 374], "u": [107, 123, 131, 324, 327, 328, 331, 333, 337, 338, 365, 367, 370], "u_": [355, 356, 360], "uci": [318, 320, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "ultim": [254, 367], "umap": [107, 125], "umer": 322, "unabl": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "unbias": [331, 333], "uncent": [331, 333, 336, 355, 356, 357, 358, 360, 361], "uncertain": [369, 371], "uncertainti": [320, 327, 340, 368, 369, 370, 371], "unchang": [331, 336, 338, 370], "uncov": [344, 345, 359, 367, 371], "under": [67, 68, 71, 72, 79, 80, 83, 209, 211, 212, 217, 226, 227, 228, 233, 254, 318, 320, 324, 327, 328, 340, 349, 351, 365, 367, 368, 369, 370, 371], "underbrac": 366, "underestim": 366, "underfit": [219, 316, 327, 364, 367], "undergo": [318, 320], "underli": [267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298, 324, 356, 358, 362, 367], "underperform": [367, 369, 371], "understand": [227, 238, 324, 326, 335, 343, 359, 361, 365, 367, 368, 369, 371], "understood": 366, "uneven": 371, "unfair": [208, 220, 221, 222, 319, 365], "unfit": [286, 287], "uni_featur": [333, 335, 337], "unifi": [332, 356], "uniform": [21, 22, 46, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 112, 114, 210, 213, 214, 215, 216, 217, 221, 222, 225, 226, 228, 229, 230, 231, 232, 233, 318, 320, 322, 323, 342, 346, 352, 359, 365, 366, 367, 368, 369, 374], "uniformli": [273, 274, 300, 302, 352, 359, 371], "union": [229, 230, 231, 232, 233], "uniqu": [3, 5, 322, 324, 325, 328, 342, 343, 350, 356, 359, 360, 361, 369], "unit": 164, "univ": [324, 328], "univari": [120, 321, 324, 340, 365, 368, 369, 370], "unless": [299, 300, 301, 302, 318, 320], "unlik": [318, 320, 324, 332, 339, 356, 367], "unmodel": 367, "unnecessarili": 361, "unpen": 361, "unprivileg": 365, "unreli": [71, 209, 211, 216, 223, 232, 233, 331, 333, 365, 368], "unseen": [323, 366, 367], "unstabl": 361, "unsupervis": [324, 367], "unsupport": 307, "until": [324, 328, 355, 356, 359, 360], "unus": 353, "unusu": 367, "unwrap": 361, "unwrapp": 253, "up": [40, 107, 235, 236, 238, 323, 331, 333, 334, 335, 337, 339, 344, 345, 356], "updat": [2, 107, 166, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 343, 353, 356, 357, 359], "upon": 361, "upper": [83, 208, 214, 220, 221, 222, 230, 236, 238, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 365], "upper_inclus": [83, 208, 214, 220, 221, 222, 230, 365], "us": [2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 48, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 135, 136, 139, 140, 142, 143, 144, 147, 152, 153, 160, 164, 168, 169, 173, 174, 175, 180, 181, 187, 199, 201, 202, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 373, 374, 375, 376], "usag": [51, 323, 324, 363], "use_multi_thread": 29, "use_predict": [57, 58, 224], "use_test": [333, 334, 335, 336, 337, 338, 339], "use_weight": 117, "user": [120, 211, 300, 305, 322, 324, 325, 327, 340, 346, 350, 351, 352, 353, 356, 358, 362, 363, 371], "usual": [331, 332, 333, 338, 339, 374], "util": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 107, 215, 216, 319, 320, 322, 324, 328, 353, 366, 370], "v": [208, 220, 240, 300, 301, 302, 327, 329, 344, 349, 367, 368, 369, 370], "v_": 359, "v_m": [355, 356, 360], "val": [332, 339], "val_ratio": [273, 274, 275, 276, 286, 287, 290, 291], "valid": [0, 9, 17, 18, 23, 24, 52, 93, 223, 230, 247, 255, 263, 266, 273, 274, 275, 276, 284, 285, 286, 287, 290, 291, 299, 300, 301, 302, 307, 336, 339, 340, 348, 355, 360, 366, 367, 373, 374, 377], "validation_epoch_loss_": [290, 291], "validationresult": [0, 51, 55, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 263, 299, 300, 301, 302, 379], "valu": [4, 5, 6, 21, 22, 25, 29, 31, 43, 44, 45, 46, 52, 57, 58, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 112, 114, 117, 118, 119, 123, 124, 125, 126, 131, 132, 133, 144, 164, 180, 181, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 251, 252, 254, 255, 256, 257, 259, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 319, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 347, 351, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 374], "valuabl": [238, 324, 338, 369], "valueerror": [235, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 307], "var": 366, "vari": [236, 238, 335, 336, 359, 365, 371], "variabl": [3, 7, 79, 80, 83, 123, 124, 125, 126, 131, 136, 224, 226, 238, 267, 268, 270, 271, 272, 279, 280, 281, 282, 283, 284, 285, 288, 289, 297, 298, 305, 306, 318, 319, 320, 323, 324, 326, 327, 328, 329, 331, 335, 338, 339, 340, 346, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 369, 371], "varialb": 226, "varianc": [119, 124, 164, 226, 236, 324, 326, 328, 339, 355, 356, 357, 358, 359, 360, 366, 367], "variat": [228, 369, 370], "variou": [49, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 112, 114, 121, 144, 164, 181, 208, 209, 212, 215, 216, 217, 220, 230, 233, 318, 320, 323, 324, 328, 332, 339, 355, 365, 370], "vdot": 357, "vector": [30, 324, 332, 333, 339, 356, 359, 361], "vectorassembl": 30, "veloc": 359, "vendor": 376, "verbos": [17, 18, 23, 24, 25, 26, 31, 32, 33, 43, 45, 46, 49, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 273, 274, 275, 276, 286, 287, 290, 291], "veri": [273, 274, 319, 331, 333, 336, 338, 355], "verifi": [355, 360], "versa": 361, "version": [2, 49, 107, 113, 136, 139, 140, 142, 143, 153, 162, 187, 193, 194, 202, 255, 323, 329], "vertic": 52, "via": [23, 24, 225, 331, 334, 355, 359, 363, 368, 369, 370], "vice": 361, "vicin": 324, "victori": [332, 339], "view": [2, 123, 250, 326, 331, 333, 337, 338, 339, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362], "viewport": 122, "violat": [355, 360, 365, 368], "violin": 254, "visual": [51, 55, 67, 68, 107, 114, 117, 118, 119, 120, 121, 122, 123, 124, 131, 132, 133, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 246, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 299, 300, 301, 302, 307, 324, 326, 331, 333, 335, 337, 340, 347, 349, 351, 355, 356, 361, 362, 366, 367, 368, 370, 371, 379], "visualmap": 52, "visualmap_typ": 52, "visweswaran": 327, "vulner": [227, 340, 359, 369], "w": [331, 360, 361, 368, 369, 370], "w_": 366, "w_1": 358, "w_2": 358, "w_d": 358, "w_i": [360, 366, 370], "wai": [238, 243, 320, 323, 324, 331, 332, 335, 339, 357, 361, 367, 368, 376], "wang": 327, "want": [325, 332, 335, 337, 339, 342], "warm_start": [14, 44, 273, 274], "wasserstein": [114, 323, 329, 340], "wasserstein_dist": [323, 329], "wd": 340, "wd1": [114, 323, 329], "we": [9, 71, 72, 273, 274, 300, 301, 302, 318, 319, 320, 323, 324, 325, 327, 328, 331, 332, 333, 334, 335, 336, 337, 338, 339, 361, 365, 367, 369, 370, 373, 375, 376], "weak": [9, 34, 35, 63, 64, 67, 68, 71, 72, 79, 80, 83, 214, 215, 216, 217, 229, 230, 231, 232, 233, 236, 316, 318, 320, 340, 341, 347, 364, 367], "weakspot": 317, "weathersit": [4, 8, 9, 10, 14, 64, 68, 72, 80, 333], "websit": [318, 355, 356, 357, 358, 359, 360, 361, 366, 367, 368, 369, 370, 371], "weekdai": [4, 8, 9, 10, 64, 72, 80, 355, 368, 370], "weight": [2, 117, 162, 168, 169, 174, 248, 251, 254, 257, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 322, 328, 332, 336, 339, 342, 353, 356, 359, 360, 361, 366, 368, 369], "well": [227, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 323, 324, 347, 359, 365, 367, 368, 369, 370, 371], "went": [332, 339], "were": 144, "what": 316, "when": [114, 119, 120, 123, 144, 195, 199, 209, 210, 211, 212, 213, 214, 215, 216, 217, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 240, 258, 268, 271, 272, 273, 274, 275, 276, 278, 280, 282, 285, 287, 289, 291, 292, 294, 296, 298, 318, 319, 323, 324, 327, 331, 332, 333, 335, 336, 338, 339, 355, 356, 359, 360, 361, 362, 365, 366, 367, 370, 371, 374], "where": [117, 118, 119, 123, 144, 207, 208, 211, 213, 215, 216, 217, 223, 224, 227, 228, 229, 232, 233, 235, 236, 237, 238, 239, 240, 246, 249, 251, 255, 256, 257, 284, 285, 290, 291, 299, 300, 319, 323, 324, 326, 327, 328, 331, 332, 333, 334, 337, 339, 355, 356, 357, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 374], "wherea": 361, "whether": [117, 119, 172, 180, 195, 201, 214, 215, 216, 217, 224, 229, 230, 231, 232, 233, 237, 255, 266, 273, 274, 275, 276, 277, 278, 284, 285, 307, 324, 327, 331, 337, 359, 367, 369], "which": [93, 112, 117, 118, 120, 121, 122, 123, 124, 125, 126, 180, 181, 208, 209, 210, 211, 212, 214, 215, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 247, 256, 290, 291, 300, 306, 318, 320, 322, 323, 324, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 371, 376], "while": [210, 225, 235, 238, 275, 276, 324, 331, 333, 335, 338, 339, 346, 355, 356, 358, 359, 360, 361, 362, 365, 366, 370, 371, 374], "who": [332, 339, 365], "whole": [229, 230, 231, 232, 233, 323, 348], "whose": [246, 368, 369], "why": [332, 367], "wide": [361, 362], "widest": [223, 368], "width": [9, 34, 35, 38, 40, 52, 71, 72, 112, 209, 210, 213, 215, 216, 217, 221, 223, 225, 229, 230, 231, 232, 233, 307, 323, 329, 347, 349, 368, 371], "width_threshold": 223, "wiggli": 366, "wikipedia": 327, "windspe": [4, 8, 9, 10, 64, 72, 80, 359], "winner": [332, 339], "wise": [114, 233], "withcolumn": 30, "within": [210, 211, 222, 225, 227, 240, 255, 273, 274, 318, 319, 323, 324, 328, 340, 342, 346, 359, 365, 368, 369], "without": [9, 34, 35, 286, 287, 295, 296, 332, 339, 355, 360], "won": [332, 339], "word": [323, 331, 333], "work": [222, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 324, 337, 339, 355, 356, 360, 365, 368, 371], "workflow": [124, 340, 341, 363, 373, 376], "workingdai": [4, 8, 9, 10, 14, 64, 337, 338, 355, 360, 366], "world": [349, 356, 359, 367, 369, 370], "worst": [75, 76, 211, 212, 227, 340, 347, 349, 368, 369, 370], "worth": [324, 332, 339], "would": [71, 72, 273, 274, 333, 334, 335, 337], "wrap": [28, 36, 48, 293, 294, 316, 375, 379], "wrap_estim": 49, "wraparbmodel": 376, "wrapper": [0, 29, 30, 49, 267, 268, 269, 270, 271, 272, 279, 280, 281, 282, 283, 288, 289, 292, 293, 294, 295, 296, 297, 298, 316, 324, 328, 356, 358, 362, 363], "wrapscoredmodel": 376, "wrapskmlp": 376, "written": 356, "wu": 327, "x": [6, 8, 9, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 114, 117, 118, 119, 121, 122, 127, 128, 129, 130, 134, 135, 136, 155, 185, 190, 207, 208, 210, 211, 213, 215, 216, 217, 223, 224, 225, 227, 228, 229, 230, 232, 233, 235, 236, 237, 238, 239, 240, 246, 249, 251, 255, 256, 257, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 320, 323, 324, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 344, 345, 346, 349, 352, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 376], "x0": [112, 213, 214, 215, 216, 217, 229, 230, 231, 232, 233, 334], "x1": [34, 35, 229, 230, 231, 232, 233, 334], "x2": [229, 230, 231, 232, 233, 334], "x27": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38, 39, 40, 43, 44, 45, 46, 53, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "x3": 334, "x4": 334, "x5": 334, "x6": 334, "x7": 334, "x8": 334, "x9": 334, "x_": [323, 324, 328, 331, 333, 335, 337, 355, 356, 357, 359, 360, 366, 368, 370], "x_1": 358, "x_2": 358, "x_c": [331, 337], "x_column": 29, "x_d": 358, "x_h2o": 29, "x_i": [355, 356, 359, 360, 366, 368, 369], "x_j": [331, 334, 355, 356, 357, 360, 366], "x_k": [331, 334, 355, 356, 357, 359, 360], "x_n": 368, "x_spark": 30, "x_test": [34, 35], "x_train": [34, 35], "xaxi": 52, "xgb": [9, 38, 64, 327, 340, 351, 374, 375], "xgb1": [63, 64, 67, 68, 79, 80, 83, 112, 213, 214, 215, 216, 217, 221, 226, 229, 230, 231, 232, 233, 303, 352, 365, 366, 370, 371], "xgb2": [49, 318, 320, 334, 335, 336, 337, 339], "xgb7": 320, "xgb_kwarg": 226, "xgb_model": [356, 365, 366, 367, 368, 369, 370, 371], "xgbclassifi": 297, "xgboost": [63, 107, 112, 133, 213, 214, 215, 216, 217, 221, 226, 229, 230, 231, 232, 233, 284, 285, 297, 298, 324, 327, 328, 347, 348, 349, 350, 351, 352, 353, 356, 359, 365, 366, 367, 368, 369, 370], "xgbregressor": 298, "xi": [123, 326], "xianji": 327, "xiaofei": [324, 328], "xicor": [3, 123, 326], "xindong": 327, "xiyang": 324, "xu": [324, 328], "xxx": [114, 207, 208, 209, 210, 214, 219, 220, 221, 222, 225, 226, 229, 230, 231, 232, 233, 234, 299, 300, 301, 302], "xxxxxx": 322, "y": [5, 29, 31, 32, 33, 34, 35, 38, 39, 40, 114, 117, 118, 119, 121, 122, 135, 136, 186, 191, 207, 208, 211, 213, 215, 216, 217, 223, 224, 225, 227, 228, 235, 236, 237, 238, 239, 240, 246, 249, 251, 255, 256, 257, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 318, 319, 320, 323, 327, 332, 336, 339, 344, 345, 346, 355, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370], "y_": [323, 368], "y_column": 29, "y_hat": 224, "y_i": [356, 359, 366, 367, 368, 369], "y_n": 368, "y_test": [34, 35], "y_train": [34, 35], "yaxi": 52, "yet": 371, "yield": [284, 285, 299, 300, 301, 302, 374], "you": [5, 9, 10, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 46, 54, 83, 93, 107, 175, 316, 324, 325, 327, 332, 333, 334, 335, 336, 337, 339, 342, 344, 347, 369, 373, 374], "your": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87, 93, 325, 343, 344, 345, 346, 350, 351], "yr": [4, 8, 9, 10, 14, 20, 64, 325, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "yu": 327, "yu2020": 327, "yue": 324, "z": [52, 122, 327, 332, 339, 345, 346, 360, 361], "z_": [324, 328, 331, 333], "z_i": 327, "z_j": [332, 339, 355, 360], "zengyou": [324, 328], "zero": [123, 164, 323, 326, 327, 331, 333, 338, 355, 356, 360, 361, 367], "zhang": 327, "zhang2012": 327, "zhao": 324, "zhaolong": 327, "zheng": 324, "zhi": [324, 328], "zhou": [324, 328], "zhu": 331, "zip": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 45, 46, 49, 52, 53, 54, 57, 58, 61, 62, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 86, 87], "zoo": [0, 316, 350, 363], "\u03b1": 368, "\u03b2": [368, 369], "\u03b5": 369, "\u03c4": 368, "\u211d": 360}, "titles": ["API Reference", "Dataset", "Basic Dataset Operations", "Exploratory Data Analysis", "Feature Selection", "Data Processing and Feature Engineering", "Subsampling", "Data Drift Test", "Outlier Detection", "Data with Model Predictions", "Dealing with Extra Data Sets", "Computation times", "Built-in Interpretable Models", "Logistic Regression (Classification)", "Linear Regression (Regression)", "Decision Tree Classification", "Decision Tree Regression", "MoReLUDNN Classification", "MoReLUDNN Regression", "GAMINet Classification", "GAMINet Regression", "Mixture of Expert (MoE) Classification", "Mixture of Expert (MoE) Regression", "Linear Tree Classification", "Linear Tree Regression", "Tree Ensemble Models (Classification)", "Tree Ensemble Models (Regression)", "Computation times", "External Models", "Wrapping H2O Models", "Wrapping PySpark Models", "Wrapping sklearn-style Models", "Wrapping Arbitrary Classifier", "Wrapping Arbitrary Regressor", "Wrapping Scored Classifier", "Wrapping Scored Regressor", "Computation times", "Model Calibration", "Calibrating Binary Classifier", "Calibrating Binary Classifier Prediction Interval", "Calibrating Regressor Prediction Interval", "Computation times", "Hyperparameter Tuning", "Grid Search", "Random Search", "Particle Swarm Optimization Search", "Tuning with optuna (Experimental)", "Computation times", "Model Development", "ModelZoo", "Computation times", "Utilities", "ValidationResult - Attributes", "ValidationResult - Visualization", "Pipeline", "Computation times", "Model Residual", "Residual Analysis (Classification)", "Residual Analysis (Regression)", "Computation times", "Model Performance", "Performance Metrics (Classification)", "Performance Metrics (Regression)", "Sliced Performance (Classification)", "Sliced Performance (Regression)", "Computation times", "Overfit Detection", "Overfitting Analysis (Classification)", "Overfitting Analysis (Regression)", "Computation times", "Reliability Analysis", "Reliability Analysis (Classification)", "Reliability Analysis (Regression)", "Computation times", "Resilience Analysis", "Resilience Analysis (Classification)", "Resilience Analysis (Regression)", "Computation times", "Robustness Analysis", "Robustness Analysis (Classification)", "Robustness Analysis (Regression)", "Computation times", "Fairness Analysis", "Model Fairness Analysis (Classification)", "Computation times", "Explainability", "Global Explainability", "Local Explainability", "Computation times", "Model Validation", "Computation times", "Change Log", "Frequently Asked Questions", "Gallery of Modeva Examples", "sphinx_gallery.backreferences", "sphinx_gallery.block_parser", "sphinx_gallery.directives", "sphinx_gallery.docs_resolv", "sphinx_gallery.downloads", "sphinx_gallery.gen_gallery", "sphinx_gallery.gen_rst", "sphinx_gallery.interactive_example", "sphinx_gallery.notebook", "sphinx_gallery.py_source_parser", "sphinx_gallery.scrapers", "sphinx_gallery.sorting", "sphinx_gallery.utils.optipng", "Installation", "Low Code", "DataSet", "modeva.DataSet.all_feature_names", "modeva.DataSet.all_feature_types", "modeva.DataSet.bin_numerical", "modeva.DataSet.data", "modeva.DataSet.data_drift_test", "modeva.DataSet.delete_extra_data", "modeva.DataSet.delete_registered_data", "modeva.DataSet.detect_outlier_cblof", "modeva.DataSet.detect_outlier_isolation_forest", "modeva.DataSet.detect_outlier_pca", "modeva.DataSet.eda_1d", "modeva.DataSet.eda_2d", "modeva.DataSet.eda_3d", "modeva.DataSet.eda_correlation", "modeva.DataSet.eda_pca", "modeva.DataSet.eda_umap", "modeva.DataSet.encode_categorical", "modeva.DataSet.feature_names", "modeva.DataSet.feature_names_categorical", "modeva.DataSet.feature_names_mixed", "modeva.DataSet.feature_names_numerical", "modeva.DataSet.feature_select_corr", "modeva.DataSet.feature_select_rcit", "modeva.DataSet.feature_select_xgbpfi", "modeva.DataSet.feature_types", "modeva.DataSet.get_X_y_data", "modeva.DataSet.get_data", "modeva.DataSet.get_data_list", "modeva.DataSet.get_extra_data_list", "modeva.DataSet.get_prediction_data", "modeva.DataSet.get_prediction_proba_data", "modeva.DataSet.get_preprocessor", "modeva.DataSet.get_protected_data", "modeva.DataSet.get_raw_data", "modeva.DataSet.impute_missing", "modeva.DataSet.inverse_transform", "modeva.DataSet.is_splitted", "modeva.DataSet.list_registered_data", "modeva.DataSet.load", "modeva.DataSet.load_csv", "modeva.DataSet.load_dataframe", "modeva.DataSet.load_dataframe_train_test", "modeva.DataSet.load_preprocessing", "modeva.DataSet.load_registered_data", "modeva.DataSet.load_spark", "modeva.DataSet.n_features", "modeva.DataSet.name", "modeva.DataSet.prediction", "modeva.DataSet.preprocess", "modeva.DataSet.raw_data", "modeva.DataSet.register", "modeva.DataSet.reset_preprocess", "modeva.DataSet.sample_weight", "modeva.DataSet.save_preprocessing", "modeva.DataSet.scale_numerical", "modeva.DataSet.set_active_features", "modeva.DataSet.set_feature_type", "modeva.DataSet.set_inactive_features", "modeva.DataSet.set_prediction", "modeva.DataSet.set_prediction_proba", "modeva.DataSet.set_protected_data", "modeva.DataSet.set_protected_extra_data", "modeva.DataSet.set_random_split", "modeva.DataSet.set_raw_extra_data", "modeva.DataSet.set_sample_weight", "modeva.DataSet.set_target", "modeva.DataSet.set_task_type", "modeva.DataSet.set_test_idx", "modeva.DataSet.set_train_idx", "modeva.DataSet.shape", "modeva.DataSet.subsample_random", "modeva.DataSet.summary", "modeva.DataSet.task_type", "modeva.DataSet.test_prediction", "modeva.DataSet.test_sample_weight", "modeva.DataSet.test_x", "modeva.DataSet.test_y", "modeva.DataSet.to_df", "modeva.DataSet.train_prediction", "modeva.DataSet.train_sample_weight", "modeva.DataSet.train_x", "modeva.DataSet.train_y", "modeva.DataSet.transform", "modeva.DataSet.x", "modeva.DataSet.y", "modeva.ModelZoo.add_model", "modeva.ModelZoo.dataset", "modeva.ModelZoo.delete_registered_model", "modeva.ModelZoo.get_model", "modeva.ModelZoo.leaderboard", "modeva.ModelZoo.list_model_names", "modeva.ModelZoo.list_registered_models", "modeva.ModelZoo.load_registered_model", "modeva.ModelZoo.models", "modeva.ModelZoo.register", "modeva.ModelZoo.train", "modeva.ModelZoo.train_all", "modeva.TestSuite.compare_accuracy_table", "modeva.TestSuite.compare_fairness", "modeva.TestSuite.compare_reliability", "modeva.TestSuite.compare_residual_cluster", "modeva.TestSuite.compare_resilience", "modeva.TestSuite.compare_robustness", "modeva.TestSuite.compare_slicing_accuracy", "modeva.TestSuite.compare_slicing_fairness", "modeva.TestSuite.compare_slicing_overfit", "modeva.TestSuite.compare_slicing_reliability", "modeva.TestSuite.compare_slicing_robustness", "modeva.TestSuite.delete_registed_test", "modeva.TestSuite.diagnose_accuracy_table", "modeva.TestSuite.diagnose_fairness", "modeva.TestSuite.diagnose_mitigate_unfair_binning", "modeva.TestSuite.diagnose_mitigate_unfair_thresholding", "modeva.TestSuite.diagnose_reliability", "modeva.TestSuite.diagnose_residual_analysis", "modeva.TestSuite.diagnose_residual_cluster", "modeva.TestSuite.diagnose_residual_interpret", "modeva.TestSuite.diagnose_resilience", "modeva.TestSuite.diagnose_robustness", "modeva.TestSuite.diagnose_slicing_accuracy", "modeva.TestSuite.diagnose_slicing_fairness", "modeva.TestSuite.diagnose_slicing_overfit", "modeva.TestSuite.diagnose_slicing_reliability", "modeva.TestSuite.diagnose_slicing_robustness", "modeva.TestSuite.display_test_results", "modeva.TestSuite.explain_ale", "modeva.TestSuite.explain_hstatistic", "modeva.TestSuite.explain_lime", "modeva.TestSuite.explain_pdp", "modeva.TestSuite.explain_pfi", "modeva.TestSuite.explain_shap", "modeva.TestSuite.export_report", "modeva.TestSuite.get_dataset", "modeva.TestSuite.get_interactions", "modeva.TestSuite.get_main_effects", "modeva.TestSuite.get_model", "modeva.TestSuite.interpret_coef", "modeva.TestSuite.interpret_effects", "modeva.TestSuite.interpret_effects_moe_average", "modeva.TestSuite.interpret_fi", "modeva.TestSuite.interpret_global_tree", "modeva.TestSuite.interpret_llm_pc", "modeva.TestSuite.interpret_llm_profile", "modeva.TestSuite.interpret_llm_summary", "modeva.TestSuite.interpret_llm_violin", "modeva.TestSuite.interpret_local_fi", "modeva.TestSuite.interpret_local_linear_fi", "modeva.TestSuite.interpret_local_moe_weights", "modeva.TestSuite.interpret_local_tree", "modeva.TestSuite.interpret_moe_cluster_analysis", "modeva.TestSuite.list", "modeva.TestSuite.list_registered_tests", "modeva.TestSuite.load_registered_test", "modeva.TestSuite.register", "modeva.TestSuite.set_dataset", "modeva.TestSuite.set_model", "modeva.automation.pipeline.Pipeline", "modeva.models.MoCatBoostClassifier", "modeva.models.MoCatBoostRegressor", "modeva.models.MoClassifier", "modeva.models.MoDecisionTreeClassifier", "modeva.models.MoDecisionTreeRegressor", "modeva.models.MoElasticNet", "modeva.models.MoGAMINetClassifier", "modeva.models.MoGAMINetRegressor", "modeva.models.MoGLMTreeBoostClassifier", "modeva.models.MoGLMTreeBoostRegressor", "modeva.models.MoGLMTreeClassifier", "modeva.models.MoGLMTreeRegressor", "modeva.models.MoGradientBoostingClassifier", "modeva.models.MoGradientBoostingRegressor", "modeva.models.MoLGBMClassifier", "modeva.models.MoLGBMRegressor", "modeva.models.MoLogisticRegression", "modeva.models.MoMoEClassifier", "modeva.models.MoMoERegressor", "modeva.models.MoNeuralTreeClassifier", "modeva.models.MoNeuralTreeRegressor", "modeva.models.MoRandomForestClassifier", "modeva.models.MoRandomForestRegressor", "modeva.models.MoReLUDNNClassifier", "modeva.models.MoReLUDNNRegressor", "modeva.models.MoRegressor", "modeva.models.MoSKLearnClassifier", "modeva.models.MoSKLearnRegressor", "modeva.models.MoScoredClassifier", "modeva.models.MoScoredRegressor", "modeva.models.MoXGBClassifier", "modeva.models.MoXGBRegressor", "modeva.models.ModelTuneGridSearch", "modeva.models.ModelTuneOptuna", "modeva.models.ModelTunePSO", "modeva.models.ModelTuneRandomSearch", "modeva.testsuite.utils.slicing_utils.get_data_info", "modeva.utils.mlflow.clear_mlflow_home", "modeva.utils.mlflow.get_mlflow_home", "modeva.utils.mlflow.set_mlflow_home", "modeva.utils.results.ValidationResult", "Hyperparameter Tuning", "Interpretable Models", "Model Zoo", "Pipeline", "Validation Result", "Test Suite", "Utilities", "Model Wrappers", "Using Modeva", "Model Comparison", "Comparison for Classification", "Fairness Comparison", "Comparison for Regression", "Data Processing", "Basic Data Operations", "Data Quality (Drift Test)", "Data Quality (Outlier Detection)", "Data Summary", "Exploratory Data Analysis", "Feature Selection", "Outlier Detection", "Subsampling and Data Drift", "Model Explainability", "Global Explainability", "Local Explainability", "ALE (Accumulated Local Effects)", "Hstats (Friedman\u2019s H-statistic)", "ICE (Individual Conditional Expectation)", "LIME (Local Interpretable Model-Agnostic Explanation)", "PDP (Partial Dependence Plot)", "PFI (Permutation Feature Importance)", "SHAP (SHapley Additive exPlanations)", "Introduction", "Low code", "Data Processing", "Data Summary", "EDA 2D Charts", "EDA 3D Scatter", "EDA Multivariate", "Model Comparison", "Model Explainability", "Model Test", "Model Training", "Model Tuning", "Weakness Test", "Registry Hub", "Interpretable Models", "GAMI-Net", "Gradient Boosted Decision Trees", "Linear Tree and Gradient Boosted Linear Trees", "Generalized Linear Models", "Mixture of Experts (MoE)", "Neural Tree", "ReLU Neural Network", "Decision Tree", "Model Wrapping", "Diagnostic Suite", "Fairness", "Underfitting and Overfitting", "Performance and Residual Analysis", "Reliability", "Resilience", "Robustness", "Weakness Detection", "Model Training", "Register H2O Models", "Model Tuning", "Model Zoo and Leaderboard", "Model Wrappers", "MoDeVa.ai", "Unused API Entries", "Computation times"], "titleterms": {"": [331, 334], "0": 90, "00": [36, 41, 55, 65, 69, 73, 77, 81, 84, 88, 90], "000": 90, "01": [11, 50, 59], "02": [], "03": 47, "05": 41, "09": [27, 77], "095": 59, "1": [21, 22, 50, 84, 318, 320, 333, 334, 335, 336, 337, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376], "10": 84, "12": 55, "13": [36, 88], "14": 27, "16": 11, "1d": [3, 67, 68, 86, 326], "2": [57, 58, 59, 69, 73, 77, 81, 88, 333, 334, 335, 336, 337, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371, 374, 376], "22": 81, "221": 27, "23": [50, 69, 73], "25": 65, "2d": [3, 67, 68, 86, 326, 344], "3": [41, 55, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 366, 371, 374, 376], "343": 73, "364": 84, "3d": [3, 326, 345], "4": [47, 65, 343, 344, 345, 346, 347, 348, 349, 350, 351, 376], "40": 47, "41": 27, "444": 69, "5": [343, 346, 347, 349, 376], "50": 59, "5000": 10, "544": 88, "577": 47, "6": [343, 347, 349], "624": 41, "7": 36, "718": 50, "725": 11, "733": 36, "785": 81, "8000": 10, "806": 77, "846": 55, "879": [], "895": 65, "9": 11, "9000": 10, "If": [343, 344, 345], "One": [324, 333, 337], "The": 339, "_sourceauto_galleriesdata": 11, "_sourceauto_galleriesdev": 50, "_sourceauto_galleriesdev0_model": 27, "_sourceauto_galleriesdev1_extmodel": 36, "_sourceauto_galleriesdev2_calibr": 41, "_sourceauto_galleriesdev3_hpo": 47, "_sourceauto_galleriesutil": 55, "_sourceauto_galleriesv": 90, "_sourceauto_galleriesval0_residu": 59, "_sourceauto_galleriesval1_perform": 65, "_sourceauto_galleriesval2_overfit": 69, "_sourceauto_galleriesval3_reli": 73, "_sourceauto_galleriesval4_resili": 77, "_sourceauto_galleriesval5_robust": 81, "_sourceauto_galleriesval6_fair": 84, "_sourceauto_galleriesval7_explain": 88, "abov": [5, 14], "absolut": [57, 58, 320], "access": 109, "accumul": [331, 333], "accuraci": [14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 61, 62, 63, 64, 318, 320], "activ": 6, "add": 49, "add_model": 195, "addit": [332, 339, 371], "address": [368, 369, 370], "adjust": [343, 344, 345, 365], "advanc": [49, 63, 64, 346, 371], "advantag": 357, "advers": 365, "after": 38, "against": [17, 18, 57, 58], "aggreg": 356, "agnost": [332, 336], "ai": 377, "air": 365, "al": [86, 331, 333], "algorithm": [327, 333, 334, 335, 336, 337, 338, 339], "all": 49, "all_feature_nam": 110, "all_feature_typ": 111, "analysi": [3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 57, 58, 61, 62, 63, 64, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 89, 324, 326, 340, 346, 355, 356, 357, 359, 360, 361, 366, 367, 368, 369, 370], "analyz": [57, 58, 343], "anova": [355, 356, 359, 360], "api": [0, 378], "appli": [6, 346], "applic": [365, 366, 367], "approach": [366, 368, 369, 370, 371], "arbitrari": [32, 33, 376], "architectur": [359, 360, 361], "ask": 92, "assess": [366, 368], "attribut": [52, 355, 359, 360], "auc": 318, "autom": 266, "automat": 371, "avail": [10, 53], "backrefer": 94, "bandwidth": [318, 320], "bar": 53, "base": [4, 57, 58, 324, 328, 360], "baselin": 87, "basic": [2, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 61, 62, 63, 64, 71, 72, 75, 76, 79, 80, 83, 322, 355, 360], "batch": [67, 68], "befor": 38, "benefit": 356, "best": [43, 44, 45, 46, 351], "between": [21, 22, 365], "bike": [333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "bikeshar": 320, "bin": [322, 365, 371], "bin_numer": 112, "binari": [38, 39], "bivari": 326, "block_pars": 95, "boost": [23, 24, 356, 357], "build": [29, 30, 31, 32, 33, 34, 35, 38, 39, 40], "built": [2, 12, 48, 322], "calibr": [37, 38, 39, 40, 48], "case": 356, "categor": [322, 325, 343, 355, 370], "cblof": [8, 324, 328], "centric": [366, 368, 369, 370], "challeng": 367, "chang": [91, 325], "character": 366, "chart": 344, "check": 38, "class": 324, "classif": [13, 15, 17, 19, 21, 23, 25, 57, 61, 63, 67, 71, 75, 79, 83, 309, 318, 367], "classifi": [32, 34, 38, 39], "clear_mlflow_hom": 304, "cluster": [21, 22, 57, 58, 324, 368, 369, 370], "code": [108, 341], "coeffici": [13, 14, 327], "combin": 365, "compar": [38, 57, 58, 61, 62, 350], "compare_accuracy_t": 207, "compare_fair": 208, "compare_reli": 209, "compare_residual_clust": 210, "compare_resili": 211, "compare_robust": 212, "compare_slicing_accuraci": 213, "compare_slicing_fair": 214, "compare_slicing_overfit": 215, "compare_slicing_reli": 216, "compare_slicing_robust": 217, "comparison": [63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 313, 317, 318, 319, 320, 324, 347, 365, 366, 367, 368, 369, 370, 371], "complex": 366, "compon": [324, 346], "comput": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90, 355, 360, 379], "conceptu": 340, "condit": [327, 335], "conduct": [67, 68], "configur": [49, 344, 345, 351], "conform": 368, "connect": 366, "consider": [355, 360, 370], "constraint": [23, 24, 355, 356, 360], "continu": 369, "convert": [34, 35], "coordin": [17, 18, 361], "correl": [3, 4, 326, 327, 346], "coverag": 320, "creat": [29, 30, 31, 32, 33, 34, 35, 353, 376], "credit": [318, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "cumul": 324, "curvatur": 366, "d": 6, "data": [2, 3, 5, 7, 9, 10, 21, 22, 29, 30, 31, 32, 33, 34, 35, 109, 113, 321, 322, 323, 324, 325, 326, 329, 342, 343, 353, 366, 368, 369, 370, 376], "data_drift_test": 114, "dataset": [1, 2, 49, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 322, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353], "deal": 10, "decis": [15, 16, 356, 362], "decomposit": [355, 356, 359, 360, 366], "defin": [5, 14], "definit": 365, "delet": 10, "delete_extra_data": 115, "delete_registed_test": 218, "delete_registered_data": 116, "delete_registered_model": 197, "depend": [86, 331, 337, 339], "depth": [57, 58, 356, 357, 360, 371], "detail": [333, 334, 335, 336, 337, 338, 339], "detect": [8, 66, 89, 109, 324, 328, 352, 366, 371], "detect_outlier_cblof": 117, "detect_outlier_isolation_forest": 118, "detect_outlier_pca": 119, "develop": 48, "diagnos": [43, 44, 45, 46], "diagnose_accuracy_t": 219, "diagnose_fair": 220, "diagnose_mitigate_unfair_bin": 221, "diagnose_mitigate_unfair_threshold": 222, "diagnose_reli": 223, "diagnose_residual_analysi": 224, "diagnose_residual_clust": 225, "diagnose_residual_interpret": 226, "diagnose_resili": 227, "diagnose_robust": 228, "diagnose_slicing_accuraci": 229, "diagnose_slicing_fair": 230, "diagnose_slicing_overfit": 231, "diagnose_slicing_reli": 232, "diagnose_slicing_robust": 233, "diagnost": [29, 30, 31, 32, 33, 34, 35, 313, 364, 365, 368, 373], "diagram": 318, "differ": 324, "direct": 96, "discret": 369, "dispar": 365, "displai": 53, "display_test_result": 234, "distanc": [318, 320, 323, 369], "distribut": [323, 324, 329, 369, 370], "diverg": 369, "dnn": 361, "docs_resolv": 97, "download": 98, "drift": [7, 21, 22, 109, 323, 329, 369], "eda": [3, 344, 345, 346], "eda_1d": 120, "eda_2d": 121, "eda_3d": 122, "eda_correl": 123, "eda_pca": 124, "eda_umap": 125, "effect": [13, 14, 19, 20, 21, 22, 25, 26, 331, 333, 355, 356, 359, 360], "empir": [324, 356, 366], "encod": 322, "encode_categor": 126, "energi": 323, "engin": [5, 366], "enhanc": 356, "ensembl": [25, 26, 356], "entri": 378, "error": [320, 366, 371], "estim": 366, "evalu": [349, 350, 365, 367], "exact": [332, 339], "exampl": [49, 93, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376], "execut": [5, 11, 14, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90], "expect": 335, "experi": 353, "experiment": 46, "expert": [21, 22, 359], "explain": [85, 86, 87, 89, 330, 331, 332, 348], "explain_al": 235, "explain_hstatist": 236, "explain_lim": 237, "explain_pdp": 238, "explain_pfi": 239, "explain_shap": 240, "explan": [313, 332, 336, 339, 348, 355], "explor": [109, 326], "exploratori": [3, 326], "export": [343, 346], "export_report": 241, "extern": [28, 48, 322, 376], "extra": [10, 109], "extract": [17, 18], "f1": 318, "factor": 324, "fair": [82, 83, 89, 319, 365], "fbedk": 327, "featur": [4, 5, 13, 14, 17, 18, 19, 20, 21, 22, 25, 26, 57, 58, 67, 68, 86, 109, 325, 327, 331, 338, 339, 340, 342, 343, 344, 345, 352, 355, 359, 360, 361, 365, 366], "feature_nam": 127, "feature_names_categor": 128, "feature_names_mix": 129, "feature_names_numer": 130, "feature_select_corr": 131, "feature_select_rcit": 132, "feature_select_xgbpfi": 133, "feature_typ": 134, "figur": 53, "file": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90], "first": 10, "fit": 373, "forest": [8, 57, 58, 324, 328, 368, 370], "formul": [356, 359, 369], "framework": 366, "frequent": 92, "friedman": [331, 334], "from": [2, 10, 11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90, 366], "full": 368, "function": [355, 356, 359, 360], "galleri": 93, "gami": 355, "gaminet": [19, 20], "gap": 366, "gate": 359, "gbdt": 356, "gblt": [357, 360], "gen_galleri": 99, "gen_rst": 100, "gener": [53, 358, 366], "get": [10, 39, 40], "get_data": 136, "get_data_info": 303, "get_data_list": 137, "get_dataset": 242, "get_extra_data_list": 138, "get_interact": 243, "get_main_effect": 244, "get_mlflow_hom": 305, "get_model": [198, 245], "get_prediction_data": 139, "get_prediction_proba_data": 140, "get_preprocessor": 141, "get_protected_data": 142, "get_raw_data": 143, "get_x_y_data": 135, "glm": 358, "glmtree": [23, 24], "global": [15, 16, 19, 86, 331, 342, 348, 355, 356, 357, 358, 359, 360, 362], "gradient": [356, 357, 366], "grid": [43, 374], "group": [87, 365], "h": [86, 331, 334], "h2o": [29, 373], "handl": 322, "heatmap": 326, "hidden": [17, 18], "histogram": 324, "hoc": 313, "hpo": 46, "hstat": [331, 334], "hub": 353, "hyperparamet": [42, 43, 44, 45, 46, 48, 308], "i": 371, "ic": 335, "identif": [368, 370], "identifi": 366, "impact": [365, 368, 370], "implement": [355, 360, 366], "import": [13, 14, 17, 18, 19, 20, 21, 22, 25, 26, 57, 58, 86, 327, 331, 338, 339, 355, 359, 360, 361, 371], "impute_miss": 144, "independ": 327, "index": 10, "individu": [335, 355, 356, 357, 359, 360, 361], "inher": 313, "initi": [49, 54, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 353], "input": 370, "instal": 107, "interact": [67, 68, 356], "interactive_exampl": 101, "interpret": [12, 13, 14, 15, 16, 19, 20, 21, 22, 48, 49, 57, 58, 309, 313, 332, 336, 354, 355, 356, 357, 358, 359, 360, 361, 362, 367], "interpret_coef": 246, "interpret_effect": 247, "interpret_effects_moe_averag": 248, "interpret_fi": 249, "interpret_global_tre": 250, "interpret_llm_pc": 251, "interpret_llm_profil": 252, "interpret_llm_summari": 253, "interpret_llm_violin": 254, "interpret_local_fi": 255, "interpret_local_linear_fi": 256, "interpret_local_moe_weight": 257, "interpret_local_tre": 258, "interpret_moe_cluster_analysi": 259, "interv": [39, 40, 57, 58], "introduct": [340, 367, 371], "inverse_transform": 145, "is_split": 146, "isol": [8, 324, 328], "issu": [368, 370], "its": 53, "jensen": 369, "k": 324, "kei": [340, 371], "kernel": 87, "kernelshap": [332, 339], "kmeanstre": 324, "kolmogorov": 369, "last": [10, 17, 18], "layer": [17, 18], "leaderboard": [49, 199, 375], "learn": [49, 367, 368, 370], "lgbm": [23, 24, 38, 61, 62], "lime": [87, 332, 336], "limit": [53, 356], "linear": [13, 14, 23, 24, 357, 358, 361], "linearshap": 332, "list": [53, 260], "list_model_nam": 200, "list_registered_data": 147, "list_registered_model": 201, "list_registered_test": 261, "llm": [17, 18, 361], "load": [2, 5, 10, 49, 109, 148, 322, 343, 344, 345, 346, 348, 373], "load_csv": 149, "load_datafram": 150, "load_dataframe_train_test": 151, "load_preprocess": 152, "load_registered_data": 153, "load_registered_model": 202, "load_registered_test": 262, "load_spark": 154, "local": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 87, 324, 331, 332, 333, 336, 348, 355, 356, 357, 358, 359, 360, 361, 362, 366], "log": 91, "logist": 13, "loss": [355, 360], "low": [108, 341], "machin": [368, 370], "main": [13, 14, 25, 26, 356], "manag": [109, 310, 353, 375], "manifest": 366, "manipul": 325, "margin": [323, 324], "mathemat": [356, 359], "mean": 320, "measur": [366, 367, 369], "method": [324, 328, 351, 366], "methodologi": [324, 367], "metric": [61, 62, 319, 365, 367], "miss": 322, "mitig": [83, 365], "mixtur": [21, 22, 359], "ml": 49, "mlflow": [2, 49, 304, 305, 306], "mocatboostclassifi": 267, "mocatboostregressor": 268, "moclassifi": 269, "mode": [67, 68], "modecisiontreeclassifi": 270, "modecisiontreeregressor": 271, "model": [9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 56, 57, 58, 60, 61, 62, 63, 64, 67, 68, 71, 72, 80, 83, 89, 203, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 309, 310, 313, 315, 317, 330, 332, 336, 339, 347, 348, 349, 350, 351, 352, 354, 356, 358, 359, 360, 361, 363, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376], "modeltun": 374, "modeltunegridsearch": 299, "modeltuneoptuna": 300, "modeltunepso": 301, "modeltunerandomsearch": 302, "modelzoo": [49, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206], "modeva": [10, 29, 30, 31, 32, 33, 34, 35, 93, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 316, 355, 356, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371, 376, 377], "modul": 340, "moe": [21, 22, 359], "moelasticnet": 272, "mogaminetclassifi": 273, "mogaminetregressor": 274, "moglmtreeboostclassifi": 275, "moglmtreeboostregressor": 276, "moglmtreeclassifi": 277, "moglmtreeregressor": 278, "mogradientboostingclassifi": 279, "mogradientboostingregressor": 280, "molgbmclassifi": 281, "molgbmregressor": 282, "mologisticregress": 283, "momoeclassifi": 284, "momoeregressor": 285, "moneuraltreeclassifi": 286, "moneuraltreeregressor": 287, "monoton": [23, 24, 355, 356, 360], "morandomforestclassifi": 288, "morandomforestregressor": 289, "moregressor": 292, "moreludnn": [17, 18], "moreludnnclassifi": 290, "moreludnnregressor": 291, "moscoredclassifi": 295, "moscoredregressor": 296, "mosklearnclassifi": 293, "mosklearnregressor": 294, "moxgbclassifi": 297, "moxgbregressor": 298, "multipl": [57, 58], "multivari": [346, 366], "n_featur": 155, "name": [10, 53, 156], "nearest": 324, "necessari": [343, 344, 345], "need": [10, 38, 39, 40], "neighbor": 324, "net": 355, "network": 361, "neural": [23, 24, 360, 361], "nois": 370, "nonconform": 368, "normal": 370, "notebook": 102, "number": 53, "numer": [322, 325, 343], "one": [10, 53], "oot1": 10, "oot2": 10, "oot3": 10, "oper": [2, 4, 322], "optim": [45, 374], "option": 54, "optipng": 106, "optuna": 46, "outcom": 340, "outlier": [8, 109, 324, 328], "output": [17, 18], "overfit": [66, 67, 68, 89, 318, 320, 366], "overview": 343, "pairwis": 356, "panel": [342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 353], "parallel": [17, 18, 361], "paramet": 351, "partial": [86, 331, 337], "particl": [45, 374], "partit": 366, "pca": [3, 8, 326, 328, 346], "pdp": [331, 337], "perform": [60, 61, 62, 63, 64, 89, 318, 320, 346, 347, 349, 365, 367], "permut": [86, 331, 338], "perturb": [57, 58, 370], "pfi": [4, 331, 338], "pipelin": [54, 266, 311], "plot": [13, 14, 17, 18, 25, 26, 53, 86, 326, 331, 337, 339, 355, 356, 359, 360, 361], "post": 313, "practic": [366, 370], "predict": [9, 34, 35, 39, 40, 57, 58, 157, 355, 356, 357, 359, 360, 361, 368], "predictor": [57, 58], "prepar": [49, 322, 376], "preprocess": [5, 14, 109, 158, 322], "prerequisit": 107, "princip": [324, 346], "proba": [38, 57], "problemat": 366, "process": [5, 321, 342, 356, 359], "profil": [17, 18, 361], "properti": [109, 310], "protect": 109, "psi": 369, "pso": 45, "purif": [355, 356, 360], "purpos": 367, "py_source_pars": 103, "pyspark": 30, "qualiti": [323, 324, 356], "quantil": [370, 371], "question": 92, "r": 320, "random": [6, 44, 57, 58, 368, 370, 374], "ratio": 365, "raw_data": 159, "rcit": [4, 327], "refer": [0, 324, 326, 327, 328, 331, 332, 334, 335, 338, 339], "region": [67, 68, 366], "regist": [2, 49, 160, 204, 263, 342, 344, 345, 350, 351, 373], "registr": [49, 322], "registri": [310, 353], "regress": [13, 14, 16, 18, 20, 22, 24, 26, 58, 62, 64, 68, 72, 76, 80, 309, 320, 367], "regressor": [33, 35, 40], "reliabl": [70, 71, 72, 89, 318, 320, 347, 349, 368], "relu": 361, "remedi": 366, "remov": 325, "represent": [355, 359, 360], "reset": [5, 6], "reset_preprocess": 161, "residu": [56, 57, 58, 89, 367], "resili": [74, 75, 76, 89, 318, 320, 347, 349, 369], "respons": [57, 58], "rest": [21, 22, 38, 39, 40], "result": [8, 54, 307, 312, 343, 346, 347, 348, 349, 352, 356, 367], "retrain": [43, 44, 45, 46], "review": 343, "risk": 366, "robust": [78, 79, 80, 89, 318, 320, 347, 349, 366, 370], "row": 10, "run": [43, 44, 45, 46, 54, 351, 373], "sampl": [6, 10, 21, 22, 87, 109, 318, 320, 342], "sample_weight": 162, "save": [34, 35, 53, 54, 343, 344, 345, 346, 347, 348, 349, 352, 373], "save_preprocess": 163, "scale": 322, "scale_numer": 164, "scatter": [326, 345], "scikit": 49, "score": [34, 35, 318, 320, 324, 368, 376], "scraper": 104, "script": [29, 30, 32, 33], "search": [43, 44, 45, 351, 374], "segment": [319, 352], "select": [4, 109, 327, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352], "sensit": 366, "set": [5, 6, 10, 49, 342, 344, 345], "set_active_featur": 165, "set_active_sampl": 6, "set_dataset": 264, "set_feature_typ": 166, "set_inactive_featur": 167, "set_mlflow_hom": 306, "set_model": 265, "set_predict": 168, "set_prediction_proba": 169, "set_protected_data": 170, "set_protected_extra_data": 171, "set_random_split": 172, "set_raw_extra_data": 173, "set_sample_weight": 174, "set_target": 175, "set_task_typ": 176, "set_test_idx": 177, "set_train_idx": 178, "shannon": 369, "shap": [87, 332, 339], "shape": 179, "shaplei": [332, 339], "share": [333, 334, 335, 336, 337, 338, 339, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "shoot": 107, "show": [10, 49], "simpl": 370, "simucredit": [333, 334, 335, 336, 337, 338, 339], "singl": 87, "sklearn": [31, 376], "slice": [63, 64, 67, 68, 71, 72, 79, 80, 83, 365, 366, 371], "slicing_util": 303, "smirnov": 369, "solut": [332, 339, 366], "sort": 105, "sound": 340, "sparsiti": 366, "special": [340, 356], "specif": 339, "sphinx_galleri": [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106], "split": [10, 109, 342, 368], "squar": 320, "stage": 356, "statist": [86, 325, 331, 334, 369], "step": [5, 14, 54, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 359, 367], "strategi": [366, 368, 369, 370], "style": 31, "sub": 53, "subplot": 53, "subsampl": [6, 329], "subsample_random": 180, "suit": [29, 30, 31, 32, 33, 34, 35, 313, 364], "summari": [3, 5, 17, 18, 181, 322, 325, 339, 343, 361], "supervis": [367, 368, 369, 370], "svm": 324, "swarm": [45, 374], "tabl": [17, 18, 361], "taiwan": [318, 355, 356, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 371], "taiwancredit": 326, "task_typ": 182, "techniqu": 367, "test": [7, 21, 22, 29, 30, 31, 32, 33, 34, 35, 109, 313, 323, 327, 349, 352, 366, 370, 373], "test_i": 186, "test_predict": 183, "test_sample_weight": 184, "test_x": 185, "testsuit": [207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 303, 376], "theoret": 366, "threshold": 365, "through": [356, 369], "time": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90, 379], "to_df": 187, "total": [11, 27, 36, 41, 47, 50, 55, 59, 65, 69, 73, 77, 81, 84, 88, 90], "track": 353, "tradeoff": 365, "tradit": 49, "train": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 49, 109, 205, 310, 350, 366, 372, 373, 375], "train_al": 206, "train_i": 191, "train_predict": 188, "train_sample_weight": 189, "train_x": 190, "transform": [192, 360], "tree": [15, 16, 23, 24, 25, 26, 356, 357, 360, 362, 371], "treeshap": 332, "troubl": 107, "troubleshoot": [346, 351], "tune": [42, 43, 44, 45, 46, 48, 308, 351, 374], "two": [333, 337], "type": [325, 343, 344, 345], "umap": [3, 346], "uncertainti": 366, "underfit": 366, "unfair": 83, "uniform": [370, 371], "univari": [326, 366], "unus": 378, "upload": 353, "us": [8, 316, 371], "usag": [333, 334, 335, 336, 337, 338, 339, 374], "util": [51, 106, 303, 304, 305, 306, 307, 313, 314, 371], "valid": [89, 312, 376], "validationresult": [52, 53, 307], "valu": 322, "variabl": [57, 58, 322, 342, 355, 368, 370], "verifi": 49, "view": 8, "visual": [40, 53, 57, 58, 344, 345, 346], "wai": [333, 337], "wasserstein": 369, "waterfal": 339, "weak": [352, 366, 368, 369, 370, 371], "weakspot": [318, 320], "weight": [21, 22], "when": [38, 39, 40], "why": 371, "width": [57, 58], "workflow": [342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353], "worst": [318, 320], "wrap": [29, 30, 31, 32, 33, 34, 35, 49, 363, 376], "wrapper": [315, 376], "x": 193, "xgb": [4, 57, 58], "xgboost": [38, 61, 62, 371], "xi": 3, "y": 194, "zoo": [310, 375]}})