{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0858c6-ed32-495c-a994-29b864e1dcac",
   "metadata": {},
   "source": [
    "# Showcase 3: Pipeline Experimentation based on CaliforniaHousing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468bc68-15aa-41a2-be17-d735d4d0100d",
   "metadata": {},
   "source": [
    "## 0) Setting up Modeva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b05993-50d2-4faf-a77e-21f63f0fad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =============================================================\n",
    "## Install or update packages(recommended to run in Terminal)\n",
    "## =============================================================\n",
    "!pip show modeva\n",
    "# !pip uninstall modeva\n",
    "#!pip install modeva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda9d04-ab9d-4569-9f86-a9a123f2b3cb",
   "metadata": {},
   "source": [
    "## 1) Prepare Step Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18f18e-76c0-4a25-babe-9e5a36303394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from modeva import DataSet\n",
    "from modeva import ModelZoo\n",
    "from modeva import FactSheet\n",
    "from modeva.models import MoLGBMRegressor\n",
    "from modeva.models import MoMoERegressor\n",
    "from modeva.models.tune import ModelTuneRandomSearch\n",
    "\n",
    "from modeva.automation.pipeline import Pipeline\n",
    "\n",
    "def load_data(name, inactive_features, target_feature, task_type, test_ratio):\n",
    "    ds = DataSet(name=name)\n",
    "    ds.load(name)\n",
    "    ds.reset_preprocess()\n",
    "    ds.impute_missing()\n",
    "    ds.scale_numerical(method=\"minmax\")\n",
    "    ds.encode_categorical(method=\"ordinal\")\n",
    "    ds.preprocess()\n",
    "    ds.set_inactive_features(features=inactive_features)\n",
    "    ds.set_target(feature=target_feature)\n",
    "    ds.set_task_type(task_type)\n",
    "    ds.set_random_split(test_ratio=test_ratio)\n",
    "    return ds\n",
    "\n",
    "def train_lgbm(ds):\n",
    "    model = MoLGBMRegressor(name=\"LGBM\", max_depth=2, n_estimators=100, verbose=-1)\n",
    "    model.fit(ds.train_x, ds.train_y.ravel())\n",
    "    return model\n",
    "\n",
    "def train_moe(ds):\n",
    "    model = MoMoERegressor(name=\"MOE\", n_clusters=5, max_depth=2, n_estimators=100, verbose=-1)\n",
    "    model.fit(ds.train_x, ds.train_y.ravel())\n",
    "    return model\n",
    "\n",
    "def train_moe_tuned(ds):\n",
    "    hyperspace = dict(n_clusters=[2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "    hpo = ModelTuneRandomSearch(dataset=ds,\n",
    "                                model=MoMoERegressor(verbose=-1))\n",
    "    result = hpo.run(param_distributions=hyperspace,\n",
    "                     n_iter=10,\n",
    "                     metric=\"MSE\",\n",
    "                     cv=5,\n",
    "                     random_state=0)\n",
    "\n",
    "    best_param_idx = np.where(result.value[\"rank_test_MSE\"] == 1)[0][0]\n",
    "    model = MoMoERegressor(**result.value[\"params\"][best_param_idx],\n",
    "                           name=\"MoE-Tuned\",\n",
    "                           verbose=-1)\n",
    "    model.fit(ds.train_x, ds.train_y)\n",
    "    return model\n",
    "\n",
    "def interpret_model(ds, model):\n",
    "    fs = FactSheet(ds, model=model)\n",
    "\n",
    "    result1 = fs.interpret_fi()\n",
    "    result1.plot(figsize=(6, 4))\n",
    "\n",
    "    result2 = fs.interpret_ei()\n",
    "    result2.plot(figsize=(6.5, 4))\n",
    "\n",
    "    result3 = fs.interpret_effects(features=\"MedInc\")\n",
    "    result3.plot(figsize=(6, 4))\n",
    "\n",
    "    result4 = fs.interpret_local_fi(dataset='test', sample_index=0, centered=True)\n",
    "    result4.plot(figsize=(6, 4))\n",
    "    return result1, result2, result3, result4\n",
    "\n",
    "def explain_model(ds, model):\n",
    "    fs = FactSheet(ds, model=model)\n",
    "\n",
    "    result1 = fs.explain_pfi()\n",
    "    result1.plot(figsize=(6, 4))\n",
    "\n",
    "    result2 = fs.explain_hstatistic(sample_size=1000, grid_resolution=10)\n",
    "    result2.plot(figsize=(6, 5))\n",
    "\n",
    "    result3 = fs.explain_pdp(features=\"MedInc\")\n",
    "    result3.plot(figsize=(6, 5))\n",
    "\n",
    "    result4 = fs.explain_lime(dataset=\"test\", sample_index=0, centered=False)\n",
    "    result4.plot(figsize=(6, 4))\n",
    "    return result1, result2, result3, result4\n",
    "\n",
    "def test_model(ds, model):\n",
    "    fs = FactSheet(ds, model=model)\n",
    "\n",
    "    result1 = fs.diagnose_accuracy_table(train_dataset=\"train\", test_dataset=\"test\", metric=None)\n",
    "    print(result1.table)\n",
    "\n",
    "    result2 = fs.diagnose_robustness(dataset=\"test\", perturb_features=None, \n",
    "                                     noise_levels=(0.2, 0.4, 0.6, 0.8), metric=\"MAE\")\n",
    "    result2.plot(figsize=(6, 4))\n",
    "\n",
    "    result3 = fs.diagnose_residual_fi(method=\"uniform\")\n",
    "    result3.plot(figsize=(6, 4))\n",
    "\n",
    "    result4 = fs.diagnose_slicing_accuracy(features=((\"MedInc\",), (\"Population\", ), ), metric=\"MAE\",\n",
    "                                           method=\"quantile\", threshold=None)\n",
    "    result4.table\n",
    "    return result1, result2, result3, result4\n",
    "\n",
    "def compare_models(ds, model1, model2, model3):\n",
    "    fsc = FactSheet(ds, models=[model1, model2, model3])\n",
    "\n",
    "    result1 = fsc.compare_accuracy_table(train_dataset=\"train\", test_dataset=\"test\", metric=(\"MSE\", \"MAE\"))\n",
    "    result1.plot(figsize=(6.5, 4))\n",
    "\n",
    "    result2 = fsc.compare_robustness(noise_levels=(0.1, 0.2, 0.3, 0.4), \n",
    "                                     perturb_method=\"quantile\", metric=\"MAE\")\n",
    "    result2.plot(figsize=(6.5, 4))\n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa856968-cf70-493c-b6a4-0c5f25758455",
   "metadata": {},
   "source": [
    "## 2) Construct Pipeline with Step Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19feefb1-b43e-4d4e-b34d-96ee51c7e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Pipeline(name='CH-Pipeline')\n",
    "\n",
    "exp.add_step(\n",
    "    name='load_data',\n",
    "    func=load_data,\n",
    "    func_inputs={'name': 'CaliforniaHousing',\n",
    "                 \"target_feature\": \"MedHouseVal\",\n",
    "                 \"inactive_features\": None,\n",
    "                 \"task_type\": \"Regression\",\n",
    "                 \"test_ratio\": 0.33},\n",
    "    save_data=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    name='train_lgbm', \n",
    "    parent='load_data',\n",
    "    func=train_lgbm,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    save_model=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    name='train_moe', \n",
    "    parent='load_data',\n",
    "    func=train_moe,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    save_model=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    name='train_moe_tuned',\n",
    "    parent='load_data',\n",
    "    func=train_moe_tuned,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    save_model=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    func=interpret_model,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    name='interpret_model', parent=['load_data', 'train_lgbm'],\n",
    "    save_factsheet=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    func=explain_model,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    name='explain_model', parent=['load_data', 'train_lgbm'],\n",
    "    save_factsheet=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    func=test_model,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    name='test_model', parent=['load_data', 'train_lgbm'],\n",
    "    save_factsheet=True,\n",
    ")\n",
    "\n",
    "exp.add_step(\n",
    "    func=compare_models,\n",
    "    func_inputs={}, # auto map from parent steps\n",
    "    name='compare_model', parent=['load_data', 'train_lgbm', 'train_moe', 'train_moe_tuned'],\n",
    "    save_factsheet=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b60faf-7b94-4734-a44e-465f1006cfaa",
   "metadata": {},
   "source": [
    "## 3) Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08eeec-d86b-4231-be18-871deb282250",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43ed5b-4885-4b6b-ac7b-0d55f6e42487",
   "metadata": {},
   "source": [
    "## 3) Export Factsheet Results to HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e3521-720c-41cf-b530-735633fad964",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =============================================================\n",
    "## Factsheet-export API (to be merged to Modeva in next release)\n",
    "## =============================================================\n",
    "\n",
    "import json\n",
    "from modeva.dashboard.utils.report import create_html_reprt\n",
    "\n",
    "def export_report(fs, path: str = \"report.html\"):\n",
    "    \"\"\"Export report to html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str, optional\n",
    "        The export path, by default \"report.html\"\n",
    "    \"\"\"\n",
    "    names = fs.list_registered_tests().Name.unique().tolist()\n",
    "    rs = []\n",
    "    for name in names:\n",
    "        f = fs.load_registered_test(name=name)\n",
    "        plots = []\n",
    "        plot = f['options']\n",
    "        if plot:\n",
    "            if 'chart_id' in plot:\n",
    "                plots.append(plot)\n",
    "            else:\n",
    "                for name, option in plot.items():\n",
    "                    plots.append(option)\n",
    "        if f['table'] is not None:\n",
    "            table = f['table'].replace({float('nan'): None}).round(6).to_dict(orient=\"split\")\n",
    "        else:\n",
    "            table = {}\n",
    "        rs.append({\n",
    "            \"name\": name,\n",
    "            \"data\": json.dumps(f['data']),\n",
    "            \"model\": json.dumps(f['model']),\n",
    "            \"inputs\": json.dumps(f['inputs']),\n",
    "            \"table\": json.dumps(table),\n",
    "            \"plots\": json.dumps(plots)\n",
    "        })\n",
    "    html_str = create_html_reprt(fs.name, rs)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f4a2a-1277-473d-8ef4-0a6276673a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FactSheet(name='CH-Pipeline-FactSheet')\n",
    "export_report(fs, path=\"report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca975928-8445-4ef0-a530-1e9864032d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
